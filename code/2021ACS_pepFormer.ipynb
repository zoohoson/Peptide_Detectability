{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T14:03:22.862009Z",
     "start_time": "2021-09-19T14:03:22.068000Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import time\n",
    "import pickle\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw code\n",
    "  - paper's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T14:03:22.870184Z",
     "start_time": "2021-09-19T14:03:22.863711Z"
    }
   },
   "outputs": [],
   "source": [
    "def genData(file,max_len):\n",
    "    aa_dict={'A':1,'R':2,'N':3,'D':4,'C':5,'Q':6,'E':7,'G':8,'H':9,'I':10,\n",
    "             'L':11,'K':12,'M':13,'F':14,'P':15,'O':16,'S':17,'U':18,'T':19,\n",
    "             'W':20,'Y':21,'V':22,'X':23}\n",
    "    with open(file, 'r') as inf:\n",
    "        lines = inf.read().splitlines()\n",
    "        \n",
    "    long_pep_counter=0\n",
    "    pep_codes=[]\n",
    "    labels=[]\n",
    "    for pep in lines:\n",
    "        pep,label=pep.split(\",\")\n",
    "        labels.append(int(label))\n",
    "        if not len(pep) > max_len:\n",
    "            current_pep=[]\n",
    "            for aa in pep:\n",
    "                current_pep.append(aa_dict[aa])\n",
    "            pep_codes.append(torch.tensor(current_pep))\n",
    "        else:\n",
    "            long_pep_counter += 1\n",
    "    print(\"length > {}:\".format(max_len),long_pep_counter)\n",
    "    data = rnn_utils.pad_sequence(pep_codes, batch_first=True)  # padding\n",
    "    return data,torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T14:03:23.414769Z",
     "start_time": "2021-09-19T14:03:23.397936Z"
    }
   },
   "outputs": [],
   "source": [
    "class newModel(nn.Module):\n",
    "    def __init__(self, vocab_size=24):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 25\n",
    "        self.batch_size = 256\n",
    "        self.emb_dim = 512\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, self.emb_dim, padding_idx=0)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.gru = nn.GRU(self.emb_dim, self.hidden_dim, num_layers=2, \n",
    "                               bidirectional=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.block1=nn.Sequential(nn.Linear(4050,1024),\n",
    "                                            nn.BatchNorm1d(1024),\n",
    "                                            nn.LeakyReLU(),\n",
    "                                            nn.Linear(1024,256),\n",
    "                                 )\n",
    "\n",
    "        self.block2=nn.Sequential(\n",
    "                                               nn.BatchNorm1d(256),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(256,128),\n",
    "                                               nn.BatchNorm1d(128),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(128,64),\n",
    "                                               nn.BatchNorm1d(64),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(64,2)\n",
    "                                            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.embedding(x)\n",
    "        output=self.transformer_encoder(x).permute(1, 0, 2)\n",
    "        output,hn=self.gru(output)\n",
    "        output=output.permute(1,0,2)\n",
    "        hn=hn.permute(1,0,2)\n",
    "        output=output.reshape(output.shape[0],-1)\n",
    "        hn=hn.reshape(output.shape[0],-1)\n",
    "        output=torch.cat([output,hn],1)\n",
    "        return self.block1(output)\n",
    "\n",
    "    def trainModel(self, x):\n",
    "        with torch.no_grad():\n",
    "            output=self.forward(x)\n",
    "        return self.block2(output)\n",
    "\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # euclidean_distance: [128]\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +     # calmp夹断用法\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))     \n",
    "        \n",
    "        return loss_contrastive\n",
    "    \n",
    "    \n",
    "def collate(batch):\n",
    "    seq1_ls=[]\n",
    "    seq2_ls=[]\n",
    "    label1_ls=[]\n",
    "    label2_ls=[]\n",
    "    label_ls=[]\n",
    "    batch_size=len(batch)\n",
    "    for i in range(int(batch_size/2)):\n",
    "        seq1,label1=batch[i][0],batch[i][1]\n",
    "        seq2,label2=batch[i+int(batch_size/2)][0],batch[i+int(batch_size/2)][1]\n",
    "        label1_ls.append(label1.unsqueeze(0))\n",
    "        label2_ls.append(label2.unsqueeze(0))\n",
    "        label=(label1^label2)\n",
    "        seq1_ls.append(seq1.unsqueeze(0))\n",
    "        seq2_ls.append(seq2.unsqueeze(0))\n",
    "        label_ls.append(label.unsqueeze(0))\n",
    "    seq1=torch.cat(seq1_ls).to(device)\n",
    "    seq2=torch.cat(seq2_ls).to(device)\n",
    "    label=torch.cat(label_ls).to(device)\n",
    "    label1=torch.cat(label1_ls).to(device)\n",
    "    label2=torch.cat(label2_ls).to(device)\n",
    "    return seq1,seq2,label,label1,label2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T14:03:27.547816Z",
     "start_time": "2021-09-19T14:03:26.042840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length > 81: 0\n",
      "torch.Size([90000, 79]) torch.Size([90000])\n"
     ]
    }
   ],
   "source": [
    "data,label=genData(\"compareModel/2021ACS_PepFormer/dataset/Homo_sapiens.csv\",81)\n",
    "print(data.shape,label.shape)\n",
    "\n",
    "train_data,train_label=data[:70000],label[:70000]\n",
    "test_data,test_label=data[70000:],label[70000:]\n",
    "\n",
    "train_dataset = Data.TensorDataset(train_data, train_label)\n",
    "test_dataset = Data.TensorDataset(test_data, test_label)\n",
    "batch_size=256\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_iter_cont = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                                                  shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T14:03:32.146744Z",
     "start_time": "2021-09-19T14:03:28.586241Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newModel(\n",
      "  (embedding): Embedding(24, 512, padding_idx=0)\n",
      "  (encoder_layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (gru): GRU(512, 25, num_layers=2, dropout=0.2, bidirectional=True)\n",
      "  (block1): Sequential(\n",
      "    (0): Linear(in_features=4050, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "total param cnt : 10,864,306\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\",0)\n",
    "model = newModel().to(device)\n",
    "\n",
    "print(model)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('total param cnt : {:,}'.format(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T14:04:18.502174Z",
     "start_time": "2021-09-19T14:04:18.497624Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        acc_sum += (outputs.argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "def to_log(log):\n",
    "    with open(\"compareModel/2021ACS_PepFormer/modelLog.log\",\"a+\") as f:\n",
    "        f.write(log+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T15:17:46.989273Z",
     "start_time": "2021-09-19T14:04:19.899694Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 181.31001, loss1: 2.54977, loss2_3: 178.76024\n",
      "\ttrain_acc: 0.5275, test_acc: \u001b[31m0.5252\u001b[0m, time: 36.03\n",
      "best_acc: 0.5252\n",
      "epoch: 2, loss: 176.02166, loss1: 1.02241, loss2_3: 174.99925\n",
      "\ttrain_acc: 0.5453, test_acc: \u001b[31m0.5433\u001b[0m, time: 36.42\n",
      "best_acc: 0.5433\n",
      "epoch: 3, loss: 170.48735, loss1: 1.02546, loss2_3: 169.46189\n",
      "\ttrain_acc: 0.6366, test_acc: \u001b[31m0.63205\u001b[0m, time: 36.40\n",
      "best_acc: 0.63205\n",
      "epoch: 4, loss: 147.53434, loss1: 0.99737, loss2_3: 146.53697\n",
      "\ttrain_acc: 0.7145, test_acc: \u001b[31m0.71295\u001b[0m, time: 36.45\n",
      "best_acc: 0.71295\n",
      "epoch: 5, loss: 135.65731, loss1: 0.97018, loss2_3: 134.68713\n",
      "\ttrain_acc: 0.7490, test_acc: \u001b[31m0.74845\u001b[0m, time: 36.47\n",
      "best_acc: 0.74845\n",
      "epoch: 6, loss: 132.02680, loss1: 0.95435, loss2_3: 131.07244\n",
      "\ttrain_acc: 0.7395, test_acc: \u001b[31m0.7388\u001b[0m, time: 36.50\n",
      "epoch: 7, loss: 130.36009, loss1: 0.93608, loss2_3: 129.42402\n",
      "\ttrain_acc: 0.7538, test_acc: \u001b[31m0.75435\u001b[0m, time: 36.51\n",
      "best_acc: 0.75435\n",
      "epoch: 8, loss: 129.20100, loss1: 0.94109, loss2_3: 128.25991\n",
      "\ttrain_acc: 0.7548, test_acc: \u001b[31m0.75585\u001b[0m, time: 36.47\n",
      "best_acc: 0.75585\n",
      "epoch: 9, loss: 127.88602, loss1: 0.92789, loss2_3: 126.95813\n",
      "\ttrain_acc: 0.7707, test_acc: \u001b[31m0.7691\u001b[0m, time: 36.89\n",
      "best_acc: 0.7691\n",
      "epoch: 10, loss: 127.63268, loss1: 0.92918, loss2_3: 126.70350\n",
      "\ttrain_acc: 0.7686, test_acc: \u001b[31m0.7688\u001b[0m, time: 36.84\n",
      "epoch: 11, loss: 125.58964, loss1: 0.91140, loss2_3: 124.67825\n",
      "\ttrain_acc: 0.7755, test_acc: \u001b[31m0.7744\u001b[0m, time: 36.58\n",
      "best_acc: 0.7744\n",
      "epoch: 12, loss: 124.84084, loss1: 0.91295, loss2_3: 123.92789\n",
      "\ttrain_acc: 0.7765, test_acc: \u001b[31m0.77475\u001b[0m, time: 36.71\n",
      "best_acc: 0.77475\n",
      "epoch: 13, loss: 124.18623, loss1: 0.90344, loss2_3: 123.28280\n",
      "\ttrain_acc: 0.7760, test_acc: \u001b[31m0.77575\u001b[0m, time: 36.50\n",
      "best_acc: 0.77575\n",
      "epoch: 14, loss: 123.45140, loss1: 0.90050, loss2_3: 122.55090\n",
      "\ttrain_acc: 0.7683, test_acc: \u001b[31m0.7682\u001b[0m, time: 36.45\n",
      "epoch: 15, loss: 122.78955, loss1: 0.89722, loss2_3: 121.89233\n",
      "\ttrain_acc: 0.7782, test_acc: \u001b[31m0.77775\u001b[0m, time: 36.53\n",
      "best_acc: 0.77775\n",
      "epoch: 16, loss: 122.37934, loss1: 0.90071, loss2_3: 121.47862\n",
      "\ttrain_acc: 0.7900, test_acc: \u001b[31m0.7895\u001b[0m, time: 36.46\n",
      "best_acc: 0.7895\n",
      "epoch: 17, loss: 121.97854, loss1: 0.89539, loss2_3: 121.08315\n",
      "\ttrain_acc: 0.7821, test_acc: \u001b[31m0.7795\u001b[0m, time: 36.53\n",
      "epoch: 18, loss: 121.16777, loss1: 0.88860, loss2_3: 120.27917\n",
      "\ttrain_acc: 0.7886, test_acc: \u001b[31m0.78865\u001b[0m, time: 36.44\n",
      "epoch: 19, loss: 121.07219, loss1: 0.89311, loss2_3: 120.17908\n",
      "\ttrain_acc: 0.7688, test_acc: \u001b[31m0.76935\u001b[0m, time: 36.49\n",
      "epoch: 20, loss: 121.17495, loss1: 0.88555, loss2_3: 120.28940\n",
      "\ttrain_acc: 0.7835, test_acc: \u001b[31m0.78435\u001b[0m, time: 36.46\n",
      "epoch: 21, loss: 120.75244, loss1: 0.88544, loss2_3: 119.86700\n",
      "\ttrain_acc: 0.7850, test_acc: \u001b[31m0.7881\u001b[0m, time: 36.58\n",
      "epoch: 22, loss: 120.57096, loss1: 0.87981, loss2_3: 119.69115\n",
      "\ttrain_acc: 0.7875, test_acc: \u001b[31m0.78765\u001b[0m, time: 36.76\n",
      "epoch: 23, loss: 120.97152, loss1: 0.88354, loss2_3: 120.08797\n",
      "\ttrain_acc: 0.7861, test_acc: \u001b[31m0.78575\u001b[0m, time: 36.49\n",
      "epoch: 24, loss: 120.15891, loss1: 0.88219, loss2_3: 119.27672\n",
      "\ttrain_acc: 0.7918, test_acc: \u001b[31m0.79235\u001b[0m, time: 36.41\n",
      "best_acc: 0.79235\n",
      "epoch: 25, loss: 119.79850, loss1: 0.88039, loss2_3: 118.91812\n",
      "\ttrain_acc: 0.7875, test_acc: \u001b[31m0.78885\u001b[0m, time: 36.50\n",
      "epoch: 26, loss: 119.52728, loss1: 0.87262, loss2_3: 118.65466\n",
      "\ttrain_acc: 0.7934, test_acc: \u001b[31m0.79085\u001b[0m, time: 36.42\n",
      "epoch: 27, loss: 119.41545, loss1: 0.87373, loss2_3: 118.54171\n",
      "\ttrain_acc: 0.7957, test_acc: \u001b[31m0.79355\u001b[0m, time: 36.60\n",
      "best_acc: 0.79355\n",
      "epoch: 28, loss: 119.65605, loss1: 0.87260, loss2_3: 118.78345\n",
      "\ttrain_acc: 0.7905, test_acc: \u001b[31m0.79025\u001b[0m, time: 36.46\n",
      "epoch: 29, loss: 119.41327, loss1: 0.87612, loss2_3: 118.53715\n",
      "\ttrain_acc: 0.7955, test_acc: \u001b[31m0.79535\u001b[0m, time: 36.61\n",
      "best_acc: 0.79535\n",
      "epoch: 30, loss: 119.23578, loss1: 0.86825, loss2_3: 118.36753\n",
      "\ttrain_acc: 0.7954, test_acc: \u001b[31m0.79515\u001b[0m, time: 36.81\n",
      "epoch: 31, loss: 118.90040, loss1: 0.86991, loss2_3: 118.03049\n",
      "\ttrain_acc: 0.7928, test_acc: \u001b[31m0.79145\u001b[0m, time: 37.00\n",
      "epoch: 32, loss: 119.09740, loss1: 0.87360, loss2_3: 118.22380\n",
      "\ttrain_acc: 0.7939, test_acc: \u001b[31m0.7937\u001b[0m, time: 36.49\n",
      "epoch: 33, loss: 118.56883, loss1: 0.87217, loss2_3: 117.69665\n",
      "\ttrain_acc: 0.7896, test_acc: \u001b[31m0.7903\u001b[0m, time: 36.46\n",
      "epoch: 34, loss: 118.52638, loss1: 0.86953, loss2_3: 117.65686\n",
      "\ttrain_acc: 0.7961, test_acc: \u001b[31m0.79395\u001b[0m, time: 36.39\n",
      "epoch: 35, loss: 118.20234, loss1: 0.86537, loss2_3: 117.33698\n",
      "\ttrain_acc: 0.7926, test_acc: \u001b[31m0.7923\u001b[0m, time: 36.44\n",
      "epoch: 36, loss: 118.58969, loss1: 0.86455, loss2_3: 117.72514\n",
      "\ttrain_acc: 0.7959, test_acc: \u001b[31m0.7938\u001b[0m, time: 36.40\n",
      "epoch: 37, loss: 118.20032, loss1: 0.86383, loss2_3: 117.33649\n",
      "\ttrain_acc: 0.7958, test_acc: \u001b[31m0.79375\u001b[0m, time: 36.41\n",
      "epoch: 38, loss: 117.91574, loss1: 0.86810, loss2_3: 117.04764\n",
      "\ttrain_acc: 0.7965, test_acc: \u001b[31m0.7951\u001b[0m, time: 36.40\n",
      "epoch: 39, loss: 118.38684, loss1: 0.86931, loss2_3: 117.51752\n",
      "\ttrain_acc: 0.7972, test_acc: \u001b[31m0.79815\u001b[0m, time: 36.40\n",
      "best_acc: 0.79815\n",
      "epoch: 40, loss: 117.50291, loss1: 0.85602, loss2_3: 116.64690\n",
      "\ttrain_acc: 0.7942, test_acc: \u001b[31m0.79195\u001b[0m, time: 36.41\n",
      "epoch: 41, loss: 117.45798, loss1: 0.86161, loss2_3: 116.59637\n",
      "\ttrain_acc: 0.7957, test_acc: \u001b[31m0.79545\u001b[0m, time: 36.45\n",
      "epoch: 42, loss: 117.51880, loss1: 0.85783, loss2_3: 116.66097\n",
      "\ttrain_acc: 0.7982, test_acc: \u001b[31m0.79515\u001b[0m, time: 36.45\n",
      "epoch: 43, loss: 117.56542, loss1: 0.86268, loss2_3: 116.70274\n",
      "\ttrain_acc: 0.7992, test_acc: \u001b[31m0.79685\u001b[0m, time: 36.41\n",
      "epoch: 44, loss: 117.55692, loss1: 0.85643, loss2_3: 116.70049\n",
      "\ttrain_acc: 0.7953, test_acc: \u001b[31m0.7924\u001b[0m, time: 36.46\n",
      "epoch: 45, loss: 117.49883, loss1: 0.85923, loss2_3: 116.63961\n",
      "\ttrain_acc: 0.7998, test_acc: \u001b[31m0.798\u001b[0m, time: 36.39\n",
      "epoch: 46, loss: 117.01920, loss1: 0.85792, loss2_3: 116.16127\n",
      "\ttrain_acc: 0.7965, test_acc: \u001b[31m0.79615\u001b[0m, time: 36.42\n",
      "epoch: 47, loss: 116.97179, loss1: 0.85730, loss2_3: 116.11450\n",
      "\ttrain_acc: 0.8000, test_acc: \u001b[31m0.7976\u001b[0m, time: 36.41\n",
      "epoch: 48, loss: 116.89632, loss1: 0.85851, loss2_3: 116.03780\n",
      "\ttrain_acc: 0.7995, test_acc: \u001b[31m0.7975\u001b[0m, time: 36.40\n",
      "epoch: 49, loss: 116.67313, loss1: 0.85898, loss2_3: 115.81415\n",
      "\ttrain_acc: 0.7972, test_acc: \u001b[31m0.7949\u001b[0m, time: 36.38\n",
      "epoch: 50, loss: 116.90813, loss1: 0.85766, loss2_3: 116.05047\n",
      "\ttrain_acc: 0.7978, test_acc: \u001b[31m0.79485\u001b[0m, time: 36.42\n",
      "epoch: 51, loss: 117.15653, loss1: 0.85829, loss2_3: 116.29825\n",
      "\ttrain_acc: 0.7904, test_acc: \u001b[31m0.7892\u001b[0m, time: 36.36\n",
      "epoch: 52, loss: 116.81628, loss1: 0.85802, loss2_3: 115.95827\n",
      "\ttrain_acc: 0.7965, test_acc: \u001b[31m0.7947\u001b[0m, time: 36.42\n",
      "epoch: 53, loss: 116.29008, loss1: 0.84646, loss2_3: 115.44363\n",
      "\ttrain_acc: 0.8007, test_acc: \u001b[31m0.79735\u001b[0m, time: 36.37\n",
      "epoch: 54, loss: 116.29158, loss1: 0.85184, loss2_3: 115.43974\n",
      "\ttrain_acc: 0.7986, test_acc: \u001b[31m0.79695\u001b[0m, time: 36.39\n",
      "epoch: 55, loss: 116.21945, loss1: 0.85219, loss2_3: 115.36727\n",
      "\ttrain_acc: 0.7985, test_acc: \u001b[31m0.7968\u001b[0m, time: 36.36\n",
      "epoch: 56, loss: 115.91954, loss1: 0.84921, loss2_3: 115.07033\n",
      "\ttrain_acc: 0.8021, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.33\n",
      "best_acc: 0.80015\n",
      "epoch: 57, loss: 115.83059, loss1: 0.84852, loss2_3: 114.98208\n",
      "\ttrain_acc: 0.8013, test_acc: \u001b[31m0.7986\u001b[0m, time: 36.37\n",
      "epoch: 58, loss: 115.97863, loss1: 0.84883, loss2_3: 115.12980\n",
      "\ttrain_acc: 0.8018, test_acc: \u001b[31m0.79925\u001b[0m, time: 36.32\n",
      "epoch: 59, loss: 116.38829, loss1: 0.84846, loss2_3: 115.53983\n",
      "\ttrain_acc: 0.7995, test_acc: \u001b[31m0.79745\u001b[0m, time: 36.32\n",
      "epoch: 60, loss: 115.53003, loss1: 0.85022, loss2_3: 114.67981\n",
      "\ttrain_acc: 0.8012, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.36\n",
      "epoch: 61, loss: 115.94014, loss1: 0.84444, loss2_3: 115.09571\n",
      "\ttrain_acc: 0.7997, test_acc: \u001b[31m0.7971\u001b[0m, time: 36.54\n",
      "epoch: 62, loss: 115.91227, loss1: 0.84916, loss2_3: 115.06311\n",
      "\ttrain_acc: 0.8007, test_acc: \u001b[31m0.79895\u001b[0m, time: 37.28\n",
      "epoch: 63, loss: 115.55541, loss1: 0.84753, loss2_3: 114.70788\n",
      "\ttrain_acc: 0.8031, test_acc: \u001b[31m0.7983\u001b[0m, time: 36.85\n",
      "epoch: 64, loss: 115.00907, loss1: 0.84845, loss2_3: 114.16062\n",
      "\ttrain_acc: 0.8001, test_acc: \u001b[31m0.7957\u001b[0m, time: 36.33\n",
      "epoch: 65, loss: 115.28960, loss1: 0.84677, loss2_3: 114.44283\n",
      "\ttrain_acc: 0.7966, test_acc: \u001b[31m0.79295\u001b[0m, time: 36.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66, loss: 115.37742, loss1: 0.84335, loss2_3: 114.53408\n",
      "\ttrain_acc: 0.8020, test_acc: \u001b[31m0.7991\u001b[0m, time: 36.34\n",
      "epoch: 67, loss: 115.33950, loss1: 0.84454, loss2_3: 114.49496\n",
      "\ttrain_acc: 0.8012, test_acc: \u001b[31m0.7983\u001b[0m, time: 36.27\n",
      "epoch: 68, loss: 115.33733, loss1: 0.84454, loss2_3: 114.49279\n",
      "\ttrain_acc: 0.8030, test_acc: \u001b[31m0.7986\u001b[0m, time: 36.35\n",
      "epoch: 69, loss: 115.23097, loss1: 0.83745, loss2_3: 114.39352\n",
      "\ttrain_acc: 0.8020, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.26\n",
      "epoch: 70, loss: 115.06869, loss1: 0.84343, loss2_3: 114.22526\n",
      "\ttrain_acc: 0.8014, test_acc: \u001b[31m0.79935\u001b[0m, time: 36.32\n",
      "epoch: 71, loss: 114.86291, loss1: 0.83919, loss2_3: 114.02372\n",
      "\ttrain_acc: 0.8038, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.39\n",
      "best_acc: 0.8007\n",
      "epoch: 72, loss: 115.07691, loss1: 0.83774, loss2_3: 114.23917\n",
      "\ttrain_acc: 0.7967, test_acc: \u001b[31m0.7926\u001b[0m, time: 36.62\n",
      "epoch: 73, loss: 114.43407, loss1: 0.84365, loss2_3: 113.59042\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.8016\u001b[0m, time: 36.60\n",
      "best_acc: 0.8016\n",
      "epoch: 74, loss: 114.65314, loss1: 0.84187, loss2_3: 113.81127\n",
      "\ttrain_acc: 0.8034, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.60\n",
      "epoch: 75, loss: 114.82326, loss1: 0.84177, loss2_3: 113.98149\n",
      "\ttrain_acc: 0.8019, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.65\n",
      "epoch: 76, loss: 114.70247, loss1: 0.83662, loss2_3: 113.86585\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.8011\u001b[0m, time: 36.62\n",
      "epoch: 77, loss: 114.49194, loss1: 0.84178, loss2_3: 113.65016\n",
      "\ttrain_acc: 0.8049, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.64\n",
      "epoch: 78, loss: 114.55579, loss1: 0.84011, loss2_3: 113.71568\n",
      "\ttrain_acc: 0.8023, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.60\n",
      "epoch: 79, loss: 114.43322, loss1: 0.83665, loss2_3: 113.59657\n",
      "\ttrain_acc: 0.8041, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.68\n",
      "epoch: 80, loss: 114.17483, loss1: 0.83232, loss2_3: 113.34252\n",
      "\ttrain_acc: 0.8007, test_acc: \u001b[31m0.7959\u001b[0m, time: 36.62\n",
      "epoch: 81, loss: 114.40929, loss1: 0.83538, loss2_3: 113.57390\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.8011\u001b[0m, time: 37.00\n",
      "epoch: 82, loss: 113.98378, loss1: 0.83572, loss2_3: 113.14807\n",
      "\ttrain_acc: 0.8028, test_acc: \u001b[31m0.79825\u001b[0m, time: 37.35\n",
      "epoch: 83, loss: 114.04516, loss1: 0.83768, loss2_3: 113.20748\n",
      "\ttrain_acc: 0.8068, test_acc: \u001b[31m0.80185\u001b[0m, time: 37.32\n",
      "best_acc: 0.80185\n",
      "epoch: 84, loss: 113.64787, loss1: 0.83102, loss2_3: 112.81686\n",
      "\ttrain_acc: 0.8047, test_acc: \u001b[31m0.8003\u001b[0m, time: 37.34\n",
      "epoch: 85, loss: 114.20907, loss1: 0.83763, loss2_3: 113.37144\n",
      "\ttrain_acc: 0.8054, test_acc: \u001b[31m0.8004\u001b[0m, time: 37.33\n",
      "epoch: 86, loss: 113.70160, loss1: 0.84079, loss2_3: 112.86080\n",
      "\ttrain_acc: 0.8065, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.38\n",
      "epoch: 87, loss: 113.79506, loss1: 0.83038, loss2_3: 112.96468\n",
      "\ttrain_acc: 0.8045, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.30\n",
      "epoch: 88, loss: 113.92085, loss1: 0.83123, loss2_3: 113.08962\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.29\n",
      "epoch: 89, loss: 113.63004, loss1: 0.83120, loss2_3: 112.79884\n",
      "\ttrain_acc: 0.8059, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.31\n",
      "epoch: 90, loss: 113.78842, loss1: 0.83038, loss2_3: 112.95804\n",
      "\ttrain_acc: 0.8054, test_acc: \u001b[31m0.8025\u001b[0m, time: 36.28\n",
      "best_acc: 0.8025\n",
      "epoch: 91, loss: 113.59988, loss1: 0.82956, loss2_3: 112.77032\n",
      "\ttrain_acc: 0.8047, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.30\n",
      "epoch: 92, loss: 113.63655, loss1: 0.83073, loss2_3: 112.80583\n",
      "\ttrain_acc: 0.8067, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.33\n",
      "epoch: 93, loss: 113.34774, loss1: 0.83474, loss2_3: 112.51300\n",
      "\ttrain_acc: 0.8065, test_acc: \u001b[31m0.8018\u001b[0m, time: 36.31\n",
      "epoch: 94, loss: 113.56210, loss1: 0.82764, loss2_3: 112.73446\n",
      "\ttrain_acc: 0.8069, test_acc: \u001b[31m0.8031\u001b[0m, time: 36.33\n",
      "best_acc: 0.8031\n",
      "epoch: 95, loss: 113.37189, loss1: 0.82795, loss2_3: 112.54393\n",
      "\ttrain_acc: 0.8047, test_acc: \u001b[31m0.79865\u001b[0m, time: 36.34\n",
      "epoch: 96, loss: 113.20430, loss1: 0.83053, loss2_3: 112.37377\n",
      "\ttrain_acc: 0.8067, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.30\n",
      "epoch: 97, loss: 113.47457, loss1: 0.83553, loss2_3: 112.63904\n",
      "\ttrain_acc: 0.8065, test_acc: \u001b[31m0.80245\u001b[0m, time: 36.32\n",
      "epoch: 98, loss: 113.04596, loss1: 0.83317, loss2_3: 112.21279\n",
      "\ttrain_acc: 0.8047, test_acc: \u001b[31m0.8001\u001b[0m, time: 36.33\n",
      "epoch: 99, loss: 113.11401, loss1: 0.82903, loss2_3: 112.28498\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.31\n",
      "epoch: 100, loss: 112.79576, loss1: 0.82512, loss2_3: 111.97064\n",
      "\ttrain_acc: 0.8022, test_acc: \u001b[31m0.7973\u001b[0m, time: 36.31\n",
      "epoch: 101, loss: 112.99801, loss1: 0.83143, loss2_3: 112.16658\n",
      "\ttrain_acc: 0.8063, test_acc: \u001b[31m0.8029\u001b[0m, time: 36.30\n",
      "epoch: 102, loss: 112.93797, loss1: 0.82748, loss2_3: 112.11049\n",
      "\ttrain_acc: 0.8050, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.33\n",
      "epoch: 103, loss: 112.78694, loss1: 0.82592, loss2_3: 111.96102\n",
      "\ttrain_acc: 0.8072, test_acc: \u001b[31m0.8031\u001b[0m, time: 36.28\n",
      "epoch: 104, loss: 112.62252, loss1: 0.82892, loss2_3: 111.79361\n",
      "\ttrain_acc: 0.8074, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.29\n",
      "epoch: 105, loss: 112.70305, loss1: 0.82757, loss2_3: 111.87549\n",
      "\ttrain_acc: 0.8078, test_acc: \u001b[31m0.80345\u001b[0m, time: 36.33\n",
      "best_acc: 0.80345\n",
      "epoch: 106, loss: 112.59056, loss1: 0.82525, loss2_3: 111.76531\n",
      "\ttrain_acc: 0.8077, test_acc: \u001b[31m0.8004\u001b[0m, time: 36.30\n",
      "epoch: 107, loss: 112.53220, loss1: 0.82426, loss2_3: 111.70794\n",
      "\ttrain_acc: 0.8084, test_acc: \u001b[31m0.8037\u001b[0m, time: 36.34\n",
      "best_acc: 0.8037\n",
      "epoch: 108, loss: 112.58734, loss1: 0.82596, loss2_3: 111.76138\n",
      "\ttrain_acc: 0.8087, test_acc: \u001b[31m0.80285\u001b[0m, time: 36.33\n",
      "epoch: 109, loss: 112.32661, loss1: 0.82051, loss2_3: 111.50611\n",
      "\ttrain_acc: 0.8087, test_acc: \u001b[31m0.8029\u001b[0m, time: 36.31\n",
      "epoch: 110, loss: 112.13980, loss1: 0.82241, loss2_3: 111.31738\n",
      "\ttrain_acc: 0.8073, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.32\n",
      "epoch: 111, loss: 112.12280, loss1: 0.82293, loss2_3: 111.29987\n",
      "\ttrain_acc: 0.8076, test_acc: \u001b[31m0.8018\u001b[0m, time: 36.31\n",
      "epoch: 112, loss: 112.34406, loss1: 0.82210, loss2_3: 111.52196\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.7984\u001b[0m, time: 36.30\n",
      "epoch: 113, loss: 111.91954, loss1: 0.81682, loss2_3: 111.10273\n",
      "\ttrain_acc: 0.8098, test_acc: \u001b[31m0.801\u001b[0m, time: 36.30\n",
      "epoch: 114, loss: 111.70959, loss1: 0.82027, loss2_3: 110.88932\n",
      "\ttrain_acc: 0.8066, test_acc: \u001b[31m0.8018\u001b[0m, time: 36.30\n",
      "epoch: 115, loss: 111.95014, loss1: 0.82187, loss2_3: 111.12827\n",
      "\ttrain_acc: 0.8080, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.31\n",
      "epoch: 116, loss: 111.58239, loss1: 0.82119, loss2_3: 110.76120\n",
      "\ttrain_acc: 0.8101, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.32\n",
      "epoch: 117, loss: 111.64904, loss1: 0.81787, loss2_3: 110.83118\n",
      "\ttrain_acc: 0.8091, test_acc: \u001b[31m0.7997\u001b[0m, time: 36.32\n",
      "epoch: 118, loss: 111.57469, loss1: 0.82606, loss2_3: 110.74863\n",
      "\ttrain_acc: 0.8104, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.34\n",
      "epoch: 119, loss: 111.46542, loss1: 0.82369, loss2_3: 110.64174\n",
      "\ttrain_acc: 0.8103, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.31\n",
      "epoch: 120, loss: 111.25968, loss1: 0.82464, loss2_3: 110.43504\n",
      "\ttrain_acc: 0.8088, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.31\n",
      "epoch: 121, loss: 111.32608, loss1: 0.81598, loss2_3: 110.51011\n",
      "\ttrain_acc: 0.8102, test_acc: \u001b[31m0.80205\u001b[0m, time: 36.32\n",
      "epoch: 122, loss: 111.25651, loss1: 0.82113, loss2_3: 110.43538\n",
      "\ttrain_acc: 0.8104, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.30\n",
      "epoch: 123, loss: 111.34843, loss1: 0.82245, loss2_3: 110.52599\n",
      "\ttrain_acc: 0.8082, test_acc: \u001b[31m0.8\u001b[0m, time: 36.28\n",
      "epoch: 124, loss: 111.10788, loss1: 0.81551, loss2_3: 110.29237\n",
      "\ttrain_acc: 0.8114, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.32\n",
      "epoch: 125, loss: 110.99907, loss1: 0.81609, loss2_3: 110.18298\n",
      "\ttrain_acc: 0.8070, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.29\n",
      "epoch: 126, loss: 110.77493, loss1: 0.81754, loss2_3: 109.95739\n",
      "\ttrain_acc: 0.8111, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.30\n",
      "epoch: 127, loss: 110.66166, loss1: 0.81505, loss2_3: 109.84662\n",
      "\ttrain_acc: 0.8117, test_acc: \u001b[31m0.8\u001b[0m, time: 36.32\n",
      "epoch: 128, loss: 110.66898, loss1: 0.82118, loss2_3: 109.84780\n",
      "\ttrain_acc: 0.8063, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.30\n",
      "epoch: 129, loss: 110.69184, loss1: 0.81495, loss2_3: 109.87689\n",
      "\ttrain_acc: 0.8065, test_acc: \u001b[31m0.7992\u001b[0m, time: 36.33\n",
      "epoch: 130, loss: 110.52250, loss1: 0.81688, loss2_3: 109.70562\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.32\n",
      "epoch: 131, loss: 110.46977, loss1: 0.81034, loss2_3: 109.65943\n",
      "\ttrain_acc: 0.8115, test_acc: \u001b[31m0.8018\u001b[0m, time: 36.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 132, loss: 110.29523, loss1: 0.81712, loss2_3: 109.47811\n",
      "\ttrain_acc: 0.8137, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.34\n",
      "epoch: 133, loss: 110.22239, loss1: 0.81547, loss2_3: 109.40693\n",
      "\ttrain_acc: 0.8133, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.28\n",
      "epoch: 134, loss: 109.97700, loss1: 0.81109, loss2_3: 109.16591\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.29\n",
      "epoch: 135, loss: 109.94794, loss1: 0.81106, loss2_3: 109.13688\n",
      "\ttrain_acc: 0.8128, test_acc: \u001b[31m0.80285\u001b[0m, time: 36.30\n",
      "epoch: 136, loss: 109.86472, loss1: 0.81372, loss2_3: 109.05100\n",
      "\ttrain_acc: 0.8110, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.27\n",
      "epoch: 137, loss: 109.58782, loss1: 0.81357, loss2_3: 108.77425\n",
      "\ttrain_acc: 0.8140, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.29\n",
      "epoch: 138, loss: 109.68763, loss1: 0.81622, loss2_3: 108.87141\n",
      "\ttrain_acc: 0.8115, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.27\n",
      "epoch: 139, loss: 109.67825, loss1: 0.81371, loss2_3: 108.86454\n",
      "\ttrain_acc: 0.8072, test_acc: \u001b[31m0.79225\u001b[0m, time: 36.30\n",
      "epoch: 140, loss: 109.72257, loss1: 0.81342, loss2_3: 108.90915\n",
      "\ttrain_acc: 0.8157, test_acc: \u001b[31m0.801\u001b[0m, time: 36.29\n",
      "epoch: 141, loss: 109.46767, loss1: 0.81403, loss2_3: 108.65364\n",
      "\ttrain_acc: 0.8120, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.28\n",
      "epoch: 142, loss: 109.40603, loss1: 0.80902, loss2_3: 108.59701\n",
      "\ttrain_acc: 0.8149, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.26\n",
      "epoch: 143, loss: 109.21300, loss1: 0.80572, loss2_3: 108.40728\n",
      "\ttrain_acc: 0.8144, test_acc: \u001b[31m0.8012\u001b[0m, time: 36.28\n",
      "epoch: 144, loss: 109.14558, loss1: 0.80978, loss2_3: 108.33581\n",
      "\ttrain_acc: 0.8103, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.28\n",
      "epoch: 145, loss: 109.08898, loss1: 0.81051, loss2_3: 108.27848\n",
      "\ttrain_acc: 0.8112, test_acc: \u001b[31m0.7988\u001b[0m, time: 36.26\n",
      "epoch: 146, loss: 109.09110, loss1: 0.80790, loss2_3: 108.28320\n",
      "\ttrain_acc: 0.8147, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.29\n",
      "epoch: 147, loss: 108.92953, loss1: 0.80716, loss2_3: 108.12237\n",
      "\ttrain_acc: 0.8153, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.26\n",
      "epoch: 148, loss: 108.82692, loss1: 0.81235, loss2_3: 108.01457\n",
      "\ttrain_acc: 0.8168, test_acc: \u001b[31m0.8029\u001b[0m, time: 36.29\n",
      "epoch: 149, loss: 108.82113, loss1: 0.80272, loss2_3: 108.01841\n",
      "\ttrain_acc: 0.8170, test_acc: \u001b[31m0.8025\u001b[0m, time: 36.27\n",
      "epoch: 150, loss: 108.28112, loss1: 0.80897, loss2_3: 107.47215\n",
      "\ttrain_acc: 0.8174, test_acc: \u001b[31m0.80075\u001b[0m, time: 36.28\n",
      "epoch: 151, loss: 108.60531, loss1: 0.80911, loss2_3: 107.79620\n",
      "\ttrain_acc: 0.8168, test_acc: \u001b[31m0.8037\u001b[0m, time: 36.31\n",
      "epoch: 152, loss: 108.66368, loss1: 0.81144, loss2_3: 107.85223\n",
      "\ttrain_acc: 0.8157, test_acc: \u001b[31m0.8001\u001b[0m, time: 36.26\n",
      "epoch: 153, loss: 108.28321, loss1: 0.80699, loss2_3: 107.47622\n",
      "\ttrain_acc: 0.8185, test_acc: \u001b[31m0.80345\u001b[0m, time: 36.32\n",
      "epoch: 154, loss: 107.94312, loss1: 0.80979, loss2_3: 107.13332\n",
      "\ttrain_acc: 0.8178, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.26\n",
      "epoch: 155, loss: 108.10613, loss1: 0.80439, loss2_3: 107.30174\n",
      "\ttrain_acc: 0.8185, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.27\n",
      "epoch: 156, loss: 107.99894, loss1: 0.80981, loss2_3: 107.18914\n",
      "\ttrain_acc: 0.8169, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.27\n",
      "epoch: 157, loss: 107.79435, loss1: 0.80848, loss2_3: 106.98586\n",
      "\ttrain_acc: 0.8138, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.27\n",
      "epoch: 158, loss: 107.44205, loss1: 0.80094, loss2_3: 106.64111\n",
      "\ttrain_acc: 0.8148, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.26\n",
      "epoch: 159, loss: 107.54165, loss1: 0.80738, loss2_3: 106.73427\n",
      "\ttrain_acc: 0.8136, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.31\n",
      "epoch: 160, loss: 107.27495, loss1: 0.80567, loss2_3: 106.46929\n",
      "\ttrain_acc: 0.8199, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.29\n",
      "epoch: 161, loss: 107.40962, loss1: 0.81005, loss2_3: 106.59958\n",
      "\ttrain_acc: 0.8185, test_acc: \u001b[31m0.80335\u001b[0m, time: 36.31\n",
      "epoch: 162, loss: 107.18320, loss1: 0.80630, loss2_3: 106.37689\n",
      "\ttrain_acc: 0.8168, test_acc: \u001b[31m0.80075\u001b[0m, time: 36.30\n",
      "epoch: 163, loss: 107.24086, loss1: 0.80424, loss2_3: 106.43662\n",
      "\ttrain_acc: 0.8198, test_acc: \u001b[31m0.80085\u001b[0m, time: 36.30\n",
      "epoch: 164, loss: 107.12566, loss1: 0.80098, loss2_3: 106.32468\n",
      "\ttrain_acc: 0.8151, test_acc: \u001b[31m0.79725\u001b[0m, time: 36.29\n",
      "epoch: 165, loss: 107.44881, loss1: 0.80393, loss2_3: 106.64488\n",
      "\ttrain_acc: 0.8194, test_acc: \u001b[31m0.7975\u001b[0m, time: 36.28\n",
      "epoch: 166, loss: 107.18608, loss1: 0.80321, loss2_3: 106.38287\n",
      "\ttrain_acc: 0.8205, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.26\n",
      "epoch: 167, loss: 106.68879, loss1: 0.80310, loss2_3: 105.88568\n",
      "\ttrain_acc: 0.8221, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.26\n",
      "epoch: 168, loss: 106.66275, loss1: 0.80084, loss2_3: 105.86191\n",
      "\ttrain_acc: 0.8185, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.25\n",
      "epoch: 169, loss: 106.54036, loss1: 0.79905, loss2_3: 105.74131\n",
      "\ttrain_acc: 0.8136, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.29\n",
      "epoch: 170, loss: 106.44841, loss1: 0.80113, loss2_3: 105.64728\n",
      "\ttrain_acc: 0.8203, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.28\n",
      "epoch: 171, loss: 106.46459, loss1: 0.79606, loss2_3: 105.66853\n",
      "\ttrain_acc: 0.8208, test_acc: \u001b[31m0.79495\u001b[0m, time: 36.29\n",
      "epoch: 172, loss: 106.30692, loss1: 0.80181, loss2_3: 105.50511\n",
      "\ttrain_acc: 0.8239, test_acc: \u001b[31m0.79525\u001b[0m, time: 36.31\n",
      "epoch: 173, loss: 106.06937, loss1: 0.80208, loss2_3: 105.26729\n",
      "\ttrain_acc: 0.8124, test_acc: \u001b[31m0.79535\u001b[0m, time: 36.30\n",
      "epoch: 174, loss: 105.93835, loss1: 0.80662, loss2_3: 105.13172\n",
      "\ttrain_acc: 0.8243, test_acc: \u001b[31m0.798\u001b[0m, time: 36.28\n",
      "epoch: 175, loss: 106.16327, loss1: 0.80029, loss2_3: 105.36298\n",
      "\ttrain_acc: 0.8207, test_acc: \u001b[31m0.79735\u001b[0m, time: 36.32\n",
      "epoch: 176, loss: 105.83288, loss1: 0.79803, loss2_3: 105.03485\n",
      "\ttrain_acc: 0.8252, test_acc: \u001b[31m0.79685\u001b[0m, time: 36.27\n",
      "epoch: 177, loss: 105.57445, loss1: 0.79896, loss2_3: 104.77549\n",
      "\ttrain_acc: 0.8218, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.27\n",
      "epoch: 178, loss: 105.26314, loss1: 0.79921, loss2_3: 104.46393\n",
      "\ttrain_acc: 0.8249, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.30\n",
      "epoch: 179, loss: 105.36115, loss1: 0.79812, loss2_3: 104.56303\n",
      "\ttrain_acc: 0.8149, test_acc: \u001b[31m0.79555\u001b[0m, time: 36.27\n",
      "epoch: 180, loss: 105.21630, loss1: 0.80198, loss2_3: 104.41431\n",
      "\ttrain_acc: 0.8253, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.28\n",
      "epoch: 181, loss: 104.98358, loss1: 0.80062, loss2_3: 104.18296\n",
      "\ttrain_acc: 0.8105, test_acc: \u001b[31m0.7961\u001b[0m, time: 36.25\n",
      "epoch: 182, loss: 104.90291, loss1: 0.79380, loss2_3: 104.10911\n",
      "\ttrain_acc: 0.8221, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.30\n",
      "epoch: 183, loss: 104.56948, loss1: 0.79860, loss2_3: 103.77088\n",
      "\ttrain_acc: 0.8243, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.26\n",
      "epoch: 184, loss: 104.92306, loss1: 0.79666, loss2_3: 104.12639\n",
      "\ttrain_acc: 0.8264, test_acc: \u001b[31m0.79655\u001b[0m, time: 36.28\n",
      "epoch: 185, loss: 104.73993, loss1: 0.79638, loss2_3: 103.94355\n",
      "\ttrain_acc: 0.8261, test_acc: \u001b[31m0.79795\u001b[0m, time: 36.29\n",
      "epoch: 186, loss: 104.25788, loss1: 0.79407, loss2_3: 103.46381\n",
      "\ttrain_acc: 0.8248, test_acc: \u001b[31m0.7922\u001b[0m, time: 36.29\n",
      "epoch: 187, loss: 104.29316, loss1: 0.79599, loss2_3: 103.49716\n",
      "\ttrain_acc: 0.8296, test_acc: \u001b[31m0.7983\u001b[0m, time: 36.27\n",
      "epoch: 188, loss: 103.99591, loss1: 0.79101, loss2_3: 103.20490\n",
      "\ttrain_acc: 0.8172, test_acc: \u001b[31m0.79545\u001b[0m, time: 36.30\n",
      "epoch: 189, loss: 103.69955, loss1: 0.79318, loss2_3: 102.90638\n",
      "\ttrain_acc: 0.8274, test_acc: \u001b[31m0.7959\u001b[0m, time: 36.27\n",
      "epoch: 190, loss: 103.65818, loss1: 0.79174, loss2_3: 102.86644\n",
      "\ttrain_acc: 0.8278, test_acc: \u001b[31m0.795\u001b[0m, time: 36.28\n",
      "epoch: 191, loss: 103.98043, loss1: 0.79170, loss2_3: 103.18872\n",
      "\ttrain_acc: 0.8306, test_acc: \u001b[31m0.7977\u001b[0m, time: 36.28\n",
      "epoch: 192, loss: 103.89176, loss1: 0.79354, loss2_3: 103.09821\n",
      "\ttrain_acc: 0.8293, test_acc: \u001b[31m0.798\u001b[0m, time: 36.25\n",
      "epoch: 193, loss: 103.49677, loss1: 0.79090, loss2_3: 102.70587\n",
      "\ttrain_acc: 0.8283, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.27\n",
      "epoch: 194, loss: 103.25753, loss1: 0.78701, loss2_3: 102.47052\n",
      "\ttrain_acc: 0.8296, test_acc: \u001b[31m0.79535\u001b[0m, time: 36.27\n",
      "epoch: 195, loss: 103.28131, loss1: 0.79007, loss2_3: 102.49124\n",
      "\ttrain_acc: 0.8301, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.25\n",
      "epoch: 196, loss: 102.84364, loss1: 0.79028, loss2_3: 102.05336\n",
      "\ttrain_acc: 0.8316, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.27\n",
      "epoch: 197, loss: 102.94135, loss1: 0.78698, loss2_3: 102.15437\n",
      "\ttrain_acc: 0.8314, test_acc: \u001b[31m0.80135\u001b[0m, time: 36.24\n",
      "epoch: 198, loss: 102.80206, loss1: 0.79058, loss2_3: 102.01148\n",
      "\ttrain_acc: 0.8296, test_acc: \u001b[31m0.8025\u001b[0m, time: 36.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 199, loss: 102.63043, loss1: 0.78510, loss2_3: 101.84533\n",
      "\ttrain_acc: 0.8308, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.26\n",
      "epoch: 200, loss: 102.53651, loss1: 0.78422, loss2_3: 101.75229\n",
      "\ttrain_acc: 0.8223, test_acc: \u001b[31m0.79815\u001b[0m, time: 36.28\n",
      "epoch: 201, loss: 102.35170, loss1: 0.78987, loss2_3: 101.56183\n",
      "\ttrain_acc: 0.8284, test_acc: \u001b[31m0.79895\u001b[0m, time: 36.29\n",
      "epoch: 202, loss: 102.12463, loss1: 0.78497, loss2_3: 101.33966\n",
      "\ttrain_acc: 0.8338, test_acc: \u001b[31m0.79535\u001b[0m, time: 36.27\n",
      "epoch: 203, loss: 101.73831, loss1: 0.78592, loss2_3: 100.95239\n",
      "\ttrain_acc: 0.8252, test_acc: \u001b[31m0.79925\u001b[0m, time: 36.27\n",
      "epoch: 204, loss: 101.61346, loss1: 0.78400, loss2_3: 100.82945\n",
      "\ttrain_acc: 0.8347, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.27\n",
      "epoch: 205, loss: 101.54796, loss1: 0.77963, loss2_3: 100.76833\n",
      "\ttrain_acc: 0.8253, test_acc: \u001b[31m0.79715\u001b[0m, time: 36.27\n",
      "epoch: 206, loss: 101.34622, loss1: 0.78579, loss2_3: 100.56043\n",
      "\ttrain_acc: 0.8346, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.25\n",
      "epoch: 207, loss: 101.09353, loss1: 0.78455, loss2_3: 100.30898\n",
      "\ttrain_acc: 0.8340, test_acc: \u001b[31m0.7948\u001b[0m, time: 36.26\n",
      "epoch: 208, loss: 101.38426, loss1: 0.78573, loss2_3: 100.59853\n",
      "\ttrain_acc: 0.8306, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.26\n",
      "epoch: 209, loss: 100.71245, loss1: 0.77764, loss2_3: 99.93482\n",
      "\ttrain_acc: 0.8320, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.24\n",
      "epoch: 210, loss: 100.71580, loss1: 0.78101, loss2_3: 99.93478\n",
      "\ttrain_acc: 0.8339, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.26\n",
      "epoch: 211, loss: 100.39716, loss1: 0.78047, loss2_3: 99.61669\n",
      "\ttrain_acc: 0.8331, test_acc: \u001b[31m0.7979\u001b[0m, time: 36.25\n",
      "epoch: 212, loss: 100.34526, loss1: 0.77803, loss2_3: 99.56723\n",
      "\ttrain_acc: 0.8348, test_acc: \u001b[31m0.78305\u001b[0m, time: 36.26\n",
      "epoch: 213, loss: 100.50639, loss1: 0.77365, loss2_3: 99.73274\n",
      "\ttrain_acc: 0.7702, test_acc: \u001b[31m0.7261\u001b[0m, time: 36.25\n",
      "epoch: 214, loss: 100.27418, loss1: 0.77961, loss2_3: 99.49457\n",
      "\ttrain_acc: 0.8396, test_acc: \u001b[31m0.79525\u001b[0m, time: 36.28\n",
      "epoch: 215, loss: 100.09087, loss1: 0.77615, loss2_3: 99.31473\n",
      "\ttrain_acc: 0.8350, test_acc: \u001b[31m0.7983\u001b[0m, time: 36.36\n",
      "epoch: 216, loss: 100.01512, loss1: 0.77820, loss2_3: 99.23692\n",
      "\ttrain_acc: 0.8405, test_acc: \u001b[31m0.7904\u001b[0m, time: 36.28\n",
      "epoch: 217, loss: 99.50455, loss1: 0.77562, loss2_3: 98.72893\n",
      "\ttrain_acc: 0.8174, test_acc: \u001b[31m0.76485\u001b[0m, time: 36.30\n",
      "epoch: 218, loss: 99.42155, loss1: 0.77660, loss2_3: 98.64495\n",
      "\ttrain_acc: 0.8294, test_acc: \u001b[31m0.7978\u001b[0m, time: 36.83\n",
      "epoch: 219, loss: 99.25684, loss1: 0.77705, loss2_3: 98.47979\n",
      "\ttrain_acc: 0.8122, test_acc: \u001b[31m0.79045\u001b[0m, time: 37.27\n",
      "epoch: 220, loss: 98.89507, loss1: 0.77419, loss2_3: 98.12087\n",
      "\ttrain_acc: 0.8403, test_acc: \u001b[31m0.79585\u001b[0m, time: 37.31\n",
      "epoch: 221, loss: 98.61070, loss1: 0.77720, loss2_3: 97.83350\n",
      "\ttrain_acc: 0.8366, test_acc: \u001b[31m0.7805\u001b[0m, time: 37.26\n",
      "epoch: 222, loss: 98.80063, loss1: 0.77876, loss2_3: 98.02187\n",
      "\ttrain_acc: 0.8413, test_acc: \u001b[31m0.79845\u001b[0m, time: 37.28\n",
      "epoch: 223, loss: 97.88330, loss1: 0.77060, loss2_3: 97.11270\n",
      "\ttrain_acc: 0.7087, test_acc: \u001b[31m0.6603\u001b[0m, time: 37.28\n",
      "epoch: 224, loss: 97.86336, loss1: 0.76933, loss2_3: 97.09402\n",
      "\ttrain_acc: 0.8309, test_acc: \u001b[31m0.7694\u001b[0m, time: 37.28\n",
      "epoch: 225, loss: 98.00657, loss1: 0.77179, loss2_3: 97.23477\n",
      "\ttrain_acc: 0.8455, test_acc: \u001b[31m0.79705\u001b[0m, time: 37.28\n",
      "epoch: 226, loss: 97.50777, loss1: 0.77272, loss2_3: 96.73505\n",
      "\ttrain_acc: 0.8433, test_acc: \u001b[31m0.79115\u001b[0m, time: 37.30\n",
      "epoch: 227, loss: 97.21552, loss1: 0.76717, loss2_3: 96.44834\n",
      "\ttrain_acc: 0.8470, test_acc: \u001b[31m0.79665\u001b[0m, time: 37.29\n",
      "epoch: 228, loss: 97.00382, loss1: 0.77076, loss2_3: 96.23306\n",
      "\ttrain_acc: 0.8290, test_acc: \u001b[31m0.76555\u001b[0m, time: 36.28\n",
      "epoch: 229, loss: 96.79724, loss1: 0.76813, loss2_3: 96.02911\n",
      "\ttrain_acc: 0.8247, test_acc: \u001b[31m0.79145\u001b[0m, time: 36.22\n",
      "epoch: 230, loss: 96.73562, loss1: 0.76400, loss2_3: 95.97162\n",
      "\ttrain_acc: 0.7534, test_acc: \u001b[31m0.6912\u001b[0m, time: 36.21\n",
      "epoch: 231, loss: 96.47728, loss1: 0.76290, loss2_3: 95.71438\n",
      "\ttrain_acc: 0.8425, test_acc: \u001b[31m0.7972\u001b[0m, time: 36.23\n",
      "epoch: 232, loss: 96.30356, loss1: 0.76007, loss2_3: 95.54349\n",
      "\ttrain_acc: 0.8016, test_acc: \u001b[31m0.7787\u001b[0m, time: 36.21\n",
      "epoch: 233, loss: 96.12815, loss1: 0.76497, loss2_3: 95.36318\n",
      "\ttrain_acc: 0.8453, test_acc: \u001b[31m0.79165\u001b[0m, time: 36.20\n",
      "epoch: 234, loss: 95.55358, loss1: 0.76365, loss2_3: 94.78993\n",
      "\ttrain_acc: 0.8288, test_acc: \u001b[31m0.79585\u001b[0m, time: 36.21\n",
      "epoch: 235, loss: 95.22113, loss1: 0.75892, loss2_3: 94.46220\n",
      "\ttrain_acc: 0.5582, test_acc: \u001b[31m0.53145\u001b[0m, time: 36.20\n",
      "epoch: 236, loss: 95.44114, loss1: 0.75703, loss2_3: 94.68411\n",
      "\ttrain_acc: 0.8442, test_acc: \u001b[31m0.79785\u001b[0m, time: 36.21\n",
      "epoch: 237, loss: 94.63226, loss1: 0.75545, loss2_3: 93.87681\n",
      "\ttrain_acc: 0.8357, test_acc: \u001b[31m0.7663\u001b[0m, time: 36.18\n",
      "epoch: 238, loss: 94.52333, loss1: 0.75761, loss2_3: 93.76572\n",
      "\ttrain_acc: 0.8525, test_acc: \u001b[31m0.7958\u001b[0m, time: 36.19\n",
      "epoch: 239, loss: 94.09922, loss1: 0.75562, loss2_3: 93.34361\n",
      "\ttrain_acc: 0.8525, test_acc: \u001b[31m0.79255\u001b[0m, time: 36.21\n",
      "epoch: 240, loss: 94.21503, loss1: 0.75543, loss2_3: 93.45960\n",
      "\ttrain_acc: 0.8396, test_acc: \u001b[31m0.7974\u001b[0m, time: 36.18\n",
      "epoch: 241, loss: 93.83628, loss1: 0.75318, loss2_3: 93.08311\n",
      "\ttrain_acc: 0.8548, test_acc: \u001b[31m0.7962\u001b[0m, time: 36.19\n",
      "epoch: 242, loss: 93.79964, loss1: 0.75303, loss2_3: 93.04661\n",
      "\ttrain_acc: 0.8237, test_acc: \u001b[31m0.78765\u001b[0m, time: 36.22\n",
      "epoch: 243, loss: 93.45052, loss1: 0.75413, loss2_3: 92.69639\n",
      "\ttrain_acc: 0.7287, test_acc: \u001b[31m0.6545\u001b[0m, time: 36.17\n",
      "epoch: 244, loss: 92.87249, loss1: 0.75620, loss2_3: 92.11629\n",
      "\ttrain_acc: 0.5868, test_acc: \u001b[31m0.5518\u001b[0m, time: 36.24\n",
      "epoch: 245, loss: 92.68814, loss1: 0.74731, loss2_3: 91.94082\n",
      "\ttrain_acc: 0.8544, test_acc: \u001b[31m0.79495\u001b[0m, time: 36.18\n",
      "epoch: 246, loss: 92.37361, loss1: 0.75788, loss2_3: 91.61574\n",
      "\ttrain_acc: 0.8557, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.23\n",
      "epoch: 247, loss: 92.06203, loss1: 0.75048, loss2_3: 91.31155\n",
      "\ttrain_acc: 0.8248, test_acc: \u001b[31m0.7875\u001b[0m, time: 36.22\n",
      "epoch: 248, loss: 92.24248, loss1: 0.74586, loss2_3: 91.49661\n",
      "\ttrain_acc: 0.8560, test_acc: \u001b[31m0.7795\u001b[0m, time: 36.21\n",
      "epoch: 249, loss: 91.69513, loss1: 0.74576, loss2_3: 90.94937\n",
      "\ttrain_acc: 0.6564, test_acc: \u001b[31m0.6025\u001b[0m, time: 36.22\n",
      "epoch: 250, loss: 91.57691, loss1: 0.74550, loss2_3: 90.83140\n",
      "\ttrain_acc: 0.8625, test_acc: \u001b[31m0.7899\u001b[0m, time: 36.22\n",
      "epoch: 1, loss: 180.59983, loss1: 2.69969, loss2_3: 177.90014\n",
      "\ttrain_acc: 0.5386, test_acc: \u001b[31m0.53795\u001b[0m, time: 36.43\n",
      "best_acc: 0.53795\n",
      "epoch: 2, loss: 172.76137, loss1: 1.02170, loss2_3: 171.73968\n",
      "\ttrain_acc: 0.5840, test_acc: \u001b[31m0.58465\u001b[0m, time: 36.49\n",
      "best_acc: 0.58465\n",
      "epoch: 3, loss: 151.45903, loss1: 1.00442, loss2_3: 150.45461\n",
      "\ttrain_acc: 0.7212, test_acc: \u001b[31m0.7153\u001b[0m, time: 36.43\n",
      "best_acc: 0.7153\n",
      "epoch: 4, loss: 136.04172, loss1: 0.97531, loss2_3: 135.06640\n",
      "\ttrain_acc: 0.7492, test_acc: \u001b[31m0.7495\u001b[0m, time: 36.48\n",
      "best_acc: 0.7495\n",
      "epoch: 5, loss: 132.13898, loss1: 0.95397, loss2_3: 131.18502\n",
      "\ttrain_acc: 0.7652, test_acc: \u001b[31m0.766\u001b[0m, time: 36.45\n",
      "best_acc: 0.766\n",
      "epoch: 6, loss: 129.43343, loss1: 0.94131, loss2_3: 128.49212\n",
      "\ttrain_acc: 0.7662, test_acc: \u001b[31m0.76655\u001b[0m, time: 36.47\n",
      "best_acc: 0.76655\n",
      "epoch: 7, loss: 129.29978, loss1: 0.93466, loss2_3: 128.36512\n",
      "\ttrain_acc: 0.7408, test_acc: \u001b[31m0.7409\u001b[0m, time: 36.44\n",
      "epoch: 8, loss: 127.46874, loss1: 0.93106, loss2_3: 126.53769\n",
      "\ttrain_acc: 0.7686, test_acc: \u001b[31m0.76735\u001b[0m, time: 36.52\n",
      "best_acc: 0.76735\n",
      "epoch: 9, loss: 126.17149, loss1: 0.91689, loss2_3: 125.25460\n",
      "\ttrain_acc: 0.7792, test_acc: \u001b[31m0.7789\u001b[0m, time: 36.45\n",
      "best_acc: 0.7789\n",
      "epoch: 10, loss: 125.33225, loss1: 0.91121, loss2_3: 124.42103\n",
      "\ttrain_acc: 0.7765, test_acc: \u001b[31m0.77535\u001b[0m, time: 36.48\n",
      "epoch: 11, loss: 124.69108, loss1: 0.91442, loss2_3: 123.77666\n",
      "\ttrain_acc: 0.7616, test_acc: \u001b[31m0.7611\u001b[0m, time: 36.45\n",
      "epoch: 12, loss: 124.02340, loss1: 0.91047, loss2_3: 123.11292\n",
      "\ttrain_acc: 0.7791, test_acc: \u001b[31m0.7784\u001b[0m, time: 36.47\n",
      "epoch: 13, loss: 123.12232, loss1: 0.90208, loss2_3: 122.22024\n",
      "\ttrain_acc: 0.7679, test_acc: \u001b[31m0.76875\u001b[0m, time: 36.42\n",
      "epoch: 14, loss: 123.10104, loss1: 0.90719, loss2_3: 122.19386\n",
      "\ttrain_acc: 0.7743, test_acc: \u001b[31m0.7745\u001b[0m, time: 36.43\n",
      "epoch: 15, loss: 122.77110, loss1: 0.90609, loss2_3: 121.86501\n",
      "\ttrain_acc: 0.7859, test_acc: \u001b[31m0.7822\u001b[0m, time: 36.44\n",
      "best_acc: 0.7822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, loss: 122.64707, loss1: 0.90378, loss2_3: 121.74329\n",
      "\ttrain_acc: 0.7840, test_acc: \u001b[31m0.78425\u001b[0m, time: 36.43\n",
      "best_acc: 0.78425\n",
      "epoch: 17, loss: 122.18648, loss1: 0.89128, loss2_3: 121.29520\n",
      "\ttrain_acc: 0.7788, test_acc: \u001b[31m0.77695\u001b[0m, time: 36.39\n",
      "epoch: 18, loss: 122.72890, loss1: 0.89950, loss2_3: 121.82939\n",
      "\ttrain_acc: 0.7853, test_acc: \u001b[31m0.78425\u001b[0m, time: 36.47\n",
      "epoch: 19, loss: 121.40967, loss1: 0.89217, loss2_3: 120.51750\n",
      "\ttrain_acc: 0.7782, test_acc: \u001b[31m0.7782\u001b[0m, time: 36.39\n",
      "epoch: 20, loss: 121.76388, loss1: 0.89309, loss2_3: 120.87079\n",
      "\ttrain_acc: 0.7826, test_acc: \u001b[31m0.7814\u001b[0m, time: 36.45\n",
      "epoch: 21, loss: 121.24577, loss1: 0.88203, loss2_3: 120.36374\n",
      "\ttrain_acc: 0.7906, test_acc: \u001b[31m0.79115\u001b[0m, time: 36.65\n",
      "best_acc: 0.79115\n",
      "epoch: 22, loss: 120.61898, loss1: 0.88574, loss2_3: 119.73324\n",
      "\ttrain_acc: 0.7866, test_acc: \u001b[31m0.7841\u001b[0m, time: 37.36\n",
      "epoch: 23, loss: 120.95050, loss1: 0.88563, loss2_3: 120.06487\n",
      "\ttrain_acc: 0.7815, test_acc: \u001b[31m0.78345\u001b[0m, time: 36.71\n",
      "epoch: 24, loss: 120.88696, loss1: 0.89071, loss2_3: 119.99625\n",
      "\ttrain_acc: 0.7877, test_acc: \u001b[31m0.7874\u001b[0m, time: 36.47\n",
      "epoch: 25, loss: 120.41684, loss1: 0.88243, loss2_3: 119.53442\n",
      "\ttrain_acc: 0.7898, test_acc: \u001b[31m0.78885\u001b[0m, time: 36.43\n",
      "epoch: 26, loss: 119.87769, loss1: 0.88492, loss2_3: 118.99277\n",
      "\ttrain_acc: 0.7926, test_acc: \u001b[31m0.79175\u001b[0m, time: 36.46\n",
      "best_acc: 0.79175\n",
      "epoch: 27, loss: 119.52842, loss1: 0.88267, loss2_3: 118.64575\n",
      "\ttrain_acc: 0.7913, test_acc: \u001b[31m0.79155\u001b[0m, time: 36.42\n",
      "epoch: 28, loss: 119.43512, loss1: 0.87387, loss2_3: 118.56125\n",
      "\ttrain_acc: 0.7887, test_acc: \u001b[31m0.7866\u001b[0m, time: 36.44\n",
      "epoch: 29, loss: 120.16445, loss1: 0.87845, loss2_3: 119.28601\n",
      "\ttrain_acc: 0.7931, test_acc: \u001b[31m0.793\u001b[0m, time: 36.38\n",
      "best_acc: 0.793\n",
      "epoch: 30, loss: 118.96364, loss1: 0.87541, loss2_3: 118.08823\n",
      "\ttrain_acc: 0.7966, test_acc: \u001b[31m0.79595\u001b[0m, time: 36.41\n",
      "best_acc: 0.79595\n",
      "epoch: 31, loss: 118.97694, loss1: 0.87498, loss2_3: 118.10196\n",
      "\ttrain_acc: 0.7952, test_acc: \u001b[31m0.7944\u001b[0m, time: 36.39\n",
      "epoch: 32, loss: 118.76413, loss1: 0.87257, loss2_3: 117.89156\n",
      "\ttrain_acc: 0.7902, test_acc: \u001b[31m0.78785\u001b[0m, time: 36.39\n",
      "epoch: 33, loss: 118.71506, loss1: 0.87833, loss2_3: 117.83674\n",
      "\ttrain_acc: 0.7919, test_acc: \u001b[31m0.7916\u001b[0m, time: 36.36\n",
      "epoch: 34, loss: 118.19691, loss1: 0.86826, loss2_3: 117.32865\n",
      "\ttrain_acc: 0.7970, test_acc: \u001b[31m0.79625\u001b[0m, time: 36.40\n",
      "best_acc: 0.79625\n",
      "epoch: 35, loss: 118.47095, loss1: 0.86926, loss2_3: 117.60169\n",
      "\ttrain_acc: 0.7959, test_acc: \u001b[31m0.7957\u001b[0m, time: 36.35\n",
      "epoch: 36, loss: 117.99082, loss1: 0.87148, loss2_3: 117.11934\n",
      "\ttrain_acc: 0.7996, test_acc: \u001b[31m0.79745\u001b[0m, time: 36.37\n",
      "best_acc: 0.79745\n",
      "epoch: 37, loss: 117.80603, loss1: 0.86720, loss2_3: 116.93883\n",
      "\ttrain_acc: 0.7959, test_acc: \u001b[31m0.79445\u001b[0m, time: 36.38\n",
      "epoch: 38, loss: 117.47711, loss1: 0.86585, loss2_3: 116.61127\n",
      "\ttrain_acc: 0.7959, test_acc: \u001b[31m0.7949\u001b[0m, time: 36.38\n",
      "epoch: 39, loss: 117.62068, loss1: 0.87077, loss2_3: 116.74991\n",
      "\ttrain_acc: 0.7953, test_acc: \u001b[31m0.7968\u001b[0m, time: 36.36\n",
      "epoch: 40, loss: 117.22500, loss1: 0.86577, loss2_3: 116.35922\n",
      "\ttrain_acc: 0.7989, test_acc: \u001b[31m0.7969\u001b[0m, time: 36.41\n",
      "epoch: 41, loss: 117.45367, loss1: 0.86187, loss2_3: 116.59181\n",
      "\ttrain_acc: 0.7951, test_acc: \u001b[31m0.79365\u001b[0m, time: 36.34\n",
      "epoch: 42, loss: 117.12560, loss1: 0.85460, loss2_3: 116.27100\n",
      "\ttrain_acc: 0.7982, test_acc: \u001b[31m0.7951\u001b[0m, time: 36.41\n",
      "epoch: 43, loss: 117.57037, loss1: 0.86199, loss2_3: 116.70838\n",
      "\ttrain_acc: 0.7965, test_acc: \u001b[31m0.79635\u001b[0m, time: 36.32\n",
      "epoch: 44, loss: 117.16292, loss1: 0.86232, loss2_3: 116.30060\n",
      "\ttrain_acc: 0.7948, test_acc: \u001b[31m0.79485\u001b[0m, time: 36.41\n",
      "epoch: 45, loss: 116.99689, loss1: 0.85899, loss2_3: 116.13790\n",
      "\ttrain_acc: 0.7986, test_acc: \u001b[31m0.7976\u001b[0m, time: 36.32\n",
      "best_acc: 0.7976\n",
      "epoch: 46, loss: 116.64947, loss1: 0.85798, loss2_3: 115.79149\n",
      "\ttrain_acc: 0.7956, test_acc: \u001b[31m0.7961\u001b[0m, time: 36.37\n",
      "epoch: 47, loss: 116.66047, loss1: 0.85914, loss2_3: 115.80133\n",
      "\ttrain_acc: 0.7966, test_acc: \u001b[31m0.79525\u001b[0m, time: 36.34\n",
      "epoch: 48, loss: 116.81024, loss1: 0.85112, loss2_3: 115.95911\n",
      "\ttrain_acc: 0.7994, test_acc: \u001b[31m0.7959\u001b[0m, time: 36.34\n",
      "epoch: 49, loss: 116.49962, loss1: 0.85596, loss2_3: 115.64366\n",
      "\ttrain_acc: 0.7994, test_acc: \u001b[31m0.7975\u001b[0m, time: 36.32\n",
      "epoch: 50, loss: 116.57484, loss1: 0.85857, loss2_3: 115.71627\n",
      "\ttrain_acc: 0.8004, test_acc: \u001b[31m0.7984\u001b[0m, time: 36.35\n",
      "best_acc: 0.7984\n",
      "epoch: 51, loss: 116.46099, loss1: 0.86308, loss2_3: 115.59791\n",
      "\ttrain_acc: 0.7997, test_acc: \u001b[31m0.7951\u001b[0m, time: 36.32\n",
      "epoch: 52, loss: 116.30920, loss1: 0.85030, loss2_3: 115.45891\n",
      "\ttrain_acc: 0.7984, test_acc: \u001b[31m0.7959\u001b[0m, time: 36.33\n",
      "epoch: 53, loss: 116.63156, loss1: 0.85408, loss2_3: 115.77747\n",
      "\ttrain_acc: 0.7979, test_acc: \u001b[31m0.79545\u001b[0m, time: 36.33\n",
      "epoch: 54, loss: 116.21290, loss1: 0.85678, loss2_3: 115.35612\n",
      "\ttrain_acc: 0.7997, test_acc: \u001b[31m0.79685\u001b[0m, time: 36.31\n",
      "epoch: 55, loss: 115.88303, loss1: 0.85092, loss2_3: 115.03211\n",
      "\ttrain_acc: 0.8015, test_acc: \u001b[31m0.7995\u001b[0m, time: 36.27\n",
      "best_acc: 0.7995\n",
      "epoch: 56, loss: 115.73497, loss1: 0.84583, loss2_3: 114.88914\n",
      "\ttrain_acc: 0.8023, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.30\n",
      "best_acc: 0.80035\n",
      "epoch: 57, loss: 115.86917, loss1: 0.84999, loss2_3: 115.01918\n",
      "\ttrain_acc: 0.7966, test_acc: \u001b[31m0.7931\u001b[0m, time: 36.24\n",
      "epoch: 58, loss: 115.69697, loss1: 0.84771, loss2_3: 114.84926\n",
      "\ttrain_acc: 0.8012, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.27\n",
      "epoch: 59, loss: 115.86720, loss1: 0.85268, loss2_3: 115.01452\n",
      "\ttrain_acc: 0.8015, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.24\n",
      "epoch: 60, loss: 116.05316, loss1: 0.85008, loss2_3: 115.20308\n",
      "\ttrain_acc: 0.7995, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.25\n",
      "epoch: 61, loss: 115.95478, loss1: 0.84772, loss2_3: 115.10705\n",
      "\ttrain_acc: 0.8016, test_acc: \u001b[31m0.7976\u001b[0m, time: 36.26\n",
      "epoch: 62, loss: 115.77202, loss1: 0.84946, loss2_3: 114.92255\n",
      "\ttrain_acc: 0.8025, test_acc: \u001b[31m0.7992\u001b[0m, time: 36.24\n",
      "epoch: 63, loss: 115.38414, loss1: 0.84694, loss2_3: 114.53720\n",
      "\ttrain_acc: 0.8019, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.26\n",
      "epoch: 64, loss: 115.76638, loss1: 0.85273, loss2_3: 114.91366\n",
      "\ttrain_acc: 0.8002, test_acc: \u001b[31m0.79725\u001b[0m, time: 36.24\n",
      "epoch: 65, loss: 115.26705, loss1: 0.84270, loss2_3: 114.42435\n",
      "\ttrain_acc: 0.8023, test_acc: \u001b[31m0.7999\u001b[0m, time: 36.25\n",
      "epoch: 66, loss: 115.59286, loss1: 0.84635, loss2_3: 114.74651\n",
      "\ttrain_acc: 0.7974, test_acc: \u001b[31m0.79615\u001b[0m, time: 36.29\n",
      "epoch: 67, loss: 115.37151, loss1: 0.84395, loss2_3: 114.52755\n",
      "\ttrain_acc: 0.8028, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.27\n",
      "epoch: 68, loss: 115.37862, loss1: 0.84460, loss2_3: 114.53402\n",
      "\ttrain_acc: 0.7989, test_acc: \u001b[31m0.7976\u001b[0m, time: 36.26\n",
      "epoch: 69, loss: 115.43111, loss1: 0.84917, loss2_3: 114.58194\n",
      "\ttrain_acc: 0.8013, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.26\n",
      "epoch: 70, loss: 115.01244, loss1: 0.84289, loss2_3: 114.16956\n",
      "\ttrain_acc: 0.7998, test_acc: \u001b[31m0.7966\u001b[0m, time: 36.24\n",
      "epoch: 71, loss: 115.14407, loss1: 0.83797, loss2_3: 114.30610\n",
      "\ttrain_acc: 0.7980, test_acc: \u001b[31m0.79515\u001b[0m, time: 36.21\n",
      "epoch: 72, loss: 114.98216, loss1: 0.83990, loss2_3: 114.14227\n",
      "\ttrain_acc: 0.8034, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.27\n",
      "best_acc: 0.80045\n",
      "epoch: 73, loss: 114.83549, loss1: 0.84130, loss2_3: 113.99419\n",
      "\ttrain_acc: 0.8036, test_acc: \u001b[31m0.79865\u001b[0m, time: 36.19\n",
      "epoch: 74, loss: 114.46767, loss1: 0.83928, loss2_3: 113.62839\n",
      "\ttrain_acc: 0.8023, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.26\n",
      "epoch: 75, loss: 114.80575, loss1: 0.84400, loss2_3: 113.96175\n",
      "\ttrain_acc: 0.8014, test_acc: \u001b[31m0.7969\u001b[0m, time: 36.18\n",
      "epoch: 76, loss: 114.56441, loss1: 0.83920, loss2_3: 113.72522\n",
      "\ttrain_acc: 0.8028, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.24\n",
      "epoch: 77, loss: 114.22433, loss1: 0.84355, loss2_3: 113.38079\n",
      "\ttrain_acc: 0.8033, test_acc: \u001b[31m0.8017\u001b[0m, time: 36.22\n",
      "best_acc: 0.8017\n",
      "epoch: 78, loss: 114.52490, loss1: 0.84027, loss2_3: 113.68463\n",
      "\ttrain_acc: 0.8030, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.26\n",
      "epoch: 79, loss: 114.54146, loss1: 0.83392, loss2_3: 113.70754\n",
      "\ttrain_acc: 0.8023, test_acc: \u001b[31m0.7976\u001b[0m, time: 36.23\n",
      "epoch: 80, loss: 114.37863, loss1: 0.83963, loss2_3: 113.53899\n",
      "\ttrain_acc: 0.8005, test_acc: \u001b[31m0.79605\u001b[0m, time: 36.28\n",
      "epoch: 81, loss: 114.32583, loss1: 0.83744, loss2_3: 113.48839\n",
      "\ttrain_acc: 0.8022, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 82, loss: 113.98213, loss1: 0.83234, loss2_3: 113.14978\n",
      "\ttrain_acc: 0.8052, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.30\n",
      "epoch: 83, loss: 113.87083, loss1: 0.83930, loss2_3: 113.03153\n",
      "\ttrain_acc: 0.7997, test_acc: \u001b[31m0.79375\u001b[0m, time: 36.23\n",
      "epoch: 84, loss: 113.82954, loss1: 0.83300, loss2_3: 112.99654\n",
      "\ttrain_acc: 0.8058, test_acc: \u001b[31m0.8027\u001b[0m, time: 36.26\n",
      "best_acc: 0.8027\n",
      "epoch: 85, loss: 113.83339, loss1: 0.83688, loss2_3: 112.99651\n",
      "\ttrain_acc: 0.8017, test_acc: \u001b[31m0.7967\u001b[0m, time: 36.25\n",
      "epoch: 86, loss: 114.14336, loss1: 0.83437, loss2_3: 113.30899\n",
      "\ttrain_acc: 0.8048, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.27\n",
      "epoch: 87, loss: 113.86717, loss1: 0.83586, loss2_3: 113.03131\n",
      "\ttrain_acc: 0.8042, test_acc: \u001b[31m0.8001\u001b[0m, time: 36.22\n",
      "epoch: 88, loss: 113.48967, loss1: 0.82834, loss2_3: 112.66133\n",
      "\ttrain_acc: 0.8035, test_acc: \u001b[31m0.79775\u001b[0m, time: 36.28\n",
      "epoch: 89, loss: 113.50384, loss1: 0.83455, loss2_3: 112.66928\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.80245\u001b[0m, time: 36.21\n",
      "epoch: 90, loss: 113.62574, loss1: 0.82937, loss2_3: 112.79638\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.80245\u001b[0m, time: 36.28\n",
      "epoch: 91, loss: 113.55164, loss1: 0.83033, loss2_3: 112.72131\n",
      "\ttrain_acc: 0.8036, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.22\n",
      "epoch: 92, loss: 113.43853, loss1: 0.83235, loss2_3: 112.60618\n",
      "\ttrain_acc: 0.8037, test_acc: \u001b[31m0.7988\u001b[0m, time: 36.26\n",
      "epoch: 93, loss: 113.14346, loss1: 0.82869, loss2_3: 112.31477\n",
      "\ttrain_acc: 0.8045, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.29\n",
      "epoch: 94, loss: 113.39904, loss1: 0.83005, loss2_3: 112.56898\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.28\n",
      "epoch: 95, loss: 113.15018, loss1: 0.83249, loss2_3: 112.31769\n",
      "\ttrain_acc: 0.8068, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.28\n",
      "epoch: 96, loss: 112.96318, loss1: 0.82793, loss2_3: 112.13525\n",
      "\ttrain_acc: 0.8014, test_acc: \u001b[31m0.7934\u001b[0m, time: 36.27\n",
      "epoch: 97, loss: 113.12677, loss1: 0.82587, loss2_3: 112.30090\n",
      "\ttrain_acc: 0.8054, test_acc: \u001b[31m0.7988\u001b[0m, time: 36.22\n",
      "epoch: 98, loss: 112.97004, loss1: 0.83184, loss2_3: 112.13821\n",
      "\ttrain_acc: 0.8058, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.30\n",
      "epoch: 99, loss: 112.84485, loss1: 0.82331, loss2_3: 112.02154\n",
      "\ttrain_acc: 0.8044, test_acc: \u001b[31m0.7978\u001b[0m, time: 36.22\n",
      "epoch: 100, loss: 113.02951, loss1: 0.82489, loss2_3: 112.20462\n",
      "\ttrain_acc: 0.8036, test_acc: \u001b[31m0.79615\u001b[0m, time: 36.28\n",
      "epoch: 101, loss: 112.88028, loss1: 0.82402, loss2_3: 112.05626\n",
      "\ttrain_acc: 0.8046, test_acc: \u001b[31m0.7983\u001b[0m, time: 36.23\n",
      "epoch: 102, loss: 113.02398, loss1: 0.82838, loss2_3: 112.19560\n",
      "\ttrain_acc: 0.8081, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.26\n",
      "epoch: 103, loss: 112.68217, loss1: 0.83344, loss2_3: 111.84873\n",
      "\ttrain_acc: 0.8063, test_acc: \u001b[31m0.80145\u001b[0m, time: 36.20\n",
      "epoch: 104, loss: 112.72443, loss1: 0.82633, loss2_3: 111.89810\n",
      "\ttrain_acc: 0.8061, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.27\n",
      "epoch: 105, loss: 112.45500, loss1: 0.82823, loss2_3: 111.62677\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.7974\u001b[0m, time: 36.21\n",
      "epoch: 106, loss: 112.69083, loss1: 0.82810, loss2_3: 111.86274\n",
      "\ttrain_acc: 0.8083, test_acc: \u001b[31m0.8034\u001b[0m, time: 36.30\n",
      "best_acc: 0.8034\n",
      "epoch: 107, loss: 112.46585, loss1: 0.82359, loss2_3: 111.64226\n",
      "\ttrain_acc: 0.8073, test_acc: \u001b[31m0.8017\u001b[0m, time: 36.23\n",
      "epoch: 108, loss: 112.47699, loss1: 0.82558, loss2_3: 111.65141\n",
      "\ttrain_acc: 0.8020, test_acc: \u001b[31m0.79565\u001b[0m, time: 36.30\n",
      "epoch: 109, loss: 112.39352, loss1: 0.82711, loss2_3: 111.56640\n",
      "\ttrain_acc: 0.8072, test_acc: \u001b[31m0.79815\u001b[0m, time: 36.23\n",
      "epoch: 110, loss: 112.24340, loss1: 0.82682, loss2_3: 111.41658\n",
      "\ttrain_acc: 0.8087, test_acc: \u001b[31m0.80275\u001b[0m, time: 36.24\n",
      "epoch: 111, loss: 112.01217, loss1: 0.82501, loss2_3: 111.18716\n",
      "\ttrain_acc: 0.8057, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.25\n",
      "epoch: 112, loss: 112.19402, loss1: 0.82565, loss2_3: 111.36837\n",
      "\ttrain_acc: 0.8081, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.24\n",
      "epoch: 113, loss: 111.90934, loss1: 0.81906, loss2_3: 111.09028\n",
      "\ttrain_acc: 0.8047, test_acc: \u001b[31m0.79655\u001b[0m, time: 36.23\n",
      "epoch: 114, loss: 111.86453, loss1: 0.82295, loss2_3: 111.04158\n",
      "\ttrain_acc: 0.8061, test_acc: \u001b[31m0.79715\u001b[0m, time: 36.26\n",
      "epoch: 115, loss: 111.84392, loss1: 0.82354, loss2_3: 111.02038\n",
      "\ttrain_acc: 0.8010, test_acc: \u001b[31m0.7936\u001b[0m, time: 36.22\n",
      "epoch: 116, loss: 111.84825, loss1: 0.82394, loss2_3: 111.02431\n",
      "\ttrain_acc: 0.8091, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.24\n",
      "epoch: 117, loss: 111.69391, loss1: 0.82445, loss2_3: 110.86946\n",
      "\ttrain_acc: 0.8063, test_acc: \u001b[31m0.7975\u001b[0m, time: 36.22\n",
      "epoch: 118, loss: 111.34829, loss1: 0.81846, loss2_3: 110.52982\n",
      "\ttrain_acc: 0.8082, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.25\n",
      "epoch: 119, loss: 111.51252, loss1: 0.82712, loss2_3: 110.68541\n",
      "\ttrain_acc: 0.8084, test_acc: \u001b[31m0.79875\u001b[0m, time: 36.20\n",
      "epoch: 120, loss: 111.15034, loss1: 0.81927, loss2_3: 110.33107\n",
      "\ttrain_acc: 0.8101, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.29\n",
      "epoch: 121, loss: 111.26484, loss1: 0.81832, loss2_3: 110.44652\n",
      "\ttrain_acc: 0.8093, test_acc: \u001b[31m0.7997\u001b[0m, time: 36.21\n",
      "epoch: 122, loss: 111.27741, loss1: 0.82484, loss2_3: 110.45258\n",
      "\ttrain_acc: 0.8098, test_acc: \u001b[31m0.8016\u001b[0m, time: 36.30\n",
      "epoch: 123, loss: 111.28415, loss1: 0.82029, loss2_3: 110.46386\n",
      "\ttrain_acc: 0.8085, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.23\n",
      "epoch: 124, loss: 111.28309, loss1: 0.81942, loss2_3: 110.46366\n",
      "\ttrain_acc: 0.8098, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.30\n",
      "epoch: 125, loss: 111.20277, loss1: 0.81889, loss2_3: 110.38388\n",
      "\ttrain_acc: 0.8095, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.21\n",
      "epoch: 126, loss: 110.92244, loss1: 0.81785, loss2_3: 110.10459\n",
      "\ttrain_acc: 0.8072, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.25\n",
      "epoch: 127, loss: 110.91472, loss1: 0.81795, loss2_3: 110.09677\n",
      "\ttrain_acc: 0.8104, test_acc: \u001b[31m0.80375\u001b[0m, time: 36.24\n",
      "best_acc: 0.80375\n",
      "epoch: 128, loss: 110.96843, loss1: 0.82134, loss2_3: 110.14710\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.24\n",
      "epoch: 129, loss: 110.70508, loss1: 0.81886, loss2_3: 109.88622\n",
      "\ttrain_acc: 0.8065, test_acc: \u001b[31m0.7973\u001b[0m, time: 36.22\n",
      "epoch: 130, loss: 110.73626, loss1: 0.81745, loss2_3: 109.91881\n",
      "\ttrain_acc: 0.8095, test_acc: \u001b[31m0.7986\u001b[0m, time: 36.25\n",
      "epoch: 131, loss: 110.66355, loss1: 0.81757, loss2_3: 109.84598\n",
      "\ttrain_acc: 0.8086, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.23\n",
      "epoch: 132, loss: 110.32690, loss1: 0.81810, loss2_3: 109.50880\n",
      "\ttrain_acc: 0.8116, test_acc: \u001b[31m0.8042\u001b[0m, time: 36.24\n",
      "best_acc: 0.8042\n",
      "epoch: 133, loss: 110.40823, loss1: 0.81819, loss2_3: 109.59005\n",
      "\ttrain_acc: 0.8130, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.24\n",
      "epoch: 134, loss: 110.46534, loss1: 0.81741, loss2_3: 109.64793\n",
      "\ttrain_acc: 0.8111, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.25\n",
      "epoch: 135, loss: 110.16925, loss1: 0.82119, loss2_3: 109.34806\n",
      "\ttrain_acc: 0.8125, test_acc: \u001b[31m0.802\u001b[0m, time: 36.23\n",
      "epoch: 136, loss: 110.13604, loss1: 0.81375, loss2_3: 109.32229\n",
      "\ttrain_acc: 0.8128, test_acc: \u001b[31m0.8032\u001b[0m, time: 36.32\n",
      "epoch: 137, loss: 110.13068, loss1: 0.81989, loss2_3: 109.31080\n",
      "\ttrain_acc: 0.8103, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.23\n",
      "epoch: 138, loss: 109.93358, loss1: 0.81897, loss2_3: 109.11461\n",
      "\ttrain_acc: 0.8112, test_acc: \u001b[31m0.8016\u001b[0m, time: 36.31\n",
      "epoch: 139, loss: 109.96981, loss1: 0.81215, loss2_3: 109.15766\n",
      "\ttrain_acc: 0.8112, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.23\n",
      "epoch: 140, loss: 109.83186, loss1: 0.81740, loss2_3: 109.01447\n",
      "\ttrain_acc: 0.8093, test_acc: \u001b[31m0.7975\u001b[0m, time: 36.30\n",
      "epoch: 141, loss: 109.53272, loss1: 0.81657, loss2_3: 108.71615\n",
      "\ttrain_acc: 0.8139, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.21\n",
      "epoch: 142, loss: 109.98953, loss1: 0.81169, loss2_3: 109.17785\n",
      "\ttrain_acc: 0.8140, test_acc: \u001b[31m0.8048\u001b[0m, time: 36.27\n",
      "best_acc: 0.8048\n",
      "epoch: 143, loss: 109.54892, loss1: 0.80964, loss2_3: 108.73928\n",
      "\ttrain_acc: 0.8133, test_acc: \u001b[31m0.80335\u001b[0m, time: 36.23\n",
      "epoch: 144, loss: 109.73132, loss1: 0.80737, loss2_3: 108.92395\n",
      "\ttrain_acc: 0.8134, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.25\n",
      "epoch: 145, loss: 109.33320, loss1: 0.81291, loss2_3: 108.52029\n",
      "\ttrain_acc: 0.8150, test_acc: \u001b[31m0.803\u001b[0m, time: 36.19\n",
      "epoch: 146, loss: 109.27025, loss1: 0.81533, loss2_3: 108.45492\n",
      "\ttrain_acc: 0.8107, test_acc: \u001b[31m0.7986\u001b[0m, time: 36.26\n",
      "epoch: 147, loss: 109.20934, loss1: 0.81276, loss2_3: 108.39657\n",
      "\ttrain_acc: 0.8130, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 148, loss: 109.39500, loss1: 0.81581, loss2_3: 108.57919\n",
      "\ttrain_acc: 0.8165, test_acc: \u001b[31m0.80405\u001b[0m, time: 36.24\n",
      "epoch: 149, loss: 109.31931, loss1: 0.81792, loss2_3: 108.50139\n",
      "\ttrain_acc: 0.8159, test_acc: \u001b[31m0.80305\u001b[0m, time: 36.23\n",
      "epoch: 150, loss: 109.14573, loss1: 0.80999, loss2_3: 108.33574\n",
      "\ttrain_acc: 0.8170, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.26\n",
      "epoch: 151, loss: 109.22863, loss1: 0.81115, loss2_3: 108.41748\n",
      "\ttrain_acc: 0.8145, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.22\n",
      "epoch: 152, loss: 109.05321, loss1: 0.81310, loss2_3: 108.24011\n",
      "\ttrain_acc: 0.8157, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.27\n",
      "epoch: 153, loss: 108.69429, loss1: 0.81207, loss2_3: 107.88222\n",
      "\ttrain_acc: 0.8173, test_acc: \u001b[31m0.80085\u001b[0m, time: 36.22\n",
      "epoch: 154, loss: 108.43033, loss1: 0.81063, loss2_3: 107.61970\n",
      "\ttrain_acc: 0.8095, test_acc: \u001b[31m0.7907\u001b[0m, time: 36.25\n",
      "epoch: 155, loss: 108.48127, loss1: 0.80936, loss2_3: 107.67191\n",
      "\ttrain_acc: 0.8180, test_acc: \u001b[31m0.8001\u001b[0m, time: 36.22\n",
      "epoch: 156, loss: 108.31966, loss1: 0.80746, loss2_3: 107.51219\n",
      "\ttrain_acc: 0.8189, test_acc: \u001b[31m0.801\u001b[0m, time: 36.22\n",
      "epoch: 157, loss: 108.19482, loss1: 0.80770, loss2_3: 107.38712\n",
      "\ttrain_acc: 0.8153, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.23\n",
      "epoch: 158, loss: 108.38412, loss1: 0.81125, loss2_3: 107.57287\n",
      "\ttrain_acc: 0.8162, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.21\n",
      "epoch: 159, loss: 107.85120, loss1: 0.80794, loss2_3: 107.04325\n",
      "\ttrain_acc: 0.8155, test_acc: \u001b[31m0.7999\u001b[0m, time: 36.21\n",
      "epoch: 160, loss: 107.66865, loss1: 0.80901, loss2_3: 106.85963\n",
      "\ttrain_acc: 0.8160, test_acc: \u001b[31m0.8017\u001b[0m, time: 36.24\n",
      "epoch: 161, loss: 108.04102, loss1: 0.80763, loss2_3: 107.23339\n",
      "\ttrain_acc: 0.8119, test_acc: \u001b[31m0.79845\u001b[0m, time: 36.18\n",
      "epoch: 162, loss: 108.03055, loss1: 0.80988, loss2_3: 107.22067\n",
      "\ttrain_acc: 0.8154, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.26\n",
      "epoch: 163, loss: 107.56061, loss1: 0.80232, loss2_3: 106.75829\n",
      "\ttrain_acc: 0.8167, test_acc: \u001b[31m0.80135\u001b[0m, time: 36.20\n",
      "epoch: 164, loss: 107.75398, loss1: 0.80372, loss2_3: 106.95026\n",
      "\ttrain_acc: 0.8181, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.26\n",
      "epoch: 165, loss: 107.36555, loss1: 0.80741, loss2_3: 106.55814\n",
      "\ttrain_acc: 0.8212, test_acc: \u001b[31m0.80145\u001b[0m, time: 36.22\n",
      "epoch: 166, loss: 107.53540, loss1: 0.80617, loss2_3: 106.72923\n",
      "\ttrain_acc: 0.8185, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.25\n",
      "epoch: 167, loss: 107.47663, loss1: 0.80308, loss2_3: 106.67354\n",
      "\ttrain_acc: 0.8157, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.19\n",
      "epoch: 168, loss: 106.89274, loss1: 0.81272, loss2_3: 106.08001\n",
      "\ttrain_acc: 0.8205, test_acc: \u001b[31m0.8045\u001b[0m, time: 36.26\n",
      "epoch: 169, loss: 107.35661, loss1: 0.80699, loss2_3: 106.54962\n",
      "\ttrain_acc: 0.8097, test_acc: \u001b[31m0.7962\u001b[0m, time: 36.19\n",
      "epoch: 170, loss: 106.89310, loss1: 0.80737, loss2_3: 106.08573\n",
      "\ttrain_acc: 0.8145, test_acc: \u001b[31m0.79935\u001b[0m, time: 36.26\n",
      "epoch: 171, loss: 106.55261, loss1: 0.80530, loss2_3: 105.74731\n",
      "\ttrain_acc: 0.8222, test_acc: \u001b[31m0.7991\u001b[0m, time: 36.18\n",
      "epoch: 172, loss: 106.72642, loss1: 0.80578, loss2_3: 105.92064\n",
      "\ttrain_acc: 0.8202, test_acc: \u001b[31m0.80305\u001b[0m, time: 36.22\n",
      "epoch: 173, loss: 106.37376, loss1: 0.80353, loss2_3: 105.57024\n",
      "\ttrain_acc: 0.8197, test_acc: \u001b[31m0.7936\u001b[0m, time: 36.22\n",
      "epoch: 174, loss: 106.33135, loss1: 0.80094, loss2_3: 105.53041\n",
      "\ttrain_acc: 0.8183, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.20\n",
      "epoch: 175, loss: 106.65056, loss1: 0.80045, loss2_3: 105.85011\n",
      "\ttrain_acc: 0.8214, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.23\n",
      "epoch: 176, loss: 106.17221, loss1: 0.80189, loss2_3: 105.37032\n",
      "\ttrain_acc: 0.8208, test_acc: \u001b[31m0.8034\u001b[0m, time: 36.24\n",
      "epoch: 177, loss: 106.24699, loss1: 0.80315, loss2_3: 105.44385\n",
      "\ttrain_acc: 0.8172, test_acc: \u001b[31m0.7988\u001b[0m, time: 36.24\n",
      "epoch: 178, loss: 106.42500, loss1: 0.80528, loss2_3: 105.61972\n",
      "\ttrain_acc: 0.8151, test_acc: \u001b[31m0.79455\u001b[0m, time: 36.26\n",
      "epoch: 179, loss: 105.98446, loss1: 0.80094, loss2_3: 105.18351\n",
      "\ttrain_acc: 0.8222, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.22\n",
      "epoch: 180, loss: 105.78693, loss1: 0.80171, loss2_3: 104.98522\n",
      "\ttrain_acc: 0.8200, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.23\n",
      "epoch: 181, loss: 105.67139, loss1: 0.79983, loss2_3: 104.87155\n",
      "\ttrain_acc: 0.8181, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.24\n",
      "epoch: 182, loss: 105.57821, loss1: 0.80199, loss2_3: 104.77621\n",
      "\ttrain_acc: 0.8233, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.21\n",
      "epoch: 183, loss: 105.40945, loss1: 0.80179, loss2_3: 104.60766\n",
      "\ttrain_acc: 0.8206, test_acc: \u001b[31m0.7911\u001b[0m, time: 36.21\n",
      "epoch: 184, loss: 105.28795, loss1: 0.80460, loss2_3: 104.48335\n",
      "\ttrain_acc: 0.8237, test_acc: \u001b[31m0.8\u001b[0m, time: 36.23\n",
      "epoch: 185, loss: 105.47831, loss1: 0.80092, loss2_3: 104.67739\n",
      "\ttrain_acc: 0.8237, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.20\n",
      "epoch: 186, loss: 104.76128, loss1: 0.79876, loss2_3: 103.96252\n",
      "\ttrain_acc: 0.8265, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.24\n",
      "epoch: 187, loss: 104.79968, loss1: 0.79757, loss2_3: 104.00211\n",
      "\ttrain_acc: 0.8228, test_acc: \u001b[31m0.8017\u001b[0m, time: 36.20\n",
      "epoch: 188, loss: 105.04803, loss1: 0.80542, loss2_3: 104.24261\n",
      "\ttrain_acc: 0.8224, test_acc: \u001b[31m0.8003\u001b[0m, time: 36.21\n",
      "epoch: 189, loss: 104.39226, loss1: 0.80031, loss2_3: 103.59194\n",
      "\ttrain_acc: 0.8244, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.23\n",
      "epoch: 190, loss: 104.59483, loss1: 0.79508, loss2_3: 103.79975\n",
      "\ttrain_acc: 0.8229, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.23\n",
      "epoch: 191, loss: 104.44418, loss1: 0.79489, loss2_3: 103.64929\n",
      "\ttrain_acc: 0.8182, test_acc: \u001b[31m0.7959\u001b[0m, time: 36.22\n",
      "epoch: 192, loss: 103.99673, loss1: 0.79983, loss2_3: 103.19690\n",
      "\ttrain_acc: 0.8252, test_acc: \u001b[31m0.7981\u001b[0m, time: 36.26\n",
      "epoch: 193, loss: 104.06555, loss1: 0.79568, loss2_3: 103.26987\n",
      "\ttrain_acc: 0.8239, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.20\n",
      "epoch: 194, loss: 103.60240, loss1: 0.79585, loss2_3: 102.80655\n",
      "\ttrain_acc: 0.8261, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.27\n",
      "epoch: 195, loss: 104.10227, loss1: 0.80035, loss2_3: 103.30192\n",
      "\ttrain_acc: 0.8280, test_acc: \u001b[31m0.79615\u001b[0m, time: 36.19\n",
      "epoch: 196, loss: 103.70668, loss1: 0.79826, loss2_3: 102.90842\n",
      "\ttrain_acc: 0.8273, test_acc: \u001b[31m0.79875\u001b[0m, time: 36.26\n",
      "epoch: 197, loss: 103.68936, loss1: 0.79548, loss2_3: 102.89388\n",
      "\ttrain_acc: 0.8279, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.22\n",
      "epoch: 198, loss: 103.57305, loss1: 0.79110, loss2_3: 102.78196\n",
      "\ttrain_acc: 0.8281, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.24\n",
      "epoch: 199, loss: 103.54562, loss1: 0.79254, loss2_3: 102.75308\n",
      "\ttrain_acc: 0.8283, test_acc: \u001b[31m0.7984\u001b[0m, time: 37.04\n",
      "epoch: 200, loss: 103.41798, loss1: 0.79603, loss2_3: 102.62195\n",
      "\ttrain_acc: 0.8267, test_acc: \u001b[31m0.80055\u001b[0m, time: 37.31\n",
      "epoch: 201, loss: 103.13402, loss1: 0.79700, loss2_3: 102.33702\n",
      "\ttrain_acc: 0.8259, test_acc: \u001b[31m0.79825\u001b[0m, time: 37.28\n",
      "epoch: 202, loss: 103.11829, loss1: 0.79533, loss2_3: 102.32296\n",
      "\ttrain_acc: 0.8280, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.94\n",
      "epoch: 203, loss: 103.00288, loss1: 0.79511, loss2_3: 102.20777\n",
      "\ttrain_acc: 0.8289, test_acc: \u001b[31m0.8\u001b[0m, time: 36.18\n",
      "epoch: 204, loss: 102.95747, loss1: 0.79362, loss2_3: 102.16385\n",
      "\ttrain_acc: 0.8322, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.26\n",
      "epoch: 205, loss: 102.82969, loss1: 0.79298, loss2_3: 102.03672\n",
      "\ttrain_acc: 0.8280, test_acc: \u001b[31m0.79775\u001b[0m, time: 36.20\n",
      "epoch: 206, loss: 102.73491, loss1: 0.79037, loss2_3: 101.94454\n",
      "\ttrain_acc: 0.8248, test_acc: \u001b[31m0.7972\u001b[0m, time: 36.26\n",
      "epoch: 207, loss: 102.63232, loss1: 0.79158, loss2_3: 101.84074\n",
      "\ttrain_acc: 0.8329, test_acc: \u001b[31m0.79565\u001b[0m, time: 36.22\n",
      "epoch: 208, loss: 102.39170, loss1: 0.79166, loss2_3: 101.60004\n",
      "\ttrain_acc: 0.8281, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.26\n",
      "epoch: 209, loss: 102.25819, loss1: 0.78470, loss2_3: 101.47349\n",
      "\ttrain_acc: 0.8305, test_acc: \u001b[31m0.79785\u001b[0m, time: 36.20\n",
      "epoch: 210, loss: 102.33891, loss1: 0.78615, loss2_3: 101.55275\n",
      "\ttrain_acc: 0.8294, test_acc: \u001b[31m0.7978\u001b[0m, time: 36.26\n",
      "epoch: 211, loss: 102.68607, loss1: 0.79047, loss2_3: 101.89560\n",
      "\ttrain_acc: 0.8291, test_acc: \u001b[31m0.78965\u001b[0m, time: 36.19\n",
      "epoch: 212, loss: 102.21487, loss1: 0.78920, loss2_3: 101.42567\n",
      "\ttrain_acc: 0.8344, test_acc: \u001b[31m0.79585\u001b[0m, time: 36.23\n",
      "epoch: 213, loss: 102.11277, loss1: 0.78406, loss2_3: 101.32870\n",
      "\ttrain_acc: 0.8259, test_acc: \u001b[31m0.7986\u001b[0m, time: 36.22\n",
      "epoch: 214, loss: 101.59189, loss1: 0.79147, loss2_3: 100.80042\n",
      "\ttrain_acc: 0.8358, test_acc: \u001b[31m0.7974\u001b[0m, time: 36.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 215, loss: 101.52764, loss1: 0.78540, loss2_3: 100.74224\n",
      "\ttrain_acc: 0.8322, test_acc: \u001b[31m0.7878\u001b[0m, time: 36.20\n",
      "epoch: 216, loss: 101.56752, loss1: 0.78501, loss2_3: 100.78251\n",
      "\ttrain_acc: 0.8358, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.23\n",
      "epoch: 217, loss: 101.09031, loss1: 0.78377, loss2_3: 100.30653\n",
      "\ttrain_acc: 0.8351, test_acc: \u001b[31m0.7993\u001b[0m, time: 36.20\n",
      "epoch: 218, loss: 101.39153, loss1: 0.78967, loss2_3: 100.60186\n",
      "\ttrain_acc: 0.8354, test_acc: \u001b[31m0.7922\u001b[0m, time: 36.26\n",
      "epoch: 219, loss: 100.60394, loss1: 0.78445, loss2_3: 99.81949\n",
      "\ttrain_acc: 0.8351, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.21\n",
      "epoch: 220, loss: 100.89512, loss1: 0.78345, loss2_3: 100.11167\n",
      "\ttrain_acc: 0.8378, test_acc: \u001b[31m0.79565\u001b[0m, time: 36.26\n",
      "epoch: 221, loss: 100.70584, loss1: 0.78303, loss2_3: 99.92281\n",
      "\ttrain_acc: 0.8293, test_acc: \u001b[31m0.7983\u001b[0m, time: 36.20\n",
      "epoch: 222, loss: 100.08516, loss1: 0.78109, loss2_3: 99.30407\n",
      "\ttrain_acc: 0.8397, test_acc: \u001b[31m0.79425\u001b[0m, time: 36.22\n",
      "epoch: 223, loss: 99.94210, loss1: 0.78328, loss2_3: 99.15882\n",
      "\ttrain_acc: 0.8343, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.19\n",
      "epoch: 224, loss: 99.53907, loss1: 0.78690, loss2_3: 98.75217\n",
      "\ttrain_acc: 0.8390, test_acc: \u001b[31m0.7992\u001b[0m, time: 36.24\n",
      "epoch: 225, loss: 99.82766, loss1: 0.78165, loss2_3: 99.04601\n",
      "\ttrain_acc: 0.8363, test_acc: \u001b[31m0.7978\u001b[0m, time: 36.18\n",
      "epoch: 226, loss: 99.97817, loss1: 0.78021, loss2_3: 99.19796\n",
      "\ttrain_acc: 0.8419, test_acc: \u001b[31m0.78915\u001b[0m, time: 36.26\n",
      "epoch: 227, loss: 99.52260, loss1: 0.77951, loss2_3: 98.74309\n",
      "\ttrain_acc: 0.8233, test_acc: \u001b[31m0.7945\u001b[0m, time: 36.18\n",
      "epoch: 228, loss: 99.55654, loss1: 0.78069, loss2_3: 98.77585\n",
      "\ttrain_acc: 0.8344, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.23\n",
      "epoch: 229, loss: 99.34032, loss1: 0.78093, loss2_3: 98.55939\n",
      "\ttrain_acc: 0.8339, test_acc: \u001b[31m0.79825\u001b[0m, time: 36.20\n",
      "epoch: 230, loss: 99.23707, loss1: 0.78255, loss2_3: 98.45452\n",
      "\ttrain_acc: 0.8430, test_acc: \u001b[31m0.7911\u001b[0m, time: 36.23\n",
      "epoch: 231, loss: 98.61147, loss1: 0.78172, loss2_3: 97.82975\n",
      "\ttrain_acc: 0.8385, test_acc: \u001b[31m0.78755\u001b[0m, time: 36.16\n",
      "epoch: 232, loss: 98.65703, loss1: 0.77522, loss2_3: 97.88181\n",
      "\ttrain_acc: 0.8396, test_acc: \u001b[31m0.7914\u001b[0m, time: 36.25\n",
      "epoch: 233, loss: 98.68571, loss1: 0.77459, loss2_3: 97.91112\n",
      "\ttrain_acc: 0.8365, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.18\n",
      "epoch: 234, loss: 98.54364, loss1: 0.77617, loss2_3: 97.76747\n",
      "\ttrain_acc: 0.8353, test_acc: \u001b[31m0.77965\u001b[0m, time: 36.25\n",
      "epoch: 235, loss: 98.40755, loss1: 0.77490, loss2_3: 97.63265\n",
      "\ttrain_acc: 0.8345, test_acc: \u001b[31m0.79935\u001b[0m, time: 36.17\n",
      "epoch: 236, loss: 98.26263, loss1: 0.77307, loss2_3: 97.48956\n",
      "\ttrain_acc: 0.8347, test_acc: \u001b[31m0.79435\u001b[0m, time: 36.24\n",
      "epoch: 237, loss: 98.19824, loss1: 0.77405, loss2_3: 97.42419\n",
      "\ttrain_acc: 0.8179, test_acc: \u001b[31m0.7605\u001b[0m, time: 36.22\n",
      "epoch: 238, loss: 98.01797, loss1: 0.77007, loss2_3: 97.24790\n",
      "\ttrain_acc: 0.8411, test_acc: \u001b[31m0.79725\u001b[0m, time: 36.22\n",
      "epoch: 239, loss: 97.83472, loss1: 0.76489, loss2_3: 97.06983\n",
      "\ttrain_acc: 0.8454, test_acc: \u001b[31m0.78995\u001b[0m, time: 36.24\n",
      "epoch: 240, loss: 97.46584, loss1: 0.77666, loss2_3: 96.68918\n",
      "\ttrain_acc: 0.8438, test_acc: \u001b[31m0.79455\u001b[0m, time: 36.19\n",
      "epoch: 241, loss: 97.63967, loss1: 0.77494, loss2_3: 96.86472\n",
      "\ttrain_acc: 0.8459, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.18\n",
      "epoch: 242, loss: 97.10406, loss1: 0.77248, loss2_3: 96.33158\n",
      "\ttrain_acc: 0.8413, test_acc: \u001b[31m0.78165\u001b[0m, time: 36.24\n",
      "epoch: 243, loss: 96.87631, loss1: 0.77358, loss2_3: 96.10274\n",
      "\ttrain_acc: 0.8249, test_acc: \u001b[31m0.7634\u001b[0m, time: 36.18\n",
      "epoch: 244, loss: 96.79059, loss1: 0.77069, loss2_3: 96.01991\n",
      "\ttrain_acc: 0.8507, test_acc: \u001b[31m0.79845\u001b[0m, time: 36.24\n",
      "epoch: 245, loss: 96.53828, loss1: 0.77055, loss2_3: 95.76773\n",
      "\ttrain_acc: 0.8459, test_acc: \u001b[31m0.79495\u001b[0m, time: 36.19\n",
      "epoch: 246, loss: 96.61955, loss1: 0.76704, loss2_3: 95.85251\n",
      "\ttrain_acc: 0.8360, test_acc: \u001b[31m0.77245\u001b[0m, time: 36.21\n",
      "epoch: 247, loss: 96.31716, loss1: 0.76476, loss2_3: 95.55240\n",
      "\ttrain_acc: 0.8361, test_acc: \u001b[31m0.798\u001b[0m, time: 36.17\n",
      "epoch: 248, loss: 96.02599, loss1: 0.76622, loss2_3: 95.25978\n",
      "\ttrain_acc: 0.8481, test_acc: \u001b[31m0.8011\u001b[0m, time: 36.26\n",
      "epoch: 249, loss: 96.04619, loss1: 0.76521, loss2_3: 95.28098\n",
      "\ttrain_acc: 0.8489, test_acc: \u001b[31m0.79255\u001b[0m, time: 36.20\n",
      "epoch: 250, loss: 95.82366, loss1: 0.76832, loss2_3: 95.05533\n",
      "\ttrain_acc: 0.8481, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.27\n",
      "epoch: 1, loss: 180.15779, loss1: 2.56389, loss2_3: 177.59390\n",
      "\ttrain_acc: 0.5496, test_acc: \u001b[31m0.53915\u001b[0m, time: 36.43\n",
      "best_acc: 0.53915\n",
      "epoch: 2, loss: 172.79025, loss1: 1.02143, loss2_3: 171.76882\n",
      "\ttrain_acc: 0.5776, test_acc: \u001b[31m0.5731\u001b[0m, time: 36.49\n",
      "best_acc: 0.5731\n",
      "epoch: 3, loss: 159.08398, loss1: 1.02028, loss2_3: 158.06370\n",
      "\ttrain_acc: 0.7094, test_acc: \u001b[31m0.70945\u001b[0m, time: 36.41\n",
      "best_acc: 0.70945\n",
      "epoch: 4, loss: 137.18788, loss1: 0.97076, loss2_3: 136.21712\n",
      "\ttrain_acc: 0.7381, test_acc: \u001b[31m0.73975\u001b[0m, time: 36.46\n",
      "best_acc: 0.73975\n",
      "epoch: 5, loss: 133.55561, loss1: 0.95319, loss2_3: 132.60242\n",
      "\ttrain_acc: 0.7608, test_acc: \u001b[31m0.75915\u001b[0m, time: 36.43\n",
      "best_acc: 0.75915\n",
      "epoch: 6, loss: 131.20417, loss1: 0.94571, loss2_3: 130.25846\n",
      "\ttrain_acc: 0.7523, test_acc: \u001b[31m0.75205\u001b[0m, time: 36.45\n",
      "epoch: 7, loss: 129.30460, loss1: 0.93023, loss2_3: 128.37437\n",
      "\ttrain_acc: 0.7732, test_acc: \u001b[31m0.77135\u001b[0m, time: 36.40\n",
      "best_acc: 0.77135\n",
      "epoch: 8, loss: 127.54995, loss1: 0.92776, loss2_3: 126.62219\n",
      "\ttrain_acc: 0.7407, test_acc: \u001b[31m0.74185\u001b[0m, time: 36.46\n",
      "epoch: 9, loss: 128.25321, loss1: 0.93494, loss2_3: 127.31827\n",
      "\ttrain_acc: 0.7601, test_acc: \u001b[31m0.7616\u001b[0m, time: 36.39\n",
      "epoch: 10, loss: 127.29617, loss1: 0.92827, loss2_3: 126.36790\n",
      "\ttrain_acc: 0.7732, test_acc: \u001b[31m0.77105\u001b[0m, time: 36.44\n",
      "epoch: 11, loss: 125.70329, loss1: 0.91560, loss2_3: 124.78768\n",
      "\ttrain_acc: 0.7667, test_acc: \u001b[31m0.7666\u001b[0m, time: 36.42\n",
      "epoch: 12, loss: 124.71628, loss1: 0.91211, loss2_3: 123.80416\n",
      "\ttrain_acc: 0.7780, test_acc: \u001b[31m0.77605\u001b[0m, time: 36.43\n",
      "best_acc: 0.77605\n",
      "epoch: 13, loss: 124.92295, loss1: 0.91437, loss2_3: 124.00857\n",
      "\ttrain_acc: 0.7768, test_acc: \u001b[31m0.777\u001b[0m, time: 36.40\n",
      "best_acc: 0.777\n",
      "epoch: 14, loss: 124.89582, loss1: 0.91512, loss2_3: 123.98070\n",
      "\ttrain_acc: 0.7565, test_acc: \u001b[31m0.7543\u001b[0m, time: 36.45\n",
      "epoch: 15, loss: 123.91622, loss1: 0.91038, loss2_3: 123.00585\n",
      "\ttrain_acc: 0.7800, test_acc: \u001b[31m0.7786\u001b[0m, time: 36.44\n",
      "best_acc: 0.7786\n",
      "epoch: 16, loss: 123.83214, loss1: 0.90277, loss2_3: 122.92937\n",
      "\ttrain_acc: 0.7689, test_acc: \u001b[31m0.76865\u001b[0m, time: 36.47\n",
      "epoch: 17, loss: 123.04811, loss1: 0.89853, loss2_3: 122.14958\n",
      "\ttrain_acc: 0.7839, test_acc: \u001b[31m0.78295\u001b[0m, time: 36.44\n",
      "best_acc: 0.78295\n",
      "epoch: 18, loss: 122.64874, loss1: 0.89700, loss2_3: 121.75174\n",
      "\ttrain_acc: 0.7759, test_acc: \u001b[31m0.7767\u001b[0m, time: 36.44\n",
      "epoch: 19, loss: 122.22598, loss1: 0.89327, loss2_3: 121.33271\n",
      "\ttrain_acc: 0.7822, test_acc: \u001b[31m0.78125\u001b[0m, time: 36.45\n",
      "epoch: 20, loss: 121.96275, loss1: 0.89164, loss2_3: 121.07111\n",
      "\ttrain_acc: 0.7809, test_acc: \u001b[31m0.7808\u001b[0m, time: 36.42\n",
      "epoch: 21, loss: 121.67800, loss1: 0.88899, loss2_3: 120.78902\n",
      "\ttrain_acc: 0.7883, test_acc: \u001b[31m0.788\u001b[0m, time: 36.41\n",
      "best_acc: 0.788\n",
      "epoch: 22, loss: 121.61149, loss1: 0.89113, loss2_3: 120.72035\n",
      "\ttrain_acc: 0.7903, test_acc: \u001b[31m0.79005\u001b[0m, time: 36.42\n",
      "best_acc: 0.79005\n",
      "epoch: 23, loss: 121.05843, loss1: 0.88301, loss2_3: 120.17542\n",
      "\ttrain_acc: 0.7880, test_acc: \u001b[31m0.7875\u001b[0m, time: 36.36\n",
      "epoch: 24, loss: 120.87887, loss1: 0.88243, loss2_3: 119.99644\n",
      "\ttrain_acc: 0.7897, test_acc: \u001b[31m0.7884\u001b[0m, time: 36.45\n",
      "epoch: 25, loss: 121.07133, loss1: 0.88682, loss2_3: 120.18451\n",
      "\ttrain_acc: 0.7628, test_acc: \u001b[31m0.75915\u001b[0m, time: 36.37\n",
      "epoch: 26, loss: 120.95576, loss1: 0.88638, loss2_3: 120.06938\n",
      "\ttrain_acc: 0.7895, test_acc: \u001b[31m0.7897\u001b[0m, time: 36.44\n",
      "epoch: 27, loss: 120.30196, loss1: 0.87719, loss2_3: 119.42477\n",
      "\ttrain_acc: 0.7942, test_acc: \u001b[31m0.79155\u001b[0m, time: 36.40\n",
      "best_acc: 0.79155\n",
      "epoch: 28, loss: 120.06496, loss1: 0.87564, loss2_3: 119.18932\n",
      "\ttrain_acc: 0.7902, test_acc: \u001b[31m0.7908\u001b[0m, time: 36.42\n",
      "epoch: 29, loss: 120.12127, loss1: 0.87587, loss2_3: 119.24540\n",
      "\ttrain_acc: 0.7896, test_acc: \u001b[31m0.79\u001b[0m, time: 36.37\n",
      "epoch: 30, loss: 119.88354, loss1: 0.87763, loss2_3: 119.00590\n",
      "\ttrain_acc: 0.7888, test_acc: \u001b[31m0.7882\u001b[0m, time: 36.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31, loss: 119.70125, loss1: 0.87514, loss2_3: 118.82610\n",
      "\ttrain_acc: 0.7933, test_acc: \u001b[31m0.7924\u001b[0m, time: 36.35\n",
      "best_acc: 0.7924\n",
      "epoch: 32, loss: 119.62094, loss1: 0.87733, loss2_3: 118.74361\n",
      "\ttrain_acc: 0.7871, test_acc: \u001b[31m0.7875\u001b[0m, time: 36.42\n",
      "epoch: 33, loss: 119.13628, loss1: 0.87109, loss2_3: 118.26520\n",
      "\ttrain_acc: 0.7858, test_acc: \u001b[31m0.7845\u001b[0m, time: 36.34\n",
      "epoch: 34, loss: 119.02014, loss1: 0.86648, loss2_3: 118.15366\n",
      "\ttrain_acc: 0.7910, test_acc: \u001b[31m0.78905\u001b[0m, time: 36.38\n",
      "epoch: 35, loss: 118.96418, loss1: 0.87010, loss2_3: 118.09408\n",
      "\ttrain_acc: 0.7920, test_acc: \u001b[31m0.79135\u001b[0m, time: 36.36\n",
      "epoch: 36, loss: 119.02294, loss1: 0.87279, loss2_3: 118.15015\n",
      "\ttrain_acc: 0.7960, test_acc: \u001b[31m0.795\u001b[0m, time: 36.35\n",
      "best_acc: 0.795\n",
      "epoch: 37, loss: 118.34633, loss1: 0.87047, loss2_3: 117.47586\n",
      "\ttrain_acc: 0.7934, test_acc: \u001b[31m0.79235\u001b[0m, time: 36.36\n",
      "epoch: 38, loss: 118.67796, loss1: 0.86700, loss2_3: 117.81096\n",
      "\ttrain_acc: 0.7940, test_acc: \u001b[31m0.79365\u001b[0m, time: 36.34\n",
      "epoch: 39, loss: 118.67769, loss1: 0.86815, loss2_3: 117.80955\n",
      "\ttrain_acc: 0.7927, test_acc: \u001b[31m0.7903\u001b[0m, time: 36.34\n",
      "epoch: 40, loss: 118.27618, loss1: 0.86264, loss2_3: 117.41354\n",
      "\ttrain_acc: 0.7965, test_acc: \u001b[31m0.79465\u001b[0m, time: 36.38\n",
      "epoch: 41, loss: 118.26930, loss1: 0.85793, loss2_3: 117.41137\n",
      "\ttrain_acc: 0.7967, test_acc: \u001b[31m0.79685\u001b[0m, time: 36.35\n",
      "best_acc: 0.79685\n",
      "epoch: 42, loss: 118.01529, loss1: 0.86090, loss2_3: 117.15439\n",
      "\ttrain_acc: 0.7916, test_acc: \u001b[31m0.79065\u001b[0m, time: 36.37\n",
      "epoch: 43, loss: 118.21155, loss1: 0.86835, loss2_3: 117.34320\n",
      "\ttrain_acc: 0.7940, test_acc: \u001b[31m0.7928\u001b[0m, time: 36.36\n",
      "epoch: 44, loss: 117.61885, loss1: 0.86068, loss2_3: 116.75817\n",
      "\ttrain_acc: 0.7960, test_acc: \u001b[31m0.7943\u001b[0m, time: 36.35\n",
      "epoch: 45, loss: 117.82138, loss1: 0.85618, loss2_3: 116.96520\n",
      "\ttrain_acc: 0.7953, test_acc: \u001b[31m0.79495\u001b[0m, time: 36.32\n",
      "epoch: 46, loss: 117.40409, loss1: 0.86007, loss2_3: 116.54402\n",
      "\ttrain_acc: 0.7922, test_acc: \u001b[31m0.7915\u001b[0m, time: 36.36\n",
      "epoch: 47, loss: 117.23268, loss1: 0.85080, loss2_3: 116.38188\n",
      "\ttrain_acc: 0.7915, test_acc: \u001b[31m0.79055\u001b[0m, time: 36.30\n",
      "epoch: 48, loss: 117.42577, loss1: 0.85830, loss2_3: 116.56747\n",
      "\ttrain_acc: 0.7957, test_acc: \u001b[31m0.79565\u001b[0m, time: 36.35\n",
      "epoch: 49, loss: 117.23075, loss1: 0.85902, loss2_3: 116.37173\n",
      "\ttrain_acc: 0.7943, test_acc: \u001b[31m0.7936\u001b[0m, time: 36.28\n",
      "epoch: 50, loss: 117.06533, loss1: 0.85393, loss2_3: 116.21140\n",
      "\ttrain_acc: 0.7931, test_acc: \u001b[31m0.793\u001b[0m, time: 36.35\n",
      "epoch: 51, loss: 117.13460, loss1: 0.85418, loss2_3: 116.28042\n",
      "\ttrain_acc: 0.7946, test_acc: \u001b[31m0.79275\u001b[0m, time: 36.26\n",
      "epoch: 52, loss: 117.34731, loss1: 0.85613, loss2_3: 116.49119\n",
      "\ttrain_acc: 0.7956, test_acc: \u001b[31m0.7947\u001b[0m, time: 36.31\n",
      "epoch: 53, loss: 117.32313, loss1: 0.84942, loss2_3: 116.47371\n",
      "\ttrain_acc: 0.7961, test_acc: \u001b[31m0.79455\u001b[0m, time: 36.27\n",
      "epoch: 54, loss: 117.09398, loss1: 0.85157, loss2_3: 116.24241\n",
      "\ttrain_acc: 0.7985, test_acc: \u001b[31m0.7971\u001b[0m, time: 36.30\n",
      "best_acc: 0.7971\n",
      "epoch: 55, loss: 117.13358, loss1: 0.86111, loss2_3: 116.27247\n",
      "\ttrain_acc: 0.8003, test_acc: \u001b[31m0.7988\u001b[0m, time: 36.25\n",
      "best_acc: 0.7988\n",
      "epoch: 56, loss: 116.81998, loss1: 0.85551, loss2_3: 115.96448\n",
      "\ttrain_acc: 0.7980, test_acc: \u001b[31m0.7962\u001b[0m, time: 36.31\n",
      "epoch: 57, loss: 116.61963, loss1: 0.85148, loss2_3: 115.76815\n",
      "\ttrain_acc: 0.7947, test_acc: \u001b[31m0.7927\u001b[0m, time: 36.23\n",
      "epoch: 58, loss: 116.35948, loss1: 0.85396, loss2_3: 115.50552\n",
      "\ttrain_acc: 0.7971, test_acc: \u001b[31m0.79365\u001b[0m, time: 36.27\n",
      "epoch: 59, loss: 116.35168, loss1: 0.84769, loss2_3: 115.50399\n",
      "\ttrain_acc: 0.7999, test_acc: \u001b[31m0.79585\u001b[0m, time: 36.24\n",
      "epoch: 60, loss: 116.27757, loss1: 0.84507, loss2_3: 115.43250\n",
      "\ttrain_acc: 0.7975, test_acc: \u001b[31m0.79445\u001b[0m, time: 36.25\n",
      "epoch: 61, loss: 116.51116, loss1: 0.85294, loss2_3: 115.65822\n",
      "\ttrain_acc: 0.7977, test_acc: \u001b[31m0.79685\u001b[0m, time: 36.21\n",
      "epoch: 62, loss: 116.16657, loss1: 0.84696, loss2_3: 115.31962\n",
      "\ttrain_acc: 0.8013, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.25\n",
      "best_acc: 0.79965\n",
      "epoch: 63, loss: 115.97138, loss1: 0.85136, loss2_3: 115.12002\n",
      "\ttrain_acc: 0.8019, test_acc: \u001b[31m0.7982\u001b[0m, time: 36.23\n",
      "epoch: 64, loss: 115.90782, loss1: 0.85039, loss2_3: 115.05743\n",
      "\ttrain_acc: 0.7992, test_acc: \u001b[31m0.79505\u001b[0m, time: 36.24\n",
      "epoch: 65, loss: 116.36645, loss1: 0.84568, loss2_3: 115.52077\n",
      "\ttrain_acc: 0.8008, test_acc: \u001b[31m0.7979\u001b[0m, time: 36.21\n",
      "epoch: 66, loss: 115.86323, loss1: 0.85030, loss2_3: 115.01293\n",
      "\ttrain_acc: 0.7983, test_acc: \u001b[31m0.7969\u001b[0m, time: 36.23\n",
      "epoch: 67, loss: 115.69641, loss1: 0.85033, loss2_3: 114.84608\n",
      "\ttrain_acc: 0.8012, test_acc: \u001b[31m0.7991\u001b[0m, time: 36.21\n",
      "epoch: 68, loss: 115.51879, loss1: 0.84491, loss2_3: 114.67388\n",
      "\ttrain_acc: 0.8031, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.22\n",
      "best_acc: 0.80065\n",
      "epoch: 69, loss: 115.66703, loss1: 0.84888, loss2_3: 114.81815\n",
      "\ttrain_acc: 0.8023, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.22\n",
      "epoch: 70, loss: 115.48161, loss1: 0.84855, loss2_3: 114.63306\n",
      "\ttrain_acc: 0.8008, test_acc: \u001b[31m0.79875\u001b[0m, time: 36.28\n",
      "epoch: 71, loss: 115.34872, loss1: 0.84727, loss2_3: 114.50145\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.80165\u001b[0m, time: 36.22\n",
      "best_acc: 0.80165\n",
      "epoch: 72, loss: 115.65209, loss1: 0.84723, loss2_3: 114.80486\n",
      "\ttrain_acc: 0.8034, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.30\n",
      "epoch: 73, loss: 115.35353, loss1: 0.83678, loss2_3: 114.51676\n",
      "\ttrain_acc: 0.8027, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.22\n",
      "epoch: 74, loss: 115.77161, loss1: 0.84738, loss2_3: 114.92424\n",
      "\ttrain_acc: 0.8003, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.28\n",
      "epoch: 75, loss: 115.00661, loss1: 0.84008, loss2_3: 114.16653\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.25\n",
      "best_acc: 0.80235\n",
      "epoch: 76, loss: 115.06638, loss1: 0.83532, loss2_3: 114.23106\n",
      "\ttrain_acc: 0.8032, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.26\n",
      "epoch: 77, loss: 115.20467, loss1: 0.84207, loss2_3: 114.36260\n",
      "\ttrain_acc: 0.8022, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.23\n",
      "epoch: 78, loss: 115.36627, loss1: 0.83571, loss2_3: 114.53057\n",
      "\ttrain_acc: 0.8034, test_acc: \u001b[31m0.80075\u001b[0m, time: 36.28\n",
      "epoch: 79, loss: 115.39352, loss1: 0.84578, loss2_3: 114.54774\n",
      "\ttrain_acc: 0.8007, test_acc: \u001b[31m0.7963\u001b[0m, time: 36.22\n",
      "epoch: 80, loss: 114.98940, loss1: 0.84413, loss2_3: 114.14527\n",
      "\ttrain_acc: 0.8028, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.29\n",
      "epoch: 81, loss: 114.86679, loss1: 0.84192, loss2_3: 114.02487\n",
      "\ttrain_acc: 0.8000, test_acc: \u001b[31m0.79665\u001b[0m, time: 36.24\n",
      "epoch: 82, loss: 115.02817, loss1: 0.83902, loss2_3: 114.18915\n",
      "\ttrain_acc: 0.8026, test_acc: \u001b[31m0.79895\u001b[0m, time: 36.32\n",
      "epoch: 83, loss: 114.79846, loss1: 0.83806, loss2_3: 113.96040\n",
      "\ttrain_acc: 0.8014, test_acc: \u001b[31m0.79665\u001b[0m, time: 36.24\n",
      "epoch: 84, loss: 114.66457, loss1: 0.83810, loss2_3: 113.82647\n",
      "\ttrain_acc: 0.7997, test_acc: \u001b[31m0.7977\u001b[0m, time: 36.30\n",
      "epoch: 85, loss: 115.33012, loss1: 0.83935, loss2_3: 114.49077\n",
      "\ttrain_acc: 0.8037, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.26\n",
      "epoch: 86, loss: 114.63464, loss1: 0.83586, loss2_3: 113.79878\n",
      "\ttrain_acc: 0.8054, test_acc: \u001b[31m0.80265\u001b[0m, time: 36.28\n",
      "best_acc: 0.80265\n",
      "epoch: 87, loss: 114.65350, loss1: 0.83696, loss2_3: 113.81655\n",
      "\ttrain_acc: 0.8007, test_acc: \u001b[31m0.7972\u001b[0m, time: 36.23\n",
      "epoch: 88, loss: 114.46474, loss1: 0.84289, loss2_3: 113.62185\n",
      "\ttrain_acc: 0.8037, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.27\n",
      "epoch: 89, loss: 114.48500, loss1: 0.83909, loss2_3: 113.64591\n",
      "\ttrain_acc: 0.8067, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.23\n",
      "epoch: 90, loss: 114.23683, loss1: 0.83586, loss2_3: 113.40096\n",
      "\ttrain_acc: 0.8016, test_acc: \u001b[31m0.7992\u001b[0m, time: 36.23\n",
      "epoch: 91, loss: 114.40208, loss1: 0.83790, loss2_3: 113.56418\n",
      "\ttrain_acc: 0.8057, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.25\n",
      "epoch: 92, loss: 114.47812, loss1: 0.83710, loss2_3: 113.64102\n",
      "\ttrain_acc: 0.7994, test_acc: \u001b[31m0.796\u001b[0m, time: 36.22\n",
      "epoch: 93, loss: 113.79142, loss1: 0.82858, loss2_3: 112.96285\n",
      "\ttrain_acc: 0.8043, test_acc: \u001b[31m0.80075\u001b[0m, time: 36.22\n",
      "epoch: 94, loss: 113.99702, loss1: 0.83389, loss2_3: 113.16313\n",
      "\ttrain_acc: 0.8046, test_acc: \u001b[31m0.80225\u001b[0m, time: 36.25\n",
      "epoch: 95, loss: 113.94636, loss1: 0.83549, loss2_3: 113.11087\n",
      "\ttrain_acc: 0.8059, test_acc: \u001b[31m0.80335\u001b[0m, time: 36.23\n",
      "best_acc: 0.80335\n",
      "epoch: 96, loss: 114.24789, loss1: 0.83743, loss2_3: 113.41046\n",
      "\ttrain_acc: 0.8036, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 97, loss: 113.87403, loss1: 0.83511, loss2_3: 113.03891\n",
      "\ttrain_acc: 0.8057, test_acc: \u001b[31m0.8029\u001b[0m, time: 36.25\n",
      "epoch: 98, loss: 114.30896, loss1: 0.84103, loss2_3: 113.46793\n",
      "\ttrain_acc: 0.8055, test_acc: \u001b[31m0.80225\u001b[0m, time: 36.26\n",
      "epoch: 99, loss: 113.65236, loss1: 0.82609, loss2_3: 112.82627\n",
      "\ttrain_acc: 0.8052, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.26\n",
      "epoch: 100, loss: 113.47488, loss1: 0.82921, loss2_3: 112.64567\n",
      "\ttrain_acc: 0.8060, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.23\n",
      "epoch: 101, loss: 113.37569, loss1: 0.82528, loss2_3: 112.55041\n",
      "\ttrain_acc: 0.8048, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.25\n",
      "epoch: 102, loss: 113.50034, loss1: 0.83631, loss2_3: 112.66403\n",
      "\ttrain_acc: 0.8049, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.25\n",
      "epoch: 103, loss: 113.28999, loss1: 0.83219, loss2_3: 112.45780\n",
      "\ttrain_acc: 0.8059, test_acc: \u001b[31m0.8018\u001b[0m, time: 36.21\n",
      "epoch: 104, loss: 113.64028, loss1: 0.83062, loss2_3: 112.80966\n",
      "\ttrain_acc: 0.8053, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.28\n",
      "epoch: 105, loss: 113.45271, loss1: 0.82711, loss2_3: 112.62560\n",
      "\ttrain_acc: 0.8066, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.21\n",
      "epoch: 106, loss: 113.19944, loss1: 0.82686, loss2_3: 112.37258\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.27\n",
      "epoch: 107, loss: 113.31320, loss1: 0.82964, loss2_3: 112.48356\n",
      "\ttrain_acc: 0.8052, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.26\n",
      "epoch: 108, loss: 112.97516, loss1: 0.83010, loss2_3: 112.14506\n",
      "\ttrain_acc: 0.8081, test_acc: \u001b[31m0.80245\u001b[0m, time: 36.25\n",
      "epoch: 109, loss: 113.28900, loss1: 0.82970, loss2_3: 112.45931\n",
      "\ttrain_acc: 0.8026, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.26\n",
      "epoch: 110, loss: 112.90904, loss1: 0.82968, loss2_3: 112.07935\n",
      "\ttrain_acc: 0.8050, test_acc: \u001b[31m0.8009\u001b[0m, time: 36.30\n",
      "epoch: 111, loss: 113.11627, loss1: 0.83121, loss2_3: 112.28507\n",
      "\ttrain_acc: 0.8083, test_acc: \u001b[31m0.80165\u001b[0m, time: 36.27\n",
      "epoch: 112, loss: 112.93428, loss1: 0.83317, loss2_3: 112.10111\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.803\u001b[0m, time: 36.31\n",
      "epoch: 113, loss: 112.92762, loss1: 0.82274, loss2_3: 112.10489\n",
      "\ttrain_acc: 0.8073, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.27\n",
      "epoch: 114, loss: 113.18309, loss1: 0.82440, loss2_3: 112.35869\n",
      "\ttrain_acc: 0.7978, test_acc: \u001b[31m0.7901\u001b[0m, time: 36.27\n",
      "epoch: 115, loss: 113.05440, loss1: 0.82549, loss2_3: 112.22891\n",
      "\ttrain_acc: 0.8085, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.29\n",
      "epoch: 116, loss: 112.95269, loss1: 0.82659, loss2_3: 112.12610\n",
      "\ttrain_acc: 0.8082, test_acc: \u001b[31m0.80205\u001b[0m, time: 36.25\n",
      "epoch: 117, loss: 112.78241, loss1: 0.82266, loss2_3: 111.95975\n",
      "\ttrain_acc: 0.8044, test_acc: \u001b[31m0.79745\u001b[0m, time: 36.27\n",
      "epoch: 118, loss: 112.92804, loss1: 0.82897, loss2_3: 112.09906\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.25\n",
      "epoch: 119, loss: 112.62110, loss1: 0.82446, loss2_3: 111.79664\n",
      "\ttrain_acc: 0.8096, test_acc: \u001b[31m0.8037\u001b[0m, time: 36.24\n",
      "best_acc: 0.8037\n",
      "epoch: 120, loss: 112.53046, loss1: 0.82510, loss2_3: 111.70536\n",
      "\ttrain_acc: 0.8085, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.27\n",
      "epoch: 121, loss: 112.51817, loss1: 0.82396, loss2_3: 111.69421\n",
      "\ttrain_acc: 0.8053, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.25\n",
      "epoch: 122, loss: 112.57063, loss1: 0.81992, loss2_3: 111.75071\n",
      "\ttrain_acc: 0.8076, test_acc: \u001b[31m0.79865\u001b[0m, time: 36.25\n",
      "epoch: 123, loss: 112.44349, loss1: 0.82288, loss2_3: 111.62061\n",
      "\ttrain_acc: 0.8076, test_acc: \u001b[31m0.8\u001b[0m, time: 36.29\n",
      "epoch: 124, loss: 112.22307, loss1: 0.82692, loss2_3: 111.39614\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.27\n",
      "epoch: 125, loss: 112.08845, loss1: 0.82058, loss2_3: 111.26786\n",
      "\ttrain_acc: 0.8045, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.26\n",
      "epoch: 126, loss: 112.06150, loss1: 0.82454, loss2_3: 111.23696\n",
      "\ttrain_acc: 0.8098, test_acc: \u001b[31m0.8017\u001b[0m, time: 36.28\n",
      "epoch: 127, loss: 111.65795, loss1: 0.82214, loss2_3: 110.83581\n",
      "\ttrain_acc: 0.8047, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.25\n",
      "epoch: 128, loss: 111.86492, loss1: 0.82236, loss2_3: 111.04256\n",
      "\ttrain_acc: 0.8071, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.28\n",
      "epoch: 129, loss: 111.89587, loss1: 0.82165, loss2_3: 111.07422\n",
      "\ttrain_acc: 0.8094, test_acc: \u001b[31m0.8034\u001b[0m, time: 36.25\n",
      "epoch: 130, loss: 111.89545, loss1: 0.82244, loss2_3: 111.07300\n",
      "\ttrain_acc: 0.8061, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.25\n",
      "epoch: 131, loss: 111.78725, loss1: 0.82112, loss2_3: 110.96613\n",
      "\ttrain_acc: 0.8072, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.27\n",
      "epoch: 132, loss: 111.91664, loss1: 0.82362, loss2_3: 111.09302\n",
      "\ttrain_acc: 0.8085, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.24\n",
      "epoch: 133, loss: 111.59361, loss1: 0.81854, loss2_3: 110.77508\n",
      "\ttrain_acc: 0.8097, test_acc: \u001b[31m0.80165\u001b[0m, time: 36.27\n",
      "epoch: 134, loss: 111.45641, loss1: 0.81692, loss2_3: 110.63949\n",
      "\ttrain_acc: 0.8097, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.24\n",
      "epoch: 135, loss: 111.62064, loss1: 0.82033, loss2_3: 110.80031\n",
      "\ttrain_acc: 0.8098, test_acc: \u001b[31m0.8009\u001b[0m, time: 36.24\n",
      "epoch: 136, loss: 111.40666, loss1: 0.81768, loss2_3: 110.58897\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.27\n",
      "epoch: 137, loss: 111.15792, loss1: 0.81589, loss2_3: 110.34202\n",
      "\ttrain_acc: 0.8103, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.25\n",
      "epoch: 138, loss: 111.38336, loss1: 0.81859, loss2_3: 110.56477\n",
      "\ttrain_acc: 0.8099, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.27\n",
      "epoch: 139, loss: 111.35113, loss1: 0.81891, loss2_3: 110.53222\n",
      "\ttrain_acc: 0.8117, test_acc: \u001b[31m0.803\u001b[0m, time: 36.28\n",
      "epoch: 140, loss: 111.15103, loss1: 0.81703, loss2_3: 110.33400\n",
      "\ttrain_acc: 0.8096, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.27\n",
      "epoch: 141, loss: 111.14648, loss1: 0.81890, loss2_3: 110.32758\n",
      "\ttrain_acc: 0.8125, test_acc: \u001b[31m0.8036\u001b[0m, time: 36.24\n",
      "epoch: 142, loss: 110.96321, loss1: 0.81966, loss2_3: 110.14355\n",
      "\ttrain_acc: 0.8103, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.31\n",
      "epoch: 143, loss: 111.04902, loss1: 0.81533, loss2_3: 110.23369\n",
      "\ttrain_acc: 0.8114, test_acc: \u001b[31m0.80325\u001b[0m, time: 36.23\n",
      "epoch: 144, loss: 110.78792, loss1: 0.81757, loss2_3: 109.97035\n",
      "\ttrain_acc: 0.8116, test_acc: \u001b[31m0.8031\u001b[0m, time: 36.30\n",
      "epoch: 145, loss: 110.67301, loss1: 0.81136, loss2_3: 109.86166\n",
      "\ttrain_acc: 0.8108, test_acc: \u001b[31m0.801\u001b[0m, time: 36.21\n",
      "epoch: 146, loss: 110.70378, loss1: 0.81280, loss2_3: 109.89097\n",
      "\ttrain_acc: 0.8133, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.28\n",
      "epoch: 147, loss: 110.42408, loss1: 0.80952, loss2_3: 109.61456\n",
      "\ttrain_acc: 0.8108, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.20\n",
      "epoch: 148, loss: 110.53553, loss1: 0.81525, loss2_3: 109.72029\n",
      "\ttrain_acc: 0.8124, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.25\n",
      "epoch: 149, loss: 110.34718, loss1: 0.81564, loss2_3: 109.53154\n",
      "\ttrain_acc: 0.8099, test_acc: \u001b[31m0.7974\u001b[0m, time: 36.23\n",
      "epoch: 150, loss: 110.43489, loss1: 0.81360, loss2_3: 109.62130\n",
      "\ttrain_acc: 0.8116, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.26\n",
      "epoch: 151, loss: 110.21407, loss1: 0.81038, loss2_3: 109.40369\n",
      "\ttrain_acc: 0.8116, test_acc: \u001b[31m0.8001\u001b[0m, time: 36.23\n",
      "epoch: 152, loss: 110.26011, loss1: 0.81614, loss2_3: 109.44396\n",
      "\ttrain_acc: 0.8138, test_acc: \u001b[31m0.80205\u001b[0m, time: 36.31\n",
      "epoch: 153, loss: 110.17229, loss1: 0.81688, loss2_3: 109.35542\n",
      "\ttrain_acc: 0.8141, test_acc: \u001b[31m0.8028\u001b[0m, time: 36.23\n",
      "epoch: 154, loss: 109.87667, loss1: 0.81491, loss2_3: 109.06176\n",
      "\ttrain_acc: 0.8131, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.28\n",
      "epoch: 155, loss: 109.94388, loss1: 0.81154, loss2_3: 109.13234\n",
      "\ttrain_acc: 0.8135, test_acc: \u001b[31m0.80335\u001b[0m, time: 36.26\n",
      "epoch: 156, loss: 109.88151, loss1: 0.81623, loss2_3: 109.06528\n",
      "\ttrain_acc: 0.8109, test_acc: \u001b[31m0.8011\u001b[0m, time: 36.25\n",
      "epoch: 157, loss: 109.79521, loss1: 0.81117, loss2_3: 108.98404\n",
      "\ttrain_acc: 0.8127, test_acc: \u001b[31m0.80315\u001b[0m, time: 36.25\n",
      "epoch: 158, loss: 109.61360, loss1: 0.80905, loss2_3: 108.80455\n",
      "\ttrain_acc: 0.8088, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.27\n",
      "epoch: 159, loss: 109.69639, loss1: 0.81484, loss2_3: 108.88155\n",
      "\ttrain_acc: 0.8146, test_acc: \u001b[31m0.8042\u001b[0m, time: 36.24\n",
      "best_acc: 0.8042\n",
      "epoch: 160, loss: 109.55792, loss1: 0.81112, loss2_3: 108.74680\n",
      "\ttrain_acc: 0.8130, test_acc: \u001b[31m0.8009\u001b[0m, time: 36.26\n",
      "epoch: 161, loss: 109.49670, loss1: 0.81518, loss2_3: 108.68152\n",
      "\ttrain_acc: 0.8141, test_acc: \u001b[31m0.80285\u001b[0m, time: 36.24\n",
      "epoch: 162, loss: 109.34002, loss1: 0.81257, loss2_3: 108.52745\n",
      "\ttrain_acc: 0.8144, test_acc: \u001b[31m0.8038\u001b[0m, time: 36.26\n",
      "epoch: 163, loss: 109.19974, loss1: 0.81074, loss2_3: 108.38900\n",
      "\ttrain_acc: 0.8146, test_acc: \u001b[31m0.80405\u001b[0m, time: 36.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 164, loss: 109.14239, loss1: 0.81114, loss2_3: 108.33125\n",
      "\ttrain_acc: 0.8162, test_acc: \u001b[31m0.8025\u001b[0m, time: 36.23\n",
      "epoch: 165, loss: 109.25859, loss1: 0.80986, loss2_3: 108.44873\n",
      "\ttrain_acc: 0.8152, test_acc: \u001b[31m0.8043\u001b[0m, time: 36.26\n",
      "best_acc: 0.8043\n",
      "epoch: 166, loss: 108.81253, loss1: 0.80598, loss2_3: 108.00655\n",
      "\ttrain_acc: 0.8157, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.25\n",
      "epoch: 167, loss: 109.00570, loss1: 0.80892, loss2_3: 108.19678\n",
      "\ttrain_acc: 0.8137, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.24\n",
      "epoch: 168, loss: 108.75589, loss1: 0.80951, loss2_3: 107.94638\n",
      "\ttrain_acc: 0.8116, test_acc: \u001b[31m0.8001\u001b[0m, time: 36.28\n",
      "epoch: 169, loss: 108.66635, loss1: 0.80739, loss2_3: 107.85896\n",
      "\ttrain_acc: 0.8132, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.23\n",
      "epoch: 170, loss: 108.62761, loss1: 0.81017, loss2_3: 107.81745\n",
      "\ttrain_acc: 0.8148, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.28\n",
      "epoch: 171, loss: 108.59571, loss1: 0.81072, loss2_3: 107.78499\n",
      "\ttrain_acc: 0.8156, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.21\n",
      "epoch: 172, loss: 108.30903, loss1: 0.80388, loss2_3: 107.50516\n",
      "\ttrain_acc: 0.8138, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.24\n",
      "epoch: 173, loss: 108.53343, loss1: 0.80959, loss2_3: 107.72384\n",
      "\ttrain_acc: 0.8149, test_acc: \u001b[31m0.80245\u001b[0m, time: 36.20\n",
      "epoch: 174, loss: 108.54253, loss1: 0.80715, loss2_3: 107.73538\n",
      "\ttrain_acc: 0.8130, test_acc: \u001b[31m0.8003\u001b[0m, time: 36.27\n",
      "epoch: 175, loss: 108.41635, loss1: 0.80655, loss2_3: 107.60980\n",
      "\ttrain_acc: 0.8124, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.19\n",
      "epoch: 176, loss: 108.26703, loss1: 0.80854, loss2_3: 107.45849\n",
      "\ttrain_acc: 0.8180, test_acc: \u001b[31m0.80425\u001b[0m, time: 36.27\n",
      "epoch: 177, loss: 108.26503, loss1: 0.80424, loss2_3: 107.46079\n",
      "\ttrain_acc: 0.8185, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.20\n",
      "epoch: 178, loss: 108.26903, loss1: 0.81132, loss2_3: 107.45771\n",
      "\ttrain_acc: 0.8168, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.27\n",
      "epoch: 179, loss: 107.88313, loss1: 0.80513, loss2_3: 107.07800\n",
      "\ttrain_acc: 0.8177, test_acc: \u001b[31m0.802\u001b[0m, time: 36.20\n",
      "epoch: 180, loss: 107.69492, loss1: 0.80778, loss2_3: 106.88714\n",
      "\ttrain_acc: 0.8155, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.26\n",
      "epoch: 181, loss: 107.72972, loss1: 0.80870, loss2_3: 106.92101\n",
      "\ttrain_acc: 0.8198, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.63\n",
      "epoch: 182, loss: 107.97978, loss1: 0.80335, loss2_3: 107.17643\n",
      "\ttrain_acc: 0.8156, test_acc: \u001b[31m0.80105\u001b[0m, time: 37.35\n",
      "epoch: 183, loss: 107.41359, loss1: 0.80475, loss2_3: 106.60884\n",
      "\ttrain_acc: 0.8157, test_acc: \u001b[31m0.79995\u001b[0m, time: 37.32\n",
      "epoch: 184, loss: 107.44710, loss1: 0.80646, loss2_3: 106.64064\n",
      "\ttrain_acc: 0.8164, test_acc: \u001b[31m0.7982\u001b[0m, time: 36.82\n",
      "epoch: 185, loss: 107.27317, loss1: 0.80500, loss2_3: 106.46818\n",
      "\ttrain_acc: 0.8155, test_acc: \u001b[31m0.79795\u001b[0m, time: 36.21\n",
      "epoch: 186, loss: 107.55591, loss1: 0.80383, loss2_3: 106.75208\n",
      "\ttrain_acc: 0.8198, test_acc: \u001b[31m0.8012\u001b[0m, time: 36.27\n",
      "epoch: 187, loss: 107.17112, loss1: 0.80288, loss2_3: 106.36824\n",
      "\ttrain_acc: 0.8178, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.35\n",
      "epoch: 188, loss: 107.09993, loss1: 0.79927, loss2_3: 106.30066\n",
      "\ttrain_acc: 0.8198, test_acc: \u001b[31m0.80205\u001b[0m, time: 36.24\n",
      "epoch: 189, loss: 106.86952, loss1: 0.80705, loss2_3: 106.06247\n",
      "\ttrain_acc: 0.8219, test_acc: \u001b[31m0.8019\u001b[0m, time: 36.21\n",
      "epoch: 190, loss: 106.80237, loss1: 0.80755, loss2_3: 105.99482\n",
      "\ttrain_acc: 0.8216, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.25\n",
      "epoch: 191, loss: 106.87709, loss1: 0.80715, loss2_3: 106.06994\n",
      "\ttrain_acc: 0.8220, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.22\n",
      "epoch: 192, loss: 106.66697, loss1: 0.79916, loss2_3: 105.86781\n",
      "\ttrain_acc: 0.8186, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.24\n",
      "epoch: 193, loss: 106.73533, loss1: 0.79688, loss2_3: 105.93845\n",
      "\ttrain_acc: 0.8217, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.22\n",
      "epoch: 194, loss: 106.40618, loss1: 0.80278, loss2_3: 105.60340\n",
      "\ttrain_acc: 0.8131, test_acc: \u001b[31m0.79385\u001b[0m, time: 36.24\n",
      "epoch: 195, loss: 106.18592, loss1: 0.79458, loss2_3: 105.39133\n",
      "\ttrain_acc: 0.8219, test_acc: \u001b[31m0.802\u001b[0m, time: 36.26\n",
      "epoch: 196, loss: 106.07853, loss1: 0.80266, loss2_3: 105.27587\n",
      "\ttrain_acc: 0.8231, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.24\n",
      "epoch: 197, loss: 106.26337, loss1: 0.80294, loss2_3: 105.46044\n",
      "\ttrain_acc: 0.8169, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.23\n",
      "epoch: 198, loss: 105.93249, loss1: 0.80157, loss2_3: 105.13092\n",
      "\ttrain_acc: 0.8221, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.25\n",
      "epoch: 199, loss: 106.16949, loss1: 0.80224, loss2_3: 105.36725\n",
      "\ttrain_acc: 0.8234, test_acc: \u001b[31m0.8012\u001b[0m, time: 36.20\n",
      "epoch: 200, loss: 105.69004, loss1: 0.79651, loss2_3: 104.89352\n",
      "\ttrain_acc: 0.8226, test_acc: \u001b[31m0.80415\u001b[0m, time: 36.27\n",
      "epoch: 201, loss: 105.52191, loss1: 0.79623, loss2_3: 104.72567\n",
      "\ttrain_acc: 0.8252, test_acc: \u001b[31m0.8033\u001b[0m, time: 36.19\n",
      "epoch: 202, loss: 105.87742, loss1: 0.79883, loss2_3: 105.07859\n",
      "\ttrain_acc: 0.8228, test_acc: \u001b[31m0.8027\u001b[0m, time: 36.24\n",
      "epoch: 203, loss: 105.52718, loss1: 0.80100, loss2_3: 104.72618\n",
      "\ttrain_acc: 0.8233, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.21\n",
      "epoch: 204, loss: 105.35294, loss1: 0.79917, loss2_3: 104.55378\n",
      "\ttrain_acc: 0.8239, test_acc: \u001b[31m0.799\u001b[0m, time: 36.22\n",
      "epoch: 205, loss: 105.56320, loss1: 0.79442, loss2_3: 104.76878\n",
      "\ttrain_acc: 0.8238, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.18\n",
      "epoch: 206, loss: 105.11836, loss1: 0.79833, loss2_3: 104.32002\n",
      "\ttrain_acc: 0.8248, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.23\n",
      "epoch: 207, loss: 105.03277, loss1: 0.79693, loss2_3: 104.23584\n",
      "\ttrain_acc: 0.8235, test_acc: \u001b[31m0.79835\u001b[0m, time: 36.16\n",
      "epoch: 208, loss: 104.67829, loss1: 0.79412, loss2_3: 103.88417\n",
      "\ttrain_acc: 0.8260, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.22\n",
      "epoch: 209, loss: 105.04319, loss1: 0.79575, loss2_3: 104.24745\n",
      "\ttrain_acc: 0.8242, test_acc: \u001b[31m0.80385\u001b[0m, time: 36.17\n",
      "epoch: 210, loss: 105.20664, loss1: 0.79987, loss2_3: 104.40677\n",
      "\ttrain_acc: 0.8247, test_acc: \u001b[31m0.80325\u001b[0m, time: 36.20\n",
      "epoch: 211, loss: 104.93816, loss1: 0.79699, loss2_3: 104.14116\n",
      "\ttrain_acc: 0.8258, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.23\n",
      "epoch: 212, loss: 104.64086, loss1: 0.79404, loss2_3: 103.84683\n",
      "\ttrain_acc: 0.8242, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.21\n",
      "epoch: 213, loss: 104.82374, loss1: 0.79699, loss2_3: 104.02675\n",
      "\ttrain_acc: 0.8149, test_acc: \u001b[31m0.7905\u001b[0m, time: 36.22\n",
      "epoch: 214, loss: 104.46065, loss1: 0.79682, loss2_3: 103.66384\n",
      "\ttrain_acc: 0.8278, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.20\n",
      "epoch: 215, loss: 104.16998, loss1: 0.79928, loss2_3: 103.37071\n",
      "\ttrain_acc: 0.8263, test_acc: \u001b[31m0.7979\u001b[0m, time: 36.19\n",
      "epoch: 216, loss: 104.37007, loss1: 0.79646, loss2_3: 103.57361\n",
      "\ttrain_acc: 0.8234, test_acc: \u001b[31m0.8\u001b[0m, time: 36.21\n",
      "epoch: 217, loss: 104.42221, loss1: 0.79930, loss2_3: 103.62292\n",
      "\ttrain_acc: 0.8267, test_acc: \u001b[31m0.798\u001b[0m, time: 36.18\n",
      "epoch: 218, loss: 104.01575, loss1: 0.79174, loss2_3: 103.22401\n",
      "\ttrain_acc: 0.8298, test_acc: \u001b[31m0.7992\u001b[0m, time: 36.19\n",
      "epoch: 219, loss: 104.08728, loss1: 0.79671, loss2_3: 103.29057\n",
      "\ttrain_acc: 0.8249, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.17\n",
      "epoch: 220, loss: 104.15769, loss1: 0.79260, loss2_3: 103.36509\n",
      "\ttrain_acc: 0.8264, test_acc: \u001b[31m0.79505\u001b[0m, time: 36.19\n",
      "epoch: 221, loss: 104.14557, loss1: 0.79692, loss2_3: 103.34865\n",
      "\ttrain_acc: 0.8296, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.15\n",
      "epoch: 222, loss: 103.99755, loss1: 0.79143, loss2_3: 103.20612\n",
      "\ttrain_acc: 0.8284, test_acc: \u001b[31m0.797\u001b[0m, time: 36.22\n",
      "epoch: 223, loss: 103.47537, loss1: 0.78964, loss2_3: 102.68573\n",
      "\ttrain_acc: 0.8251, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.15\n",
      "epoch: 224, loss: 103.60509, loss1: 0.79141, loss2_3: 102.81368\n",
      "\ttrain_acc: 0.8244, test_acc: \u001b[31m0.79805\u001b[0m, time: 36.24\n",
      "epoch: 225, loss: 103.67147, loss1: 0.78946, loss2_3: 102.88201\n",
      "\ttrain_acc: 0.8304, test_acc: \u001b[31m0.79595\u001b[0m, time: 36.17\n",
      "epoch: 226, loss: 103.23177, loss1: 0.79130, loss2_3: 102.44046\n",
      "\ttrain_acc: 0.8263, test_acc: \u001b[31m0.79835\u001b[0m, time: 36.19\n",
      "epoch: 227, loss: 103.42702, loss1: 0.78803, loss2_3: 102.63899\n",
      "\ttrain_acc: 0.8296, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.23\n",
      "epoch: 228, loss: 103.18183, loss1: 0.78697, loss2_3: 102.39486\n",
      "\ttrain_acc: 0.8283, test_acc: \u001b[31m0.80075\u001b[0m, time: 36.19\n",
      "epoch: 229, loss: 103.42157, loss1: 0.79596, loss2_3: 102.62560\n",
      "\ttrain_acc: 0.8300, test_acc: \u001b[31m0.79865\u001b[0m, time: 36.21\n",
      "epoch: 230, loss: 103.01193, loss1: 0.79241, loss2_3: 102.21952\n",
      "\ttrain_acc: 0.8254, test_acc: \u001b[31m0.789\u001b[0m, time: 36.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 231, loss: 103.09965, loss1: 0.79556, loss2_3: 102.30409\n",
      "\ttrain_acc: 0.8228, test_acc: \u001b[31m0.79655\u001b[0m, time: 36.18\n",
      "epoch: 232, loss: 102.80315, loss1: 0.78423, loss2_3: 102.01892\n",
      "\ttrain_acc: 0.8281, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.21\n",
      "epoch: 233, loss: 102.72218, loss1: 0.78945, loss2_3: 101.93273\n",
      "\ttrain_acc: 0.8344, test_acc: \u001b[31m0.7952\u001b[0m, time: 36.15\n",
      "epoch: 234, loss: 102.58321, loss1: 0.79152, loss2_3: 101.79168\n",
      "\ttrain_acc: 0.8270, test_acc: \u001b[31m0.7991\u001b[0m, time: 36.22\n",
      "epoch: 235, loss: 102.18960, loss1: 0.79248, loss2_3: 101.39712\n",
      "\ttrain_acc: 0.8328, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.20\n",
      "epoch: 236, loss: 102.20759, loss1: 0.78688, loss2_3: 101.42071\n",
      "\ttrain_acc: 0.8266, test_acc: \u001b[31m0.7974\u001b[0m, time: 36.22\n",
      "epoch: 237, loss: 102.54085, loss1: 0.78643, loss2_3: 101.75442\n",
      "\ttrain_acc: 0.8270, test_acc: \u001b[31m0.78815\u001b[0m, time: 36.17\n",
      "epoch: 238, loss: 102.39317, loss1: 0.78774, loss2_3: 101.60543\n",
      "\ttrain_acc: 0.8313, test_acc: \u001b[31m0.79715\u001b[0m, time: 36.25\n",
      "epoch: 239, loss: 102.24855, loss1: 0.78687, loss2_3: 101.46168\n",
      "\ttrain_acc: 0.8321, test_acc: \u001b[31m0.7941\u001b[0m, time: 36.19\n",
      "epoch: 240, loss: 101.83107, loss1: 0.78802, loss2_3: 101.04304\n",
      "\ttrain_acc: 0.8347, test_acc: \u001b[31m0.799\u001b[0m, time: 36.25\n",
      "epoch: 241, loss: 101.70792, loss1: 0.78551, loss2_3: 100.92241\n",
      "\ttrain_acc: 0.8359, test_acc: \u001b[31m0.7945\u001b[0m, time: 36.17\n",
      "epoch: 242, loss: 101.38967, loss1: 0.78622, loss2_3: 100.60344\n",
      "\ttrain_acc: 0.8345, test_acc: \u001b[31m0.79055\u001b[0m, time: 36.25\n",
      "epoch: 243, loss: 101.29618, loss1: 0.78741, loss2_3: 100.50877\n",
      "\ttrain_acc: 0.8358, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.17\n",
      "epoch: 244, loss: 101.09573, loss1: 0.77466, loss2_3: 100.32107\n",
      "\ttrain_acc: 0.8343, test_acc: \u001b[31m0.7985\u001b[0m, time: 36.22\n",
      "epoch: 245, loss: 101.00376, loss1: 0.78567, loss2_3: 100.21809\n",
      "\ttrain_acc: 0.8185, test_acc: \u001b[31m0.7923\u001b[0m, time: 36.19\n",
      "epoch: 246, loss: 101.35184, loss1: 0.77840, loss2_3: 100.57344\n",
      "\ttrain_acc: 0.8264, test_acc: \u001b[31m0.7976\u001b[0m, time: 36.21\n",
      "epoch: 247, loss: 100.87655, loss1: 0.78232, loss2_3: 100.09423\n",
      "\ttrain_acc: 0.8318, test_acc: \u001b[31m0.79845\u001b[0m, time: 36.17\n",
      "epoch: 248, loss: 101.15187, loss1: 0.78600, loss2_3: 100.36586\n",
      "\ttrain_acc: 0.8329, test_acc: \u001b[31m0.78545\u001b[0m, time: 36.23\n",
      "epoch: 249, loss: 100.72923, loss1: 0.77965, loss2_3: 99.94958\n",
      "\ttrain_acc: 0.8172, test_acc: \u001b[31m0.7709\u001b[0m, time: 36.16\n",
      "epoch: 250, loss: 100.82297, loss1: 0.78156, loss2_3: 100.04141\n",
      "\ttrain_acc: 0.8328, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.19\n",
      "epoch: 1, loss: 178.68089, loss1: 2.80529, loss2_3: 175.87560\n",
      "\ttrain_acc: 0.5554, test_acc: \u001b[31m0.5637\u001b[0m, time: 36.48\n",
      "best_acc: 0.5637\n",
      "epoch: 2, loss: 156.31172, loss1: 1.01173, loss2_3: 155.29998\n",
      "\ttrain_acc: 0.6748, test_acc: \u001b[31m0.67625\u001b[0m, time: 36.46\n",
      "best_acc: 0.67625\n",
      "epoch: 3, loss: 142.24267, loss1: 0.98597, loss2_3: 141.25670\n",
      "\ttrain_acc: 0.7257, test_acc: \u001b[31m0.7285\u001b[0m, time: 36.47\n",
      "best_acc: 0.7285\n",
      "epoch: 4, loss: 135.01066, loss1: 0.96565, loss2_3: 134.04501\n",
      "\ttrain_acc: 0.7373, test_acc: \u001b[31m0.72995\u001b[0m, time: 36.50\n",
      "best_acc: 0.72995\n",
      "epoch: 5, loss: 131.73592, loss1: 0.94885, loss2_3: 130.78707\n",
      "\ttrain_acc: 0.7641, test_acc: \u001b[31m0.76615\u001b[0m, time: 36.47\n",
      "best_acc: 0.76615\n",
      "epoch: 6, loss: 130.34437, loss1: 0.94348, loss2_3: 129.40089\n",
      "\ttrain_acc: 0.7668, test_acc: \u001b[31m0.76785\u001b[0m, time: 36.48\n",
      "best_acc: 0.76785\n",
      "epoch: 7, loss: 128.49602, loss1: 0.93092, loss2_3: 127.56510\n",
      "\ttrain_acc: 0.7607, test_acc: \u001b[31m0.7591\u001b[0m, time: 36.46\n",
      "epoch: 8, loss: 128.40690, loss1: 0.94004, loss2_3: 127.46685\n",
      "\ttrain_acc: 0.7669, test_acc: \u001b[31m0.767\u001b[0m, time: 36.47\n",
      "epoch: 9, loss: 126.00173, loss1: 0.92252, loss2_3: 125.07921\n",
      "\ttrain_acc: 0.7706, test_acc: \u001b[31m0.76965\u001b[0m, time: 36.45\n",
      "best_acc: 0.76965\n",
      "epoch: 10, loss: 125.55078, loss1: 0.91994, loss2_3: 124.63084\n",
      "\ttrain_acc: 0.7774, test_acc: \u001b[31m0.7775\u001b[0m, time: 36.44\n",
      "best_acc: 0.7775\n",
      "epoch: 11, loss: 124.52956, loss1: 0.91382, loss2_3: 123.61575\n",
      "\ttrain_acc: 0.7748, test_acc: \u001b[31m0.7752\u001b[0m, time: 36.48\n",
      "epoch: 12, loss: 124.00922, loss1: 0.90362, loss2_3: 123.10561\n",
      "\ttrain_acc: 0.7817, test_acc: \u001b[31m0.78125\u001b[0m, time: 36.45\n",
      "best_acc: 0.78125\n",
      "epoch: 13, loss: 124.35909, loss1: 0.90649, loss2_3: 123.45260\n",
      "\ttrain_acc: 0.7801, test_acc: \u001b[31m0.77625\u001b[0m, time: 36.44\n",
      "epoch: 14, loss: 123.86055, loss1: 0.90512, loss2_3: 122.95543\n",
      "\ttrain_acc: 0.7778, test_acc: \u001b[31m0.77655\u001b[0m, time: 36.45\n",
      "epoch: 15, loss: 123.64800, loss1: 0.89811, loss2_3: 122.74989\n",
      "\ttrain_acc: 0.7796, test_acc: \u001b[31m0.77795\u001b[0m, time: 36.43\n",
      "epoch: 16, loss: 122.86442, loss1: 0.90258, loss2_3: 121.96184\n",
      "\ttrain_acc: 0.7816, test_acc: \u001b[31m0.7827\u001b[0m, time: 36.45\n",
      "best_acc: 0.7827\n",
      "epoch: 17, loss: 122.37700, loss1: 0.89686, loss2_3: 121.48013\n",
      "\ttrain_acc: 0.7841, test_acc: \u001b[31m0.7827\u001b[0m, time: 36.49\n",
      "epoch: 18, loss: 122.09606, loss1: 0.89027, loss2_3: 121.20579\n",
      "\ttrain_acc: 0.7861, test_acc: \u001b[31m0.78715\u001b[0m, time: 36.47\n",
      "best_acc: 0.78715\n",
      "epoch: 19, loss: 121.46055, loss1: 0.88879, loss2_3: 120.57176\n",
      "\ttrain_acc: 0.7883, test_acc: \u001b[31m0.7863\u001b[0m, time: 36.46\n",
      "epoch: 20, loss: 121.12689, loss1: 0.88837, loss2_3: 120.23852\n",
      "\ttrain_acc: 0.7867, test_acc: \u001b[31m0.78685\u001b[0m, time: 36.47\n",
      "epoch: 21, loss: 121.19329, loss1: 0.88989, loss2_3: 120.30339\n",
      "\ttrain_acc: 0.7860, test_acc: \u001b[31m0.7837\u001b[0m, time: 36.43\n",
      "epoch: 22, loss: 120.94141, loss1: 0.88494, loss2_3: 120.05647\n",
      "\ttrain_acc: 0.7878, test_acc: \u001b[31m0.788\u001b[0m, time: 36.48\n",
      "best_acc: 0.788\n",
      "epoch: 23, loss: 120.43316, loss1: 0.88355, loss2_3: 119.54961\n",
      "\ttrain_acc: 0.7917, test_acc: \u001b[31m0.78895\u001b[0m, time: 36.47\n",
      "best_acc: 0.78895\n",
      "epoch: 24, loss: 121.18470, loss1: 0.88837, loss2_3: 120.29633\n",
      "\ttrain_acc: 0.7903, test_acc: \u001b[31m0.7904\u001b[0m, time: 36.47\n",
      "best_acc: 0.7904\n",
      "epoch: 25, loss: 119.87089, loss1: 0.87823, loss2_3: 118.99266\n",
      "\ttrain_acc: 0.7873, test_acc: \u001b[31m0.7883\u001b[0m, time: 36.42\n",
      "epoch: 26, loss: 120.46221, loss1: 0.88506, loss2_3: 119.57715\n",
      "\ttrain_acc: 0.7875, test_acc: \u001b[31m0.7872\u001b[0m, time: 36.44\n",
      "epoch: 27, loss: 119.68645, loss1: 0.87966, loss2_3: 118.80679\n",
      "\ttrain_acc: 0.7902, test_acc: \u001b[31m0.7907\u001b[0m, time: 36.67\n",
      "best_acc: 0.7907\n",
      "epoch: 28, loss: 119.84666, loss1: 0.88090, loss2_3: 118.96576\n",
      "\ttrain_acc: 0.7913, test_acc: \u001b[31m0.78935\u001b[0m, time: 37.45\n",
      "epoch: 29, loss: 119.38319, loss1: 0.87272, loss2_3: 118.51047\n",
      "\ttrain_acc: 0.7901, test_acc: \u001b[31m0.7906\u001b[0m, time: 37.45\n",
      "epoch: 30, loss: 119.55702, loss1: 0.88141, loss2_3: 118.67561\n",
      "\ttrain_acc: 0.7903, test_acc: \u001b[31m0.7879\u001b[0m, time: 37.47\n",
      "epoch: 31, loss: 118.83828, loss1: 0.87737, loss2_3: 117.96091\n",
      "\ttrain_acc: 0.7872, test_acc: \u001b[31m0.78715\u001b[0m, time: 37.44\n",
      "epoch: 32, loss: 119.10467, loss1: 0.87569, loss2_3: 118.22898\n",
      "\ttrain_acc: 0.7939, test_acc: \u001b[31m0.794\u001b[0m, time: 37.46\n",
      "best_acc: 0.794\n",
      "epoch: 33, loss: 118.96589, loss1: 0.87174, loss2_3: 118.09415\n",
      "\ttrain_acc: 0.7921, test_acc: \u001b[31m0.79085\u001b[0m, time: 37.45\n",
      "epoch: 34, loss: 118.67635, loss1: 0.86785, loss2_3: 117.80850\n",
      "\ttrain_acc: 0.7942, test_acc: \u001b[31m0.79215\u001b[0m, time: 37.44\n",
      "epoch: 35, loss: 118.78574, loss1: 0.87694, loss2_3: 117.90880\n",
      "\ttrain_acc: 0.7916, test_acc: \u001b[31m0.7901\u001b[0m, time: 37.45\n",
      "epoch: 36, loss: 118.40465, loss1: 0.87104, loss2_3: 117.53361\n",
      "\ttrain_acc: 0.7967, test_acc: \u001b[31m0.7947\u001b[0m, time: 37.45\n",
      "best_acc: 0.7947\n",
      "epoch: 37, loss: 118.13971, loss1: 0.86117, loss2_3: 117.27854\n",
      "\ttrain_acc: 0.7937, test_acc: \u001b[31m0.7923\u001b[0m, time: 36.56\n",
      "epoch: 38, loss: 118.36855, loss1: 0.86674, loss2_3: 117.50181\n",
      "\ttrain_acc: 0.7899, test_acc: \u001b[31m0.79015\u001b[0m, time: 36.44\n",
      "epoch: 39, loss: 118.39868, loss1: 0.87002, loss2_3: 117.52866\n",
      "\ttrain_acc: 0.7973, test_acc: \u001b[31m0.79705\u001b[0m, time: 36.40\n",
      "best_acc: 0.79705\n",
      "epoch: 40, loss: 118.42411, loss1: 0.87079, loss2_3: 117.55332\n",
      "\ttrain_acc: 0.7960, test_acc: \u001b[31m0.79595\u001b[0m, time: 36.42\n",
      "epoch: 41, loss: 117.65460, loss1: 0.86512, loss2_3: 116.78949\n",
      "\ttrain_acc: 0.7964, test_acc: \u001b[31m0.7954\u001b[0m, time: 36.37\n",
      "epoch: 42, loss: 117.78101, loss1: 0.86191, loss2_3: 116.91910\n",
      "\ttrain_acc: 0.7976, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.39\n",
      "epoch: 43, loss: 117.51960, loss1: 0.86831, loss2_3: 116.65129\n",
      "\ttrain_acc: 0.7922, test_acc: \u001b[31m0.79095\u001b[0m, time: 36.36\n",
      "epoch: 44, loss: 117.28460, loss1: 0.86204, loss2_3: 116.42256\n",
      "\ttrain_acc: 0.7883, test_acc: \u001b[31m0.7859\u001b[0m, time: 36.40\n",
      "epoch: 45, loss: 117.00550, loss1: 0.85967, loss2_3: 116.14583\n",
      "\ttrain_acc: 0.7939, test_acc: \u001b[31m0.7922\u001b[0m, time: 36.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46, loss: 117.35743, loss1: 0.86081, loss2_3: 116.49662\n",
      "\ttrain_acc: 0.7950, test_acc: \u001b[31m0.7949\u001b[0m, time: 36.43\n",
      "epoch: 47, loss: 116.94248, loss1: 0.85744, loss2_3: 116.08504\n",
      "\ttrain_acc: 0.7973, test_acc: \u001b[31m0.79555\u001b[0m, time: 36.37\n",
      "epoch: 48, loss: 117.76854, loss1: 0.86474, loss2_3: 116.90380\n",
      "\ttrain_acc: 0.7990, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.39\n",
      "best_acc: 0.79765\n",
      "epoch: 49, loss: 117.11386, loss1: 0.85550, loss2_3: 116.25836\n",
      "\ttrain_acc: 0.7975, test_acc: \u001b[31m0.79695\u001b[0m, time: 36.39\n",
      "epoch: 50, loss: 117.06362, loss1: 0.85991, loss2_3: 116.20370\n",
      "\ttrain_acc: 0.7983, test_acc: \u001b[31m0.799\u001b[0m, time: 36.38\n",
      "best_acc: 0.799\n",
      "epoch: 51, loss: 117.01552, loss1: 0.85469, loss2_3: 116.16082\n",
      "\ttrain_acc: 0.7965, test_acc: \u001b[31m0.7946\u001b[0m, time: 36.37\n",
      "epoch: 52, loss: 117.15135, loss1: 0.86097, loss2_3: 116.29038\n",
      "\ttrain_acc: 0.7963, test_acc: \u001b[31m0.7967\u001b[0m, time: 36.38\n",
      "epoch: 53, loss: 116.70837, loss1: 0.85774, loss2_3: 115.85063\n",
      "\ttrain_acc: 0.7940, test_acc: \u001b[31m0.79415\u001b[0m, time: 36.33\n",
      "epoch: 54, loss: 116.74509, loss1: 0.85989, loss2_3: 115.88520\n",
      "\ttrain_acc: 0.7964, test_acc: \u001b[31m0.7948\u001b[0m, time: 36.36\n",
      "epoch: 55, loss: 116.65290, loss1: 0.85960, loss2_3: 115.79330\n",
      "\ttrain_acc: 0.7977, test_acc: \u001b[31m0.79715\u001b[0m, time: 36.29\n",
      "epoch: 56, loss: 116.80512, loss1: 0.85144, loss2_3: 115.95368\n",
      "\ttrain_acc: 0.7969, test_acc: \u001b[31m0.7965\u001b[0m, time: 36.30\n",
      "epoch: 57, loss: 116.39891, loss1: 0.85384, loss2_3: 115.54507\n",
      "\ttrain_acc: 0.7959, test_acc: \u001b[31m0.79605\u001b[0m, time: 36.32\n",
      "epoch: 58, loss: 116.61926, loss1: 0.85239, loss2_3: 115.76687\n",
      "\ttrain_acc: 0.7976, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.29\n",
      "epoch: 59, loss: 116.31881, loss1: 0.85660, loss2_3: 115.46221\n",
      "\ttrain_acc: 0.8001, test_acc: \u001b[31m0.7975\u001b[0m, time: 36.31\n",
      "epoch: 60, loss: 116.48437, loss1: 0.86123, loss2_3: 115.62314\n",
      "\ttrain_acc: 0.7984, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.29\n",
      "epoch: 61, loss: 116.37018, loss1: 0.84907, loss2_3: 115.52111\n",
      "\ttrain_acc: 0.7982, test_acc: \u001b[31m0.79805\u001b[0m, time: 36.28\n",
      "epoch: 62, loss: 116.18896, loss1: 0.85401, loss2_3: 115.33495\n",
      "\ttrain_acc: 0.7995, test_acc: \u001b[31m0.7966\u001b[0m, time: 36.31\n",
      "epoch: 63, loss: 116.20310, loss1: 0.84372, loss2_3: 115.35938\n",
      "\ttrain_acc: 0.8004, test_acc: \u001b[31m0.8\u001b[0m, time: 36.26\n",
      "best_acc: 0.8\n",
      "epoch: 64, loss: 116.13195, loss1: 0.84484, loss2_3: 115.28711\n",
      "\ttrain_acc: 0.7967, test_acc: \u001b[31m0.79435\u001b[0m, time: 36.27\n",
      "epoch: 65, loss: 116.24724, loss1: 0.84475, loss2_3: 115.40249\n",
      "\ttrain_acc: 0.7978, test_acc: \u001b[31m0.79585\u001b[0m, time: 36.27\n",
      "epoch: 66, loss: 115.57012, loss1: 0.84388, loss2_3: 114.72625\n",
      "\ttrain_acc: 0.8000, test_acc: \u001b[31m0.79745\u001b[0m, time: 36.25\n",
      "epoch: 67, loss: 115.90522, loss1: 0.84781, loss2_3: 115.05741\n",
      "\ttrain_acc: 0.8002, test_acc: \u001b[31m0.79865\u001b[0m, time: 36.23\n",
      "epoch: 68, loss: 116.11858, loss1: 0.84980, loss2_3: 115.26878\n",
      "\ttrain_acc: 0.8014, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.29\n",
      "best_acc: 0.8002\n",
      "epoch: 69, loss: 115.60133, loss1: 0.84364, loss2_3: 114.75768\n",
      "\ttrain_acc: 0.7970, test_acc: \u001b[31m0.7953\u001b[0m, time: 36.24\n",
      "epoch: 70, loss: 115.52611, loss1: 0.84071, loss2_3: 114.68541\n",
      "\ttrain_acc: 0.7968, test_acc: \u001b[31m0.79355\u001b[0m, time: 36.28\n",
      "epoch: 71, loss: 115.26848, loss1: 0.84392, loss2_3: 114.42456\n",
      "\ttrain_acc: 0.8008, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.22\n",
      "best_acc: 0.80025\n",
      "epoch: 72, loss: 115.29909, loss1: 0.84556, loss2_3: 114.45353\n",
      "\ttrain_acc: 0.8000, test_acc: \u001b[31m0.7978\u001b[0m, time: 36.27\n",
      "epoch: 73, loss: 115.44367, loss1: 0.84535, loss2_3: 114.59833\n",
      "\ttrain_acc: 0.7998, test_acc: \u001b[31m0.7971\u001b[0m, time: 36.26\n",
      "epoch: 74, loss: 115.07618, loss1: 0.84693, loss2_3: 114.22925\n",
      "\ttrain_acc: 0.7959, test_acc: \u001b[31m0.79405\u001b[0m, time: 36.27\n",
      "epoch: 75, loss: 115.49056, loss1: 0.83555, loss2_3: 114.65501\n",
      "\ttrain_acc: 0.7973, test_acc: \u001b[31m0.79735\u001b[0m, time: 36.29\n",
      "epoch: 76, loss: 115.38607, loss1: 0.84169, loss2_3: 114.54438\n",
      "\ttrain_acc: 0.8006, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.59\n",
      "epoch: 77, loss: 115.16808, loss1: 0.84058, loss2_3: 114.32750\n",
      "\ttrain_acc: 0.7943, test_acc: \u001b[31m0.79375\u001b[0m, time: 36.41\n",
      "epoch: 78, loss: 115.37170, loss1: 0.84255, loss2_3: 114.52915\n",
      "\ttrain_acc: 0.7991, test_acc: \u001b[31m0.79525\u001b[0m, time: 36.30\n",
      "epoch: 79, loss: 115.38500, loss1: 0.84461, loss2_3: 114.54039\n",
      "\ttrain_acc: 0.8013, test_acc: \u001b[31m0.7983\u001b[0m, time: 36.22\n",
      "epoch: 80, loss: 114.73961, loss1: 0.84524, loss2_3: 113.89437\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.28\n",
      "best_acc: 0.8006\n",
      "epoch: 81, loss: 114.96384, loss1: 0.83916, loss2_3: 114.12468\n",
      "\ttrain_acc: 0.7986, test_acc: \u001b[31m0.7963\u001b[0m, time: 36.22\n",
      "epoch: 82, loss: 114.75817, loss1: 0.83938, loss2_3: 113.91879\n",
      "\ttrain_acc: 0.8030, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.23\n",
      "epoch: 83, loss: 115.48511, loss1: 0.84561, loss2_3: 114.63950\n",
      "\ttrain_acc: 0.8023, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.19\n",
      "epoch: 84, loss: 114.61071, loss1: 0.84002, loss2_3: 113.77069\n",
      "\ttrain_acc: 0.8041, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.25\n",
      "best_acc: 0.8013\n",
      "epoch: 85, loss: 114.28957, loss1: 0.83892, loss2_3: 113.45065\n",
      "\ttrain_acc: 0.8027, test_acc: \u001b[31m0.7995\u001b[0m, time: 36.29\n",
      "epoch: 86, loss: 114.51226, loss1: 0.84000, loss2_3: 113.67226\n",
      "\ttrain_acc: 0.7998, test_acc: \u001b[31m0.7972\u001b[0m, time: 36.34\n",
      "epoch: 87, loss: 114.76122, loss1: 0.84280, loss2_3: 113.91842\n",
      "\ttrain_acc: 0.8048, test_acc: \u001b[31m0.8028\u001b[0m, time: 36.28\n",
      "best_acc: 0.8028\n",
      "epoch: 88, loss: 114.51010, loss1: 0.83941, loss2_3: 113.67069\n",
      "\ttrain_acc: 0.8038, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.32\n",
      "epoch: 89, loss: 114.25776, loss1: 0.83789, loss2_3: 113.41987\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.30\n",
      "epoch: 90, loss: 114.31516, loss1: 0.83213, loss2_3: 113.48303\n",
      "\ttrain_acc: 0.8046, test_acc: \u001b[31m0.8029\u001b[0m, time: 36.78\n",
      "best_acc: 0.8029\n",
      "epoch: 91, loss: 114.10440, loss1: 0.83443, loss2_3: 113.26997\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.8002\u001b[0m, time: 37.41\n",
      "epoch: 92, loss: 114.51582, loss1: 0.84082, loss2_3: 113.67500\n",
      "\ttrain_acc: 0.8062, test_acc: \u001b[31m0.80325\u001b[0m, time: 37.33\n",
      "best_acc: 0.80325\n",
      "epoch: 93, loss: 114.37700, loss1: 0.83762, loss2_3: 113.53937\n",
      "\ttrain_acc: 0.8047, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.51\n",
      "epoch: 94, loss: 114.06172, loss1: 0.83697, loss2_3: 113.22475\n",
      "\ttrain_acc: 0.8016, test_acc: \u001b[31m0.7972\u001b[0m, time: 36.32\n",
      "epoch: 95, loss: 113.89618, loss1: 0.83017, loss2_3: 113.06601\n",
      "\ttrain_acc: 0.8013, test_acc: \u001b[31m0.7977\u001b[0m, time: 36.27\n",
      "epoch: 96, loss: 113.98537, loss1: 0.83156, loss2_3: 113.15381\n",
      "\ttrain_acc: 0.8005, test_acc: \u001b[31m0.79615\u001b[0m, time: 36.30\n",
      "epoch: 97, loss: 113.87642, loss1: 0.83481, loss2_3: 113.04161\n",
      "\ttrain_acc: 0.8045, test_acc: \u001b[31m0.7999\u001b[0m, time: 36.28\n",
      "epoch: 98, loss: 113.94664, loss1: 0.83207, loss2_3: 113.11457\n",
      "\ttrain_acc: 0.8037, test_acc: \u001b[31m0.8001\u001b[0m, time: 36.43\n",
      "epoch: 99, loss: 113.70901, loss1: 0.83296, loss2_3: 112.87605\n",
      "\ttrain_acc: 0.7998, test_acc: \u001b[31m0.7958\u001b[0m, time: 36.60\n",
      "epoch: 100, loss: 113.78798, loss1: 0.83261, loss2_3: 112.95537\n",
      "\ttrain_acc: 0.8038, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.64\n",
      "epoch: 101, loss: 113.73713, loss1: 0.82814, loss2_3: 112.90899\n",
      "\ttrain_acc: 0.8033, test_acc: \u001b[31m0.79875\u001b[0m, time: 36.60\n",
      "epoch: 102, loss: 113.43156, loss1: 0.82640, loss2_3: 112.60516\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.65\n",
      "epoch: 103, loss: 113.58139, loss1: 0.83530, loss2_3: 112.74610\n",
      "\ttrain_acc: 0.8036, test_acc: \u001b[31m0.79745\u001b[0m, time: 36.62\n",
      "epoch: 104, loss: 113.66148, loss1: 0.82759, loss2_3: 112.83390\n",
      "\ttrain_acc: 0.8041, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.64\n",
      "epoch: 105, loss: 113.14948, loss1: 0.83416, loss2_3: 112.31533\n",
      "\ttrain_acc: 0.8033, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.65\n",
      "epoch: 106, loss: 113.37106, loss1: 0.82984, loss2_3: 112.54122\n",
      "\ttrain_acc: 0.8053, test_acc: \u001b[31m0.7993\u001b[0m, time: 36.42\n",
      "epoch: 107, loss: 112.88319, loss1: 0.82906, loss2_3: 112.05413\n",
      "\ttrain_acc: 0.8044, test_acc: \u001b[31m0.80015\u001b[0m, time: 37.40\n",
      "epoch: 108, loss: 112.91928, loss1: 0.82828, loss2_3: 112.09100\n",
      "\ttrain_acc: 0.8026, test_acc: \u001b[31m0.7963\u001b[0m, time: 37.32\n",
      "epoch: 109, loss: 113.17107, loss1: 0.83149, loss2_3: 112.33958\n",
      "\ttrain_acc: 0.8053, test_acc: \u001b[31m0.80025\u001b[0m, time: 37.35\n",
      "epoch: 110, loss: 113.21971, loss1: 0.83527, loss2_3: 112.38445\n",
      "\ttrain_acc: 0.8044, test_acc: \u001b[31m0.79995\u001b[0m, time: 37.33\n",
      "epoch: 111, loss: 112.75403, loss1: 0.82619, loss2_3: 111.92784\n",
      "\ttrain_acc: 0.8054, test_acc: \u001b[31m0.8006\u001b[0m, time: 37.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 112, loss: 112.64620, loss1: 0.82840, loss2_3: 111.81780\n",
      "\ttrain_acc: 0.8021, test_acc: \u001b[31m0.79765\u001b[0m, time: 37.30\n",
      "epoch: 113, loss: 112.64784, loss1: 0.82532, loss2_3: 111.82253\n",
      "\ttrain_acc: 0.8084, test_acc: \u001b[31m0.80165\u001b[0m, time: 36.65\n",
      "epoch: 114, loss: 112.62025, loss1: 0.82324, loss2_3: 111.79701\n",
      "\ttrain_acc: 0.8091, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.26\n",
      "epoch: 115, loss: 112.77412, loss1: 0.82509, loss2_3: 111.94903\n",
      "\ttrain_acc: 0.8061, test_acc: \u001b[31m0.80085\u001b[0m, time: 36.27\n",
      "epoch: 116, loss: 112.51144, loss1: 0.82734, loss2_3: 111.68410\n",
      "\ttrain_acc: 0.8077, test_acc: \u001b[31m0.8024\u001b[0m, time: 36.31\n",
      "epoch: 117, loss: 112.64294, loss1: 0.82426, loss2_3: 111.81868\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.27\n",
      "epoch: 118, loss: 112.38562, loss1: 0.82100, loss2_3: 111.56462\n",
      "\ttrain_acc: 0.8079, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.32\n",
      "epoch: 119, loss: 112.37515, loss1: 0.82210, loss2_3: 111.55305\n",
      "\ttrain_acc: 0.8082, test_acc: \u001b[31m0.80345\u001b[0m, time: 36.24\n",
      "best_acc: 0.80345\n",
      "epoch: 120, loss: 112.26277, loss1: 0.82251, loss2_3: 111.44026\n",
      "\ttrain_acc: 0.8077, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.30\n",
      "epoch: 121, loss: 112.33421, loss1: 0.82220, loss2_3: 111.51201\n",
      "\ttrain_acc: 0.8042, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.23\n",
      "epoch: 122, loss: 112.03813, loss1: 0.82228, loss2_3: 111.21586\n",
      "\ttrain_acc: 0.8077, test_acc: \u001b[31m0.8026\u001b[0m, time: 36.28\n",
      "epoch: 123, loss: 112.13526, loss1: 0.82444, loss2_3: 111.31082\n",
      "\ttrain_acc: 0.8094, test_acc: \u001b[31m0.8046\u001b[0m, time: 36.25\n",
      "best_acc: 0.8046\n",
      "epoch: 124, loss: 111.91098, loss1: 0.82723, loss2_3: 111.08375\n",
      "\ttrain_acc: 0.8095, test_acc: \u001b[31m0.80335\u001b[0m, time: 36.27\n",
      "epoch: 125, loss: 111.87826, loss1: 0.82241, loss2_3: 111.05585\n",
      "\ttrain_acc: 0.8030, test_acc: \u001b[31m0.79705\u001b[0m, time: 36.22\n",
      "epoch: 126, loss: 111.80667, loss1: 0.82036, loss2_3: 110.98631\n",
      "\ttrain_acc: 0.8049, test_acc: \u001b[31m0.7968\u001b[0m, time: 36.29\n",
      "epoch: 127, loss: 111.78685, loss1: 0.81807, loss2_3: 110.96878\n",
      "\ttrain_acc: 0.8067, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.22\n",
      "epoch: 128, loss: 111.91572, loss1: 0.81926, loss2_3: 111.09646\n",
      "\ttrain_acc: 0.8083, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.28\n",
      "epoch: 129, loss: 111.84139, loss1: 0.81533, loss2_3: 111.02606\n",
      "\ttrain_acc: 0.8080, test_acc: \u001b[31m0.8003\u001b[0m, time: 36.27\n",
      "epoch: 130, loss: 111.49011, loss1: 0.81887, loss2_3: 110.67125\n",
      "\ttrain_acc: 0.8072, test_acc: \u001b[31m0.801\u001b[0m, time: 36.28\n",
      "epoch: 131, loss: 111.64079, loss1: 0.81664, loss2_3: 110.82414\n",
      "\ttrain_acc: 0.8048, test_acc: \u001b[31m0.7974\u001b[0m, time: 36.27\n",
      "epoch: 132, loss: 111.55918, loss1: 0.81926, loss2_3: 110.73992\n",
      "\ttrain_acc: 0.8102, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.29\n",
      "epoch: 133, loss: 111.54031, loss1: 0.81665, loss2_3: 110.72366\n",
      "\ttrain_acc: 0.8028, test_acc: \u001b[31m0.79615\u001b[0m, time: 36.26\n",
      "epoch: 134, loss: 111.32849, loss1: 0.82177, loss2_3: 110.50671\n",
      "\ttrain_acc: 0.8085, test_acc: \u001b[31m0.8009\u001b[0m, time: 36.28\n",
      "epoch: 135, loss: 111.39828, loss1: 0.82056, loss2_3: 110.57772\n",
      "\ttrain_acc: 0.8095, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.26\n",
      "epoch: 136, loss: 111.21228, loss1: 0.81925, loss2_3: 110.39303\n",
      "\ttrain_acc: 0.8093, test_acc: \u001b[31m0.80315\u001b[0m, time: 36.25\n",
      "epoch: 137, loss: 111.23917, loss1: 0.81397, loss2_3: 110.42520\n",
      "\ttrain_acc: 0.8051, test_acc: \u001b[31m0.7975\u001b[0m, time: 36.28\n",
      "epoch: 138, loss: 110.93088, loss1: 0.81756, loss2_3: 110.11331\n",
      "\ttrain_acc: 0.8027, test_acc: \u001b[31m0.796\u001b[0m, time: 36.25\n",
      "epoch: 139, loss: 110.71052, loss1: 0.81825, loss2_3: 109.89227\n",
      "\ttrain_acc: 0.8091, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.27\n",
      "epoch: 140, loss: 110.86569, loss1: 0.81886, loss2_3: 110.04683\n",
      "\ttrain_acc: 0.8095, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.26\n",
      "epoch: 141, loss: 110.81659, loss1: 0.81685, loss2_3: 109.99974\n",
      "\ttrain_acc: 0.8079, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.26\n",
      "epoch: 142, loss: 111.13989, loss1: 0.81993, loss2_3: 110.31995\n",
      "\ttrain_acc: 0.8081, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.30\n",
      "epoch: 143, loss: 110.60916, loss1: 0.81247, loss2_3: 109.79669\n",
      "\ttrain_acc: 0.8085, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.26\n",
      "epoch: 144, loss: 110.47697, loss1: 0.81732, loss2_3: 109.65965\n",
      "\ttrain_acc: 0.8127, test_acc: \u001b[31m0.8028\u001b[0m, time: 36.29\n",
      "epoch: 145, loss: 110.43888, loss1: 0.81055, loss2_3: 109.62833\n",
      "\ttrain_acc: 0.8123, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.28\n",
      "epoch: 146, loss: 110.31449, loss1: 0.81813, loss2_3: 109.49636\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.80305\u001b[0m, time: 36.30\n",
      "epoch: 147, loss: 110.10097, loss1: 0.81909, loss2_3: 109.28188\n",
      "\ttrain_acc: 0.8066, test_acc: \u001b[31m0.7982\u001b[0m, time: 36.25\n",
      "epoch: 148, loss: 110.49692, loss1: 0.81329, loss2_3: 109.68363\n",
      "\ttrain_acc: 0.8112, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.32\n",
      "epoch: 149, loss: 110.06147, loss1: 0.81466, loss2_3: 109.24681\n",
      "\ttrain_acc: 0.8115, test_acc: \u001b[31m0.804\u001b[0m, time: 36.23\n",
      "epoch: 150, loss: 110.03707, loss1: 0.81481, loss2_3: 109.22226\n",
      "\ttrain_acc: 0.8108, test_acc: \u001b[31m0.80445\u001b[0m, time: 36.31\n",
      "epoch: 151, loss: 109.87606, loss1: 0.81720, loss2_3: 109.05887\n",
      "\ttrain_acc: 0.8105, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.22\n",
      "epoch: 152, loss: 109.77237, loss1: 0.82063, loss2_3: 108.95175\n",
      "\ttrain_acc: 0.8088, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.26\n",
      "epoch: 153, loss: 109.88077, loss1: 0.80958, loss2_3: 109.07119\n",
      "\ttrain_acc: 0.8032, test_acc: \u001b[31m0.79585\u001b[0m, time: 36.26\n",
      "epoch: 154, loss: 109.66760, loss1: 0.81733, loss2_3: 108.85027\n",
      "\ttrain_acc: 0.8138, test_acc: \u001b[31m0.8025\u001b[0m, time: 36.28\n",
      "epoch: 155, loss: 109.79686, loss1: 0.81501, loss2_3: 108.98185\n",
      "\ttrain_acc: 0.8146, test_acc: \u001b[31m0.8033\u001b[0m, time: 36.27\n",
      "epoch: 156, loss: 109.41437, loss1: 0.81300, loss2_3: 108.60138\n",
      "\ttrain_acc: 0.8143, test_acc: \u001b[31m0.8046\u001b[0m, time: 36.30\n",
      "epoch: 157, loss: 109.50733, loss1: 0.80625, loss2_3: 108.70108\n",
      "\ttrain_acc: 0.8132, test_acc: \u001b[31m0.80245\u001b[0m, time: 36.24\n",
      "epoch: 158, loss: 109.40865, loss1: 0.81404, loss2_3: 108.59462\n",
      "\ttrain_acc: 0.8142, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.31\n",
      "epoch: 159, loss: 109.37178, loss1: 0.81645, loss2_3: 108.55533\n",
      "\ttrain_acc: 0.8097, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.21\n",
      "epoch: 160, loss: 109.39715, loss1: 0.81043, loss2_3: 108.58672\n",
      "\ttrain_acc: 0.8046, test_acc: \u001b[31m0.79445\u001b[0m, time: 36.25\n",
      "epoch: 161, loss: 109.31442, loss1: 0.81169, loss2_3: 108.50272\n",
      "\ttrain_acc: 0.8156, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.23\n",
      "epoch: 162, loss: 109.21127, loss1: 0.81175, loss2_3: 108.39951\n",
      "\ttrain_acc: 0.8135, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.26\n",
      "epoch: 163, loss: 109.22319, loss1: 0.81151, loss2_3: 108.41168\n",
      "\ttrain_acc: 0.8138, test_acc: \u001b[31m0.80085\u001b[0m, time: 36.22\n",
      "epoch: 164, loss: 109.20785, loss1: 0.81218, loss2_3: 108.39568\n",
      "\ttrain_acc: 0.8149, test_acc: \u001b[31m0.80245\u001b[0m, time: 36.28\n",
      "epoch: 165, loss: 108.94658, loss1: 0.81107, loss2_3: 108.13550\n",
      "\ttrain_acc: 0.8170, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.22\n",
      "epoch: 166, loss: 108.96999, loss1: 0.81343, loss2_3: 108.15656\n",
      "\ttrain_acc: 0.8143, test_acc: \u001b[31m0.803\u001b[0m, time: 36.29\n",
      "epoch: 167, loss: 108.70312, loss1: 0.81403, loss2_3: 107.88909\n",
      "\ttrain_acc: 0.8146, test_acc: \u001b[31m0.8017\u001b[0m, time: 36.21\n",
      "epoch: 168, loss: 108.63630, loss1: 0.81040, loss2_3: 107.82590\n",
      "\ttrain_acc: 0.8097, test_acc: \u001b[31m0.7928\u001b[0m, time: 36.27\n",
      "epoch: 169, loss: 108.68479, loss1: 0.81387, loss2_3: 107.87092\n",
      "\ttrain_acc: 0.8130, test_acc: \u001b[31m0.8027\u001b[0m, time: 36.26\n",
      "epoch: 170, loss: 108.97751, loss1: 0.81228, loss2_3: 108.16523\n",
      "\ttrain_acc: 0.8178, test_acc: \u001b[31m0.8032\u001b[0m, time: 36.27\n",
      "epoch: 171, loss: 108.59438, loss1: 0.80547, loss2_3: 107.78891\n",
      "\ttrain_acc: 0.8144, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.24\n",
      "epoch: 172, loss: 108.41164, loss1: 0.80887, loss2_3: 107.60277\n",
      "\ttrain_acc: 0.8094, test_acc: \u001b[31m0.79665\u001b[0m, time: 36.25\n",
      "epoch: 173, loss: 108.10677, loss1: 0.80925, loss2_3: 107.29752\n",
      "\ttrain_acc: 0.8157, test_acc: \u001b[31m0.8019\u001b[0m, time: 36.22\n",
      "epoch: 174, loss: 108.31784, loss1: 0.80714, loss2_3: 107.51069\n",
      "\ttrain_acc: 0.8108, test_acc: \u001b[31m0.7991\u001b[0m, time: 36.25\n",
      "epoch: 175, loss: 108.06504, loss1: 0.80575, loss2_3: 107.25929\n",
      "\ttrain_acc: 0.8125, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.24\n",
      "epoch: 176, loss: 108.28167, loss1: 0.81022, loss2_3: 107.47145\n",
      "\ttrain_acc: 0.8165, test_acc: \u001b[31m0.80265\u001b[0m, time: 36.24\n",
      "epoch: 177, loss: 107.99635, loss1: 0.81192, loss2_3: 107.18442\n",
      "\ttrain_acc: 0.8190, test_acc: \u001b[31m0.8\u001b[0m, time: 36.27\n",
      "epoch: 178, loss: 107.67138, loss1: 0.80778, loss2_3: 106.86360\n",
      "\ttrain_acc: 0.8121, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 179, loss: 107.87598, loss1: 0.80417, loss2_3: 107.07181\n",
      "\ttrain_acc: 0.8180, test_acc: \u001b[31m0.8018\u001b[0m, time: 36.25\n",
      "epoch: 180, loss: 107.64654, loss1: 0.80358, loss2_3: 106.84296\n",
      "\ttrain_acc: 0.8159, test_acc: \u001b[31m0.80205\u001b[0m, time: 36.27\n",
      "epoch: 181, loss: 107.85815, loss1: 0.81006, loss2_3: 107.04810\n",
      "\ttrain_acc: 0.8115, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.23\n",
      "epoch: 182, loss: 107.34781, loss1: 0.80907, loss2_3: 106.53874\n",
      "\ttrain_acc: 0.8161, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.26\n",
      "epoch: 183, loss: 107.30671, loss1: 0.80523, loss2_3: 106.50148\n",
      "\ttrain_acc: 0.8184, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.24\n",
      "epoch: 184, loss: 107.12922, loss1: 0.80751, loss2_3: 106.32171\n",
      "\ttrain_acc: 0.8190, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.27\n",
      "epoch: 185, loss: 106.96401, loss1: 0.80353, loss2_3: 106.16048\n",
      "\ttrain_acc: 0.8206, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.26\n",
      "epoch: 186, loss: 107.24480, loss1: 0.80397, loss2_3: 106.44083\n",
      "\ttrain_acc: 0.8136, test_acc: \u001b[31m0.7986\u001b[0m, time: 36.26\n",
      "epoch: 187, loss: 107.11621, loss1: 0.80765, loss2_3: 106.30856\n",
      "\ttrain_acc: 0.8158, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.26\n",
      "epoch: 188, loss: 106.83629, loss1: 0.80333, loss2_3: 106.03296\n",
      "\ttrain_acc: 0.8176, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.25\n",
      "epoch: 189, loss: 107.09591, loss1: 0.80415, loss2_3: 106.29177\n",
      "\ttrain_acc: 0.8166, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.23\n",
      "epoch: 190, loss: 106.64868, loss1: 0.79864, loss2_3: 105.85003\n",
      "\ttrain_acc: 0.8173, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.26\n",
      "epoch: 191, loss: 106.55397, loss1: 0.80697, loss2_3: 105.74700\n",
      "\ttrain_acc: 0.8170, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.18\n",
      "epoch: 192, loss: 106.77601, loss1: 0.80506, loss2_3: 105.97095\n",
      "\ttrain_acc: 0.8203, test_acc: \u001b[31m0.80465\u001b[0m, time: 36.25\n",
      "best_acc: 0.80465\n",
      "epoch: 193, loss: 106.61576, loss1: 0.80049, loss2_3: 105.81527\n",
      "\ttrain_acc: 0.8173, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.23\n",
      "epoch: 194, loss: 106.17253, loss1: 0.80470, loss2_3: 105.36783\n",
      "\ttrain_acc: 0.8214, test_acc: \u001b[31m0.8004\u001b[0m, time: 36.26\n",
      "epoch: 195, loss: 106.53472, loss1: 0.80240, loss2_3: 105.73232\n",
      "\ttrain_acc: 0.8216, test_acc: \u001b[31m0.80415\u001b[0m, time: 36.22\n",
      "epoch: 196, loss: 106.24088, loss1: 0.80078, loss2_3: 105.44010\n",
      "\ttrain_acc: 0.8227, test_acc: \u001b[31m0.8037\u001b[0m, time: 36.29\n",
      "epoch: 197, loss: 106.37227, loss1: 0.80573, loss2_3: 105.56654\n",
      "\ttrain_acc: 0.8236, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.20\n",
      "epoch: 198, loss: 106.13887, loss1: 0.80391, loss2_3: 105.33496\n",
      "\ttrain_acc: 0.8172, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.27\n",
      "epoch: 199, loss: 106.26464, loss1: 0.80653, loss2_3: 105.45811\n",
      "\ttrain_acc: 0.8183, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.22\n",
      "epoch: 200, loss: 106.02713, loss1: 0.80255, loss2_3: 105.22458\n",
      "\ttrain_acc: 0.8177, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.25\n",
      "epoch: 201, loss: 105.72748, loss1: 0.80044, loss2_3: 104.92704\n",
      "\ttrain_acc: 0.8244, test_acc: \u001b[31m0.8038\u001b[0m, time: 36.23\n",
      "epoch: 202, loss: 105.48716, loss1: 0.79574, loss2_3: 104.69142\n",
      "\ttrain_acc: 0.8158, test_acc: \u001b[31m0.7982\u001b[0m, time: 36.22\n",
      "epoch: 203, loss: 105.43609, loss1: 0.80086, loss2_3: 104.63522\n",
      "\ttrain_acc: 0.8226, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.24\n",
      "epoch: 204, loss: 105.44045, loss1: 0.80017, loss2_3: 104.64028\n",
      "\ttrain_acc: 0.8135, test_acc: \u001b[31m0.79745\u001b[0m, time: 36.23\n",
      "epoch: 205, loss: 105.13886, loss1: 0.79837, loss2_3: 104.34049\n",
      "\ttrain_acc: 0.8231, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.24\n",
      "epoch: 206, loss: 105.52682, loss1: 0.79644, loss2_3: 104.73038\n",
      "\ttrain_acc: 0.8221, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.28\n",
      "epoch: 207, loss: 105.13289, loss1: 0.80022, loss2_3: 104.33268\n",
      "\ttrain_acc: 0.8228, test_acc: \u001b[31m0.8011\u001b[0m, time: 36.24\n",
      "epoch: 208, loss: 105.17720, loss1: 0.79829, loss2_3: 104.37890\n",
      "\ttrain_acc: 0.8248, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.25\n",
      "epoch: 209, loss: 105.04500, loss1: 0.80079, loss2_3: 104.24421\n",
      "\ttrain_acc: 0.8208, test_acc: \u001b[31m0.8\u001b[0m, time: 36.27\n",
      "epoch: 210, loss: 105.13145, loss1: 0.79795, loss2_3: 104.33350\n",
      "\ttrain_acc: 0.8232, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.23\n",
      "epoch: 211, loss: 105.11027, loss1: 0.79680, loss2_3: 104.31347\n",
      "\ttrain_acc: 0.8258, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.22\n",
      "epoch: 212, loss: 104.50932, loss1: 0.79545, loss2_3: 103.71387\n",
      "\ttrain_acc: 0.8134, test_acc: \u001b[31m0.79815\u001b[0m, time: 36.27\n",
      "epoch: 213, loss: 104.88847, loss1: 0.79982, loss2_3: 104.08865\n",
      "\ttrain_acc: 0.8216, test_acc: \u001b[31m0.8003\u001b[0m, time: 36.20\n",
      "epoch: 214, loss: 104.85316, loss1: 0.79524, loss2_3: 104.05792\n",
      "\ttrain_acc: 0.8251, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.26\n",
      "epoch: 215, loss: 104.35345, loss1: 0.79339, loss2_3: 103.56006\n",
      "\ttrain_acc: 0.8255, test_acc: \u001b[31m0.79865\u001b[0m, time: 36.19\n",
      "epoch: 216, loss: 104.16803, loss1: 0.79665, loss2_3: 103.37138\n",
      "\ttrain_acc: 0.8148, test_acc: \u001b[31m0.7985\u001b[0m, time: 36.27\n",
      "epoch: 217, loss: 104.27476, loss1: 0.79735, loss2_3: 103.47742\n",
      "\ttrain_acc: 0.8223, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.21\n",
      "epoch: 218, loss: 104.15111, loss1: 0.79451, loss2_3: 103.35660\n",
      "\ttrain_acc: 0.8253, test_acc: \u001b[31m0.80135\u001b[0m, time: 36.26\n",
      "epoch: 219, loss: 104.17704, loss1: 0.79892, loss2_3: 103.37812\n",
      "\ttrain_acc: 0.8264, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.24\n",
      "epoch: 220, loss: 104.13511, loss1: 0.79942, loss2_3: 103.33569\n",
      "\ttrain_acc: 0.8266, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.25\n",
      "epoch: 221, loss: 103.90834, loss1: 0.79705, loss2_3: 103.11129\n",
      "\ttrain_acc: 0.8271, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.21\n",
      "epoch: 222, loss: 103.59568, loss1: 0.79676, loss2_3: 102.79892\n",
      "\ttrain_acc: 0.8258, test_acc: \u001b[31m0.7991\u001b[0m, time: 36.25\n",
      "epoch: 223, loss: 103.86619, loss1: 0.79788, loss2_3: 103.06831\n",
      "\ttrain_acc: 0.8287, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.23\n",
      "epoch: 224, loss: 104.03109, loss1: 0.79990, loss2_3: 103.23119\n",
      "\ttrain_acc: 0.8090, test_acc: \u001b[31m0.7728\u001b[0m, time: 36.23\n",
      "epoch: 225, loss: 103.38208, loss1: 0.79743, loss2_3: 102.58466\n",
      "\ttrain_acc: 0.8210, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.25\n",
      "epoch: 226, loss: 103.30855, loss1: 0.79274, loss2_3: 102.51582\n",
      "\ttrain_acc: 0.8292, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.22\n",
      "epoch: 227, loss: 103.21665, loss1: 0.79470, loss2_3: 102.42195\n",
      "\ttrain_acc: 0.8233, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.22\n",
      "epoch: 228, loss: 103.24112, loss1: 0.79670, loss2_3: 102.44443\n",
      "\ttrain_acc: 0.8317, test_acc: \u001b[31m0.7967\u001b[0m, time: 36.26\n",
      "epoch: 229, loss: 103.11131, loss1: 0.79234, loss2_3: 102.31897\n",
      "\ttrain_acc: 0.8275, test_acc: \u001b[31m0.79485\u001b[0m, time: 36.23\n",
      "epoch: 230, loss: 102.98899, loss1: 0.79075, loss2_3: 102.19824\n",
      "\ttrain_acc: 0.8294, test_acc: \u001b[31m0.8012\u001b[0m, time: 36.27\n",
      "epoch: 231, loss: 102.94645, loss1: 0.79002, loss2_3: 102.15643\n",
      "\ttrain_acc: 0.8233, test_acc: \u001b[31m0.78485\u001b[0m, time: 36.23\n",
      "epoch: 232, loss: 102.85831, loss1: 0.79096, loss2_3: 102.06735\n",
      "\ttrain_acc: 0.8289, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.32\n",
      "epoch: 233, loss: 102.51229, loss1: 0.79323, loss2_3: 101.71906\n",
      "\ttrain_acc: 0.8320, test_acc: \u001b[31m0.7975\u001b[0m, time: 36.23\n",
      "epoch: 234, loss: 102.83080, loss1: 0.79332, loss2_3: 102.03748\n",
      "\ttrain_acc: 0.8227, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.24\n",
      "epoch: 235, loss: 102.41938, loss1: 0.78685, loss2_3: 101.63253\n",
      "\ttrain_acc: 0.8250, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.22\n",
      "epoch: 236, loss: 102.43587, loss1: 0.79125, loss2_3: 101.64462\n",
      "\ttrain_acc: 0.8229, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.25\n",
      "epoch: 237, loss: 102.23601, loss1: 0.78969, loss2_3: 101.44632\n",
      "\ttrain_acc: 0.8313, test_acc: \u001b[31m0.7927\u001b[0m, time: 36.18\n",
      "epoch: 238, loss: 102.13585, loss1: 0.79063, loss2_3: 101.34522\n",
      "\ttrain_acc: 0.8321, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.26\n",
      "epoch: 239, loss: 101.69263, loss1: 0.78669, loss2_3: 100.90594\n",
      "\ttrain_acc: 0.8253, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.18\n",
      "epoch: 240, loss: 101.78783, loss1: 0.78870, loss2_3: 100.99913\n",
      "\ttrain_acc: 0.8332, test_acc: \u001b[31m0.7944\u001b[0m, time: 36.24\n",
      "epoch: 241, loss: 101.79352, loss1: 0.78992, loss2_3: 101.00360\n",
      "\ttrain_acc: 0.8337, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.22\n",
      "epoch: 242, loss: 102.10623, loss1: 0.79313, loss2_3: 101.31310\n",
      "\ttrain_acc: 0.8277, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.25\n",
      "epoch: 243, loss: 101.30889, loss1: 0.78740, loss2_3: 100.52150\n",
      "\ttrain_acc: 0.8350, test_acc: \u001b[31m0.79835\u001b[0m, time: 36.20\n",
      "epoch: 244, loss: 101.79157, loss1: 0.78570, loss2_3: 101.00587\n",
      "\ttrain_acc: 0.8304, test_acc: \u001b[31m0.80275\u001b[0m, time: 36.26\n",
      "epoch: 245, loss: 101.27431, loss1: 0.78906, loss2_3: 100.48525\n",
      "\ttrain_acc: 0.8332, test_acc: \u001b[31m0.79795\u001b[0m, time: 36.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 246, loss: 101.30597, loss1: 0.79145, loss2_3: 100.51452\n",
      "\ttrain_acc: 0.8170, test_acc: \u001b[31m0.79515\u001b[0m, time: 36.26\n",
      "epoch: 247, loss: 101.32149, loss1: 0.78200, loss2_3: 100.53949\n",
      "\ttrain_acc: 0.8170, test_acc: \u001b[31m0.79235\u001b[0m, time: 36.19\n",
      "epoch: 248, loss: 101.07662, loss1: 0.78554, loss2_3: 100.29108\n",
      "\ttrain_acc: 0.8216, test_acc: \u001b[31m0.7969\u001b[0m, time: 36.21\n",
      "epoch: 249, loss: 100.72435, loss1: 0.78405, loss2_3: 99.94030\n",
      "\ttrain_acc: 0.8225, test_acc: \u001b[31m0.79805\u001b[0m, time: 36.23\n",
      "epoch: 250, loss: 101.07406, loss1: 0.78400, loss2_3: 100.29006\n",
      "\ttrain_acc: 0.8388, test_acc: \u001b[31m0.7995\u001b[0m, time: 36.20\n",
      "epoch: 1, loss: 183.08824, loss1: 2.66521, loss2_3: 180.42303\n",
      "\ttrain_acc: 0.5449, test_acc: \u001b[31m0.5449\u001b[0m, time: 36.45\n",
      "best_acc: 0.5449\n",
      "epoch: 2, loss: 174.77000, loss1: 1.02281, loss2_3: 173.74719\n",
      "\ttrain_acc: 0.5663, test_acc: \u001b[31m0.55425\u001b[0m, time: 36.45\n",
      "best_acc: 0.55425\n",
      "epoch: 3, loss: 170.17260, loss1: 1.02838, loss2_3: 169.14421\n",
      "\ttrain_acc: 0.6127, test_acc: \u001b[31m0.60915\u001b[0m, time: 36.42\n",
      "best_acc: 0.60915\n",
      "epoch: 4, loss: 149.29235, loss1: 1.00230, loss2_3: 148.29005\n",
      "\ttrain_acc: 0.7111, test_acc: \u001b[31m0.7087\u001b[0m, time: 36.49\n",
      "best_acc: 0.7087\n",
      "epoch: 5, loss: 135.62840, loss1: 0.97175, loss2_3: 134.65665\n",
      "\ttrain_acc: 0.7466, test_acc: \u001b[31m0.74625\u001b[0m, time: 36.45\n",
      "best_acc: 0.74625\n",
      "epoch: 6, loss: 131.50734, loss1: 0.94388, loss2_3: 130.56347\n",
      "\ttrain_acc: 0.7663, test_acc: \u001b[31m0.7625\u001b[0m, time: 36.50\n",
      "best_acc: 0.7625\n",
      "epoch: 7, loss: 129.97726, loss1: 0.94185, loss2_3: 129.03541\n",
      "\ttrain_acc: 0.7133, test_acc: \u001b[31m0.6929\u001b[0m, time: 36.49\n",
      "epoch: 8, loss: 128.41568, loss1: 0.93300, loss2_3: 127.48269\n",
      "\ttrain_acc: 0.7631, test_acc: \u001b[31m0.7631\u001b[0m, time: 36.49\n",
      "best_acc: 0.7631\n",
      "epoch: 9, loss: 127.63002, loss1: 0.92479, loss2_3: 126.70523\n",
      "\ttrain_acc: 0.7688, test_acc: \u001b[31m0.76585\u001b[0m, time: 36.45\n",
      "best_acc: 0.76585\n",
      "epoch: 10, loss: 125.93209, loss1: 0.92297, loss2_3: 125.00912\n",
      "\ttrain_acc: 0.7662, test_acc: \u001b[31m0.7627\u001b[0m, time: 36.50\n",
      "epoch: 11, loss: 126.31322, loss1: 0.92384, loss2_3: 125.38938\n",
      "\ttrain_acc: 0.7709, test_acc: \u001b[31m0.76915\u001b[0m, time: 36.43\n",
      "best_acc: 0.76915\n",
      "epoch: 12, loss: 124.41440, loss1: 0.91145, loss2_3: 123.50296\n",
      "\ttrain_acc: 0.7778, test_acc: \u001b[31m0.7792\u001b[0m, time: 36.52\n",
      "best_acc: 0.7792\n",
      "epoch: 13, loss: 124.33619, loss1: 0.90675, loss2_3: 123.42944\n",
      "\ttrain_acc: 0.7699, test_acc: \u001b[31m0.7698\u001b[0m, time: 36.42\n",
      "epoch: 14, loss: 123.99709, loss1: 0.91254, loss2_3: 123.08455\n",
      "\ttrain_acc: 0.7208, test_acc: \u001b[31m0.71305\u001b[0m, time: 36.49\n",
      "epoch: 15, loss: 123.55045, loss1: 0.90984, loss2_3: 122.64062\n",
      "\ttrain_acc: 0.7067, test_acc: \u001b[31m0.69665\u001b[0m, time: 36.43\n",
      "epoch: 16, loss: 123.01461, loss1: 0.90259, loss2_3: 122.11202\n",
      "\ttrain_acc: 0.7855, test_acc: \u001b[31m0.78525\u001b[0m, time: 36.46\n",
      "best_acc: 0.78525\n",
      "epoch: 17, loss: 122.59550, loss1: 0.89856, loss2_3: 121.69695\n",
      "\ttrain_acc: 0.7803, test_acc: \u001b[31m0.7767\u001b[0m, time: 36.43\n",
      "epoch: 18, loss: 122.34047, loss1: 0.89381, loss2_3: 121.44666\n",
      "\ttrain_acc: 0.7788, test_acc: \u001b[31m0.77615\u001b[0m, time: 36.48\n",
      "epoch: 19, loss: 122.33130, loss1: 0.89458, loss2_3: 121.43673\n",
      "\ttrain_acc: 0.7724, test_acc: \u001b[31m0.77035\u001b[0m, time: 36.43\n",
      "epoch: 20, loss: 122.01523, loss1: 0.89392, loss2_3: 121.12131\n",
      "\ttrain_acc: 0.7824, test_acc: \u001b[31m0.77925\u001b[0m, time: 36.51\n",
      "epoch: 21, loss: 122.24633, loss1: 0.88895, loss2_3: 121.35738\n",
      "\ttrain_acc: 0.7795, test_acc: \u001b[31m0.7776\u001b[0m, time: 36.42\n",
      "epoch: 22, loss: 121.33677, loss1: 0.88741, loss2_3: 120.44936\n",
      "\ttrain_acc: 0.7788, test_acc: \u001b[31m0.77135\u001b[0m, time: 36.46\n",
      "epoch: 23, loss: 121.35713, loss1: 0.89187, loss2_3: 120.46526\n",
      "\ttrain_acc: 0.7882, test_acc: \u001b[31m0.786\u001b[0m, time: 36.44\n",
      "best_acc: 0.786\n",
      "epoch: 24, loss: 121.10428, loss1: 0.88378, loss2_3: 120.22050\n",
      "\ttrain_acc: 0.7858, test_acc: \u001b[31m0.78315\u001b[0m, time: 36.43\n",
      "epoch: 25, loss: 120.85121, loss1: 0.87754, loss2_3: 119.97367\n",
      "\ttrain_acc: 0.7867, test_acc: \u001b[31m0.7863\u001b[0m, time: 36.41\n",
      "best_acc: 0.7863\n",
      "epoch: 26, loss: 120.83487, loss1: 0.88630, loss2_3: 119.94857\n",
      "\ttrain_acc: 0.7866, test_acc: \u001b[31m0.7858\u001b[0m, time: 36.45\n",
      "epoch: 27, loss: 120.55546, loss1: 0.88426, loss2_3: 119.67120\n",
      "\ttrain_acc: 0.7829, test_acc: \u001b[31m0.7823\u001b[0m, time: 36.40\n",
      "epoch: 28, loss: 120.15078, loss1: 0.88336, loss2_3: 119.26743\n",
      "\ttrain_acc: 0.7876, test_acc: \u001b[31m0.7873\u001b[0m, time: 36.45\n",
      "best_acc: 0.7873\n",
      "epoch: 29, loss: 120.05070, loss1: 0.88275, loss2_3: 119.16795\n",
      "\ttrain_acc: 0.7928, test_acc: \u001b[31m0.79215\u001b[0m, time: 36.41\n",
      "best_acc: 0.79215\n",
      "epoch: 30, loss: 119.59825, loss1: 0.87806, loss2_3: 118.72019\n",
      "\ttrain_acc: 0.7903, test_acc: \u001b[31m0.7873\u001b[0m, time: 36.44\n",
      "epoch: 31, loss: 119.79663, loss1: 0.87662, loss2_3: 118.92001\n",
      "\ttrain_acc: 0.7922, test_acc: \u001b[31m0.791\u001b[0m, time: 36.75\n",
      "epoch: 32, loss: 120.48872, loss1: 0.88298, loss2_3: 119.60573\n",
      "\ttrain_acc: 0.7897, test_acc: \u001b[31m0.7857\u001b[0m, time: 36.76\n",
      "epoch: 33, loss: 119.41313, loss1: 0.87472, loss2_3: 118.53840\n",
      "\ttrain_acc: 0.7920, test_acc: \u001b[31m0.7911\u001b[0m, time: 36.56\n",
      "epoch: 34, loss: 119.38882, loss1: 0.87881, loss2_3: 118.51001\n",
      "\ttrain_acc: 0.7877, test_acc: \u001b[31m0.786\u001b[0m, time: 36.43\n",
      "epoch: 35, loss: 119.20491, loss1: 0.87431, loss2_3: 118.33060\n",
      "\ttrain_acc: 0.7957, test_acc: \u001b[31m0.7945\u001b[0m, time: 36.39\n",
      "best_acc: 0.7945\n",
      "epoch: 36, loss: 118.66008, loss1: 0.87432, loss2_3: 117.78576\n",
      "\ttrain_acc: 0.7903, test_acc: \u001b[31m0.78975\u001b[0m, time: 36.42\n",
      "epoch: 37, loss: 119.00173, loss1: 0.86943, loss2_3: 118.13230\n",
      "\ttrain_acc: 0.7901, test_acc: \u001b[31m0.78755\u001b[0m, time: 36.37\n",
      "epoch: 38, loss: 118.77908, loss1: 0.86916, loss2_3: 117.90992\n",
      "\ttrain_acc: 0.7958, test_acc: \u001b[31m0.7946\u001b[0m, time: 36.38\n",
      "best_acc: 0.7946\n",
      "epoch: 39, loss: 118.48334, loss1: 0.86905, loss2_3: 117.61429\n",
      "\ttrain_acc: 0.7956, test_acc: \u001b[31m0.79295\u001b[0m, time: 36.38\n",
      "epoch: 40, loss: 118.46503, loss1: 0.86784, loss2_3: 117.59719\n",
      "\ttrain_acc: 0.7916, test_acc: \u001b[31m0.7906\u001b[0m, time: 36.37\n",
      "epoch: 41, loss: 118.00870, loss1: 0.86365, loss2_3: 117.14504\n",
      "\ttrain_acc: 0.7987, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.35\n",
      "best_acc: 0.79765\n",
      "epoch: 42, loss: 118.18323, loss1: 0.86470, loss2_3: 117.31853\n",
      "\ttrain_acc: 0.7941, test_acc: \u001b[31m0.79445\u001b[0m, time: 36.39\n",
      "epoch: 43, loss: 118.08579, loss1: 0.86625, loss2_3: 117.21954\n",
      "\ttrain_acc: 0.7926, test_acc: \u001b[31m0.79115\u001b[0m, time: 36.31\n",
      "epoch: 44, loss: 118.02464, loss1: 0.86260, loss2_3: 117.16204\n",
      "\ttrain_acc: 0.7995, test_acc: \u001b[31m0.79925\u001b[0m, time: 36.40\n",
      "best_acc: 0.79925\n",
      "epoch: 45, loss: 117.70353, loss1: 0.86477, loss2_3: 116.83876\n",
      "\ttrain_acc: 0.7906, test_acc: \u001b[31m0.79125\u001b[0m, time: 36.31\n",
      "epoch: 46, loss: 117.43413, loss1: 0.86023, loss2_3: 116.57390\n",
      "\ttrain_acc: 0.7979, test_acc: \u001b[31m0.79805\u001b[0m, time: 36.40\n",
      "epoch: 47, loss: 117.37406, loss1: 0.86549, loss2_3: 116.50857\n",
      "\ttrain_acc: 0.7952, test_acc: \u001b[31m0.7956\u001b[0m, time: 36.31\n",
      "epoch: 48, loss: 117.23772, loss1: 0.86105, loss2_3: 116.37667\n",
      "\ttrain_acc: 0.7980, test_acc: \u001b[31m0.79615\u001b[0m, time: 36.38\n",
      "epoch: 49, loss: 116.89618, loss1: 0.85578, loss2_3: 116.04039\n",
      "\ttrain_acc: 0.7944, test_acc: \u001b[31m0.7948\u001b[0m, time: 36.34\n",
      "epoch: 50, loss: 117.19425, loss1: 0.85956, loss2_3: 116.33469\n",
      "\ttrain_acc: 0.7984, test_acc: \u001b[31m0.7968\u001b[0m, time: 36.36\n",
      "epoch: 51, loss: 116.91342, loss1: 0.86537, loss2_3: 116.04805\n",
      "\ttrain_acc: 0.7977, test_acc: \u001b[31m0.7972\u001b[0m, time: 36.28\n",
      "epoch: 52, loss: 116.62563, loss1: 0.85543, loss2_3: 115.77020\n",
      "\ttrain_acc: 0.8016, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.34\n",
      "best_acc: 0.80015\n",
      "epoch: 53, loss: 116.30863, loss1: 0.86121, loss2_3: 115.44742\n",
      "\ttrain_acc: 0.7962, test_acc: \u001b[31m0.79375\u001b[0m, time: 36.28\n",
      "epoch: 54, loss: 116.39362, loss1: 0.86151, loss2_3: 115.53210\n",
      "\ttrain_acc: 0.7959, test_acc: \u001b[31m0.79335\u001b[0m, time: 36.27\n",
      "epoch: 55, loss: 116.46107, loss1: 0.85150, loss2_3: 115.60957\n",
      "\ttrain_acc: 0.7994, test_acc: \u001b[31m0.7973\u001b[0m, time: 36.26\n",
      "epoch: 56, loss: 116.44034, loss1: 0.85453, loss2_3: 115.58581\n",
      "\ttrain_acc: 0.8001, test_acc: \u001b[31m0.7986\u001b[0m, time: 36.23\n",
      "epoch: 57, loss: 115.90669, loss1: 0.85497, loss2_3: 115.05172\n",
      "\ttrain_acc: 0.7999, test_acc: \u001b[31m0.7975\u001b[0m, time: 36.23\n",
      "epoch: 58, loss: 116.42252, loss1: 0.85488, loss2_3: 115.56764\n",
      "\ttrain_acc: 0.7984, test_acc: \u001b[31m0.79555\u001b[0m, time: 36.26\n",
      "epoch: 59, loss: 116.37927, loss1: 0.84984, loss2_3: 115.52943\n",
      "\ttrain_acc: 0.7994, test_acc: \u001b[31m0.79655\u001b[0m, time: 36.22\n",
      "epoch: 60, loss: 116.20123, loss1: 0.85249, loss2_3: 115.34873\n",
      "\ttrain_acc: 0.8016, test_acc: \u001b[31m0.8011\u001b[0m, time: 36.26\n",
      "best_acc: 0.8011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 61, loss: 116.18953, loss1: 0.85160, loss2_3: 115.33793\n",
      "\ttrain_acc: 0.8016, test_acc: \u001b[31m0.79925\u001b[0m, time: 36.22\n",
      "epoch: 62, loss: 116.02106, loss1: 0.85096, loss2_3: 115.17010\n",
      "\ttrain_acc: 0.8011, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.28\n",
      "epoch: 63, loss: 115.82115, loss1: 0.85044, loss2_3: 114.97071\n",
      "\ttrain_acc: 0.7999, test_acc: \u001b[31m0.7978\u001b[0m, time: 36.21\n",
      "epoch: 64, loss: 115.63587, loss1: 0.84562, loss2_3: 114.79025\n",
      "\ttrain_acc: 0.8003, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.27\n",
      "epoch: 65, loss: 115.50891, loss1: 0.84796, loss2_3: 114.66095\n",
      "\ttrain_acc: 0.8008, test_acc: \u001b[31m0.79935\u001b[0m, time: 36.22\n",
      "epoch: 66, loss: 115.78509, loss1: 0.84696, loss2_3: 114.93813\n",
      "\ttrain_acc: 0.8011, test_acc: \u001b[31m0.79935\u001b[0m, time: 36.26\n",
      "epoch: 67, loss: 115.57004, loss1: 0.85077, loss2_3: 114.71927\n",
      "\ttrain_acc: 0.8019, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.18\n",
      "epoch: 68, loss: 115.56945, loss1: 0.85014, loss2_3: 114.71931\n",
      "\ttrain_acc: 0.8011, test_acc: \u001b[31m0.79925\u001b[0m, time: 36.27\n",
      "epoch: 69, loss: 115.48700, loss1: 0.84752, loss2_3: 114.63948\n",
      "\ttrain_acc: 0.7989, test_acc: \u001b[31m0.79575\u001b[0m, time: 36.19\n",
      "epoch: 70, loss: 115.48443, loss1: 0.84255, loss2_3: 114.64188\n",
      "\ttrain_acc: 0.8000, test_acc: \u001b[31m0.79925\u001b[0m, time: 36.25\n",
      "epoch: 71, loss: 115.50308, loss1: 0.84337, loss2_3: 114.65971\n",
      "\ttrain_acc: 0.8032, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.21\n",
      "epoch: 72, loss: 115.10907, loss1: 0.84431, loss2_3: 114.26476\n",
      "\ttrain_acc: 0.8041, test_acc: \u001b[31m0.801\u001b[0m, time: 36.24\n",
      "epoch: 73, loss: 115.37306, loss1: 0.84519, loss2_3: 114.52786\n",
      "\ttrain_acc: 0.8043, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.18\n",
      "best_acc: 0.8022\n",
      "epoch: 74, loss: 115.10608, loss1: 0.84524, loss2_3: 114.26084\n",
      "\ttrain_acc: 0.8043, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.26\n",
      "epoch: 75, loss: 115.06663, loss1: 0.84296, loss2_3: 114.22367\n",
      "\ttrain_acc: 0.8035, test_acc: \u001b[31m0.8009\u001b[0m, time: 36.21\n",
      "epoch: 76, loss: 114.93654, loss1: 0.84572, loss2_3: 114.09081\n",
      "\ttrain_acc: 0.8031, test_acc: \u001b[31m0.8009\u001b[0m, time: 36.27\n",
      "epoch: 77, loss: 114.84843, loss1: 0.84118, loss2_3: 114.00726\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.24\n",
      "epoch: 78, loss: 114.89635, loss1: 0.83696, loss2_3: 114.05939\n",
      "\ttrain_acc: 0.8022, test_acc: \u001b[31m0.79815\u001b[0m, time: 36.26\n",
      "epoch: 79, loss: 114.84044, loss1: 0.84546, loss2_3: 113.99499\n",
      "\ttrain_acc: 0.8042, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.26\n",
      "epoch: 80, loss: 114.71185, loss1: 0.84565, loss2_3: 113.86619\n",
      "\ttrain_acc: 0.8032, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.26\n",
      "epoch: 81, loss: 114.37692, loss1: 0.83901, loss2_3: 113.53790\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.801\u001b[0m, time: 36.25\n",
      "epoch: 82, loss: 114.84025, loss1: 0.83614, loss2_3: 114.00411\n",
      "\ttrain_acc: 0.8035, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.25\n",
      "epoch: 83, loss: 114.60843, loss1: 0.83817, loss2_3: 113.77027\n",
      "\ttrain_acc: 0.8047, test_acc: \u001b[31m0.8019\u001b[0m, time: 36.22\n",
      "epoch: 84, loss: 114.63614, loss1: 0.83627, loss2_3: 113.79987\n",
      "\ttrain_acc: 0.8038, test_acc: \u001b[31m0.80075\u001b[0m, time: 36.29\n",
      "epoch: 85, loss: 114.46615, loss1: 0.84145, loss2_3: 113.62471\n",
      "\ttrain_acc: 0.8030, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.22\n",
      "epoch: 86, loss: 114.31089, loss1: 0.83173, loss2_3: 113.47917\n",
      "\ttrain_acc: 0.8036, test_acc: \u001b[31m0.8\u001b[0m, time: 36.24\n",
      "epoch: 87, loss: 114.34336, loss1: 0.83726, loss2_3: 113.50610\n",
      "\ttrain_acc: 0.7992, test_acc: \u001b[31m0.79665\u001b[0m, time: 36.23\n",
      "epoch: 88, loss: 114.28480, loss1: 0.83808, loss2_3: 113.44671\n",
      "\ttrain_acc: 0.8049, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.27\n",
      "epoch: 89, loss: 114.02072, loss1: 0.83533, loss2_3: 113.18538\n",
      "\ttrain_acc: 0.8056, test_acc: \u001b[31m0.8029\u001b[0m, time: 36.21\n",
      "best_acc: 0.8029\n",
      "epoch: 90, loss: 114.06883, loss1: 0.83353, loss2_3: 113.23530\n",
      "\ttrain_acc: 0.8053, test_acc: \u001b[31m0.80245\u001b[0m, time: 36.31\n",
      "epoch: 91, loss: 114.31594, loss1: 0.83936, loss2_3: 113.47658\n",
      "\ttrain_acc: 0.8033, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.21\n",
      "epoch: 92, loss: 113.87463, loss1: 0.83586, loss2_3: 113.03877\n",
      "\ttrain_acc: 0.8045, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.30\n",
      "epoch: 93, loss: 113.90934, loss1: 0.83397, loss2_3: 113.07538\n",
      "\ttrain_acc: 0.8052, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.21\n",
      "epoch: 94, loss: 113.87176, loss1: 0.83111, loss2_3: 113.04065\n",
      "\ttrain_acc: 0.8058, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.26\n",
      "epoch: 95, loss: 113.55886, loss1: 0.83395, loss2_3: 112.72491\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.8024\u001b[0m, time: 36.23\n",
      "epoch: 96, loss: 113.43985, loss1: 0.82907, loss2_3: 112.61078\n",
      "\ttrain_acc: 0.8059, test_acc: \u001b[31m0.8036\u001b[0m, time: 36.24\n",
      "best_acc: 0.8036\n",
      "epoch: 97, loss: 113.81877, loss1: 0.83747, loss2_3: 112.98130\n",
      "\ttrain_acc: 0.8070, test_acc: \u001b[31m0.80265\u001b[0m, time: 36.25\n",
      "epoch: 98, loss: 113.58186, loss1: 0.82860, loss2_3: 112.75326\n",
      "\ttrain_acc: 0.8036, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.25\n",
      "epoch: 99, loss: 113.30082, loss1: 0.83382, loss2_3: 112.46700\n",
      "\ttrain_acc: 0.8070, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.24\n",
      "epoch: 100, loss: 113.35328, loss1: 0.83307, loss2_3: 112.52021\n",
      "\ttrain_acc: 0.8063, test_acc: \u001b[31m0.801\u001b[0m, time: 36.28\n",
      "epoch: 101, loss: 113.26897, loss1: 0.83177, loss2_3: 112.43720\n",
      "\ttrain_acc: 0.8030, test_acc: \u001b[31m0.7975\u001b[0m, time: 36.24\n",
      "epoch: 102, loss: 113.10319, loss1: 0.82767, loss2_3: 112.27553\n",
      "\ttrain_acc: 0.8071, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.25\n",
      "epoch: 103, loss: 113.15662, loss1: 0.83159, loss2_3: 112.32503\n",
      "\ttrain_acc: 0.8078, test_acc: \u001b[31m0.80145\u001b[0m, time: 36.25\n",
      "epoch: 104, loss: 112.90629, loss1: 0.82877, loss2_3: 112.07752\n",
      "\ttrain_acc: 0.8066, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.25\n",
      "epoch: 105, loss: 112.80905, loss1: 0.82953, loss2_3: 111.97952\n",
      "\ttrain_acc: 0.8067, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.22\n",
      "epoch: 106, loss: 112.99705, loss1: 0.82995, loss2_3: 112.16710\n",
      "\ttrain_acc: 0.8050, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.27\n",
      "epoch: 107, loss: 113.01079, loss1: 0.82950, loss2_3: 112.18129\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.21\n",
      "epoch: 108, loss: 112.76435, loss1: 0.82581, loss2_3: 111.93854\n",
      "\ttrain_acc: 0.8069, test_acc: \u001b[31m0.8029\u001b[0m, time: 36.26\n",
      "epoch: 109, loss: 112.87897, loss1: 0.82703, loss2_3: 112.05194\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.22\n",
      "epoch: 110, loss: 112.49858, loss1: 0.82910, loss2_3: 111.66949\n",
      "\ttrain_acc: 0.8063, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.25\n",
      "epoch: 111, loss: 112.69413, loss1: 0.82581, loss2_3: 111.86832\n",
      "\ttrain_acc: 0.8062, test_acc: \u001b[31m0.7992\u001b[0m, time: 36.27\n",
      "epoch: 112, loss: 112.16917, loss1: 0.82736, loss2_3: 111.34181\n",
      "\ttrain_acc: 0.8089, test_acc: \u001b[31m0.8032\u001b[0m, time: 36.25\n",
      "epoch: 113, loss: 112.34863, loss1: 0.82346, loss2_3: 111.52516\n",
      "\ttrain_acc: 0.8083, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.26\n",
      "epoch: 114, loss: 112.30332, loss1: 0.82560, loss2_3: 111.47773\n",
      "\ttrain_acc: 0.8080, test_acc: \u001b[31m0.8019\u001b[0m, time: 36.24\n",
      "epoch: 115, loss: 112.27710, loss1: 0.82274, loss2_3: 111.45437\n",
      "\ttrain_acc: 0.8095, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.20\n",
      "epoch: 116, loss: 112.13172, loss1: 0.82705, loss2_3: 111.30468\n",
      "\ttrain_acc: 0.8093, test_acc: \u001b[31m0.8034\u001b[0m, time: 36.23\n",
      "epoch: 117, loss: 111.98255, loss1: 0.82485, loss2_3: 111.15770\n",
      "\ttrain_acc: 0.8098, test_acc: \u001b[31m0.80315\u001b[0m, time: 36.21\n",
      "epoch: 118, loss: 111.92370, loss1: 0.82158, loss2_3: 111.10212\n",
      "\ttrain_acc: 0.8093, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.22\n",
      "epoch: 119, loss: 111.95554, loss1: 0.82691, loss2_3: 111.12863\n",
      "\ttrain_acc: 0.8094, test_acc: \u001b[31m0.8033\u001b[0m, time: 36.23\n",
      "epoch: 120, loss: 111.67148, loss1: 0.82247, loss2_3: 110.84901\n",
      "\ttrain_acc: 0.8100, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.22\n",
      "epoch: 121, loss: 111.73482, loss1: 0.82461, loss2_3: 110.91020\n",
      "\ttrain_acc: 0.8100, test_acc: \u001b[31m0.8024\u001b[0m, time: 36.21\n",
      "epoch: 122, loss: 111.63506, loss1: 0.82562, loss2_3: 110.80944\n",
      "\ttrain_acc: 0.8088, test_acc: \u001b[31m0.80205\u001b[0m, time: 36.26\n",
      "epoch: 123, loss: 111.37184, loss1: 0.81642, loss2_3: 110.55542\n",
      "\ttrain_acc: 0.8067, test_acc: \u001b[31m0.8\u001b[0m, time: 36.20\n",
      "epoch: 124, loss: 111.34959, loss1: 0.82208, loss2_3: 110.52751\n",
      "\ttrain_acc: 0.8102, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.26\n",
      "epoch: 125, loss: 111.50965, loss1: 0.82332, loss2_3: 110.68632\n",
      "\ttrain_acc: 0.8110, test_acc: \u001b[31m0.8027\u001b[0m, time: 36.21\n",
      "epoch: 126, loss: 111.48448, loss1: 0.82007, loss2_3: 110.66441\n",
      "\ttrain_acc: 0.8110, test_acc: \u001b[31m0.80475\u001b[0m, time: 36.25\n",
      "best_acc: 0.80475\n",
      "epoch: 127, loss: 111.07735, loss1: 0.81996, loss2_3: 110.25739\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 128, loss: 110.98756, loss1: 0.82116, loss2_3: 110.16640\n",
      "\ttrain_acc: 0.8117, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.19\n",
      "epoch: 129, loss: 110.72375, loss1: 0.81716, loss2_3: 109.90658\n",
      "\ttrain_acc: 0.8114, test_acc: \u001b[31m0.8032\u001b[0m, time: 36.30\n",
      "epoch: 130, loss: 111.01603, loss1: 0.81677, loss2_3: 110.19926\n",
      "\ttrain_acc: 0.8113, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.25\n",
      "epoch: 131, loss: 110.80747, loss1: 0.82235, loss2_3: 109.98512\n",
      "\ttrain_acc: 0.8109, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.24\n",
      "epoch: 132, loss: 110.76289, loss1: 0.82209, loss2_3: 109.94081\n",
      "\ttrain_acc: 0.8101, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.26\n",
      "epoch: 133, loss: 110.48849, loss1: 0.82046, loss2_3: 109.66803\n",
      "\ttrain_acc: 0.8099, test_acc: \u001b[31m0.8024\u001b[0m, time: 36.66\n",
      "epoch: 134, loss: 110.58053, loss1: 0.81487, loss2_3: 109.76565\n",
      "\ttrain_acc: 0.8108, test_acc: \u001b[31m0.8003\u001b[0m, time: 37.27\n",
      "epoch: 135, loss: 110.45133, loss1: 0.81521, loss2_3: 109.63612\n",
      "\ttrain_acc: 0.8118, test_acc: \u001b[31m0.8037\u001b[0m, time: 37.33\n",
      "epoch: 136, loss: 110.10092, loss1: 0.81844, loss2_3: 109.28248\n",
      "\ttrain_acc: 0.8129, test_acc: \u001b[31m0.8043\u001b[0m, time: 37.27\n",
      "epoch: 137, loss: 110.01628, loss1: 0.81878, loss2_3: 109.19750\n",
      "\ttrain_acc: 0.8102, test_acc: \u001b[31m0.8025\u001b[0m, time: 36.89\n",
      "epoch: 138, loss: 110.18544, loss1: 0.81652, loss2_3: 109.36892\n",
      "\ttrain_acc: 0.8103, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.23\n",
      "epoch: 139, loss: 109.96348, loss1: 0.81584, loss2_3: 109.14764\n",
      "\ttrain_acc: 0.8095, test_acc: \u001b[31m0.8\u001b[0m, time: 36.22\n",
      "epoch: 140, loss: 109.81908, loss1: 0.81797, loss2_3: 109.00111\n",
      "\ttrain_acc: 0.8141, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.23\n",
      "epoch: 141, loss: 109.56742, loss1: 0.81292, loss2_3: 108.75450\n",
      "\ttrain_acc: 0.8125, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.22\n",
      "epoch: 142, loss: 109.41939, loss1: 0.81340, loss2_3: 108.60599\n",
      "\ttrain_acc: 0.8143, test_acc: \u001b[31m0.80465\u001b[0m, time: 36.24\n",
      "epoch: 143, loss: 109.46301, loss1: 0.80870, loss2_3: 108.65431\n",
      "\ttrain_acc: 0.8140, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.23\n",
      "epoch: 144, loss: 109.53925, loss1: 0.81720, loss2_3: 108.72205\n",
      "\ttrain_acc: 0.8134, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.22\n",
      "epoch: 145, loss: 109.34470, loss1: 0.81611, loss2_3: 108.52860\n",
      "\ttrain_acc: 0.8145, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.23\n",
      "epoch: 146, loss: 109.39087, loss1: 0.81459, loss2_3: 108.57628\n",
      "\ttrain_acc: 0.8143, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.23\n",
      "epoch: 147, loss: 109.33346, loss1: 0.81302, loss2_3: 108.52044\n",
      "\ttrain_acc: 0.8156, test_acc: \u001b[31m0.80225\u001b[0m, time: 36.19\n",
      "epoch: 148, loss: 109.23474, loss1: 0.81513, loss2_3: 108.41961\n",
      "\ttrain_acc: 0.8157, test_acc: \u001b[31m0.8041\u001b[0m, time: 36.25\n",
      "epoch: 149, loss: 109.24537, loss1: 0.81305, loss2_3: 108.43232\n",
      "\ttrain_acc: 0.8148, test_acc: \u001b[31m0.8037\u001b[0m, time: 36.20\n",
      "epoch: 150, loss: 109.11708, loss1: 0.81432, loss2_3: 108.30275\n",
      "\ttrain_acc: 0.8135, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.22\n",
      "epoch: 151, loss: 108.68857, loss1: 0.81075, loss2_3: 107.87782\n",
      "\ttrain_acc: 0.8145, test_acc: \u001b[31m0.8027\u001b[0m, time: 36.21\n",
      "epoch: 152, loss: 108.59180, loss1: 0.81041, loss2_3: 107.78139\n",
      "\ttrain_acc: 0.8162, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.22\n",
      "epoch: 153, loss: 108.60475, loss1: 0.81019, loss2_3: 107.79455\n",
      "\ttrain_acc: 0.8113, test_acc: \u001b[31m0.80085\u001b[0m, time: 36.20\n",
      "epoch: 154, loss: 108.69180, loss1: 0.80913, loss2_3: 107.88267\n",
      "\ttrain_acc: 0.8155, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.27\n",
      "epoch: 155, loss: 108.29273, loss1: 0.81331, loss2_3: 107.47942\n",
      "\ttrain_acc: 0.8150, test_acc: \u001b[31m0.8\u001b[0m, time: 36.21\n",
      "epoch: 156, loss: 108.17025, loss1: 0.80435, loss2_3: 107.36590\n",
      "\ttrain_acc: 0.8135, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.26\n",
      "epoch: 157, loss: 108.36798, loss1: 0.81167, loss2_3: 107.55632\n",
      "\ttrain_acc: 0.8173, test_acc: \u001b[31m0.80315\u001b[0m, time: 36.20\n",
      "epoch: 158, loss: 108.02578, loss1: 0.81127, loss2_3: 107.21451\n",
      "\ttrain_acc: 0.8184, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.25\n",
      "epoch: 159, loss: 107.94303, loss1: 0.80999, loss2_3: 107.13304\n",
      "\ttrain_acc: 0.8197, test_acc: \u001b[31m0.80135\u001b[0m, time: 36.18\n",
      "epoch: 160, loss: 107.90082, loss1: 0.81070, loss2_3: 107.09012\n",
      "\ttrain_acc: 0.8177, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.21\n",
      "epoch: 161, loss: 107.80098, loss1: 0.80820, loss2_3: 106.99277\n",
      "\ttrain_acc: 0.8167, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.21\n",
      "epoch: 162, loss: 107.69986, loss1: 0.81330, loss2_3: 106.88656\n",
      "\ttrain_acc: 0.8186, test_acc: \u001b[31m0.8035\u001b[0m, time: 36.21\n",
      "epoch: 163, loss: 107.53587, loss1: 0.81005, loss2_3: 106.72582\n",
      "\ttrain_acc: 0.8179, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.21\n",
      "epoch: 164, loss: 107.50660, loss1: 0.80349, loss2_3: 106.70311\n",
      "\ttrain_acc: 0.8163, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.25\n",
      "epoch: 165, loss: 107.34537, loss1: 0.80714, loss2_3: 106.53823\n",
      "\ttrain_acc: 0.8203, test_acc: \u001b[31m0.802\u001b[0m, time: 36.22\n",
      "epoch: 166, loss: 107.40051, loss1: 0.81132, loss2_3: 106.58919\n",
      "\ttrain_acc: 0.8184, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.23\n",
      "epoch: 167, loss: 107.08934, loss1: 0.80729, loss2_3: 106.28205\n",
      "\ttrain_acc: 0.8192, test_acc: \u001b[31m0.8025\u001b[0m, time: 36.23\n",
      "epoch: 168, loss: 106.97194, loss1: 0.80560, loss2_3: 106.16634\n",
      "\ttrain_acc: 0.8198, test_acc: \u001b[31m0.79845\u001b[0m, time: 36.22\n",
      "epoch: 169, loss: 107.22362, loss1: 0.80571, loss2_3: 106.41792\n",
      "\ttrain_acc: 0.8206, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.20\n",
      "epoch: 170, loss: 106.68888, loss1: 0.80311, loss2_3: 105.88577\n",
      "\ttrain_acc: 0.8215, test_acc: \u001b[31m0.8028\u001b[0m, time: 36.24\n",
      "epoch: 171, loss: 106.59844, loss1: 0.80553, loss2_3: 105.79291\n",
      "\ttrain_acc: 0.8203, test_acc: \u001b[31m0.8025\u001b[0m, time: 36.19\n",
      "epoch: 172, loss: 106.60306, loss1: 0.80211, loss2_3: 105.80095\n",
      "\ttrain_acc: 0.8224, test_acc: \u001b[31m0.8019\u001b[0m, time: 36.22\n",
      "epoch: 173, loss: 106.37006, loss1: 0.80704, loss2_3: 105.56303\n",
      "\ttrain_acc: 0.8172, test_acc: \u001b[31m0.7983\u001b[0m, time: 36.20\n",
      "epoch: 174, loss: 106.47749, loss1: 0.80586, loss2_3: 105.67164\n",
      "\ttrain_acc: 0.8236, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.21\n",
      "epoch: 175, loss: 106.59140, loss1: 0.80637, loss2_3: 105.78503\n",
      "\ttrain_acc: 0.8215, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.24\n",
      "epoch: 176, loss: 106.11720, loss1: 0.80751, loss2_3: 105.30969\n",
      "\ttrain_acc: 0.8217, test_acc: \u001b[31m0.8024\u001b[0m, time: 36.22\n",
      "epoch: 177, loss: 105.86199, loss1: 0.80641, loss2_3: 105.05558\n",
      "\ttrain_acc: 0.8210, test_acc: \u001b[31m0.8019\u001b[0m, time: 36.23\n",
      "epoch: 178, loss: 105.64643, loss1: 0.80399, loss2_3: 104.84244\n",
      "\ttrain_acc: 0.8252, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.21\n",
      "epoch: 179, loss: 105.60710, loss1: 0.80559, loss2_3: 104.80150\n",
      "\ttrain_acc: 0.8210, test_acc: \u001b[31m0.80075\u001b[0m, time: 36.19\n",
      "epoch: 180, loss: 105.51732, loss1: 0.80392, loss2_3: 104.71340\n",
      "\ttrain_acc: 0.8239, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.22\n",
      "epoch: 181, loss: 105.61833, loss1: 0.80517, loss2_3: 104.81317\n",
      "\ttrain_acc: 0.8204, test_acc: \u001b[31m0.79875\u001b[0m, time: 36.18\n",
      "epoch: 182, loss: 105.34628, loss1: 0.80659, loss2_3: 104.53969\n",
      "\ttrain_acc: 0.8243, test_acc: \u001b[31m0.80245\u001b[0m, time: 36.21\n",
      "epoch: 183, loss: 105.10260, loss1: 0.80056, loss2_3: 104.30203\n",
      "\ttrain_acc: 0.8219, test_acc: \u001b[31m0.7993\u001b[0m, time: 36.20\n",
      "epoch: 184, loss: 105.26048, loss1: 0.80513, loss2_3: 104.45535\n",
      "\ttrain_acc: 0.8252, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.23\n",
      "epoch: 185, loss: 104.99823, loss1: 0.80143, loss2_3: 104.19680\n",
      "\ttrain_acc: 0.8256, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.19\n",
      "epoch: 186, loss: 104.79327, loss1: 0.80124, loss2_3: 103.99203\n",
      "\ttrain_acc: 0.8254, test_acc: \u001b[31m0.7972\u001b[0m, time: 36.28\n",
      "epoch: 187, loss: 104.71078, loss1: 0.79807, loss2_3: 103.91271\n",
      "\ttrain_acc: 0.8242, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.19\n",
      "epoch: 188, loss: 104.79805, loss1: 0.80382, loss2_3: 103.99423\n",
      "\ttrain_acc: 0.8262, test_acc: \u001b[31m0.7983\u001b[0m, time: 36.29\n",
      "epoch: 189, loss: 104.16373, loss1: 0.79754, loss2_3: 103.36618\n",
      "\ttrain_acc: 0.8264, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.18\n",
      "epoch: 190, loss: 104.29812, loss1: 0.79939, loss2_3: 103.49873\n",
      "\ttrain_acc: 0.8229, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.24\n",
      "epoch: 191, loss: 104.04475, loss1: 0.79345, loss2_3: 103.25130\n",
      "\ttrain_acc: 0.8268, test_acc: \u001b[31m0.7974\u001b[0m, time: 36.20\n",
      "epoch: 192, loss: 103.73162, loss1: 0.79586, loss2_3: 102.93575\n",
      "\ttrain_acc: 0.8289, test_acc: \u001b[31m0.7977\u001b[0m, time: 36.24\n",
      "epoch: 193, loss: 104.03019, loss1: 0.79765, loss2_3: 103.23254\n",
      "\ttrain_acc: 0.8257, test_acc: \u001b[31m0.79505\u001b[0m, time: 36.19\n",
      "epoch: 194, loss: 103.73823, loss1: 0.80387, loss2_3: 102.93436\n",
      "\ttrain_acc: 0.8305, test_acc: \u001b[31m0.80165\u001b[0m, time: 36.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 195, loss: 103.42527, loss1: 0.79538, loss2_3: 102.62989\n",
      "\ttrain_acc: 0.8281, test_acc: \u001b[31m0.80415\u001b[0m, time: 36.17\n",
      "epoch: 196, loss: 103.04881, loss1: 0.79457, loss2_3: 102.25424\n",
      "\ttrain_acc: 0.8248, test_acc: \u001b[31m0.7921\u001b[0m, time: 36.27\n",
      "epoch: 197, loss: 103.03064, loss1: 0.79597, loss2_3: 102.23467\n",
      "\ttrain_acc: 0.8292, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.19\n",
      "epoch: 198, loss: 103.09066, loss1: 0.79502, loss2_3: 102.29564\n",
      "\ttrain_acc: 0.8315, test_acc: \u001b[31m0.7991\u001b[0m, time: 36.25\n",
      "epoch: 199, loss: 102.77282, loss1: 0.79482, loss2_3: 101.97800\n",
      "\ttrain_acc: 0.8325, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.21\n",
      "epoch: 200, loss: 102.52502, loss1: 0.79441, loss2_3: 101.73062\n",
      "\ttrain_acc: 0.8307, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.24\n",
      "epoch: 201, loss: 102.34659, loss1: 0.79410, loss2_3: 101.55249\n",
      "\ttrain_acc: 0.8301, test_acc: \u001b[31m0.8018\u001b[0m, time: 36.19\n",
      "epoch: 202, loss: 102.14450, loss1: 0.79427, loss2_3: 101.35023\n",
      "\ttrain_acc: 0.8334, test_acc: \u001b[31m0.8017\u001b[0m, time: 36.25\n",
      "epoch: 203, loss: 102.14791, loss1: 0.79176, loss2_3: 101.35615\n",
      "\ttrain_acc: 0.8347, test_acc: \u001b[31m0.8\u001b[0m, time: 36.18\n",
      "epoch: 204, loss: 102.34157, loss1: 0.79427, loss2_3: 101.54730\n",
      "\ttrain_acc: 0.8344, test_acc: \u001b[31m0.79505\u001b[0m, time: 36.24\n",
      "epoch: 205, loss: 102.11818, loss1: 0.79446, loss2_3: 101.32373\n",
      "\ttrain_acc: 0.8345, test_acc: \u001b[31m0.79685\u001b[0m, time: 36.20\n",
      "epoch: 206, loss: 101.55092, loss1: 0.78970, loss2_3: 100.76122\n",
      "\ttrain_acc: 0.8353, test_acc: \u001b[31m0.79825\u001b[0m, time: 36.21\n",
      "epoch: 207, loss: 101.56459, loss1: 0.79013, loss2_3: 100.77447\n",
      "\ttrain_acc: 0.8288, test_acc: \u001b[31m0.7995\u001b[0m, time: 36.22\n",
      "epoch: 208, loss: 101.30141, loss1: 0.78964, loss2_3: 100.51177\n",
      "\ttrain_acc: 0.8343, test_acc: \u001b[31m0.79735\u001b[0m, time: 36.22\n",
      "epoch: 209, loss: 101.20379, loss1: 0.78739, loss2_3: 100.41640\n",
      "\ttrain_acc: 0.8347, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.20\n",
      "epoch: 210, loss: 101.05698, loss1: 0.78720, loss2_3: 100.26978\n",
      "\ttrain_acc: 0.8363, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.25\n",
      "epoch: 211, loss: 100.67534, loss1: 0.78243, loss2_3: 99.89291\n",
      "\ttrain_acc: 0.8371, test_acc: \u001b[31m0.7958\u001b[0m, time: 36.19\n",
      "epoch: 212, loss: 100.90622, loss1: 0.78498, loss2_3: 100.12123\n",
      "\ttrain_acc: 0.8305, test_acc: \u001b[31m0.79935\u001b[0m, time: 36.26\n",
      "epoch: 213, loss: 100.46460, loss1: 0.78769, loss2_3: 99.67690\n",
      "\ttrain_acc: 0.8391, test_acc: \u001b[31m0.7968\u001b[0m, time: 36.18\n",
      "epoch: 214, loss: 100.04148, loss1: 0.78434, loss2_3: 99.25715\n",
      "\ttrain_acc: 0.8382, test_acc: \u001b[31m0.7977\u001b[0m, time: 36.21\n",
      "epoch: 215, loss: 100.07977, loss1: 0.78357, loss2_3: 99.29620\n",
      "\ttrain_acc: 0.8362, test_acc: \u001b[31m0.7984\u001b[0m, time: 36.20\n",
      "epoch: 216, loss: 99.94807, loss1: 0.78403, loss2_3: 99.16404\n",
      "\ttrain_acc: 0.8364, test_acc: \u001b[31m0.7977\u001b[0m, time: 36.21\n",
      "epoch: 217, loss: 99.29118, loss1: 0.78693, loss2_3: 98.50426\n",
      "\ttrain_acc: 0.8372, test_acc: \u001b[31m0.7971\u001b[0m, time: 36.19\n",
      "epoch: 218, loss: 99.22870, loss1: 0.78986, loss2_3: 98.43884\n",
      "\ttrain_acc: 0.8329, test_acc: \u001b[31m0.79305\u001b[0m, time: 36.24\n",
      "epoch: 219, loss: 99.14454, loss1: 0.78431, loss2_3: 98.36023\n",
      "\ttrain_acc: 0.8349, test_acc: \u001b[31m0.79795\u001b[0m, time: 36.20\n",
      "epoch: 220, loss: 99.47719, loss1: 0.78386, loss2_3: 98.69333\n",
      "\ttrain_acc: 0.8401, test_acc: \u001b[31m0.7969\u001b[0m, time: 36.24\n",
      "epoch: 221, loss: 98.95416, loss1: 0.78747, loss2_3: 98.16668\n",
      "\ttrain_acc: 0.8406, test_acc: \u001b[31m0.79305\u001b[0m, time: 36.20\n",
      "epoch: 222, loss: 98.53095, loss1: 0.78214, loss2_3: 97.74881\n",
      "\ttrain_acc: 0.8377, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.24\n",
      "epoch: 223, loss: 98.97923, loss1: 0.78100, loss2_3: 98.19823\n",
      "\ttrain_acc: 0.8435, test_acc: \u001b[31m0.79355\u001b[0m, time: 36.19\n",
      "epoch: 224, loss: 98.22966, loss1: 0.77942, loss2_3: 97.45023\n",
      "\ttrain_acc: 0.8376, test_acc: \u001b[31m0.79105\u001b[0m, time: 36.21\n",
      "epoch: 225, loss: 98.38274, loss1: 0.77665, loss2_3: 97.60609\n",
      "\ttrain_acc: 0.8441, test_acc: \u001b[31m0.7951\u001b[0m, time: 36.20\n",
      "epoch: 226, loss: 98.36390, loss1: 0.77781, loss2_3: 97.58610\n",
      "\ttrain_acc: 0.8374, test_acc: \u001b[31m0.79815\u001b[0m, time: 36.22\n",
      "epoch: 227, loss: 97.79749, loss1: 0.77455, loss2_3: 97.02294\n",
      "\ttrain_acc: 0.8433, test_acc: \u001b[31m0.7906\u001b[0m, time: 36.18\n",
      "epoch: 228, loss: 97.60004, loss1: 0.77302, loss2_3: 96.82702\n",
      "\ttrain_acc: 0.8450, test_acc: \u001b[31m0.7892\u001b[0m, time: 36.26\n",
      "epoch: 229, loss: 97.33343, loss1: 0.77762, loss2_3: 96.55581\n",
      "\ttrain_acc: 0.8473, test_acc: \u001b[31m0.7956\u001b[0m, time: 36.19\n",
      "epoch: 230, loss: 97.32614, loss1: 0.78112, loss2_3: 96.54502\n",
      "\ttrain_acc: 0.8441, test_acc: \u001b[31m0.7933\u001b[0m, time: 36.25\n",
      "epoch: 231, loss: 96.94717, loss1: 0.77747, loss2_3: 96.16970\n",
      "\ttrain_acc: 0.8471, test_acc: \u001b[31m0.79665\u001b[0m, time: 36.19\n",
      "epoch: 232, loss: 96.79815, loss1: 0.77142, loss2_3: 96.02674\n",
      "\ttrain_acc: 0.8476, test_acc: \u001b[31m0.7934\u001b[0m, time: 36.24\n",
      "epoch: 233, loss: 96.86053, loss1: 0.77254, loss2_3: 96.08799\n",
      "\ttrain_acc: 0.8479, test_acc: \u001b[31m0.7923\u001b[0m, time: 36.17\n",
      "epoch: 234, loss: 96.60725, loss1: 0.77307, loss2_3: 95.83418\n",
      "\ttrain_acc: 0.8474, test_acc: \u001b[31m0.7963\u001b[0m, time: 36.25\n",
      "epoch: 235, loss: 96.28947, loss1: 0.76915, loss2_3: 95.52032\n",
      "\ttrain_acc: 0.8383, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.17\n",
      "epoch: 236, loss: 95.97137, loss1: 0.77234, loss2_3: 95.19903\n",
      "\ttrain_acc: 0.8474, test_acc: \u001b[31m0.7909\u001b[0m, time: 36.25\n",
      "epoch: 237, loss: 95.84701, loss1: 0.76742, loss2_3: 95.07960\n",
      "\ttrain_acc: 0.8489, test_acc: \u001b[31m0.79115\u001b[0m, time: 36.16\n",
      "epoch: 238, loss: 95.46201, loss1: 0.76680, loss2_3: 94.69521\n",
      "\ttrain_acc: 0.8486, test_acc: \u001b[31m0.7941\u001b[0m, time: 36.24\n",
      "epoch: 239, loss: 95.33032, loss1: 0.76783, loss2_3: 94.56249\n",
      "\ttrain_acc: 0.8504, test_acc: \u001b[31m0.78915\u001b[0m, time: 36.16\n",
      "epoch: 240, loss: 95.28868, loss1: 0.76269, loss2_3: 94.52600\n",
      "\ttrain_acc: 0.8506, test_acc: \u001b[31m0.7944\u001b[0m, time: 36.22\n",
      "epoch: 241, loss: 95.07620, loss1: 0.76336, loss2_3: 94.31285\n",
      "\ttrain_acc: 0.8425, test_acc: \u001b[31m0.7935\u001b[0m, time: 36.19\n",
      "epoch: 242, loss: 94.25599, loss1: 0.76828, loss2_3: 93.48771\n",
      "\ttrain_acc: 0.8523, test_acc: \u001b[31m0.78675\u001b[0m, time: 36.24\n",
      "epoch: 243, loss: 93.95978, loss1: 0.76297, loss2_3: 93.19680\n",
      "\ttrain_acc: 0.8476, test_acc: \u001b[31m0.7932\u001b[0m, time: 36.18\n",
      "epoch: 244, loss: 94.17937, loss1: 0.75919, loss2_3: 93.42017\n",
      "\ttrain_acc: 0.8501, test_acc: \u001b[31m0.78995\u001b[0m, time: 36.24\n",
      "epoch: 245, loss: 94.20363, loss1: 0.76447, loss2_3: 93.43916\n",
      "\ttrain_acc: 0.8551, test_acc: \u001b[31m0.7914\u001b[0m, time: 36.18\n",
      "epoch: 246, loss: 93.70030, loss1: 0.76151, loss2_3: 92.93879\n",
      "\ttrain_acc: 0.8532, test_acc: \u001b[31m0.7898\u001b[0m, time: 36.20\n",
      "epoch: 247, loss: 93.96831, loss1: 0.76324, loss2_3: 93.20507\n",
      "\ttrain_acc: 0.8528, test_acc: \u001b[31m0.7904\u001b[0m, time: 36.21\n",
      "epoch: 248, loss: 93.19373, loss1: 0.76135, loss2_3: 92.43238\n",
      "\ttrain_acc: 0.8563, test_acc: \u001b[31m0.789\u001b[0m, time: 36.20\n",
      "epoch: 249, loss: 93.28143, loss1: 0.75763, loss2_3: 92.52379\n",
      "\ttrain_acc: 0.8486, test_acc: \u001b[31m0.7925\u001b[0m, time: 36.18\n",
      "epoch: 250, loss: 93.07589, loss1: 0.75194, loss2_3: 92.32395\n",
      "\ttrain_acc: 0.8560, test_acc: \u001b[31m0.79215\u001b[0m, time: 36.21\n",
      "epoch: 1, loss: 181.40331, loss1: 2.71914, loss2_3: 178.68417\n",
      "\ttrain_acc: 0.5411, test_acc: \u001b[31m0.5305\u001b[0m, time: 36.44\n",
      "best_acc: 0.5305\n",
      "epoch: 2, loss: 172.30510, loss1: 1.02018, loss2_3: 171.28492\n",
      "\ttrain_acc: 0.6558, test_acc: \u001b[31m0.6607\u001b[0m, time: 36.48\n",
      "best_acc: 0.6607\n",
      "epoch: 3, loss: 146.90890, loss1: 0.99661, loss2_3: 145.91229\n",
      "\ttrain_acc: 0.7197, test_acc: \u001b[31m0.721\u001b[0m, time: 36.45\n",
      "best_acc: 0.721\n",
      "epoch: 4, loss: 135.89868, loss1: 0.97173, loss2_3: 134.92695\n",
      "\ttrain_acc: 0.7447, test_acc: \u001b[31m0.74695\u001b[0m, time: 36.45\n",
      "best_acc: 0.74695\n",
      "epoch: 5, loss: 131.35192, loss1: 0.95310, loss2_3: 130.39882\n",
      "\ttrain_acc: 0.7401, test_acc: \u001b[31m0.73895\u001b[0m, time: 36.46\n",
      "epoch: 6, loss: 129.89276, loss1: 0.94138, loss2_3: 128.95138\n",
      "\ttrain_acc: 0.7335, test_acc: \u001b[31m0.73565\u001b[0m, time: 36.43\n",
      "epoch: 7, loss: 128.33664, loss1: 0.93341, loss2_3: 127.40323\n",
      "\ttrain_acc: 0.7604, test_acc: \u001b[31m0.7597\u001b[0m, time: 36.48\n",
      "best_acc: 0.7597\n",
      "epoch: 8, loss: 126.63235, loss1: 0.92560, loss2_3: 125.70675\n",
      "\ttrain_acc: 0.7600, test_acc: \u001b[31m0.75855\u001b[0m, time: 36.41\n",
      "epoch: 9, loss: 125.62832, loss1: 0.92044, loss2_3: 124.70788\n",
      "\ttrain_acc: 0.7668, test_acc: \u001b[31m0.76685\u001b[0m, time: 36.43\n",
      "best_acc: 0.76685\n",
      "epoch: 10, loss: 124.86660, loss1: 0.91110, loss2_3: 123.95550\n",
      "\ttrain_acc: 0.7696, test_acc: \u001b[31m0.7693\u001b[0m, time: 36.42\n",
      "best_acc: 0.7693\n",
      "epoch: 11, loss: 124.31639, loss1: 0.91078, loss2_3: 123.40561\n",
      "\ttrain_acc: 0.7747, test_acc: \u001b[31m0.77465\u001b[0m, time: 36.42\n",
      "best_acc: 0.77465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, loss: 124.03347, loss1: 0.90918, loss2_3: 123.12429\n",
      "\ttrain_acc: 0.7726, test_acc: \u001b[31m0.7709\u001b[0m, time: 36.40\n",
      "epoch: 13, loss: 123.98693, loss1: 0.90711, loss2_3: 123.07982\n",
      "\ttrain_acc: 0.7594, test_acc: \u001b[31m0.7601\u001b[0m, time: 36.44\n",
      "epoch: 14, loss: 123.50803, loss1: 0.90795, loss2_3: 122.60008\n",
      "\ttrain_acc: 0.7802, test_acc: \u001b[31m0.78205\u001b[0m, time: 36.39\n",
      "best_acc: 0.78205\n",
      "epoch: 15, loss: 122.97276, loss1: 0.89943, loss2_3: 122.07333\n",
      "\ttrain_acc: 0.7689, test_acc: \u001b[31m0.76725\u001b[0m, time: 36.39\n",
      "epoch: 16, loss: 122.67407, loss1: 0.89809, loss2_3: 121.77598\n",
      "\ttrain_acc: 0.7838, test_acc: \u001b[31m0.7827\u001b[0m, time: 36.43\n",
      "best_acc: 0.7827\n",
      "epoch: 17, loss: 122.76096, loss1: 0.89576, loss2_3: 121.86520\n",
      "\ttrain_acc: 0.7618, test_acc: \u001b[31m0.76155\u001b[0m, time: 36.39\n",
      "epoch: 18, loss: 121.89263, loss1: 0.89132, loss2_3: 121.00131\n",
      "\ttrain_acc: 0.7800, test_acc: \u001b[31m0.7807\u001b[0m, time: 36.43\n",
      "epoch: 19, loss: 122.10675, loss1: 0.89212, loss2_3: 121.21463\n",
      "\ttrain_acc: 0.7825, test_acc: \u001b[31m0.781\u001b[0m, time: 36.39\n",
      "epoch: 20, loss: 121.35472, loss1: 0.89354, loss2_3: 120.46117\n",
      "\ttrain_acc: 0.7884, test_acc: \u001b[31m0.78775\u001b[0m, time: 36.40\n",
      "best_acc: 0.78775\n",
      "epoch: 21, loss: 121.03096, loss1: 0.88948, loss2_3: 120.14148\n",
      "\ttrain_acc: 0.7790, test_acc: \u001b[31m0.77385\u001b[0m, time: 36.42\n",
      "epoch: 22, loss: 121.52893, loss1: 0.88936, loss2_3: 120.63958\n",
      "\ttrain_acc: 0.7761, test_acc: \u001b[31m0.7773\u001b[0m, time: 36.40\n",
      "epoch: 23, loss: 120.92944, loss1: 0.88766, loss2_3: 120.04179\n",
      "\ttrain_acc: 0.7836, test_acc: \u001b[31m0.7842\u001b[0m, time: 36.41\n",
      "epoch: 24, loss: 120.39891, loss1: 0.88015, loss2_3: 119.51877\n",
      "\ttrain_acc: 0.7872, test_acc: \u001b[31m0.789\u001b[0m, time: 36.40\n",
      "best_acc: 0.789\n",
      "epoch: 25, loss: 120.43029, loss1: 0.88910, loss2_3: 119.54118\n",
      "\ttrain_acc: 0.7847, test_acc: \u001b[31m0.78475\u001b[0m, time: 36.37\n",
      "epoch: 26, loss: 120.03378, loss1: 0.88025, loss2_3: 119.15352\n",
      "\ttrain_acc: 0.7883, test_acc: \u001b[31m0.787\u001b[0m, time: 36.74\n",
      "epoch: 27, loss: 119.90126, loss1: 0.87740, loss2_3: 119.02386\n",
      "\ttrain_acc: 0.7897, test_acc: \u001b[31m0.7895\u001b[0m, time: 36.74\n",
      "best_acc: 0.7895\n",
      "epoch: 28, loss: 119.55811, loss1: 0.88030, loss2_3: 118.67781\n",
      "\ttrain_acc: 0.7905, test_acc: \u001b[31m0.79025\u001b[0m, time: 36.71\n",
      "best_acc: 0.79025\n",
      "epoch: 29, loss: 119.44227, loss1: 0.87466, loss2_3: 118.56761\n",
      "\ttrain_acc: 0.7949, test_acc: \u001b[31m0.793\u001b[0m, time: 36.77\n",
      "best_acc: 0.793\n",
      "epoch: 30, loss: 119.24102, loss1: 0.87663, loss2_3: 118.36439\n",
      "\ttrain_acc: 0.7930, test_acc: \u001b[31m0.792\u001b[0m, time: 36.69\n",
      "epoch: 31, loss: 119.35786, loss1: 0.87170, loss2_3: 118.48616\n",
      "\ttrain_acc: 0.7920, test_acc: \u001b[31m0.79075\u001b[0m, time: 36.73\n",
      "epoch: 32, loss: 118.39206, loss1: 0.86788, loss2_3: 117.52418\n",
      "\ttrain_acc: 0.7934, test_acc: \u001b[31m0.79205\u001b[0m, time: 36.73\n",
      "epoch: 33, loss: 118.65463, loss1: 0.87121, loss2_3: 117.78342\n",
      "\ttrain_acc: 0.7868, test_acc: \u001b[31m0.78445\u001b[0m, time: 36.74\n",
      "epoch: 34, loss: 118.66977, loss1: 0.87241, loss2_3: 117.79735\n",
      "\ttrain_acc: 0.7945, test_acc: \u001b[31m0.7927\u001b[0m, time: 36.75\n",
      "epoch: 35, loss: 118.46190, loss1: 0.87295, loss2_3: 117.58895\n",
      "\ttrain_acc: 0.7856, test_acc: \u001b[31m0.78635\u001b[0m, time: 36.69\n",
      "epoch: 36, loss: 118.59406, loss1: 0.86241, loss2_3: 117.73165\n",
      "\ttrain_acc: 0.7793, test_acc: \u001b[31m0.78\u001b[0m, time: 36.70\n",
      "epoch: 37, loss: 118.22341, loss1: 0.86845, loss2_3: 117.35496\n",
      "\ttrain_acc: 0.7970, test_acc: \u001b[31m0.7941\u001b[0m, time: 36.64\n",
      "best_acc: 0.7941\n",
      "epoch: 38, loss: 118.25599, loss1: 0.86906, loss2_3: 117.38692\n",
      "\ttrain_acc: 0.7948, test_acc: \u001b[31m0.7941\u001b[0m, time: 36.37\n",
      "epoch: 39, loss: 118.01291, loss1: 0.86857, loss2_3: 117.14434\n",
      "\ttrain_acc: 0.7963, test_acc: \u001b[31m0.7947\u001b[0m, time: 36.31\n",
      "best_acc: 0.7947\n",
      "epoch: 40, loss: 117.85282, loss1: 0.86622, loss2_3: 116.98659\n",
      "\ttrain_acc: 0.7929, test_acc: \u001b[31m0.791\u001b[0m, time: 36.36\n",
      "epoch: 41, loss: 117.51935, loss1: 0.86978, loss2_3: 116.64957\n",
      "\ttrain_acc: 0.7938, test_acc: \u001b[31m0.79105\u001b[0m, time: 36.31\n",
      "epoch: 42, loss: 117.83294, loss1: 0.86736, loss2_3: 116.96558\n",
      "\ttrain_acc: 0.7896, test_acc: \u001b[31m0.78845\u001b[0m, time: 36.39\n",
      "epoch: 43, loss: 117.23859, loss1: 0.86375, loss2_3: 116.37485\n",
      "\ttrain_acc: 0.7928, test_acc: \u001b[31m0.7899\u001b[0m, time: 36.34\n",
      "epoch: 44, loss: 117.46018, loss1: 0.86332, loss2_3: 116.59686\n",
      "\ttrain_acc: 0.7913, test_acc: \u001b[31m0.78715\u001b[0m, time: 36.36\n",
      "epoch: 45, loss: 117.04653, loss1: 0.85783, loss2_3: 116.18870\n",
      "\ttrain_acc: 0.7943, test_acc: \u001b[31m0.793\u001b[0m, time: 36.36\n",
      "epoch: 46, loss: 117.22646, loss1: 0.86060, loss2_3: 116.36587\n",
      "\ttrain_acc: 0.7954, test_acc: \u001b[31m0.7936\u001b[0m, time: 36.34\n",
      "epoch: 47, loss: 117.01995, loss1: 0.85345, loss2_3: 116.16650\n",
      "\ttrain_acc: 0.7964, test_acc: \u001b[31m0.7923\u001b[0m, time: 36.29\n",
      "epoch: 48, loss: 117.15593, loss1: 0.86306, loss2_3: 116.29287\n",
      "\ttrain_acc: 0.7923, test_acc: \u001b[31m0.7914\u001b[0m, time: 36.34\n",
      "epoch: 49, loss: 116.97896, loss1: 0.85731, loss2_3: 116.12164\n",
      "\ttrain_acc: 0.7914, test_acc: \u001b[31m0.78915\u001b[0m, time: 36.28\n",
      "epoch: 50, loss: 116.99318, loss1: 0.85300, loss2_3: 116.14018\n",
      "\ttrain_acc: 0.7968, test_acc: \u001b[31m0.7949\u001b[0m, time: 36.33\n",
      "best_acc: 0.7949\n",
      "epoch: 51, loss: 116.70505, loss1: 0.85747, loss2_3: 115.84758\n",
      "\ttrain_acc: 0.7952, test_acc: \u001b[31m0.79205\u001b[0m, time: 36.27\n",
      "epoch: 52, loss: 116.70714, loss1: 0.85266, loss2_3: 115.85448\n",
      "\ttrain_acc: 0.8014, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.29\n",
      "best_acc: 0.7998\n",
      "epoch: 53, loss: 116.54310, loss1: 0.85682, loss2_3: 115.68628\n",
      "\ttrain_acc: 0.7979, test_acc: \u001b[31m0.7969\u001b[0m, time: 36.27\n",
      "epoch: 54, loss: 116.26089, loss1: 0.85032, loss2_3: 115.41057\n",
      "\ttrain_acc: 0.7952, test_acc: \u001b[31m0.7935\u001b[0m, time: 36.27\n",
      "epoch: 55, loss: 116.22611, loss1: 0.85403, loss2_3: 115.37208\n",
      "\ttrain_acc: 0.7995, test_acc: \u001b[31m0.7979\u001b[0m, time: 36.23\n",
      "epoch: 56, loss: 116.04493, loss1: 0.85495, loss2_3: 115.18998\n",
      "\ttrain_acc: 0.7906, test_acc: \u001b[31m0.7894\u001b[0m, time: 36.26\n",
      "epoch: 57, loss: 116.08255, loss1: 0.85335, loss2_3: 115.22919\n",
      "\ttrain_acc: 0.7993, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.19\n",
      "epoch: 58, loss: 116.30807, loss1: 0.85818, loss2_3: 115.44989\n",
      "\ttrain_acc: 0.7980, test_acc: \u001b[31m0.79695\u001b[0m, time: 36.26\n",
      "epoch: 59, loss: 115.81959, loss1: 0.85613, loss2_3: 114.96347\n",
      "\ttrain_acc: 0.7989, test_acc: \u001b[31m0.79705\u001b[0m, time: 36.18\n",
      "epoch: 60, loss: 115.77200, loss1: 0.84812, loss2_3: 114.92388\n",
      "\ttrain_acc: 0.8002, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.22\n",
      "epoch: 61, loss: 115.82357, loss1: 0.84736, loss2_3: 114.97622\n",
      "\ttrain_acc: 0.8029, test_acc: \u001b[31m0.8\u001b[0m, time: 36.21\n",
      "best_acc: 0.8\n",
      "epoch: 62, loss: 115.88570, loss1: 0.84910, loss2_3: 115.03659\n",
      "\ttrain_acc: 0.7969, test_acc: \u001b[31m0.794\u001b[0m, time: 36.21\n",
      "epoch: 63, loss: 115.48058, loss1: 0.84773, loss2_3: 114.63285\n",
      "\ttrain_acc: 0.7976, test_acc: \u001b[31m0.79515\u001b[0m, time: 36.20\n",
      "epoch: 64, loss: 115.48538, loss1: 0.84607, loss2_3: 114.63930\n",
      "\ttrain_acc: 0.7986, test_acc: \u001b[31m0.7969\u001b[0m, time: 36.25\n",
      "epoch: 65, loss: 115.71747, loss1: 0.84768, loss2_3: 114.86979\n",
      "\ttrain_acc: 0.7984, test_acc: \u001b[31m0.7946\u001b[0m, time: 36.18\n",
      "epoch: 66, loss: 115.82775, loss1: 0.85228, loss2_3: 114.97548\n",
      "\ttrain_acc: 0.8004, test_acc: \u001b[31m0.79825\u001b[0m, time: 36.25\n",
      "epoch: 67, loss: 115.53818, loss1: 0.84655, loss2_3: 114.69163\n",
      "\ttrain_acc: 0.7956, test_acc: \u001b[31m0.7935\u001b[0m, time: 36.16\n",
      "epoch: 68, loss: 115.29081, loss1: 0.84277, loss2_3: 114.44804\n",
      "\ttrain_acc: 0.8011, test_acc: \u001b[31m0.7985\u001b[0m, time: 36.26\n",
      "epoch: 69, loss: 115.21882, loss1: 0.84677, loss2_3: 114.37205\n",
      "\ttrain_acc: 0.7983, test_acc: \u001b[31m0.79535\u001b[0m, time: 36.17\n",
      "epoch: 70, loss: 115.25089, loss1: 0.84851, loss2_3: 114.40238\n",
      "\ttrain_acc: 0.7991, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.25\n",
      "epoch: 71, loss: 115.12157, loss1: 0.84158, loss2_3: 114.27999\n",
      "\ttrain_acc: 0.7989, test_acc: \u001b[31m0.79605\u001b[0m, time: 36.21\n",
      "epoch: 72, loss: 115.01473, loss1: 0.84193, loss2_3: 114.17280\n",
      "\ttrain_acc: 0.7979, test_acc: \u001b[31m0.79445\u001b[0m, time: 36.25\n",
      "epoch: 73, loss: 115.11126, loss1: 0.84011, loss2_3: 114.27114\n",
      "\ttrain_acc: 0.7995, test_acc: \u001b[31m0.79675\u001b[0m, time: 36.17\n",
      "epoch: 74, loss: 115.24793, loss1: 0.84191, loss2_3: 114.40602\n",
      "\ttrain_acc: 0.8023, test_acc: \u001b[31m0.79845\u001b[0m, time: 36.26\n",
      "epoch: 75, loss: 114.87557, loss1: 0.83857, loss2_3: 114.03700\n",
      "\ttrain_acc: 0.8013, test_acc: \u001b[31m0.79815\u001b[0m, time: 36.16\n",
      "epoch: 76, loss: 114.61395, loss1: 0.83713, loss2_3: 113.77682\n",
      "\ttrain_acc: 0.8018, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.23\n",
      "epoch: 77, loss: 114.56496, loss1: 0.83653, loss2_3: 113.72844\n",
      "\ttrain_acc: 0.8049, test_acc: \u001b[31m0.7999\u001b[0m, time: 36.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 78, loss: 114.35542, loss1: 0.84070, loss2_3: 113.51472\n",
      "\ttrain_acc: 0.8049, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.21\n",
      "best_acc: 0.80055\n",
      "epoch: 79, loss: 114.22856, loss1: 0.83337, loss2_3: 113.39519\n",
      "\ttrain_acc: 0.8024, test_acc: \u001b[31m0.7992\u001b[0m, time: 36.15\n",
      "epoch: 80, loss: 114.27450, loss1: 0.83703, loss2_3: 113.43747\n",
      "\ttrain_acc: 0.8047, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.21\n",
      "epoch: 81, loss: 114.24322, loss1: 0.83676, loss2_3: 113.40646\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.17\n",
      "epoch: 82, loss: 114.49299, loss1: 0.83790, loss2_3: 113.65509\n",
      "\ttrain_acc: 0.8024, test_acc: \u001b[31m0.799\u001b[0m, time: 36.22\n",
      "epoch: 83, loss: 114.27854, loss1: 0.83651, loss2_3: 113.44203\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.8004\u001b[0m, time: 36.18\n",
      "epoch: 84, loss: 114.15212, loss1: 0.83202, loss2_3: 113.32010\n",
      "\ttrain_acc: 0.8041, test_acc: \u001b[31m0.79835\u001b[0m, time: 36.24\n",
      "epoch: 85, loss: 114.25645, loss1: 0.83588, loss2_3: 113.42057\n",
      "\ttrain_acc: 0.8021, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.20\n",
      "epoch: 86, loss: 114.29680, loss1: 0.83514, loss2_3: 113.46166\n",
      "\ttrain_acc: 0.8014, test_acc: \u001b[31m0.7991\u001b[0m, time: 36.23\n",
      "epoch: 87, loss: 114.04523, loss1: 0.83570, loss2_3: 113.20953\n",
      "\ttrain_acc: 0.8029, test_acc: \u001b[31m0.7988\u001b[0m, time: 36.22\n",
      "epoch: 88, loss: 114.10046, loss1: 0.83431, loss2_3: 113.26615\n",
      "\ttrain_acc: 0.8060, test_acc: \u001b[31m0.8024\u001b[0m, time: 36.21\n",
      "best_acc: 0.8024\n",
      "epoch: 89, loss: 113.56965, loss1: 0.82640, loss2_3: 112.74325\n",
      "\ttrain_acc: 0.8057, test_acc: \u001b[31m0.80325\u001b[0m, time: 36.18\n",
      "best_acc: 0.80325\n",
      "epoch: 90, loss: 113.70463, loss1: 0.83053, loss2_3: 112.87410\n",
      "\ttrain_acc: 0.8045, test_acc: \u001b[31m0.80075\u001b[0m, time: 36.22\n",
      "epoch: 91, loss: 113.76113, loss1: 0.83248, loss2_3: 112.92865\n",
      "\ttrain_acc: 0.8008, test_acc: \u001b[31m0.7972\u001b[0m, time: 36.16\n",
      "epoch: 92, loss: 113.68369, loss1: 0.83545, loss2_3: 112.84825\n",
      "\ttrain_acc: 0.8048, test_acc: \u001b[31m0.801\u001b[0m, time: 36.20\n",
      "epoch: 93, loss: 113.44648, loss1: 0.83180, loss2_3: 112.61468\n",
      "\ttrain_acc: 0.8041, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.16\n",
      "epoch: 94, loss: 113.66826, loss1: 0.82568, loss2_3: 112.84258\n",
      "\ttrain_acc: 0.8055, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.20\n",
      "epoch: 95, loss: 113.52783, loss1: 0.83081, loss2_3: 112.69702\n",
      "\ttrain_acc: 0.8056, test_acc: \u001b[31m0.7993\u001b[0m, time: 36.14\n",
      "epoch: 96, loss: 113.16008, loss1: 0.83351, loss2_3: 112.32658\n",
      "\ttrain_acc: 0.8022, test_acc: \u001b[31m0.79785\u001b[0m, time: 36.21\n",
      "epoch: 97, loss: 113.33602, loss1: 0.83511, loss2_3: 112.50091\n",
      "\ttrain_acc: 0.8037, test_acc: \u001b[31m0.79865\u001b[0m, time: 36.13\n",
      "epoch: 98, loss: 113.21613, loss1: 0.82763, loss2_3: 112.38850\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.79895\u001b[0m, time: 36.20\n",
      "epoch: 99, loss: 113.07620, loss1: 0.82813, loss2_3: 112.24807\n",
      "\ttrain_acc: 0.8085, test_acc: \u001b[31m0.80165\u001b[0m, time: 36.16\n",
      "epoch: 100, loss: 113.16942, loss1: 0.82772, loss2_3: 112.34170\n",
      "\ttrain_acc: 0.8079, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.22\n",
      "epoch: 101, loss: 113.16112, loss1: 0.83635, loss2_3: 112.32477\n",
      "\ttrain_acc: 0.8071, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.18\n",
      "epoch: 102, loss: 113.13504, loss1: 0.82720, loss2_3: 112.30784\n",
      "\ttrain_acc: 0.8072, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.19\n",
      "epoch: 103, loss: 112.92885, loss1: 0.82236, loss2_3: 112.10649\n",
      "\ttrain_acc: 0.8069, test_acc: \u001b[31m0.80355\u001b[0m, time: 36.20\n",
      "best_acc: 0.80355\n",
      "epoch: 104, loss: 112.92485, loss1: 0.83031, loss2_3: 112.09455\n",
      "\ttrain_acc: 0.8082, test_acc: \u001b[31m0.80435\u001b[0m, time: 36.20\n",
      "best_acc: 0.80435\n",
      "epoch: 105, loss: 112.50215, loss1: 0.82429, loss2_3: 111.67786\n",
      "\ttrain_acc: 0.8071, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.17\n",
      "epoch: 106, loss: 112.54000, loss1: 0.82549, loss2_3: 111.71451\n",
      "\ttrain_acc: 0.8085, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.20\n",
      "epoch: 107, loss: 112.74052, loss1: 0.82622, loss2_3: 111.91430\n",
      "\ttrain_acc: 0.7999, test_acc: \u001b[31m0.7944\u001b[0m, time: 36.17\n",
      "epoch: 108, loss: 112.64815, loss1: 0.82132, loss2_3: 111.82683\n",
      "\ttrain_acc: 0.8078, test_acc: \u001b[31m0.8032\u001b[0m, time: 36.20\n",
      "epoch: 109, loss: 112.35256, loss1: 0.82572, loss2_3: 111.52683\n",
      "\ttrain_acc: 0.8090, test_acc: \u001b[31m0.8027\u001b[0m, time: 36.19\n",
      "epoch: 110, loss: 112.38113, loss1: 0.82795, loss2_3: 111.55318\n",
      "\ttrain_acc: 0.8091, test_acc: \u001b[31m0.80205\u001b[0m, time: 36.19\n",
      "epoch: 111, loss: 112.23287, loss1: 0.82342, loss2_3: 111.40945\n",
      "\ttrain_acc: 0.8057, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.15\n",
      "epoch: 112, loss: 112.32300, loss1: 0.82736, loss2_3: 111.49564\n",
      "\ttrain_acc: 0.8094, test_acc: \u001b[31m0.8041\u001b[0m, time: 36.21\n",
      "epoch: 113, loss: 112.51311, loss1: 0.82941, loss2_3: 111.68370\n",
      "\ttrain_acc: 0.8092, test_acc: \u001b[31m0.8011\u001b[0m, time: 36.15\n",
      "epoch: 114, loss: 112.45633, loss1: 0.82237, loss2_3: 111.63396\n",
      "\ttrain_acc: 0.8079, test_acc: \u001b[31m0.8004\u001b[0m, time: 36.21\n",
      "epoch: 115, loss: 112.04259, loss1: 0.82412, loss2_3: 111.21847\n",
      "\ttrain_acc: 0.8078, test_acc: \u001b[31m0.80245\u001b[0m, time: 36.18\n",
      "epoch: 116, loss: 111.87857, loss1: 0.82222, loss2_3: 111.05635\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.8029\u001b[0m, time: 36.21\n",
      "epoch: 117, loss: 112.13640, loss1: 0.82350, loss2_3: 111.31290\n",
      "\ttrain_acc: 0.8085, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.21\n",
      "epoch: 118, loss: 111.92155, loss1: 0.81878, loss2_3: 111.10277\n",
      "\ttrain_acc: 0.8079, test_acc: \u001b[31m0.80225\u001b[0m, time: 36.20\n",
      "epoch: 119, loss: 111.69802, loss1: 0.82075, loss2_3: 110.87727\n",
      "\ttrain_acc: 0.8089, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.21\n",
      "epoch: 120, loss: 111.68319, loss1: 0.81706, loss2_3: 110.86614\n",
      "\ttrain_acc: 0.8068, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.20\n",
      "epoch: 121, loss: 111.30465, loss1: 0.81936, loss2_3: 110.48530\n",
      "\ttrain_acc: 0.8110, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.16\n",
      "epoch: 122, loss: 111.39230, loss1: 0.81974, loss2_3: 110.57256\n",
      "\ttrain_acc: 0.8107, test_acc: \u001b[31m0.8055\u001b[0m, time: 36.22\n",
      "best_acc: 0.8055\n",
      "epoch: 123, loss: 111.42877, loss1: 0.81959, loss2_3: 110.60917\n",
      "\ttrain_acc: 0.8104, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.14\n",
      "epoch: 124, loss: 111.45085, loss1: 0.81763, loss2_3: 110.63322\n",
      "\ttrain_acc: 0.8097, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.21\n",
      "epoch: 125, loss: 111.58517, loss1: 0.81770, loss2_3: 110.76747\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.8018\u001b[0m, time: 36.16\n",
      "epoch: 126, loss: 111.13846, loss1: 0.81614, loss2_3: 110.32232\n",
      "\ttrain_acc: 0.8076, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.22\n",
      "epoch: 127, loss: 111.10021, loss1: 0.82032, loss2_3: 110.27989\n",
      "\ttrain_acc: 0.8072, test_acc: \u001b[31m0.7995\u001b[0m, time: 36.15\n",
      "epoch: 128, loss: 111.20275, loss1: 0.81548, loss2_3: 110.38727\n",
      "\ttrain_acc: 0.8122, test_acc: \u001b[31m0.80275\u001b[0m, time: 36.23\n",
      "epoch: 129, loss: 111.04286, loss1: 0.81661, loss2_3: 110.22625\n",
      "\ttrain_acc: 0.8055, test_acc: \u001b[31m0.7982\u001b[0m, time: 36.15\n",
      "epoch: 130, loss: 110.79321, loss1: 0.82166, loss2_3: 109.97154\n",
      "\ttrain_acc: 0.8097, test_acc: \u001b[31m0.7983\u001b[0m, time: 36.25\n",
      "epoch: 131, loss: 110.89729, loss1: 0.81651, loss2_3: 110.08078\n",
      "\ttrain_acc: 0.8097, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.15\n",
      "epoch: 132, loss: 110.89464, loss1: 0.81941, loss2_3: 110.07523\n",
      "\ttrain_acc: 0.8115, test_acc: \u001b[31m0.8011\u001b[0m, time: 36.22\n",
      "epoch: 133, loss: 110.94767, loss1: 0.81402, loss2_3: 110.13364\n",
      "\ttrain_acc: 0.8130, test_acc: \u001b[31m0.805\u001b[0m, time: 36.19\n",
      "epoch: 134, loss: 110.56703, loss1: 0.82030, loss2_3: 109.74674\n",
      "\ttrain_acc: 0.8090, test_acc: \u001b[31m0.8024\u001b[0m, time: 36.21\n",
      "epoch: 135, loss: 110.50094, loss1: 0.81555, loss2_3: 109.68539\n",
      "\ttrain_acc: 0.8115, test_acc: \u001b[31m0.8033\u001b[0m, time: 36.17\n",
      "epoch: 136, loss: 110.12565, loss1: 0.81620, loss2_3: 109.30946\n",
      "\ttrain_acc: 0.8082, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.23\n",
      "epoch: 137, loss: 110.12388, loss1: 0.81520, loss2_3: 109.30867\n",
      "\ttrain_acc: 0.8129, test_acc: \u001b[31m0.8049\u001b[0m, time: 36.16\n",
      "epoch: 138, loss: 110.07911, loss1: 0.81651, loss2_3: 109.26260\n",
      "\ttrain_acc: 0.8149, test_acc: \u001b[31m0.80345\u001b[0m, time: 36.24\n",
      "epoch: 139, loss: 110.20742, loss1: 0.81235, loss2_3: 109.39507\n",
      "\ttrain_acc: 0.8132, test_acc: \u001b[31m0.8018\u001b[0m, time: 36.16\n",
      "epoch: 140, loss: 110.05384, loss1: 0.81401, loss2_3: 109.23983\n",
      "\ttrain_acc: 0.8133, test_acc: \u001b[31m0.80335\u001b[0m, time: 36.20\n",
      "epoch: 141, loss: 109.84070, loss1: 0.81032, loss2_3: 109.03038\n",
      "\ttrain_acc: 0.8094, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.21\n",
      "epoch: 142, loss: 109.95052, loss1: 0.81108, loss2_3: 109.13944\n",
      "\ttrain_acc: 0.8139, test_acc: \u001b[31m0.80275\u001b[0m, time: 36.20\n",
      "epoch: 143, loss: 109.70929, loss1: 0.81160, loss2_3: 108.89769\n",
      "\ttrain_acc: 0.8123, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 144, loss: 109.78260, loss1: 0.81244, loss2_3: 108.97016\n",
      "\ttrain_acc: 0.8128, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.23\n",
      "epoch: 145, loss: 109.74562, loss1: 0.81694, loss2_3: 108.92868\n",
      "\ttrain_acc: 0.8133, test_acc: \u001b[31m0.80355\u001b[0m, time: 36.16\n",
      "epoch: 146, loss: 109.77357, loss1: 0.81286, loss2_3: 108.96071\n",
      "\ttrain_acc: 0.8090, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.22\n",
      "epoch: 147, loss: 109.40682, loss1: 0.81682, loss2_3: 108.58999\n",
      "\ttrain_acc: 0.8149, test_acc: \u001b[31m0.8017\u001b[0m, time: 36.13\n",
      "epoch: 148, loss: 109.56093, loss1: 0.81599, loss2_3: 108.74494\n",
      "\ttrain_acc: 0.8123, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.19\n",
      "epoch: 149, loss: 109.14594, loss1: 0.80959, loss2_3: 108.33635\n",
      "\ttrain_acc: 0.8132, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.15\n",
      "epoch: 150, loss: 109.08531, loss1: 0.81201, loss2_3: 108.27330\n",
      "\ttrain_acc: 0.8150, test_acc: \u001b[31m0.80205\u001b[0m, time: 36.20\n",
      "epoch: 151, loss: 109.31692, loss1: 0.80927, loss2_3: 108.50765\n",
      "\ttrain_acc: 0.8154, test_acc: \u001b[31m0.8033\u001b[0m, time: 36.17\n",
      "epoch: 152, loss: 109.10165, loss1: 0.80816, loss2_3: 108.29349\n",
      "\ttrain_acc: 0.8127, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.21\n",
      "epoch: 153, loss: 109.05229, loss1: 0.81416, loss2_3: 108.23812\n",
      "\ttrain_acc: 0.8145, test_acc: \u001b[31m0.8038\u001b[0m, time: 36.16\n",
      "epoch: 154, loss: 108.79929, loss1: 0.81085, loss2_3: 107.98844\n",
      "\ttrain_acc: 0.8162, test_acc: \u001b[31m0.8027\u001b[0m, time: 36.24\n",
      "epoch: 155, loss: 108.74584, loss1: 0.80941, loss2_3: 107.93643\n",
      "\ttrain_acc: 0.8148, test_acc: \u001b[31m0.8032\u001b[0m, time: 36.15\n",
      "epoch: 156, loss: 108.71807, loss1: 0.80803, loss2_3: 107.91004\n",
      "\ttrain_acc: 0.8148, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.20\n",
      "epoch: 157, loss: 108.52573, loss1: 0.81547, loss2_3: 107.71026\n",
      "\ttrain_acc: 0.8173, test_acc: \u001b[31m0.80475\u001b[0m, time: 36.19\n",
      "epoch: 158, loss: 108.55950, loss1: 0.81206, loss2_3: 107.74745\n",
      "\ttrain_acc: 0.8160, test_acc: \u001b[31m0.8028\u001b[0m, time: 36.19\n",
      "epoch: 159, loss: 108.53535, loss1: 0.80939, loss2_3: 107.72597\n",
      "\ttrain_acc: 0.8112, test_acc: \u001b[31m0.79745\u001b[0m, time: 36.16\n",
      "epoch: 160, loss: 108.36112, loss1: 0.80984, loss2_3: 107.55129\n",
      "\ttrain_acc: 0.8108, test_acc: \u001b[31m0.7986\u001b[0m, time: 36.20\n",
      "epoch: 161, loss: 108.17451, loss1: 0.80868, loss2_3: 107.36583\n",
      "\ttrain_acc: 0.8136, test_acc: \u001b[31m0.8016\u001b[0m, time: 36.17\n",
      "epoch: 162, loss: 108.20683, loss1: 0.80919, loss2_3: 107.39764\n",
      "\ttrain_acc: 0.8143, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.22\n",
      "epoch: 163, loss: 108.34484, loss1: 0.80955, loss2_3: 107.53529\n",
      "\ttrain_acc: 0.8180, test_acc: \u001b[31m0.8032\u001b[0m, time: 36.18\n",
      "epoch: 164, loss: 107.90069, loss1: 0.80656, loss2_3: 107.09413\n",
      "\ttrain_acc: 0.8193, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.24\n",
      "epoch: 165, loss: 107.68538, loss1: 0.80849, loss2_3: 106.87689\n",
      "\ttrain_acc: 0.8181, test_acc: \u001b[31m0.80355\u001b[0m, time: 36.16\n",
      "epoch: 166, loss: 107.72043, loss1: 0.80774, loss2_3: 106.91269\n",
      "\ttrain_acc: 0.8198, test_acc: \u001b[31m0.8047\u001b[0m, time: 36.23\n",
      "epoch: 167, loss: 107.64421, loss1: 0.80896, loss2_3: 106.83524\n",
      "\ttrain_acc: 0.8182, test_acc: \u001b[31m0.801\u001b[0m, time: 36.18\n",
      "epoch: 168, loss: 107.38661, loss1: 0.81166, loss2_3: 106.57495\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.22\n",
      "epoch: 169, loss: 107.65695, loss1: 0.80421, loss2_3: 106.85274\n",
      "\ttrain_acc: 0.8179, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.15\n",
      "epoch: 170, loss: 107.40223, loss1: 0.80917, loss2_3: 106.59305\n",
      "\ttrain_acc: 0.8209, test_acc: \u001b[31m0.80385\u001b[0m, time: 36.23\n",
      "epoch: 171, loss: 107.24516, loss1: 0.80828, loss2_3: 106.43688\n",
      "\ttrain_acc: 0.8208, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.15\n",
      "epoch: 172, loss: 107.20477, loss1: 0.80887, loss2_3: 106.39590\n",
      "\ttrain_acc: 0.8190, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.20\n",
      "epoch: 173, loss: 106.68564, loss1: 0.80238, loss2_3: 105.88326\n",
      "\ttrain_acc: 0.8184, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.25\n",
      "epoch: 174, loss: 106.65204, loss1: 0.81022, loss2_3: 105.84182\n",
      "\ttrain_acc: 0.8206, test_acc: \u001b[31m0.80265\u001b[0m, time: 36.19\n",
      "epoch: 175, loss: 106.69378, loss1: 0.80151, loss2_3: 105.89228\n",
      "\ttrain_acc: 0.8168, test_acc: \u001b[31m0.7916\u001b[0m, time: 36.24\n",
      "epoch: 176, loss: 106.67654, loss1: 0.80953, loss2_3: 105.86701\n",
      "\ttrain_acc: 0.8149, test_acc: \u001b[31m0.79745\u001b[0m, time: 36.25\n",
      "epoch: 177, loss: 106.52596, loss1: 0.80694, loss2_3: 105.71902\n",
      "\ttrain_acc: 0.8211, test_acc: \u001b[31m0.7966\u001b[0m, time: 36.24\n",
      "epoch: 178, loss: 106.75342, loss1: 0.80040, loss2_3: 105.95302\n",
      "\ttrain_acc: 0.8229, test_acc: \u001b[31m0.79745\u001b[0m, time: 36.24\n",
      "epoch: 179, loss: 106.05274, loss1: 0.79899, loss2_3: 105.25375\n",
      "\ttrain_acc: 0.8224, test_acc: \u001b[31m0.8019\u001b[0m, time: 36.24\n",
      "epoch: 180, loss: 106.21358, loss1: 0.80533, loss2_3: 105.40825\n",
      "\ttrain_acc: 0.8163, test_acc: \u001b[31m0.79895\u001b[0m, time: 36.24\n",
      "epoch: 181, loss: 106.08966, loss1: 0.79712, loss2_3: 105.29253\n",
      "\ttrain_acc: 0.8220, test_acc: \u001b[31m0.79735\u001b[0m, time: 36.23\n",
      "epoch: 182, loss: 105.96766, loss1: 0.80672, loss2_3: 105.16094\n",
      "\ttrain_acc: 0.8212, test_acc: \u001b[31m0.8001\u001b[0m, time: 36.19\n",
      "epoch: 183, loss: 105.81171, loss1: 0.80172, loss2_3: 105.00999\n",
      "\ttrain_acc: 0.8218, test_acc: \u001b[31m0.8019\u001b[0m, time: 36.24\n",
      "epoch: 184, loss: 105.70220, loss1: 0.80153, loss2_3: 104.90067\n",
      "\ttrain_acc: 0.8215, test_acc: \u001b[31m0.79715\u001b[0m, time: 36.19\n",
      "epoch: 185, loss: 105.73566, loss1: 0.80036, loss2_3: 104.93530\n",
      "\ttrain_acc: 0.8198, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.23\n",
      "epoch: 186, loss: 105.41956, loss1: 0.80097, loss2_3: 104.61860\n",
      "\ttrain_acc: 0.8237, test_acc: \u001b[31m0.80225\u001b[0m, time: 36.23\n",
      "epoch: 187, loss: 105.49229, loss1: 0.79454, loss2_3: 104.69776\n",
      "\ttrain_acc: 0.8213, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.24\n",
      "epoch: 188, loss: 105.24885, loss1: 0.80061, loss2_3: 104.44824\n",
      "\ttrain_acc: 0.8252, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.20\n",
      "epoch: 189, loss: 105.18366, loss1: 0.80127, loss2_3: 104.38239\n",
      "\ttrain_acc: 0.8125, test_acc: \u001b[31m0.79545\u001b[0m, time: 36.27\n",
      "epoch: 190, loss: 104.87659, loss1: 0.79832, loss2_3: 104.07828\n",
      "\ttrain_acc: 0.8230, test_acc: \u001b[31m0.8032\u001b[0m, time: 36.19\n",
      "epoch: 191, loss: 104.99493, loss1: 0.80007, loss2_3: 104.19485\n",
      "\ttrain_acc: 0.8260, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.24\n",
      "epoch: 192, loss: 104.72678, loss1: 0.80123, loss2_3: 103.92555\n",
      "\ttrain_acc: 0.8197, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.22\n",
      "epoch: 193, loss: 104.78810, loss1: 0.79929, loss2_3: 103.98880\n",
      "\ttrain_acc: 0.8114, test_acc: \u001b[31m0.77735\u001b[0m, time: 36.21\n",
      "epoch: 194, loss: 104.56164, loss1: 0.79395, loss2_3: 103.76769\n",
      "\ttrain_acc: 0.8268, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.21\n",
      "epoch: 195, loss: 104.49922, loss1: 0.79574, loss2_3: 103.70348\n",
      "\ttrain_acc: 0.8164, test_acc: \u001b[31m0.78215\u001b[0m, time: 36.20\n",
      "epoch: 196, loss: 104.24132, loss1: 0.79330, loss2_3: 103.44801\n",
      "\ttrain_acc: 0.8274, test_acc: \u001b[31m0.7955\u001b[0m, time: 36.22\n",
      "epoch: 197, loss: 104.09703, loss1: 0.79757, loss2_3: 103.29946\n",
      "\ttrain_acc: 0.8260, test_acc: \u001b[31m0.80205\u001b[0m, time: 36.23\n",
      "epoch: 198, loss: 103.90744, loss1: 0.79184, loss2_3: 103.11560\n",
      "\ttrain_acc: 0.8149, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.20\n",
      "epoch: 199, loss: 104.14444, loss1: 0.79418, loss2_3: 103.35026\n",
      "\ttrain_acc: 0.8217, test_acc: \u001b[31m0.7968\u001b[0m, time: 36.99\n",
      "epoch: 200, loss: 103.90945, loss1: 0.79432, loss2_3: 103.11513\n",
      "\ttrain_acc: 0.8178, test_acc: \u001b[31m0.7963\u001b[0m, time: 36.58\n",
      "epoch: 201, loss: 103.53764, loss1: 0.79666, loss2_3: 102.74098\n",
      "\ttrain_acc: 0.8293, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.25\n",
      "epoch: 202, loss: 103.48705, loss1: 0.79439, loss2_3: 102.69266\n",
      "\ttrain_acc: 0.8282, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.23\n",
      "epoch: 203, loss: 103.47032, loss1: 0.79413, loss2_3: 102.67619\n",
      "\ttrain_acc: 0.8278, test_acc: \u001b[31m0.7985\u001b[0m, time: 36.22\n",
      "epoch: 204, loss: 103.60202, loss1: 0.78957, loss2_3: 102.81245\n",
      "\ttrain_acc: 0.8286, test_acc: \u001b[31m0.79745\u001b[0m, time: 36.21\n",
      "epoch: 205, loss: 103.25852, loss1: 0.79289, loss2_3: 102.46563\n",
      "\ttrain_acc: 0.8161, test_acc: \u001b[31m0.7969\u001b[0m, time: 36.24\n",
      "epoch: 206, loss: 103.31593, loss1: 0.79797, loss2_3: 102.51796\n",
      "\ttrain_acc: 0.8246, test_acc: \u001b[31m0.7995\u001b[0m, time: 36.18\n",
      "epoch: 207, loss: 102.98898, loss1: 0.79231, loss2_3: 102.19667\n",
      "\ttrain_acc: 0.8279, test_acc: \u001b[31m0.79835\u001b[0m, time: 36.21\n",
      "epoch: 208, loss: 102.98727, loss1: 0.79112, loss2_3: 102.19614\n",
      "\ttrain_acc: 0.8265, test_acc: \u001b[31m0.80205\u001b[0m, time: 36.23\n",
      "epoch: 209, loss: 102.79735, loss1: 0.78878, loss2_3: 102.00858\n",
      "\ttrain_acc: 0.8282, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.22\n",
      "epoch: 210, loss: 102.33045, loss1: 0.79171, loss2_3: 101.53874\n",
      "\ttrain_acc: 0.8246, test_acc: \u001b[31m0.7988\u001b[0m, time: 36.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 211, loss: 102.44838, loss1: 0.79041, loss2_3: 101.65797\n",
      "\ttrain_acc: 0.8305, test_acc: \u001b[31m0.796\u001b[0m, time: 36.21\n",
      "epoch: 212, loss: 101.97264, loss1: 0.79242, loss2_3: 101.18022\n",
      "\ttrain_acc: 0.8318, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.21\n",
      "epoch: 213, loss: 102.21238, loss1: 0.78725, loss2_3: 101.42513\n",
      "\ttrain_acc: 0.8251, test_acc: \u001b[31m0.79895\u001b[0m, time: 36.22\n",
      "epoch: 214, loss: 101.89629, loss1: 0.78731, loss2_3: 101.10899\n",
      "\ttrain_acc: 0.8255, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.21\n",
      "epoch: 215, loss: 101.86706, loss1: 0.78525, loss2_3: 101.08181\n",
      "\ttrain_acc: 0.8326, test_acc: \u001b[31m0.8004\u001b[0m, time: 36.23\n",
      "epoch: 216, loss: 101.80015, loss1: 0.79030, loss2_3: 101.00985\n",
      "\ttrain_acc: 0.8261, test_acc: \u001b[31m0.7786\u001b[0m, time: 37.28\n",
      "epoch: 217, loss: 101.34370, loss1: 0.78580, loss2_3: 100.55791\n",
      "\ttrain_acc: 0.8043, test_acc: \u001b[31m0.7559\u001b[0m, time: 37.28\n",
      "epoch: 218, loss: 101.57598, loss1: 0.78667, loss2_3: 100.78931\n",
      "\ttrain_acc: 0.8200, test_acc: \u001b[31m0.76955\u001b[0m, time: 36.41\n",
      "epoch: 219, loss: 101.14858, loss1: 0.78695, loss2_3: 100.36163\n",
      "\ttrain_acc: 0.8238, test_acc: \u001b[31m0.7747\u001b[0m, time: 36.22\n",
      "epoch: 220, loss: 101.29916, loss1: 0.78599, loss2_3: 100.51318\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.78895\u001b[0m, time: 36.24\n",
      "epoch: 221, loss: 100.88294, loss1: 0.78366, loss2_3: 100.09928\n",
      "\ttrain_acc: 0.8295, test_acc: \u001b[31m0.79925\u001b[0m, time: 36.24\n",
      "epoch: 222, loss: 100.99887, loss1: 0.78151, loss2_3: 100.21736\n",
      "\ttrain_acc: 0.8260, test_acc: \u001b[31m0.7967\u001b[0m, time: 36.23\n",
      "epoch: 223, loss: 100.63267, loss1: 0.78687, loss2_3: 99.84580\n",
      "\ttrain_acc: 0.8354, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.20\n",
      "epoch: 224, loss: 100.60612, loss1: 0.77864, loss2_3: 99.82748\n",
      "\ttrain_acc: 0.8319, test_acc: \u001b[31m0.79795\u001b[0m, time: 36.25\n",
      "epoch: 225, loss: 100.63428, loss1: 0.78385, loss2_3: 99.85043\n",
      "\ttrain_acc: 0.8364, test_acc: \u001b[31m0.7986\u001b[0m, time: 36.20\n",
      "epoch: 226, loss: 100.05799, loss1: 0.78121, loss2_3: 99.27678\n",
      "\ttrain_acc: 0.8301, test_acc: \u001b[31m0.79895\u001b[0m, time: 36.24\n",
      "epoch: 227, loss: 99.76331, loss1: 0.78209, loss2_3: 98.98122\n",
      "\ttrain_acc: 0.7646, test_acc: \u001b[31m0.7128\u001b[0m, time: 36.43\n",
      "epoch: 228, loss: 99.68049, loss1: 0.78276, loss2_3: 98.89773\n",
      "\ttrain_acc: 0.8395, test_acc: \u001b[31m0.7968\u001b[0m, time: 36.42\n",
      "epoch: 229, loss: 99.32284, loss1: 0.78024, loss2_3: 98.54259\n",
      "\ttrain_acc: 0.8389, test_acc: \u001b[31m0.78385\u001b[0m, time: 36.23\n",
      "epoch: 230, loss: 99.40518, loss1: 0.78571, loss2_3: 98.61947\n",
      "\ttrain_acc: 0.8375, test_acc: \u001b[31m0.79315\u001b[0m, time: 36.21\n",
      "epoch: 231, loss: 99.48412, loss1: 0.77987, loss2_3: 98.70425\n",
      "\ttrain_acc: 0.8377, test_acc: \u001b[31m0.7855\u001b[0m, time: 36.23\n",
      "epoch: 232, loss: 98.57819, loss1: 0.77892, loss2_3: 97.79927\n",
      "\ttrain_acc: 0.7997, test_acc: \u001b[31m0.78045\u001b[0m, time: 36.21\n",
      "epoch: 233, loss: 98.70084, loss1: 0.77708, loss2_3: 97.92375\n",
      "\ttrain_acc: 0.8227, test_acc: \u001b[31m0.7708\u001b[0m, time: 36.21\n",
      "epoch: 234, loss: 98.83131, loss1: 0.77782, loss2_3: 98.05349\n",
      "\ttrain_acc: 0.8435, test_acc: \u001b[31m0.79305\u001b[0m, time: 36.23\n",
      "epoch: 235, loss: 98.18431, loss1: 0.77363, loss2_3: 97.41068\n",
      "\ttrain_acc: 0.8371, test_acc: \u001b[31m0.79615\u001b[0m, time: 36.20\n",
      "epoch: 236, loss: 98.12719, loss1: 0.77822, loss2_3: 97.34896\n",
      "\ttrain_acc: 0.8432, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.18\n",
      "epoch: 237, loss: 97.80109, loss1: 0.77291, loss2_3: 97.02818\n",
      "\ttrain_acc: 0.8438, test_acc: \u001b[31m0.7949\u001b[0m, time: 36.24\n",
      "epoch: 238, loss: 97.62402, loss1: 0.77198, loss2_3: 96.85204\n",
      "\ttrain_acc: 0.8167, test_acc: \u001b[31m0.79035\u001b[0m, time: 36.18\n",
      "epoch: 239, loss: 97.31762, loss1: 0.77085, loss2_3: 96.54677\n",
      "\ttrain_acc: 0.8330, test_acc: \u001b[31m0.79565\u001b[0m, time: 36.22\n",
      "epoch: 240, loss: 97.58607, loss1: 0.77483, loss2_3: 96.81124\n",
      "\ttrain_acc: 0.8467, test_acc: \u001b[31m0.79655\u001b[0m, time: 36.23\n",
      "epoch: 241, loss: 97.10839, loss1: 0.77643, loss2_3: 96.33196\n",
      "\ttrain_acc: 0.8283, test_acc: \u001b[31m0.76365\u001b[0m, time: 36.23\n",
      "epoch: 242, loss: 97.14793, loss1: 0.76696, loss2_3: 96.38097\n",
      "\ttrain_acc: 0.8418, test_acc: \u001b[31m0.79605\u001b[0m, time: 36.24\n",
      "epoch: 243, loss: 96.92314, loss1: 0.77212, loss2_3: 96.15102\n",
      "\ttrain_acc: 0.8244, test_acc: \u001b[31m0.79235\u001b[0m, time: 36.24\n",
      "epoch: 244, loss: 96.71197, loss1: 0.77329, loss2_3: 95.93868\n",
      "\ttrain_acc: 0.8467, test_acc: \u001b[31m0.785\u001b[0m, time: 36.21\n",
      "epoch: 245, loss: 96.22477, loss1: 0.76715, loss2_3: 95.45762\n",
      "\ttrain_acc: 0.8432, test_acc: \u001b[31m0.78045\u001b[0m, time: 36.26\n",
      "epoch: 246, loss: 96.53823, loss1: 0.77036, loss2_3: 95.76787\n",
      "\ttrain_acc: 0.8318, test_acc: \u001b[31m0.79595\u001b[0m, time: 36.21\n",
      "epoch: 247, loss: 95.90957, loss1: 0.77017, loss2_3: 95.13939\n",
      "\ttrain_acc: 0.8482, test_acc: \u001b[31m0.78515\u001b[0m, time: 36.25\n",
      "epoch: 248, loss: 95.77768, loss1: 0.76838, loss2_3: 95.00930\n",
      "\ttrain_acc: 0.8415, test_acc: \u001b[31m0.79555\u001b[0m, time: 36.19\n",
      "epoch: 249, loss: 95.57962, loss1: 0.76787, loss2_3: 94.81176\n",
      "\ttrain_acc: 0.8439, test_acc: \u001b[31m0.78935\u001b[0m, time: 36.21\n",
      "epoch: 250, loss: 94.79310, loss1: 0.76410, loss2_3: 94.02901\n",
      "\ttrain_acc: 0.8274, test_acc: \u001b[31m0.79385\u001b[0m, time: 36.22\n",
      "epoch: 1, loss: 181.10706, loss1: 2.58565, loss2_3: 178.52141\n",
      "\ttrain_acc: 0.5350, test_acc: \u001b[31m0.52765\u001b[0m, time: 36.47\n",
      "best_acc: 0.52765\n",
      "epoch: 2, loss: 176.72144, loss1: 1.02555, loss2_3: 175.69589\n",
      "\ttrain_acc: 0.5333, test_acc: \u001b[31m0.53335\u001b[0m, time: 36.49\n",
      "best_acc: 0.53335\n",
      "epoch: 3, loss: 174.69141, loss1: 1.02603, loss2_3: 173.66537\n",
      "\ttrain_acc: 0.6015, test_acc: \u001b[31m0.5982\u001b[0m, time: 36.51\n",
      "best_acc: 0.5982\n",
      "epoch: 4, loss: 166.42469, loss1: 1.02639, loss2_3: 165.39830\n",
      "\ttrain_acc: 0.6682, test_acc: \u001b[31m0.6715\u001b[0m, time: 36.51\n",
      "best_acc: 0.6715\n",
      "epoch: 5, loss: 148.98355, loss1: 1.00228, loss2_3: 147.98127\n",
      "\ttrain_acc: 0.7175, test_acc: \u001b[31m0.7224\u001b[0m, time: 36.49\n",
      "best_acc: 0.7224\n",
      "epoch: 6, loss: 137.61450, loss1: 0.97351, loss2_3: 136.64099\n",
      "\ttrain_acc: 0.7436, test_acc: \u001b[31m0.7447\u001b[0m, time: 36.51\n",
      "best_acc: 0.7447\n",
      "epoch: 7, loss: 132.79151, loss1: 0.95764, loss2_3: 131.83386\n",
      "\ttrain_acc: 0.7579, test_acc: \u001b[31m0.75985\u001b[0m, time: 36.47\n",
      "best_acc: 0.75985\n",
      "epoch: 8, loss: 129.94430, loss1: 0.94352, loss2_3: 129.00078\n",
      "\ttrain_acc: 0.7732, test_acc: \u001b[31m0.7736\u001b[0m, time: 36.51\n",
      "best_acc: 0.7736\n",
      "epoch: 9, loss: 128.91663, loss1: 0.93512, loss2_3: 127.98150\n",
      "\ttrain_acc: 0.7722, test_acc: \u001b[31m0.77365\u001b[0m, time: 36.47\n",
      "best_acc: 0.77365\n",
      "epoch: 10, loss: 127.56320, loss1: 0.93410, loss2_3: 126.62911\n",
      "\ttrain_acc: 0.7722, test_acc: \u001b[31m0.7725\u001b[0m, time: 36.48\n",
      "epoch: 11, loss: 126.20678, loss1: 0.91997, loss2_3: 125.28680\n",
      "\ttrain_acc: 0.7786, test_acc: \u001b[31m0.7796\u001b[0m, time: 36.49\n",
      "best_acc: 0.7796\n",
      "epoch: 12, loss: 125.11317, loss1: 0.91278, loss2_3: 124.20039\n",
      "\ttrain_acc: 0.7771, test_acc: \u001b[31m0.77955\u001b[0m, time: 36.46\n",
      "epoch: 13, loss: 124.46466, loss1: 0.91279, loss2_3: 123.55187\n",
      "\ttrain_acc: 0.7794, test_acc: \u001b[31m0.78215\u001b[0m, time: 36.51\n",
      "best_acc: 0.78215\n",
      "epoch: 14, loss: 123.09220, loss1: 0.90162, loss2_3: 122.19058\n",
      "\ttrain_acc: 0.7744, test_acc: \u001b[31m0.77405\u001b[0m, time: 36.46\n",
      "epoch: 15, loss: 122.60253, loss1: 0.90220, loss2_3: 121.70033\n",
      "\ttrain_acc: 0.7776, test_acc: \u001b[31m0.77695\u001b[0m, time: 36.47\n",
      "epoch: 16, loss: 122.10905, loss1: 0.89692, loss2_3: 121.21213\n",
      "\ttrain_acc: 0.7844, test_acc: \u001b[31m0.7849\u001b[0m, time: 36.48\n",
      "best_acc: 0.7849\n",
      "epoch: 17, loss: 122.00282, loss1: 0.89668, loss2_3: 121.10614\n",
      "\ttrain_acc: 0.7812, test_acc: \u001b[31m0.7806\u001b[0m, time: 36.45\n",
      "epoch: 18, loss: 121.90600, loss1: 0.89785, loss2_3: 121.00816\n",
      "\ttrain_acc: 0.7882, test_acc: \u001b[31m0.7886\u001b[0m, time: 36.48\n",
      "best_acc: 0.7886\n",
      "epoch: 19, loss: 121.37302, loss1: 0.89202, loss2_3: 120.48100\n",
      "\ttrain_acc: 0.7840, test_acc: \u001b[31m0.78525\u001b[0m, time: 36.49\n",
      "epoch: 20, loss: 120.84433, loss1: 0.89481, loss2_3: 119.94951\n",
      "\ttrain_acc: 0.7898, test_acc: \u001b[31m0.7918\u001b[0m, time: 36.49\n",
      "best_acc: 0.7918\n",
      "epoch: 21, loss: 121.05535, loss1: 0.89076, loss2_3: 120.16459\n",
      "\ttrain_acc: 0.7686, test_acc: \u001b[31m0.76985\u001b[0m, time: 36.48\n",
      "epoch: 22, loss: 120.56215, loss1: 0.88290, loss2_3: 119.67925\n",
      "\ttrain_acc: 0.7875, test_acc: \u001b[31m0.7898\u001b[0m, time: 36.50\n",
      "epoch: 23, loss: 119.98616, loss1: 0.88174, loss2_3: 119.10442\n",
      "\ttrain_acc: 0.7866, test_acc: \u001b[31m0.7874\u001b[0m, time: 36.44\n",
      "epoch: 24, loss: 120.42641, loss1: 0.88548, loss2_3: 119.54093\n",
      "\ttrain_acc: 0.7943, test_acc: \u001b[31m0.7944\u001b[0m, time: 36.48\n",
      "best_acc: 0.7944\n",
      "epoch: 25, loss: 120.04362, loss1: 0.88229, loss2_3: 119.16133\n",
      "\ttrain_acc: 0.7884, test_acc: \u001b[31m0.79205\u001b[0m, time: 36.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26, loss: 119.91162, loss1: 0.87459, loss2_3: 119.03703\n",
      "\ttrain_acc: 0.7844, test_acc: \u001b[31m0.78525\u001b[0m, time: 36.46\n",
      "epoch: 27, loss: 119.59064, loss1: 0.88335, loss2_3: 118.70730\n",
      "\ttrain_acc: 0.7921, test_acc: \u001b[31m0.79335\u001b[0m, time: 36.77\n",
      "epoch: 28, loss: 119.61938, loss1: 0.87332, loss2_3: 118.74605\n",
      "\ttrain_acc: 0.7912, test_acc: \u001b[31m0.79135\u001b[0m, time: 36.79\n",
      "epoch: 29, loss: 119.31221, loss1: 0.87749, loss2_3: 118.43472\n",
      "\ttrain_acc: 0.7896, test_acc: \u001b[31m0.78835\u001b[0m, time: 36.79\n",
      "epoch: 30, loss: 119.24796, loss1: 0.87536, loss2_3: 118.37260\n",
      "\ttrain_acc: 0.7928, test_acc: \u001b[31m0.7896\u001b[0m, time: 36.79\n",
      "epoch: 31, loss: 118.79846, loss1: 0.87819, loss2_3: 117.92026\n",
      "\ttrain_acc: 0.7892, test_acc: \u001b[31m0.78925\u001b[0m, time: 36.75\n",
      "epoch: 32, loss: 118.90374, loss1: 0.87282, loss2_3: 118.03092\n",
      "\ttrain_acc: 0.7917, test_acc: \u001b[31m0.7906\u001b[0m, time: 36.81\n",
      "epoch: 33, loss: 118.72536, loss1: 0.86645, loss2_3: 117.85891\n",
      "\ttrain_acc: 0.7941, test_acc: \u001b[31m0.79345\u001b[0m, time: 36.76\n",
      "epoch: 34, loss: 118.25424, loss1: 0.87331, loss2_3: 117.38093\n",
      "\ttrain_acc: 0.7916, test_acc: \u001b[31m0.79085\u001b[0m, time: 36.79\n",
      "epoch: 35, loss: 118.62842, loss1: 0.86882, loss2_3: 117.75960\n",
      "\ttrain_acc: 0.7946, test_acc: \u001b[31m0.79365\u001b[0m, time: 36.78\n",
      "epoch: 36, loss: 118.25057, loss1: 0.86578, loss2_3: 117.38479\n",
      "\ttrain_acc: 0.7948, test_acc: \u001b[31m0.7941\u001b[0m, time: 36.77\n",
      "epoch: 37, loss: 118.21349, loss1: 0.86687, loss2_3: 117.34662\n",
      "\ttrain_acc: 0.7927, test_acc: \u001b[31m0.7925\u001b[0m, time: 36.62\n",
      "epoch: 38, loss: 117.96164, loss1: 0.86358, loss2_3: 117.09806\n",
      "\ttrain_acc: 0.7969, test_acc: \u001b[31m0.79635\u001b[0m, time: 36.44\n",
      "best_acc: 0.79635\n",
      "epoch: 39, loss: 117.99335, loss1: 0.86725, loss2_3: 117.12610\n",
      "\ttrain_acc: 0.7906, test_acc: \u001b[31m0.78875\u001b[0m, time: 36.40\n",
      "epoch: 40, loss: 117.91818, loss1: 0.86539, loss2_3: 117.05279\n",
      "\ttrain_acc: 0.7978, test_acc: \u001b[31m0.79805\u001b[0m, time: 36.41\n",
      "best_acc: 0.79805\n",
      "epoch: 41, loss: 117.97758, loss1: 0.86256, loss2_3: 117.11501\n",
      "\ttrain_acc: 0.7957, test_acc: \u001b[31m0.7939\u001b[0m, time: 36.38\n",
      "epoch: 42, loss: 117.57418, loss1: 0.86387, loss2_3: 116.71031\n",
      "\ttrain_acc: 0.7953, test_acc: \u001b[31m0.7939\u001b[0m, time: 36.42\n",
      "epoch: 43, loss: 117.25626, loss1: 0.85560, loss2_3: 116.40066\n",
      "\ttrain_acc: 0.7968, test_acc: \u001b[31m0.79615\u001b[0m, time: 36.38\n",
      "epoch: 44, loss: 117.61058, loss1: 0.86794, loss2_3: 116.74264\n",
      "\ttrain_acc: 0.7924, test_acc: \u001b[31m0.79195\u001b[0m, time: 36.39\n",
      "epoch: 45, loss: 117.34416, loss1: 0.85720, loss2_3: 116.48696\n",
      "\ttrain_acc: 0.7964, test_acc: \u001b[31m0.79405\u001b[0m, time: 36.39\n",
      "epoch: 46, loss: 117.27473, loss1: 0.85882, loss2_3: 116.41592\n",
      "\ttrain_acc: 0.7986, test_acc: \u001b[31m0.7977\u001b[0m, time: 36.36\n",
      "epoch: 47, loss: 117.19067, loss1: 0.85846, loss2_3: 116.33221\n",
      "\ttrain_acc: 0.7978, test_acc: \u001b[31m0.79525\u001b[0m, time: 36.37\n",
      "epoch: 48, loss: 117.60516, loss1: 0.85900, loss2_3: 116.74616\n",
      "\ttrain_acc: 0.7956, test_acc: \u001b[31m0.7956\u001b[0m, time: 36.38\n",
      "epoch: 49, loss: 117.08225, loss1: 0.85923, loss2_3: 116.22302\n",
      "\ttrain_acc: 0.7987, test_acc: \u001b[31m0.7971\u001b[0m, time: 36.41\n",
      "epoch: 50, loss: 117.02844, loss1: 0.86114, loss2_3: 116.16730\n",
      "\ttrain_acc: 0.7979, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.39\n",
      "epoch: 51, loss: 117.15974, loss1: 0.85943, loss2_3: 116.30031\n",
      "\ttrain_acc: 0.7988, test_acc: \u001b[31m0.79665\u001b[0m, time: 36.42\n",
      "epoch: 52, loss: 116.76611, loss1: 0.85704, loss2_3: 115.90907\n",
      "\ttrain_acc: 0.8005, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.37\n",
      "best_acc: 0.8006\n",
      "epoch: 53, loss: 117.06349, loss1: 0.85579, loss2_3: 116.20770\n",
      "\ttrain_acc: 0.7978, test_acc: \u001b[31m0.79735\u001b[0m, time: 36.39\n",
      "epoch: 54, loss: 116.75508, loss1: 0.85194, loss2_3: 115.90314\n",
      "\ttrain_acc: 0.7961, test_acc: \u001b[31m0.79545\u001b[0m, time: 36.38\n",
      "epoch: 55, loss: 116.57015, loss1: 0.85220, loss2_3: 115.71795\n",
      "\ttrain_acc: 0.7986, test_acc: \u001b[31m0.79705\u001b[0m, time: 36.37\n",
      "epoch: 56, loss: 116.54612, loss1: 0.85433, loss2_3: 115.69179\n",
      "\ttrain_acc: 0.7999, test_acc: \u001b[31m0.7979\u001b[0m, time: 36.37\n",
      "epoch: 57, loss: 116.32353, loss1: 0.84879, loss2_3: 115.47474\n",
      "\ttrain_acc: 0.7997, test_acc: \u001b[31m0.79745\u001b[0m, time: 36.36\n",
      "epoch: 58, loss: 116.13344, loss1: 0.84554, loss2_3: 115.28790\n",
      "\ttrain_acc: 0.7982, test_acc: \u001b[31m0.79745\u001b[0m, time: 36.37\n",
      "epoch: 59, loss: 116.56105, loss1: 0.85164, loss2_3: 115.70941\n",
      "\ttrain_acc: 0.7982, test_acc: \u001b[31m0.7966\u001b[0m, time: 36.37\n",
      "epoch: 60, loss: 116.48241, loss1: 0.85077, loss2_3: 115.63164\n",
      "\ttrain_acc: 0.8022, test_acc: \u001b[31m0.799\u001b[0m, time: 36.34\n",
      "epoch: 61, loss: 116.20230, loss1: 0.84896, loss2_3: 115.35334\n",
      "\ttrain_acc: 0.8014, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.39\n",
      "epoch: 62, loss: 116.20588, loss1: 0.85181, loss2_3: 115.35407\n",
      "\ttrain_acc: 0.7986, test_acc: \u001b[31m0.79555\u001b[0m, time: 36.35\n",
      "epoch: 63, loss: 116.11474, loss1: 0.84903, loss2_3: 115.26571\n",
      "\ttrain_acc: 0.7992, test_acc: \u001b[31m0.79705\u001b[0m, time: 36.35\n",
      "epoch: 64, loss: 115.89431, loss1: 0.85051, loss2_3: 115.04380\n",
      "\ttrain_acc: 0.7986, test_acc: \u001b[31m0.7969\u001b[0m, time: 36.35\n",
      "epoch: 65, loss: 115.81018, loss1: 0.84653, loss2_3: 114.96366\n",
      "\ttrain_acc: 0.8019, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.34\n",
      "epoch: 66, loss: 115.87402, loss1: 0.84395, loss2_3: 115.03007\n",
      "\ttrain_acc: 0.8009, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.33\n",
      "epoch: 67, loss: 115.95627, loss1: 0.84482, loss2_3: 115.11145\n",
      "\ttrain_acc: 0.8016, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.37\n",
      "epoch: 68, loss: 115.78478, loss1: 0.85254, loss2_3: 114.93224\n",
      "\ttrain_acc: 0.7990, test_acc: \u001b[31m0.79585\u001b[0m, time: 36.33\n",
      "epoch: 69, loss: 115.96051, loss1: 0.84666, loss2_3: 115.11385\n",
      "\ttrain_acc: 0.8022, test_acc: \u001b[31m0.799\u001b[0m, time: 36.34\n",
      "epoch: 70, loss: 115.45831, loss1: 0.84762, loss2_3: 114.61069\n",
      "\ttrain_acc: 0.7996, test_acc: \u001b[31m0.7969\u001b[0m, time: 36.36\n",
      "epoch: 71, loss: 115.76083, loss1: 0.84456, loss2_3: 114.91627\n",
      "\ttrain_acc: 0.8010, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.33\n",
      "epoch: 72, loss: 115.61800, loss1: 0.84487, loss2_3: 114.77313\n",
      "\ttrain_acc: 0.7996, test_acc: \u001b[31m0.799\u001b[0m, time: 36.39\n",
      "epoch: 73, loss: 115.29849, loss1: 0.83737, loss2_3: 114.46113\n",
      "\ttrain_acc: 0.7996, test_acc: \u001b[31m0.79665\u001b[0m, time: 36.35\n",
      "epoch: 74, loss: 115.39992, loss1: 0.84322, loss2_3: 114.55670\n",
      "\ttrain_acc: 0.8020, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.36\n",
      "epoch: 75, loss: 115.16444, loss1: 0.84517, loss2_3: 114.31926\n",
      "\ttrain_acc: 0.8002, test_acc: \u001b[31m0.7966\u001b[0m, time: 36.38\n",
      "epoch: 76, loss: 114.98025, loss1: 0.84412, loss2_3: 114.13613\n",
      "\ttrain_acc: 0.8025, test_acc: \u001b[31m0.7992\u001b[0m, time: 36.71\n",
      "epoch: 77, loss: 115.28941, loss1: 0.83609, loss2_3: 114.45332\n",
      "\ttrain_acc: 0.8025, test_acc: \u001b[31m0.79845\u001b[0m, time: 36.48\n",
      "epoch: 78, loss: 114.98130, loss1: 0.83819, loss2_3: 114.14311\n",
      "\ttrain_acc: 0.8028, test_acc: \u001b[31m0.79735\u001b[0m, time: 36.37\n",
      "epoch: 79, loss: 115.14310, loss1: 0.84396, loss2_3: 114.29914\n",
      "\ttrain_acc: 0.8015, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.35\n",
      "epoch: 80, loss: 114.82306, loss1: 0.83819, loss2_3: 113.98487\n",
      "\ttrain_acc: 0.8012, test_acc: \u001b[31m0.79675\u001b[0m, time: 36.39\n",
      "epoch: 81, loss: 114.58446, loss1: 0.84023, loss2_3: 113.74423\n",
      "\ttrain_acc: 0.8032, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.34\n",
      "best_acc: 0.8008\n",
      "epoch: 82, loss: 114.53492, loss1: 0.83659, loss2_3: 113.69833\n",
      "\ttrain_acc: 0.8002, test_acc: \u001b[31m0.79805\u001b[0m, time: 36.36\n",
      "epoch: 83, loss: 114.53962, loss1: 0.83881, loss2_3: 113.70081\n",
      "\ttrain_acc: 0.8022, test_acc: \u001b[31m0.7978\u001b[0m, time: 36.37\n",
      "epoch: 84, loss: 114.66765, loss1: 0.83520, loss2_3: 113.83245\n",
      "\ttrain_acc: 0.8027, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.36\n",
      "epoch: 85, loss: 114.51125, loss1: 0.83705, loss2_3: 113.67420\n",
      "\ttrain_acc: 0.8036, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.35\n",
      "epoch: 86, loss: 114.93398, loss1: 0.84324, loss2_3: 114.09074\n",
      "\ttrain_acc: 0.8019, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.39\n",
      "epoch: 87, loss: 113.95793, loss1: 0.83844, loss2_3: 113.11949\n",
      "\ttrain_acc: 0.8032, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.36\n",
      "best_acc: 0.80095\n",
      "epoch: 88, loss: 114.60031, loss1: 0.83374, loss2_3: 113.76657\n",
      "\ttrain_acc: 0.8006, test_acc: \u001b[31m0.79795\u001b[0m, time: 36.42\n",
      "epoch: 89, loss: 114.45491, loss1: 0.83700, loss2_3: 113.61791\n",
      "\ttrain_acc: 0.8029, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.36\n",
      "epoch: 90, loss: 114.07267, loss1: 0.83461, loss2_3: 113.23806\n",
      "\ttrain_acc: 0.8041, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.37\n",
      "epoch: 91, loss: 114.31311, loss1: 0.83730, loss2_3: 113.47581\n",
      "\ttrain_acc: 0.8015, test_acc: \u001b[31m0.7999\u001b[0m, time: 36.38\n",
      "epoch: 92, loss: 113.94345, loss1: 0.83105, loss2_3: 113.11240\n",
      "\ttrain_acc: 0.8038, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 93, loss: 114.07998, loss1: 0.83273, loss2_3: 113.24725\n",
      "\ttrain_acc: 0.8042, test_acc: \u001b[31m0.7992\u001b[0m, time: 36.37\n",
      "epoch: 94, loss: 114.06489, loss1: 0.83812, loss2_3: 113.22677\n",
      "\ttrain_acc: 0.8048, test_acc: \u001b[31m0.80085\u001b[0m, time: 36.32\n",
      "epoch: 95, loss: 113.75643, loss1: 0.83359, loss2_3: 112.92284\n",
      "\ttrain_acc: 0.8068, test_acc: \u001b[31m0.801\u001b[0m, time: 36.35\n",
      "best_acc: 0.801\n",
      "epoch: 96, loss: 113.47939, loss1: 0.83053, loss2_3: 112.64886\n",
      "\ttrain_acc: 0.8052, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.34\n",
      "epoch: 97, loss: 113.78173, loss1: 0.83446, loss2_3: 112.94727\n",
      "\ttrain_acc: 0.8044, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.34\n",
      "best_acc: 0.80195\n",
      "epoch: 98, loss: 113.38104, loss1: 0.83111, loss2_3: 112.54993\n",
      "\ttrain_acc: 0.8062, test_acc: \u001b[31m0.80145\u001b[0m, time: 36.31\n",
      "epoch: 99, loss: 113.59805, loss1: 0.83357, loss2_3: 112.76448\n",
      "\ttrain_acc: 0.8065, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.36\n",
      "epoch: 100, loss: 113.24373, loss1: 0.83141, loss2_3: 112.41232\n",
      "\ttrain_acc: 0.8056, test_acc: \u001b[31m0.79775\u001b[0m, time: 36.32\n",
      "epoch: 101, loss: 113.29310, loss1: 0.83301, loss2_3: 112.46008\n",
      "\ttrain_acc: 0.8043, test_acc: \u001b[31m0.7991\u001b[0m, time: 36.36\n",
      "epoch: 102, loss: 113.14138, loss1: 0.82469, loss2_3: 112.31669\n",
      "\ttrain_acc: 0.8016, test_acc: \u001b[31m0.79565\u001b[0m, time: 36.35\n",
      "epoch: 103, loss: 113.11910, loss1: 0.82899, loss2_3: 112.29011\n",
      "\ttrain_acc: 0.8048, test_acc: \u001b[31m0.79935\u001b[0m, time: 36.37\n",
      "epoch: 104, loss: 113.11695, loss1: 0.83076, loss2_3: 112.28619\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.8004\u001b[0m, time: 36.36\n",
      "epoch: 105, loss: 113.12215, loss1: 0.82692, loss2_3: 112.29523\n",
      "\ttrain_acc: 0.8068, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.37\n",
      "epoch: 106, loss: 112.92038, loss1: 0.82537, loss2_3: 112.09501\n",
      "\ttrain_acc: 0.8012, test_acc: \u001b[31m0.794\u001b[0m, time: 36.35\n",
      "epoch: 107, loss: 112.92941, loss1: 0.82606, loss2_3: 112.10334\n",
      "\ttrain_acc: 0.8070, test_acc: \u001b[31m0.8017\u001b[0m, time: 36.36\n",
      "epoch: 108, loss: 112.73867, loss1: 0.82401, loss2_3: 111.91466\n",
      "\ttrain_acc: 0.8063, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.32\n",
      "epoch: 109, loss: 113.12194, loss1: 0.83158, loss2_3: 112.29036\n",
      "\ttrain_acc: 0.8056, test_acc: \u001b[31m0.8\u001b[0m, time: 36.37\n",
      "epoch: 110, loss: 112.79695, loss1: 0.82802, loss2_3: 111.96893\n",
      "\ttrain_acc: 0.8062, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.33\n",
      "epoch: 111, loss: 112.37513, loss1: 0.82404, loss2_3: 111.55109\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.8012\u001b[0m, time: 36.36\n",
      "epoch: 112, loss: 112.55892, loss1: 0.82964, loss2_3: 111.72928\n",
      "\ttrain_acc: 0.8052, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.34\n",
      "epoch: 113, loss: 112.41927, loss1: 0.82179, loss2_3: 111.59748\n",
      "\ttrain_acc: 0.8041, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.36\n",
      "epoch: 114, loss: 112.33646, loss1: 0.83029, loss2_3: 111.50617\n",
      "\ttrain_acc: 0.8054, test_acc: \u001b[31m0.7986\u001b[0m, time: 36.34\n",
      "epoch: 115, loss: 112.04825, loss1: 0.82087, loss2_3: 111.22738\n",
      "\ttrain_acc: 0.8090, test_acc: \u001b[31m0.8004\u001b[0m, time: 36.38\n",
      "epoch: 116, loss: 112.16960, loss1: 0.82582, loss2_3: 111.34378\n",
      "\ttrain_acc: 0.8084, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.32\n",
      "epoch: 117, loss: 112.19267, loss1: 0.82186, loss2_3: 111.37082\n",
      "\ttrain_acc: 0.8062, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.32\n",
      "epoch: 118, loss: 111.90955, loss1: 0.82154, loss2_3: 111.08800\n",
      "\ttrain_acc: 0.8081, test_acc: \u001b[31m0.8009\u001b[0m, time: 36.33\n",
      "epoch: 119, loss: 111.71626, loss1: 0.82317, loss2_3: 110.89309\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.79865\u001b[0m, time: 36.30\n",
      "epoch: 120, loss: 111.74039, loss1: 0.82442, loss2_3: 110.91597\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.32\n",
      "epoch: 121, loss: 111.51685, loss1: 0.82508, loss2_3: 110.69177\n",
      "\ttrain_acc: 0.8086, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.29\n",
      "epoch: 122, loss: 111.70286, loss1: 0.81936, loss2_3: 110.88350\n",
      "\ttrain_acc: 0.8082, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.32\n",
      "epoch: 123, loss: 111.74007, loss1: 0.82214, loss2_3: 110.91794\n",
      "\ttrain_acc: 0.8069, test_acc: \u001b[31m0.8\u001b[0m, time: 36.28\n",
      "epoch: 124, loss: 111.17004, loss1: 0.81818, loss2_3: 110.35186\n",
      "\ttrain_acc: 0.8098, test_acc: \u001b[31m0.8016\u001b[0m, time: 36.31\n",
      "epoch: 125, loss: 110.93546, loss1: 0.81660, loss2_3: 110.11886\n",
      "\ttrain_acc: 0.8094, test_acc: \u001b[31m0.80085\u001b[0m, time: 36.32\n",
      "epoch: 126, loss: 111.01400, loss1: 0.82226, loss2_3: 110.19174\n",
      "\ttrain_acc: 0.8089, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.30\n",
      "epoch: 127, loss: 111.18372, loss1: 0.81913, loss2_3: 110.36459\n",
      "\ttrain_acc: 0.8082, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.31\n",
      "epoch: 128, loss: 110.92485, loss1: 0.81895, loss2_3: 110.10591\n",
      "\ttrain_acc: 0.8085, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.33\n",
      "epoch: 129, loss: 111.19508, loss1: 0.82154, loss2_3: 110.37354\n",
      "\ttrain_acc: 0.8101, test_acc: \u001b[31m0.8003\u001b[0m, time: 36.34\n",
      "epoch: 130, loss: 110.84701, loss1: 0.81724, loss2_3: 110.02977\n",
      "\ttrain_acc: 0.8067, test_acc: \u001b[31m0.7969\u001b[0m, time: 36.31\n",
      "epoch: 131, loss: 110.78118, loss1: 0.82123, loss2_3: 109.95995\n",
      "\ttrain_acc: 0.8095, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.37\n",
      "epoch: 132, loss: 110.50169, loss1: 0.81720, loss2_3: 109.68448\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.8019\u001b[0m, time: 36.30\n",
      "epoch: 133, loss: 110.38572, loss1: 0.81415, loss2_3: 109.57157\n",
      "\ttrain_acc: 0.8114, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.33\n",
      "epoch: 134, loss: 110.56288, loss1: 0.81663, loss2_3: 109.74626\n",
      "\ttrain_acc: 0.8080, test_acc: \u001b[31m0.79935\u001b[0m, time: 36.33\n",
      "epoch: 135, loss: 110.20311, loss1: 0.81299, loss2_3: 109.39012\n",
      "\ttrain_acc: 0.8117, test_acc: \u001b[31m0.80305\u001b[0m, time: 36.32\n",
      "best_acc: 0.80305\n",
      "epoch: 136, loss: 110.05250, loss1: 0.81586, loss2_3: 109.23665\n",
      "\ttrain_acc: 0.8118, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.33\n",
      "epoch: 137, loss: 110.26473, loss1: 0.81612, loss2_3: 109.44862\n",
      "\ttrain_acc: 0.8087, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.34\n",
      "epoch: 138, loss: 110.34044, loss1: 0.81450, loss2_3: 109.52594\n",
      "\ttrain_acc: 0.8133, test_acc: \u001b[31m0.80085\u001b[0m, time: 36.34\n",
      "epoch: 139, loss: 109.95556, loss1: 0.81513, loss2_3: 109.14044\n",
      "\ttrain_acc: 0.8130, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.34\n",
      "epoch: 140, loss: 109.92346, loss1: 0.81332, loss2_3: 109.11014\n",
      "\ttrain_acc: 0.8144, test_acc: \u001b[31m0.8028\u001b[0m, time: 36.32\n",
      "epoch: 141, loss: 109.92691, loss1: 0.81339, loss2_3: 109.11351\n",
      "\ttrain_acc: 0.8117, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.37\n",
      "epoch: 142, loss: 109.67999, loss1: 0.81104, loss2_3: 108.86895\n",
      "\ttrain_acc: 0.8129, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.33\n",
      "epoch: 143, loss: 109.62063, loss1: 0.80993, loss2_3: 108.81070\n",
      "\ttrain_acc: 0.8131, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.34\n",
      "epoch: 144, loss: 109.54762, loss1: 0.81191, loss2_3: 108.73571\n",
      "\ttrain_acc: 0.8143, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.35\n",
      "epoch: 145, loss: 109.26634, loss1: 0.81211, loss2_3: 108.45422\n",
      "\ttrain_acc: 0.8144, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.32\n",
      "epoch: 146, loss: 109.34389, loss1: 0.81310, loss2_3: 108.53079\n",
      "\ttrain_acc: 0.8139, test_acc: \u001b[31m0.8017\u001b[0m, time: 36.30\n",
      "epoch: 147, loss: 109.05255, loss1: 0.81308, loss2_3: 108.23947\n",
      "\ttrain_acc: 0.8142, test_acc: \u001b[31m0.8016\u001b[0m, time: 36.32\n",
      "epoch: 148, loss: 109.25217, loss1: 0.80943, loss2_3: 108.44274\n",
      "\ttrain_acc: 0.8159, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.30\n",
      "epoch: 149, loss: 109.15597, loss1: 0.81465, loss2_3: 108.34132\n",
      "\ttrain_acc: 0.8171, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.27\n",
      "epoch: 150, loss: 108.94034, loss1: 0.80254, loss2_3: 108.13780\n",
      "\ttrain_acc: 0.8098, test_acc: \u001b[31m0.799\u001b[0m, time: 36.31\n",
      "epoch: 151, loss: 108.84252, loss1: 0.80667, loss2_3: 108.03585\n",
      "\ttrain_acc: 0.8145, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.27\n",
      "epoch: 152, loss: 108.74511, loss1: 0.80993, loss2_3: 107.93518\n",
      "\ttrain_acc: 0.8162, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.33\n",
      "epoch: 153, loss: 108.60110, loss1: 0.80950, loss2_3: 107.79160\n",
      "\ttrain_acc: 0.8142, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.30\n",
      "epoch: 154, loss: 108.75714, loss1: 0.80913, loss2_3: 107.94801\n",
      "\ttrain_acc: 0.8165, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.31\n",
      "epoch: 155, loss: 108.73066, loss1: 0.80914, loss2_3: 107.92152\n",
      "\ttrain_acc: 0.8147, test_acc: \u001b[31m0.80075\u001b[0m, time: 36.33\n",
      "epoch: 156, loss: 108.81507, loss1: 0.81244, loss2_3: 108.00263\n",
      "\ttrain_acc: 0.8162, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.32\n",
      "epoch: 157, loss: 108.56349, loss1: 0.80383, loss2_3: 107.75966\n",
      "\ttrain_acc: 0.8133, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.31\n",
      "epoch: 158, loss: 108.23598, loss1: 0.81135, loss2_3: 107.42463\n",
      "\ttrain_acc: 0.8182, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.30\n",
      "epoch: 159, loss: 108.14188, loss1: 0.80539, loss2_3: 107.33649\n",
      "\ttrain_acc: 0.8176, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 160, loss: 107.80207, loss1: 0.81066, loss2_3: 106.99141\n",
      "\ttrain_acc: 0.8182, test_acc: \u001b[31m0.8028\u001b[0m, time: 36.32\n",
      "epoch: 161, loss: 107.81316, loss1: 0.80622, loss2_3: 107.00693\n",
      "\ttrain_acc: 0.8165, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.28\n",
      "epoch: 162, loss: 107.89797, loss1: 0.81154, loss2_3: 107.08643\n",
      "\ttrain_acc: 0.8110, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.28\n",
      "epoch: 163, loss: 107.54679, loss1: 0.80738, loss2_3: 106.73942\n",
      "\ttrain_acc: 0.8129, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.30\n",
      "epoch: 164, loss: 107.46727, loss1: 0.80733, loss2_3: 106.65994\n",
      "\ttrain_acc: 0.8162, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.29\n",
      "epoch: 165, loss: 107.48871, loss1: 0.80879, loss2_3: 106.67992\n",
      "\ttrain_acc: 0.8185, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.29\n",
      "epoch: 166, loss: 107.42283, loss1: 0.80323, loss2_3: 106.61960\n",
      "\ttrain_acc: 0.8172, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.33\n",
      "epoch: 167, loss: 107.09086, loss1: 0.80715, loss2_3: 106.28371\n",
      "\ttrain_acc: 0.8181, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.30\n",
      "epoch: 168, loss: 106.76581, loss1: 0.80190, loss2_3: 105.96391\n",
      "\ttrain_acc: 0.8094, test_acc: \u001b[31m0.7947\u001b[0m, time: 36.31\n",
      "epoch: 169, loss: 107.01170, loss1: 0.80760, loss2_3: 106.20410\n",
      "\ttrain_acc: 0.8130, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.30\n",
      "epoch: 170, loss: 106.67278, loss1: 0.80665, loss2_3: 105.86613\n",
      "\ttrain_acc: 0.8217, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.26\n",
      "epoch: 171, loss: 106.74250, loss1: 0.80441, loss2_3: 105.93809\n",
      "\ttrain_acc: 0.8212, test_acc: \u001b[31m0.8016\u001b[0m, time: 36.31\n",
      "epoch: 172, loss: 106.41272, loss1: 0.80205, loss2_3: 105.61068\n",
      "\ttrain_acc: 0.8229, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.25\n",
      "epoch: 173, loss: 106.19602, loss1: 0.80107, loss2_3: 105.39496\n",
      "\ttrain_acc: 0.8213, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.30\n",
      "epoch: 174, loss: 106.54480, loss1: 0.80380, loss2_3: 105.74100\n",
      "\ttrain_acc: 0.8204, test_acc: \u001b[31m0.8\u001b[0m, time: 36.25\n",
      "epoch: 175, loss: 106.26316, loss1: 0.79733, loss2_3: 105.46583\n",
      "\ttrain_acc: 0.8229, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.28\n",
      "epoch: 176, loss: 106.17248, loss1: 0.80420, loss2_3: 105.36828\n",
      "\ttrain_acc: 0.8168, test_acc: \u001b[31m0.79845\u001b[0m, time: 36.30\n",
      "epoch: 177, loss: 105.86394, loss1: 0.80182, loss2_3: 105.06212\n",
      "\ttrain_acc: 0.8225, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.27\n",
      "epoch: 178, loss: 105.60063, loss1: 0.79700, loss2_3: 104.80363\n",
      "\ttrain_acc: 0.8230, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.30\n",
      "epoch: 179, loss: 105.34683, loss1: 0.80084, loss2_3: 104.54599\n",
      "\ttrain_acc: 0.8226, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.29\n",
      "epoch: 180, loss: 105.46033, loss1: 0.79753, loss2_3: 104.66280\n",
      "\ttrain_acc: 0.8226, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.27\n",
      "epoch: 181, loss: 105.54589, loss1: 0.79758, loss2_3: 104.74831\n",
      "\ttrain_acc: 0.8240, test_acc: \u001b[31m0.8011\u001b[0m, time: 36.26\n",
      "epoch: 182, loss: 105.33694, loss1: 0.79824, loss2_3: 104.53870\n",
      "\ttrain_acc: 0.8256, test_acc: \u001b[31m0.8003\u001b[0m, time: 36.29\n",
      "epoch: 183, loss: 105.29323, loss1: 0.79491, loss2_3: 104.49832\n",
      "\ttrain_acc: 0.8227, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.25\n",
      "epoch: 184, loss: 105.00910, loss1: 0.79915, loss2_3: 104.20995\n",
      "\ttrain_acc: 0.8180, test_acc: \u001b[31m0.79735\u001b[0m, time: 36.29\n",
      "epoch: 185, loss: 104.97706, loss1: 0.79291, loss2_3: 104.18416\n",
      "\ttrain_acc: 0.8273, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.26\n",
      "epoch: 186, loss: 104.36721, loss1: 0.79453, loss2_3: 103.57268\n",
      "\ttrain_acc: 0.8140, test_acc: \u001b[31m0.79455\u001b[0m, time: 36.25\n",
      "epoch: 187, loss: 104.66954, loss1: 0.79746, loss2_3: 103.87208\n",
      "\ttrain_acc: 0.8261, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.32\n",
      "epoch: 188, loss: 104.65572, loss1: 0.79809, loss2_3: 103.85764\n",
      "\ttrain_acc: 0.8184, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.26\n",
      "epoch: 189, loss: 104.66835, loss1: 0.79573, loss2_3: 103.87261\n",
      "\ttrain_acc: 0.8267, test_acc: \u001b[31m0.8031\u001b[0m, time: 36.31\n",
      "best_acc: 0.8031\n",
      "epoch: 190, loss: 104.52810, loss1: 0.79238, loss2_3: 103.73572\n",
      "\ttrain_acc: 0.8253, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.27\n",
      "epoch: 191, loss: 104.11378, loss1: 0.79494, loss2_3: 103.31884\n",
      "\ttrain_acc: 0.8210, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.29\n",
      "epoch: 192, loss: 104.11733, loss1: 0.79703, loss2_3: 103.32030\n",
      "\ttrain_acc: 0.8266, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.27\n",
      "epoch: 193, loss: 103.75364, loss1: 0.79579, loss2_3: 102.95785\n",
      "\ttrain_acc: 0.8288, test_acc: \u001b[31m0.8001\u001b[0m, time: 36.28\n",
      "epoch: 194, loss: 103.81871, loss1: 0.79116, loss2_3: 103.02755\n",
      "\ttrain_acc: 0.8262, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.24\n",
      "epoch: 195, loss: 103.73316, loss1: 0.79537, loss2_3: 102.93779\n",
      "\ttrain_acc: 0.8272, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.29\n",
      "epoch: 196, loss: 103.63546, loss1: 0.78818, loss2_3: 102.84727\n",
      "\ttrain_acc: 0.8276, test_acc: \u001b[31m0.7993\u001b[0m, time: 36.23\n",
      "epoch: 197, loss: 103.28269, loss1: 0.78580, loss2_3: 102.49689\n",
      "\ttrain_acc: 0.8208, test_acc: \u001b[31m0.79735\u001b[0m, time: 36.25\n",
      "epoch: 198, loss: 103.22086, loss1: 0.79329, loss2_3: 102.42757\n",
      "\ttrain_acc: 0.8310, test_acc: \u001b[31m0.7978\u001b[0m, time: 36.27\n",
      "epoch: 199, loss: 102.90952, loss1: 0.79015, loss2_3: 102.11937\n",
      "\ttrain_acc: 0.8295, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.26\n",
      "epoch: 200, loss: 102.79994, loss1: 0.79307, loss2_3: 102.00687\n",
      "\ttrain_acc: 0.8271, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.29\n",
      "epoch: 201, loss: 102.93520, loss1: 0.79484, loss2_3: 102.14036\n",
      "\ttrain_acc: 0.8284, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.27\n",
      "epoch: 202, loss: 102.59242, loss1: 0.79010, loss2_3: 101.80232\n",
      "\ttrain_acc: 0.8270, test_acc: \u001b[31m0.79005\u001b[0m, time: 36.28\n",
      "epoch: 203, loss: 102.33640, loss1: 0.78804, loss2_3: 101.54836\n",
      "\ttrain_acc: 0.8228, test_acc: \u001b[31m0.7822\u001b[0m, time: 36.27\n",
      "epoch: 204, loss: 101.73289, loss1: 0.78581, loss2_3: 100.94709\n",
      "\ttrain_acc: 0.8337, test_acc: \u001b[31m0.795\u001b[0m, time: 36.24\n",
      "epoch: 205, loss: 101.82075, loss1: 0.78554, loss2_3: 101.03521\n",
      "\ttrain_acc: 0.8295, test_acc: \u001b[31m0.80075\u001b[0m, time: 36.25\n",
      "epoch: 206, loss: 102.02640, loss1: 0.78872, loss2_3: 101.23769\n",
      "\ttrain_acc: 0.8341, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.26\n",
      "epoch: 207, loss: 101.60198, loss1: 0.78842, loss2_3: 100.81357\n",
      "\ttrain_acc: 0.8240, test_acc: \u001b[31m0.78045\u001b[0m, time: 36.22\n",
      "epoch: 208, loss: 101.14449, loss1: 0.78435, loss2_3: 100.36014\n",
      "\ttrain_acc: 0.8078, test_acc: \u001b[31m0.79095\u001b[0m, time: 36.26\n",
      "epoch: 209, loss: 101.24803, loss1: 0.78461, loss2_3: 100.46342\n",
      "\ttrain_acc: 0.8354, test_acc: \u001b[31m0.7954\u001b[0m, time: 36.22\n",
      "epoch: 210, loss: 101.35998, loss1: 0.78819, loss2_3: 100.57178\n",
      "\ttrain_acc: 0.8252, test_acc: \u001b[31m0.79625\u001b[0m, time: 36.23\n",
      "epoch: 211, loss: 101.22241, loss1: 0.78646, loss2_3: 100.43595\n",
      "\ttrain_acc: 0.8331, test_acc: \u001b[31m0.79125\u001b[0m, time: 36.26\n",
      "epoch: 212, loss: 100.58115, loss1: 0.78690, loss2_3: 99.79425\n",
      "\ttrain_acc: 0.8262, test_acc: \u001b[31m0.79775\u001b[0m, time: 36.18\n",
      "epoch: 213, loss: 100.44523, loss1: 0.78362, loss2_3: 99.66161\n",
      "\ttrain_acc: 0.8348, test_acc: \u001b[31m0.79075\u001b[0m, time: 36.27\n",
      "epoch: 214, loss: 100.11264, loss1: 0.78517, loss2_3: 99.32747\n",
      "\ttrain_acc: 0.8350, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.22\n",
      "epoch: 215, loss: 100.44653, loss1: 0.77917, loss2_3: 99.66736\n",
      "\ttrain_acc: 0.8215, test_acc: \u001b[31m0.79545\u001b[0m, time: 36.30\n",
      "epoch: 216, loss: 100.22885, loss1: 0.78542, loss2_3: 99.44344\n",
      "\ttrain_acc: 0.8355, test_acc: \u001b[31m0.7867\u001b[0m, time: 36.23\n",
      "epoch: 217, loss: 99.63351, loss1: 0.77790, loss2_3: 98.85561\n",
      "\ttrain_acc: 0.8229, test_acc: \u001b[31m0.77215\u001b[0m, time: 36.30\n",
      "epoch: 218, loss: 99.57423, loss1: 0.78126, loss2_3: 98.79298\n",
      "\ttrain_acc: 0.8361, test_acc: \u001b[31m0.7988\u001b[0m, time: 36.22\n",
      "epoch: 219, loss: 99.53459, loss1: 0.77519, loss2_3: 98.75940\n",
      "\ttrain_acc: 0.8382, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.29\n",
      "epoch: 220, loss: 99.53359, loss1: 0.77768, loss2_3: 98.75590\n",
      "\ttrain_acc: 0.8390, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.20\n",
      "epoch: 221, loss: 99.52180, loss1: 0.77446, loss2_3: 98.74734\n",
      "\ttrain_acc: 0.8412, test_acc: \u001b[31m0.8004\u001b[0m, time: 36.31\n",
      "epoch: 222, loss: 99.01452, loss1: 0.77378, loss2_3: 98.24073\n",
      "\ttrain_acc: 0.8416, test_acc: \u001b[31m0.7964\u001b[0m, time: 36.19\n",
      "epoch: 223, loss: 98.57059, loss1: 0.77527, loss2_3: 97.79533\n",
      "\ttrain_acc: 0.8199, test_acc: \u001b[31m0.79395\u001b[0m, time: 36.29\n",
      "epoch: 224, loss: 98.36881, loss1: 0.77455, loss2_3: 97.59426\n",
      "\ttrain_acc: 0.8429, test_acc: \u001b[31m0.7999\u001b[0m, time: 36.20\n",
      "epoch: 225, loss: 98.25323, loss1: 0.77563, loss2_3: 97.47760\n",
      "\ttrain_acc: 0.8415, test_acc: \u001b[31m0.7906\u001b[0m, time: 36.28\n",
      "epoch: 226, loss: 97.59675, loss1: 0.77671, loss2_3: 96.82004\n",
      "\ttrain_acc: 0.8426, test_acc: \u001b[31m0.7899\u001b[0m, time: 36.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 227, loss: 97.92282, loss1: 0.77555, loss2_3: 97.14727\n",
      "\ttrain_acc: 0.8450, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.30\n",
      "epoch: 228, loss: 97.77376, loss1: 0.76886, loss2_3: 97.00490\n",
      "\ttrain_acc: 0.8337, test_acc: \u001b[31m0.7963\u001b[0m, time: 36.16\n",
      "epoch: 229, loss: 97.12931, loss1: 0.76746, loss2_3: 96.36184\n",
      "\ttrain_acc: 0.8428, test_acc: \u001b[31m0.79635\u001b[0m, time: 36.27\n",
      "epoch: 230, loss: 96.99532, loss1: 0.76972, loss2_3: 96.22560\n",
      "\ttrain_acc: 0.8398, test_acc: \u001b[31m0.78545\u001b[0m, time: 36.19\n",
      "epoch: 231, loss: 96.58316, loss1: 0.76650, loss2_3: 95.81665\n",
      "\ttrain_acc: 0.8419, test_acc: \u001b[31m0.79355\u001b[0m, time: 36.25\n",
      "epoch: 232, loss: 96.97429, loss1: 0.76956, loss2_3: 96.20473\n",
      "\ttrain_acc: 0.8317, test_acc: \u001b[31m0.7682\u001b[0m, time: 36.18\n",
      "epoch: 233, loss: 96.32044, loss1: 0.76530, loss2_3: 95.55513\n",
      "\ttrain_acc: 0.8430, test_acc: \u001b[31m0.8009\u001b[0m, time: 36.25\n",
      "epoch: 234, loss: 96.10391, loss1: 0.76545, loss2_3: 95.33846\n",
      "\ttrain_acc: 0.8455, test_acc: \u001b[31m0.78515\u001b[0m, time: 36.18\n",
      "epoch: 235, loss: 95.66008, loss1: 0.76046, loss2_3: 94.89962\n",
      "\ttrain_acc: 0.8480, test_acc: \u001b[31m0.79725\u001b[0m, time: 36.28\n",
      "epoch: 236, loss: 95.72148, loss1: 0.76307, loss2_3: 94.95841\n",
      "\ttrain_acc: 0.8343, test_acc: \u001b[31m0.7948\u001b[0m, time: 36.21\n",
      "epoch: 237, loss: 95.47159, loss1: 0.75867, loss2_3: 94.71292\n",
      "\ttrain_acc: 0.8444, test_acc: \u001b[31m0.77665\u001b[0m, time: 36.32\n",
      "epoch: 238, loss: 95.22338, loss1: 0.76199, loss2_3: 94.46140\n",
      "\ttrain_acc: 0.8532, test_acc: \u001b[31m0.7948\u001b[0m, time: 36.21\n",
      "epoch: 239, loss: 95.01491, loss1: 0.76375, loss2_3: 94.25116\n",
      "\ttrain_acc: 0.8381, test_acc: \u001b[31m0.79575\u001b[0m, time: 37.13\n",
      "epoch: 240, loss: 94.63437, loss1: 0.75443, loss2_3: 93.87994\n",
      "\ttrain_acc: 0.8483, test_acc: \u001b[31m0.78115\u001b[0m, time: 37.30\n",
      "epoch: 241, loss: 94.11365, loss1: 0.76127, loss2_3: 93.35239\n",
      "\ttrain_acc: 0.8405, test_acc: \u001b[31m0.76855\u001b[0m, time: 37.30\n",
      "epoch: 242, loss: 94.16598, loss1: 0.75692, loss2_3: 93.40906\n",
      "\ttrain_acc: 0.8523, test_acc: \u001b[31m0.79845\u001b[0m, time: 36.56\n",
      "epoch: 243, loss: 93.63213, loss1: 0.75708, loss2_3: 92.87505\n",
      "\ttrain_acc: 0.8481, test_acc: \u001b[31m0.79495\u001b[0m, time: 36.30\n",
      "epoch: 244, loss: 93.42345, loss1: 0.75311, loss2_3: 92.67034\n",
      "\ttrain_acc: 0.8401, test_acc: \u001b[31m0.7992\u001b[0m, time: 36.18\n",
      "epoch: 245, loss: 92.98686, loss1: 0.75533, loss2_3: 92.23153\n",
      "\ttrain_acc: 0.7776, test_acc: \u001b[31m0.7075\u001b[0m, time: 36.27\n",
      "epoch: 246, loss: 93.33786, loss1: 0.75459, loss2_3: 92.58326\n",
      "\ttrain_acc: 0.8392, test_acc: \u001b[31m0.79255\u001b[0m, time: 36.22\n",
      "epoch: 247, loss: 92.83716, loss1: 0.75499, loss2_3: 92.08218\n",
      "\ttrain_acc: 0.8541, test_acc: \u001b[31m0.78645\u001b[0m, time: 36.28\n",
      "epoch: 248, loss: 92.84758, loss1: 0.74908, loss2_3: 92.09850\n",
      "\ttrain_acc: 0.8535, test_acc: \u001b[31m0.7824\u001b[0m, time: 36.24\n",
      "epoch: 249, loss: 92.22853, loss1: 0.75354, loss2_3: 91.47499\n",
      "\ttrain_acc: 0.8549, test_acc: \u001b[31m0.7815\u001b[0m, time: 36.29\n",
      "epoch: 250, loss: 92.33655, loss1: 0.74916, loss2_3: 91.58739\n",
      "\ttrain_acc: 0.8513, test_acc: \u001b[31m0.79405\u001b[0m, time: 36.21\n",
      "epoch: 1, loss: 174.36994, loss1: 2.89333, loss2_3: 171.47661\n",
      "\ttrain_acc: 0.6239, test_acc: \u001b[31m0.6295\u001b[0m, time: 36.51\n",
      "best_acc: 0.6295\n",
      "epoch: 2, loss: 149.26521, loss1: 1.00680, loss2_3: 148.25841\n",
      "\ttrain_acc: 0.7086, test_acc: \u001b[31m0.70505\u001b[0m, time: 36.43\n",
      "best_acc: 0.70505\n",
      "epoch: 3, loss: 138.25627, loss1: 0.97464, loss2_3: 137.28163\n",
      "\ttrain_acc: 0.7346, test_acc: \u001b[31m0.7372\u001b[0m, time: 36.50\n",
      "best_acc: 0.7372\n",
      "epoch: 4, loss: 134.42124, loss1: 0.96239, loss2_3: 133.45885\n",
      "\ttrain_acc: 0.7479, test_acc: \u001b[31m0.7451\u001b[0m, time: 36.42\n",
      "best_acc: 0.7451\n",
      "epoch: 5, loss: 130.83956, loss1: 0.95193, loss2_3: 129.88762\n",
      "\ttrain_acc: 0.7419, test_acc: \u001b[31m0.74515\u001b[0m, time: 36.48\n",
      "best_acc: 0.74515\n",
      "epoch: 6, loss: 129.54660, loss1: 0.94139, loss2_3: 128.60522\n",
      "\ttrain_acc: 0.7416, test_acc: \u001b[31m0.73705\u001b[0m, time: 36.45\n",
      "epoch: 7, loss: 128.42180, loss1: 0.94501, loss2_3: 127.47680\n",
      "\ttrain_acc: 0.7661, test_acc: \u001b[31m0.7628\u001b[0m, time: 36.49\n",
      "best_acc: 0.7628\n",
      "epoch: 8, loss: 127.29323, loss1: 0.92992, loss2_3: 126.36331\n",
      "\ttrain_acc: 0.7702, test_acc: \u001b[31m0.76965\u001b[0m, time: 36.45\n",
      "best_acc: 0.76965\n",
      "epoch: 9, loss: 125.59215, loss1: 0.91564, loss2_3: 124.67651\n",
      "\ttrain_acc: 0.7778, test_acc: \u001b[31m0.77355\u001b[0m, time: 36.53\n",
      "best_acc: 0.77355\n",
      "epoch: 10, loss: 124.89777, loss1: 0.90790, loss2_3: 123.98987\n",
      "\ttrain_acc: 0.7780, test_acc: \u001b[31m0.776\u001b[0m, time: 36.46\n",
      "best_acc: 0.776\n",
      "epoch: 11, loss: 124.65471, loss1: 0.91777, loss2_3: 123.73694\n",
      "\ttrain_acc: 0.7468, test_acc: \u001b[31m0.7458\u001b[0m, time: 36.51\n",
      "epoch: 12, loss: 125.08232, loss1: 0.91090, loss2_3: 124.17142\n",
      "\ttrain_acc: 0.7605, test_acc: \u001b[31m0.7597\u001b[0m, time: 36.46\n",
      "epoch: 13, loss: 123.76947, loss1: 0.90695, loss2_3: 122.86252\n",
      "\ttrain_acc: 0.7695, test_acc: \u001b[31m0.76785\u001b[0m, time: 36.49\n",
      "epoch: 14, loss: 123.44256, loss1: 0.90143, loss2_3: 122.54113\n",
      "\ttrain_acc: 0.7718, test_acc: \u001b[31m0.77105\u001b[0m, time: 36.46\n",
      "epoch: 15, loss: 122.81010, loss1: 0.89903, loss2_3: 121.91107\n",
      "\ttrain_acc: 0.7721, test_acc: \u001b[31m0.77405\u001b[0m, time: 36.49\n",
      "epoch: 16, loss: 122.89413, loss1: 0.89811, loss2_3: 121.99602\n",
      "\ttrain_acc: 0.7772, test_acc: \u001b[31m0.77635\u001b[0m, time: 36.42\n",
      "best_acc: 0.77635\n",
      "epoch: 17, loss: 121.85039, loss1: 0.89424, loss2_3: 120.95614\n",
      "\ttrain_acc: 0.7791, test_acc: \u001b[31m0.77945\u001b[0m, time: 36.51\n",
      "best_acc: 0.77945\n",
      "epoch: 18, loss: 122.33062, loss1: 0.89302, loss2_3: 121.43760\n",
      "\ttrain_acc: 0.7744, test_acc: \u001b[31m0.77595\u001b[0m, time: 36.41\n",
      "epoch: 19, loss: 121.58070, loss1: 0.89357, loss2_3: 120.68713\n",
      "\ttrain_acc: 0.7820, test_acc: \u001b[31m0.7822\u001b[0m, time: 36.50\n",
      "best_acc: 0.7822\n",
      "epoch: 20, loss: 121.14052, loss1: 0.88223, loss2_3: 120.25829\n",
      "\ttrain_acc: 0.7828, test_acc: \u001b[31m0.7815\u001b[0m, time: 36.38\n",
      "epoch: 21, loss: 121.25960, loss1: 0.88850, loss2_3: 120.37109\n",
      "\ttrain_acc: 0.7800, test_acc: \u001b[31m0.78295\u001b[0m, time: 36.48\n",
      "best_acc: 0.78295\n",
      "epoch: 22, loss: 120.56140, loss1: 0.88660, loss2_3: 119.67481\n",
      "\ttrain_acc: 0.7653, test_acc: \u001b[31m0.77055\u001b[0m, time: 36.41\n",
      "epoch: 23, loss: 121.39451, loss1: 0.88657, loss2_3: 120.50794\n",
      "\ttrain_acc: 0.7803, test_acc: \u001b[31m0.7797\u001b[0m, time: 36.50\n",
      "epoch: 24, loss: 121.13314, loss1: 0.88485, loss2_3: 120.24829\n",
      "\ttrain_acc: 0.7824, test_acc: \u001b[31m0.78195\u001b[0m, time: 36.40\n",
      "epoch: 25, loss: 120.39565, loss1: 0.88114, loss2_3: 119.51452\n",
      "\ttrain_acc: 0.7871, test_acc: \u001b[31m0.7875\u001b[0m, time: 36.51\n",
      "best_acc: 0.7875\n",
      "epoch: 26, loss: 119.94259, loss1: 0.87428, loss2_3: 119.06831\n",
      "\ttrain_acc: 0.7849, test_acc: \u001b[31m0.78585\u001b[0m, time: 36.39\n",
      "epoch: 27, loss: 120.29357, loss1: 0.88370, loss2_3: 119.40987\n",
      "\ttrain_acc: 0.7885, test_acc: \u001b[31m0.78745\u001b[0m, time: 36.46\n",
      "epoch: 28, loss: 120.07182, loss1: 0.87839, loss2_3: 119.19343\n",
      "\ttrain_acc: 0.7826, test_acc: \u001b[31m0.78115\u001b[0m, time: 36.40\n",
      "epoch: 29, loss: 120.19825, loss1: 0.87953, loss2_3: 119.31872\n",
      "\ttrain_acc: 0.7925, test_acc: \u001b[31m0.791\u001b[0m, time: 36.45\n",
      "best_acc: 0.791\n",
      "epoch: 30, loss: 119.38071, loss1: 0.87504, loss2_3: 118.50567\n",
      "\ttrain_acc: 0.7933, test_acc: \u001b[31m0.791\u001b[0m, time: 36.38\n",
      "epoch: 31, loss: 119.75839, loss1: 0.87886, loss2_3: 118.87952\n",
      "\ttrain_acc: 0.7806, test_acc: \u001b[31m0.78075\u001b[0m, time: 36.44\n",
      "epoch: 32, loss: 119.73489, loss1: 0.87696, loss2_3: 118.85793\n",
      "\ttrain_acc: 0.7935, test_acc: \u001b[31m0.79195\u001b[0m, time: 36.36\n",
      "best_acc: 0.79195\n",
      "epoch: 33, loss: 119.04694, loss1: 0.87062, loss2_3: 118.17632\n",
      "\ttrain_acc: 0.7951, test_acc: \u001b[31m0.7937\u001b[0m, time: 36.44\n",
      "best_acc: 0.7937\n",
      "epoch: 34, loss: 118.82646, loss1: 0.86880, loss2_3: 117.95766\n",
      "\ttrain_acc: 0.7933, test_acc: \u001b[31m0.79325\u001b[0m, time: 36.36\n",
      "epoch: 35, loss: 118.81988, loss1: 0.87037, loss2_3: 117.94951\n",
      "\ttrain_acc: 0.7932, test_acc: \u001b[31m0.79115\u001b[0m, time: 36.43\n",
      "epoch: 36, loss: 118.61412, loss1: 0.86912, loss2_3: 117.74500\n",
      "\ttrain_acc: 0.7934, test_acc: \u001b[31m0.79295\u001b[0m, time: 36.35\n",
      "epoch: 37, loss: 118.42444, loss1: 0.86628, loss2_3: 117.55815\n",
      "\ttrain_acc: 0.7905, test_acc: \u001b[31m0.7902\u001b[0m, time: 36.38\n",
      "epoch: 38, loss: 118.09053, loss1: 0.87375, loss2_3: 117.21679\n",
      "\ttrain_acc: 0.7984, test_acc: \u001b[31m0.79585\u001b[0m, time: 36.36\n",
      "best_acc: 0.79585\n",
      "epoch: 39, loss: 118.50014, loss1: 0.86311, loss2_3: 117.63703\n",
      "\ttrain_acc: 0.7975, test_acc: \u001b[31m0.79675\u001b[0m, time: 36.40\n",
      "best_acc: 0.79675\n",
      "epoch: 40, loss: 118.26352, loss1: 0.86882, loss2_3: 117.39470\n",
      "\ttrain_acc: 0.7971, test_acc: \u001b[31m0.7964\u001b[0m, time: 36.36\n",
      "epoch: 41, loss: 117.65151, loss1: 0.86015, loss2_3: 116.79136\n",
      "\ttrain_acc: 0.7946, test_acc: \u001b[31m0.79545\u001b[0m, time: 36.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42, loss: 117.95183, loss1: 0.86336, loss2_3: 117.08848\n",
      "\ttrain_acc: 0.7981, test_acc: \u001b[31m0.79575\u001b[0m, time: 36.35\n",
      "epoch: 43, loss: 118.03299, loss1: 0.85505, loss2_3: 117.17794\n",
      "\ttrain_acc: 0.7956, test_acc: \u001b[31m0.79415\u001b[0m, time: 36.40\n",
      "epoch: 44, loss: 117.73547, loss1: 0.86476, loss2_3: 116.87070\n",
      "\ttrain_acc: 0.7979, test_acc: \u001b[31m0.797\u001b[0m, time: 36.36\n",
      "best_acc: 0.797\n",
      "epoch: 45, loss: 117.45557, loss1: 0.86150, loss2_3: 116.59408\n",
      "\ttrain_acc: 0.7965, test_acc: \u001b[31m0.79495\u001b[0m, time: 36.41\n",
      "epoch: 46, loss: 117.18544, loss1: 0.85947, loss2_3: 116.32597\n",
      "\ttrain_acc: 0.7957, test_acc: \u001b[31m0.79515\u001b[0m, time: 36.33\n",
      "epoch: 47, loss: 117.11972, loss1: 0.86440, loss2_3: 116.25533\n",
      "\ttrain_acc: 0.7962, test_acc: \u001b[31m0.79465\u001b[0m, time: 36.41\n",
      "epoch: 48, loss: 117.48356, loss1: 0.85956, loss2_3: 116.62401\n",
      "\ttrain_acc: 0.7925, test_acc: \u001b[31m0.79165\u001b[0m, time: 36.33\n",
      "epoch: 49, loss: 117.08593, loss1: 0.85611, loss2_3: 116.22981\n",
      "\ttrain_acc: 0.7977, test_acc: \u001b[31m0.79605\u001b[0m, time: 36.40\n",
      "epoch: 50, loss: 116.89926, loss1: 0.85537, loss2_3: 116.04389\n",
      "\ttrain_acc: 0.7955, test_acc: \u001b[31m0.7931\u001b[0m, time: 36.30\n",
      "epoch: 51, loss: 117.07740, loss1: 0.86082, loss2_3: 116.21658\n",
      "\ttrain_acc: 0.7996, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.40\n",
      "best_acc: 0.79765\n",
      "epoch: 52, loss: 116.99845, loss1: 0.85520, loss2_3: 116.14326\n",
      "\ttrain_acc: 0.7985, test_acc: \u001b[31m0.7947\u001b[0m, time: 36.28\n",
      "epoch: 53, loss: 116.95901, loss1: 0.85194, loss2_3: 116.10708\n",
      "\ttrain_acc: 0.7996, test_acc: \u001b[31m0.797\u001b[0m, time: 36.35\n",
      "epoch: 54, loss: 117.12006, loss1: 0.85927, loss2_3: 116.26079\n",
      "\ttrain_acc: 0.7982, test_acc: \u001b[31m0.79495\u001b[0m, time: 36.31\n",
      "epoch: 55, loss: 116.64685, loss1: 0.85679, loss2_3: 115.79005\n",
      "\ttrain_acc: 0.7991, test_acc: \u001b[31m0.79835\u001b[0m, time: 36.32\n",
      "best_acc: 0.79835\n",
      "epoch: 56, loss: 116.41765, loss1: 0.84867, loss2_3: 115.56898\n",
      "\ttrain_acc: 0.7985, test_acc: \u001b[31m0.79675\u001b[0m, time: 36.27\n",
      "epoch: 57, loss: 116.65131, loss1: 0.85549, loss2_3: 115.79582\n",
      "\ttrain_acc: 0.7992, test_acc: \u001b[31m0.7972\u001b[0m, time: 36.32\n",
      "epoch: 58, loss: 116.10816, loss1: 0.84725, loss2_3: 115.26091\n",
      "\ttrain_acc: 0.8015, test_acc: \u001b[31m0.79735\u001b[0m, time: 36.23\n",
      "epoch: 59, loss: 116.49167, loss1: 0.85180, loss2_3: 115.63987\n",
      "\ttrain_acc: 0.8001, test_acc: \u001b[31m0.799\u001b[0m, time: 36.28\n",
      "best_acc: 0.799\n",
      "epoch: 60, loss: 116.24530, loss1: 0.84962, loss2_3: 115.39569\n",
      "\ttrain_acc: 0.7972, test_acc: \u001b[31m0.79395\u001b[0m, time: 36.25\n",
      "epoch: 61, loss: 116.22261, loss1: 0.84765, loss2_3: 115.37495\n",
      "\ttrain_acc: 0.8005, test_acc: \u001b[31m0.7968\u001b[0m, time: 36.27\n",
      "epoch: 62, loss: 115.94055, loss1: 0.84490, loss2_3: 115.09565\n",
      "\ttrain_acc: 0.8009, test_acc: \u001b[31m0.8004\u001b[0m, time: 36.24\n",
      "best_acc: 0.8004\n",
      "epoch: 63, loss: 116.10215, loss1: 0.85070, loss2_3: 115.25145\n",
      "\ttrain_acc: 0.8011, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.26\n",
      "best_acc: 0.8008\n",
      "epoch: 64, loss: 115.76130, loss1: 0.85195, loss2_3: 114.90935\n",
      "\ttrain_acc: 0.8007, test_acc: \u001b[31m0.7969\u001b[0m, time: 36.23\n",
      "epoch: 65, loss: 115.84210, loss1: 0.85020, loss2_3: 114.99191\n",
      "\ttrain_acc: 0.8021, test_acc: \u001b[31m0.8\u001b[0m, time: 36.28\n",
      "epoch: 66, loss: 115.85498, loss1: 0.84533, loss2_3: 115.00965\n",
      "\ttrain_acc: 0.8018, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.18\n",
      "epoch: 67, loss: 115.34346, loss1: 0.84804, loss2_3: 114.49542\n",
      "\ttrain_acc: 0.8004, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.29\n",
      "epoch: 68, loss: 115.72534, loss1: 0.84247, loss2_3: 114.88286\n",
      "\ttrain_acc: 0.8019, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.19\n",
      "epoch: 69, loss: 115.55621, loss1: 0.84539, loss2_3: 114.71082\n",
      "\ttrain_acc: 0.7997, test_acc: \u001b[31m0.79875\u001b[0m, time: 36.27\n",
      "epoch: 70, loss: 115.12863, loss1: 0.84247, loss2_3: 114.28616\n",
      "\ttrain_acc: 0.8000, test_acc: \u001b[31m0.7964\u001b[0m, time: 36.21\n",
      "epoch: 71, loss: 114.94237, loss1: 0.84608, loss2_3: 114.09629\n",
      "\ttrain_acc: 0.8005, test_acc: \u001b[31m0.797\u001b[0m, time: 36.29\n",
      "epoch: 72, loss: 115.48292, loss1: 0.84426, loss2_3: 114.63867\n",
      "\ttrain_acc: 0.8001, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.22\n",
      "epoch: 73, loss: 114.96092, loss1: 0.83861, loss2_3: 114.12231\n",
      "\ttrain_acc: 0.8021, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.33\n",
      "epoch: 74, loss: 114.53999, loss1: 0.84049, loss2_3: 113.69950\n",
      "\ttrain_acc: 0.8021, test_acc: \u001b[31m0.79835\u001b[0m, time: 36.21\n",
      "epoch: 75, loss: 114.71042, loss1: 0.84276, loss2_3: 113.86766\n",
      "\ttrain_acc: 0.8029, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.30\n",
      "epoch: 76, loss: 114.67362, loss1: 0.84130, loss2_3: 113.83232\n",
      "\ttrain_acc: 0.7982, test_acc: \u001b[31m0.7946\u001b[0m, time: 36.23\n",
      "epoch: 77, loss: 114.45046, loss1: 0.84428, loss2_3: 113.60617\n",
      "\ttrain_acc: 0.8022, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.28\n",
      "epoch: 78, loss: 114.54741, loss1: 0.84196, loss2_3: 113.70545\n",
      "\ttrain_acc: 0.8006, test_acc: \u001b[31m0.79505\u001b[0m, time: 36.23\n",
      "epoch: 79, loss: 114.54164, loss1: 0.84080, loss2_3: 113.70085\n",
      "\ttrain_acc: 0.8042, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.29\n",
      "epoch: 80, loss: 114.56392, loss1: 0.83377, loss2_3: 113.73015\n",
      "\ttrain_acc: 0.8019, test_acc: \u001b[31m0.79695\u001b[0m, time: 36.22\n",
      "epoch: 81, loss: 114.41988, loss1: 0.83693, loss2_3: 113.58295\n",
      "\ttrain_acc: 0.7998, test_acc: \u001b[31m0.7963\u001b[0m, time: 36.29\n",
      "epoch: 82, loss: 114.18509, loss1: 0.83884, loss2_3: 113.34625\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.21\n",
      "best_acc: 0.80125\n",
      "epoch: 83, loss: 114.39702, loss1: 0.83647, loss2_3: 113.56056\n",
      "\ttrain_acc: 0.8008, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.34\n",
      "epoch: 84, loss: 114.12810, loss1: 0.83763, loss2_3: 113.29047\n",
      "\ttrain_acc: 0.8030, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.22\n",
      "epoch: 85, loss: 114.42867, loss1: 0.84016, loss2_3: 113.58851\n",
      "\ttrain_acc: 0.8032, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.31\n",
      "epoch: 86, loss: 114.15734, loss1: 0.83765, loss2_3: 113.31969\n",
      "\ttrain_acc: 0.8030, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.25\n",
      "epoch: 87, loss: 114.42178, loss1: 0.83016, loss2_3: 113.59162\n",
      "\ttrain_acc: 0.8024, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.33\n",
      "epoch: 88, loss: 113.82709, loss1: 0.83459, loss2_3: 112.99250\n",
      "\ttrain_acc: 0.8044, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.24\n",
      "epoch: 89, loss: 114.00723, loss1: 0.83723, loss2_3: 113.17000\n",
      "\ttrain_acc: 0.8026, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.34\n",
      "best_acc: 0.8013\n",
      "epoch: 90, loss: 113.69592, loss1: 0.82950, loss2_3: 112.86642\n",
      "\ttrain_acc: 0.8021, test_acc: \u001b[31m0.7978\u001b[0m, time: 36.23\n",
      "epoch: 91, loss: 113.75537, loss1: 0.83040, loss2_3: 112.92497\n",
      "\ttrain_acc: 0.8052, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.30\n",
      "epoch: 92, loss: 113.59861, loss1: 0.83502, loss2_3: 112.76359\n",
      "\ttrain_acc: 0.8048, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.25\n",
      "epoch: 93, loss: 113.51462, loss1: 0.82833, loss2_3: 112.68630\n",
      "\ttrain_acc: 0.8067, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.29\n",
      "epoch: 94, loss: 113.63471, loss1: 0.83146, loss2_3: 112.80325\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.25\n",
      "epoch: 95, loss: 113.48101, loss1: 0.83599, loss2_3: 112.64502\n",
      "\ttrain_acc: 0.8065, test_acc: \u001b[31m0.80085\u001b[0m, time: 36.28\n",
      "epoch: 96, loss: 113.40198, loss1: 0.83190, loss2_3: 112.57008\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.23\n",
      "epoch: 97, loss: 113.31362, loss1: 0.82998, loss2_3: 112.48365\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.31\n",
      "epoch: 98, loss: 113.25477, loss1: 0.82722, loss2_3: 112.42755\n",
      "\ttrain_acc: 0.8068, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.23\n",
      "epoch: 99, loss: 113.04161, loss1: 0.82855, loss2_3: 112.21307\n",
      "\ttrain_acc: 0.8041, test_acc: \u001b[31m0.79815\u001b[0m, time: 36.31\n",
      "epoch: 100, loss: 112.96936, loss1: 0.83208, loss2_3: 112.13728\n",
      "\ttrain_acc: 0.8057, test_acc: \u001b[31m0.80275\u001b[0m, time: 36.22\n",
      "best_acc: 0.80275\n",
      "epoch: 101, loss: 113.10603, loss1: 0.82839, loss2_3: 112.27764\n",
      "\ttrain_acc: 0.8038, test_acc: \u001b[31m0.79845\u001b[0m, time: 36.31\n",
      "epoch: 102, loss: 112.92027, loss1: 0.82685, loss2_3: 112.09342\n",
      "\ttrain_acc: 0.8027, test_acc: \u001b[31m0.7973\u001b[0m, time: 36.23\n",
      "epoch: 103, loss: 112.91671, loss1: 0.82877, loss2_3: 112.08795\n",
      "\ttrain_acc: 0.8036, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.30\n",
      "epoch: 104, loss: 112.77634, loss1: 0.82465, loss2_3: 111.95170\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.20\n",
      "epoch: 105, loss: 112.81986, loss1: 0.83015, loss2_3: 111.98971\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.8017\u001b[0m, time: 36.28\n",
      "epoch: 106, loss: 112.41966, loss1: 0.82620, loss2_3: 111.59346\n",
      "\ttrain_acc: 0.8055, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.22\n",
      "epoch: 107, loss: 112.35981, loss1: 0.82573, loss2_3: 111.53408\n",
      "\ttrain_acc: 0.8083, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 108, loss: 112.56904, loss1: 0.82161, loss2_3: 111.74743\n",
      "\ttrain_acc: 0.8077, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.26\n",
      "epoch: 109, loss: 112.31750, loss1: 0.82650, loss2_3: 111.49100\n",
      "\ttrain_acc: 0.8065, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.27\n",
      "epoch: 110, loss: 112.47604, loss1: 0.82777, loss2_3: 111.64827\n",
      "\ttrain_acc: 0.8057, test_acc: \u001b[31m0.7997\u001b[0m, time: 36.24\n",
      "epoch: 111, loss: 112.57869, loss1: 0.82975, loss2_3: 111.74894\n",
      "\ttrain_acc: 0.8042, test_acc: \u001b[31m0.7967\u001b[0m, time: 36.32\n",
      "epoch: 112, loss: 112.32233, loss1: 0.82449, loss2_3: 111.49784\n",
      "\ttrain_acc: 0.8069, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.22\n",
      "epoch: 113, loss: 112.05763, loss1: 0.82654, loss2_3: 111.23108\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.79625\u001b[0m, time: 36.34\n",
      "epoch: 114, loss: 112.29785, loss1: 0.82993, loss2_3: 111.46792\n",
      "\ttrain_acc: 0.8006, test_acc: \u001b[31m0.79515\u001b[0m, time: 36.21\n",
      "epoch: 115, loss: 112.00147, loss1: 0.81948, loss2_3: 111.18199\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.31\n",
      "epoch: 116, loss: 112.12145, loss1: 0.82192, loss2_3: 111.29953\n",
      "\ttrain_acc: 0.8052, test_acc: \u001b[31m0.7985\u001b[0m, time: 36.20\n",
      "epoch: 117, loss: 112.13750, loss1: 0.82433, loss2_3: 111.31317\n",
      "\ttrain_acc: 0.8098, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.28\n",
      "epoch: 118, loss: 112.10688, loss1: 0.82453, loss2_3: 111.28235\n",
      "\ttrain_acc: 0.8089, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.21\n",
      "epoch: 119, loss: 111.88446, loss1: 0.81685, loss2_3: 111.06762\n",
      "\ttrain_acc: 0.8070, test_acc: \u001b[31m0.8026\u001b[0m, time: 36.28\n",
      "epoch: 120, loss: 112.07897, loss1: 0.82285, loss2_3: 111.25612\n",
      "\ttrain_acc: 0.8061, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.20\n",
      "epoch: 121, loss: 111.69529, loss1: 0.82142, loss2_3: 110.87387\n",
      "\ttrain_acc: 0.8077, test_acc: \u001b[31m0.80075\u001b[0m, time: 36.30\n",
      "epoch: 122, loss: 111.50659, loss1: 0.81790, loss2_3: 110.68869\n",
      "\ttrain_acc: 0.8072, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.20\n",
      "epoch: 123, loss: 111.56003, loss1: 0.82189, loss2_3: 110.73814\n",
      "\ttrain_acc: 0.8111, test_acc: \u001b[31m0.80325\u001b[0m, time: 36.28\n",
      "best_acc: 0.80325\n",
      "epoch: 124, loss: 111.71724, loss1: 0.82211, loss2_3: 110.89513\n",
      "\ttrain_acc: 0.8091, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.23\n",
      "epoch: 125, loss: 111.41073, loss1: 0.81901, loss2_3: 110.59172\n",
      "\ttrain_acc: 0.8081, test_acc: \u001b[31m0.79895\u001b[0m, time: 36.28\n",
      "epoch: 126, loss: 111.14410, loss1: 0.81961, loss2_3: 110.32449\n",
      "\ttrain_acc: 0.8026, test_acc: \u001b[31m0.7927\u001b[0m, time: 36.26\n",
      "epoch: 127, loss: 111.07106, loss1: 0.81619, loss2_3: 110.25487\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.28\n",
      "epoch: 128, loss: 111.09650, loss1: 0.81499, loss2_3: 110.28151\n",
      "\ttrain_acc: 0.8044, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.23\n",
      "epoch: 129, loss: 110.92932, loss1: 0.81205, loss2_3: 110.11727\n",
      "\ttrain_acc: 0.8098, test_acc: \u001b[31m0.80235\u001b[0m, time: 36.29\n",
      "epoch: 130, loss: 110.86576, loss1: 0.81766, loss2_3: 110.04810\n",
      "\ttrain_acc: 0.8109, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.22\n",
      "epoch: 131, loss: 111.02078, loss1: 0.81439, loss2_3: 110.20639\n",
      "\ttrain_acc: 0.8060, test_acc: \u001b[31m0.79325\u001b[0m, time: 36.29\n",
      "epoch: 132, loss: 110.79867, loss1: 0.81880, loss2_3: 109.97988\n",
      "\ttrain_acc: 0.8111, test_acc: \u001b[31m0.79865\u001b[0m, time: 36.21\n",
      "epoch: 133, loss: 110.67404, loss1: 0.81809, loss2_3: 109.85595\n",
      "\ttrain_acc: 0.7968, test_acc: \u001b[31m0.7916\u001b[0m, time: 36.25\n",
      "epoch: 134, loss: 110.45156, loss1: 0.81525, loss2_3: 109.63631\n",
      "\ttrain_acc: 0.7492, test_acc: \u001b[31m0.73285\u001b[0m, time: 36.23\n",
      "epoch: 135, loss: 110.25285, loss1: 0.81724, loss2_3: 109.43561\n",
      "\ttrain_acc: 0.8098, test_acc: \u001b[31m0.80135\u001b[0m, time: 36.27\n",
      "epoch: 136, loss: 110.12408, loss1: 0.81826, loss2_3: 109.30582\n",
      "\ttrain_acc: 0.8083, test_acc: \u001b[31m0.79935\u001b[0m, time: 36.22\n",
      "epoch: 137, loss: 110.20600, loss1: 0.81365, loss2_3: 109.39234\n",
      "\ttrain_acc: 0.8107, test_acc: \u001b[31m0.80135\u001b[0m, time: 36.29\n",
      "epoch: 138, loss: 109.99400, loss1: 0.81418, loss2_3: 109.17983\n",
      "\ttrain_acc: 0.8121, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.23\n",
      "epoch: 139, loss: 109.82408, loss1: 0.81874, loss2_3: 109.00534\n",
      "\ttrain_acc: 0.8138, test_acc: \u001b[31m0.80435\u001b[0m, time: 36.29\n",
      "best_acc: 0.80435\n",
      "epoch: 140, loss: 109.81042, loss1: 0.81377, loss2_3: 108.99665\n",
      "\ttrain_acc: 0.8100, test_acc: \u001b[31m0.7951\u001b[0m, time: 36.26\n",
      "epoch: 141, loss: 109.84125, loss1: 0.81220, loss2_3: 109.02905\n",
      "\ttrain_acc: 0.8124, test_acc: \u001b[31m0.80135\u001b[0m, time: 36.29\n",
      "epoch: 142, loss: 109.77482, loss1: 0.81555, loss2_3: 108.95927\n",
      "\ttrain_acc: 0.8143, test_acc: \u001b[31m0.80365\u001b[0m, time: 36.23\n",
      "epoch: 143, loss: 109.65587, loss1: 0.81334, loss2_3: 108.84253\n",
      "\ttrain_acc: 0.8137, test_acc: \u001b[31m0.80395\u001b[0m, time: 36.30\n",
      "epoch: 144, loss: 109.82922, loss1: 0.81454, loss2_3: 109.01468\n",
      "\ttrain_acc: 0.7580, test_acc: \u001b[31m0.74075\u001b[0m, time: 36.22\n",
      "epoch: 145, loss: 109.67586, loss1: 0.81523, loss2_3: 108.86062\n",
      "\ttrain_acc: 0.8129, test_acc: \u001b[31m0.8027\u001b[0m, time: 36.29\n",
      "epoch: 146, loss: 109.40936, loss1: 0.81074, loss2_3: 108.59861\n",
      "\ttrain_acc: 0.7971, test_acc: \u001b[31m0.779\u001b[0m, time: 36.19\n",
      "epoch: 147, loss: 109.29970, loss1: 0.81361, loss2_3: 108.48609\n",
      "\ttrain_acc: 0.8038, test_acc: \u001b[31m0.794\u001b[0m, time: 36.30\n",
      "epoch: 148, loss: 109.11869, loss1: 0.81919, loss2_3: 108.29950\n",
      "\ttrain_acc: 0.8150, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.21\n",
      "epoch: 149, loss: 109.37179, loss1: 0.81370, loss2_3: 108.55809\n",
      "\ttrain_acc: 0.8110, test_acc: \u001b[31m0.8009\u001b[0m, time: 36.30\n",
      "epoch: 150, loss: 108.93478, loss1: 0.80858, loss2_3: 108.12620\n",
      "\ttrain_acc: 0.8153, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.23\n",
      "epoch: 151, loss: 108.93293, loss1: 0.80664, loss2_3: 108.12629\n",
      "\ttrain_acc: 0.8090, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.30\n",
      "epoch: 152, loss: 109.04682, loss1: 0.81341, loss2_3: 108.23341\n",
      "\ttrain_acc: 0.8145, test_acc: \u001b[31m0.8\u001b[0m, time: 36.22\n",
      "epoch: 153, loss: 108.90239, loss1: 0.81073, loss2_3: 108.09166\n",
      "\ttrain_acc: 0.8077, test_acc: \u001b[31m0.7995\u001b[0m, time: 36.31\n",
      "epoch: 154, loss: 108.94410, loss1: 0.81149, loss2_3: 108.13261\n",
      "\ttrain_acc: 0.8169, test_acc: \u001b[31m0.80385\u001b[0m, time: 36.19\n",
      "epoch: 155, loss: 108.46443, loss1: 0.80606, loss2_3: 107.65837\n",
      "\ttrain_acc: 0.8032, test_acc: \u001b[31m0.7917\u001b[0m, time: 36.29\n",
      "epoch: 156, loss: 108.52307, loss1: 0.81055, loss2_3: 107.71252\n",
      "\ttrain_acc: 0.8118, test_acc: \u001b[31m0.79925\u001b[0m, time: 36.22\n",
      "epoch: 157, loss: 108.22884, loss1: 0.80835, loss2_3: 107.42049\n",
      "\ttrain_acc: 0.8126, test_acc: \u001b[31m0.8\u001b[0m, time: 36.29\n",
      "epoch: 158, loss: 108.18046, loss1: 0.80791, loss2_3: 107.37255\n",
      "\ttrain_acc: 0.8016, test_acc: \u001b[31m0.79085\u001b[0m, time: 36.21\n",
      "epoch: 159, loss: 108.21206, loss1: 0.80082, loss2_3: 107.41124\n",
      "\ttrain_acc: 0.8137, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.28\n",
      "epoch: 160, loss: 107.99428, loss1: 0.80161, loss2_3: 107.19267\n",
      "\ttrain_acc: 0.8137, test_acc: \u001b[31m0.796\u001b[0m, time: 36.20\n",
      "epoch: 161, loss: 108.02436, loss1: 0.80439, loss2_3: 107.21997\n",
      "\ttrain_acc: 0.8136, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.28\n",
      "epoch: 162, loss: 107.91675, loss1: 0.80503, loss2_3: 107.11173\n",
      "\ttrain_acc: 0.8187, test_acc: \u001b[31m0.8036\u001b[0m, time: 36.19\n",
      "epoch: 163, loss: 107.83358, loss1: 0.80434, loss2_3: 107.02924\n",
      "\ttrain_acc: 0.8159, test_acc: \u001b[31m0.79705\u001b[0m, time: 36.28\n",
      "epoch: 164, loss: 107.90601, loss1: 0.80338, loss2_3: 107.10263\n",
      "\ttrain_acc: 0.8136, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.23\n",
      "epoch: 165, loss: 107.84544, loss1: 0.80631, loss2_3: 107.03913\n",
      "\ttrain_acc: 0.8133, test_acc: \u001b[31m0.7969\u001b[0m, time: 36.27\n",
      "epoch: 166, loss: 107.59623, loss1: 0.80615, loss2_3: 106.79008\n",
      "\ttrain_acc: 0.8187, test_acc: \u001b[31m0.7997\u001b[0m, time: 36.25\n",
      "epoch: 167, loss: 107.51019, loss1: 0.80714, loss2_3: 106.70306\n",
      "\ttrain_acc: 0.8197, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.25\n",
      "epoch: 168, loss: 107.07483, loss1: 0.80080, loss2_3: 106.27404\n",
      "\ttrain_acc: 0.8027, test_acc: \u001b[31m0.79355\u001b[0m, time: 36.21\n",
      "epoch: 169, loss: 106.85825, loss1: 0.80742, loss2_3: 106.05083\n",
      "\ttrain_acc: 0.7988, test_acc: \u001b[31m0.77265\u001b[0m, time: 36.27\n",
      "epoch: 170, loss: 107.04571, loss1: 0.80674, loss2_3: 106.23897\n",
      "\ttrain_acc: 0.8034, test_acc: \u001b[31m0.79255\u001b[0m, time: 36.20\n",
      "epoch: 171, loss: 106.89946, loss1: 0.80190, loss2_3: 106.09756\n",
      "\ttrain_acc: 0.8193, test_acc: \u001b[31m0.80135\u001b[0m, time: 37.14\n",
      "epoch: 172, loss: 106.65758, loss1: 0.80434, loss2_3: 105.85324\n",
      "\ttrain_acc: 0.8089, test_acc: \u001b[31m0.79825\u001b[0m, time: 37.08\n",
      "epoch: 173, loss: 106.35847, loss1: 0.80503, loss2_3: 105.55344\n",
      "\ttrain_acc: 0.8161, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.24\n",
      "epoch: 174, loss: 106.44390, loss1: 0.79999, loss2_3: 105.64391\n",
      "\ttrain_acc: 0.8205, test_acc: \u001b[31m0.7973\u001b[0m, time: 36.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 175, loss: 106.41084, loss1: 0.80306, loss2_3: 105.60778\n",
      "\ttrain_acc: 0.8212, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.25\n",
      "epoch: 176, loss: 106.17709, loss1: 0.80227, loss2_3: 105.37482\n",
      "\ttrain_acc: 0.8230, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.24\n",
      "epoch: 177, loss: 106.16927, loss1: 0.80113, loss2_3: 105.36814\n",
      "\ttrain_acc: 0.8103, test_acc: \u001b[31m0.79595\u001b[0m, time: 36.48\n",
      "epoch: 178, loss: 106.10082, loss1: 0.80074, loss2_3: 105.30008\n",
      "\ttrain_acc: 0.8193, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.54\n",
      "epoch: 179, loss: 106.22470, loss1: 0.79503, loss2_3: 105.42966\n",
      "\ttrain_acc: 0.7999, test_acc: \u001b[31m0.7885\u001b[0m, time: 36.60\n",
      "epoch: 180, loss: 105.94671, loss1: 0.80102, loss2_3: 105.14568\n",
      "\ttrain_acc: 0.8094, test_acc: \u001b[31m0.79715\u001b[0m, time: 36.36\n",
      "epoch: 181, loss: 105.64503, loss1: 0.80237, loss2_3: 104.84266\n",
      "\ttrain_acc: 0.7618, test_acc: \u001b[31m0.72625\u001b[0m, time: 36.33\n",
      "epoch: 182, loss: 105.59415, loss1: 0.80370, loss2_3: 104.79045\n",
      "\ttrain_acc: 0.8207, test_acc: \u001b[31m0.7925\u001b[0m, time: 36.22\n",
      "epoch: 183, loss: 105.35418, loss1: 0.79556, loss2_3: 104.55863\n",
      "\ttrain_acc: 0.8148, test_acc: \u001b[31m0.78645\u001b[0m, time: 36.23\n",
      "epoch: 184, loss: 105.28987, loss1: 0.79721, loss2_3: 104.49266\n",
      "\ttrain_acc: 0.8169, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.20\n",
      "epoch: 185, loss: 105.06529, loss1: 0.79473, loss2_3: 104.27057\n",
      "\ttrain_acc: 0.8216, test_acc: \u001b[31m0.7935\u001b[0m, time: 36.28\n",
      "epoch: 186, loss: 105.05231, loss1: 0.79726, loss2_3: 104.25506\n",
      "\ttrain_acc: 0.8215, test_acc: \u001b[31m0.79625\u001b[0m, time: 36.22\n",
      "epoch: 187, loss: 104.99891, loss1: 0.79615, loss2_3: 104.20276\n",
      "\ttrain_acc: 0.8098, test_acc: \u001b[31m0.7769\u001b[0m, time: 36.26\n",
      "epoch: 188, loss: 104.82998, loss1: 0.79963, loss2_3: 104.03035\n",
      "\ttrain_acc: 0.8191, test_acc: \u001b[31m0.8012\u001b[0m, time: 36.25\n",
      "epoch: 189, loss: 104.60706, loss1: 0.79757, loss2_3: 103.80949\n",
      "\ttrain_acc: 0.8276, test_acc: \u001b[31m0.7956\u001b[0m, time: 36.27\n",
      "epoch: 190, loss: 104.34116, loss1: 0.79604, loss2_3: 103.54512\n",
      "\ttrain_acc: 0.8204, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.24\n",
      "epoch: 191, loss: 104.75077, loss1: 0.79654, loss2_3: 103.95423\n",
      "\ttrain_acc: 0.8186, test_acc: \u001b[31m0.79805\u001b[0m, time: 36.25\n",
      "epoch: 192, loss: 103.78730, loss1: 0.79777, loss2_3: 102.98953\n",
      "\ttrain_acc: 0.7973, test_acc: \u001b[31m0.7835\u001b[0m, time: 36.21\n",
      "epoch: 193, loss: 104.20769, loss1: 0.79421, loss2_3: 103.41349\n",
      "\ttrain_acc: 0.8113, test_acc: \u001b[31m0.7967\u001b[0m, time: 36.26\n",
      "epoch: 194, loss: 104.14299, loss1: 0.79295, loss2_3: 103.35004\n",
      "\ttrain_acc: 0.8288, test_acc: \u001b[31m0.7966\u001b[0m, time: 36.20\n",
      "epoch: 195, loss: 103.66939, loss1: 0.79599, loss2_3: 102.87340\n",
      "\ttrain_acc: 0.6909, test_acc: \u001b[31m0.65765\u001b[0m, time: 36.24\n",
      "epoch: 196, loss: 103.81035, loss1: 0.78517, loss2_3: 103.02518\n",
      "\ttrain_acc: 0.8070, test_acc: \u001b[31m0.7918\u001b[0m, time: 36.22\n",
      "epoch: 197, loss: 103.46074, loss1: 0.79491, loss2_3: 102.66583\n",
      "\ttrain_acc: 0.8034, test_acc: \u001b[31m0.7861\u001b[0m, time: 36.23\n",
      "epoch: 198, loss: 103.65423, loss1: 0.79764, loss2_3: 102.85659\n",
      "\ttrain_acc: 0.8172, test_acc: \u001b[31m0.7988\u001b[0m, time: 36.25\n",
      "epoch: 199, loss: 103.20269, loss1: 0.79488, loss2_3: 102.40781\n",
      "\ttrain_acc: 0.8283, test_acc: \u001b[31m0.8017\u001b[0m, time: 36.23\n",
      "epoch: 200, loss: 103.26996, loss1: 0.79420, loss2_3: 102.47577\n",
      "\ttrain_acc: 0.8012, test_acc: \u001b[31m0.7889\u001b[0m, time: 36.25\n",
      "epoch: 201, loss: 103.04223, loss1: 0.78939, loss2_3: 102.25285\n",
      "\ttrain_acc: 0.7466, test_acc: \u001b[31m0.7047\u001b[0m, time: 36.26\n",
      "epoch: 202, loss: 102.95032, loss1: 0.78931, loss2_3: 102.16101\n",
      "\ttrain_acc: 0.8221, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.24\n",
      "epoch: 203, loss: 102.78719, loss1: 0.78893, loss2_3: 101.99826\n",
      "\ttrain_acc: 0.6970, test_acc: \u001b[31m0.6604\u001b[0m, time: 36.23\n",
      "epoch: 204, loss: 102.65000, loss1: 0.79056, loss2_3: 101.85944\n",
      "\ttrain_acc: 0.8207, test_acc: \u001b[31m0.78095\u001b[0m, time: 36.25\n",
      "epoch: 205, loss: 102.12945, loss1: 0.78592, loss2_3: 101.34352\n",
      "\ttrain_acc: 0.8221, test_acc: \u001b[31m0.77715\u001b[0m, time: 36.22\n",
      "epoch: 206, loss: 102.08711, loss1: 0.78586, loss2_3: 101.30126\n",
      "\ttrain_acc: 0.8306, test_acc: \u001b[31m0.7979\u001b[0m, time: 36.26\n",
      "epoch: 207, loss: 101.99628, loss1: 0.79142, loss2_3: 101.20486\n",
      "\ttrain_acc: 0.7770, test_acc: \u001b[31m0.7282\u001b[0m, time: 36.23\n",
      "epoch: 208, loss: 102.05228, loss1: 0.78818, loss2_3: 101.26410\n",
      "\ttrain_acc: 0.8341, test_acc: \u001b[31m0.79895\u001b[0m, time: 36.22\n",
      "epoch: 209, loss: 102.22395, loss1: 0.78965, loss2_3: 101.43430\n",
      "\ttrain_acc: 0.8317, test_acc: \u001b[31m0.78945\u001b[0m, time: 36.26\n",
      "epoch: 210, loss: 102.03420, loss1: 0.78812, loss2_3: 101.24608\n",
      "\ttrain_acc: 0.8327, test_acc: \u001b[31m0.79285\u001b[0m, time: 36.23\n",
      "epoch: 211, loss: 101.59267, loss1: 0.78970, loss2_3: 100.80297\n",
      "\ttrain_acc: 0.8333, test_acc: \u001b[31m0.7964\u001b[0m, time: 36.26\n",
      "epoch: 212, loss: 101.59195, loss1: 0.78675, loss2_3: 100.80520\n",
      "\ttrain_acc: 0.8344, test_acc: \u001b[31m0.7929\u001b[0m, time: 36.24\n",
      "epoch: 213, loss: 101.54592, loss1: 0.78810, loss2_3: 100.75782\n",
      "\ttrain_acc: 0.7924, test_acc: \u001b[31m0.74955\u001b[0m, time: 36.24\n",
      "epoch: 214, loss: 100.92718, loss1: 0.78457, loss2_3: 100.14260\n",
      "\ttrain_acc: 0.8308, test_acc: \u001b[31m0.79825\u001b[0m, time: 36.22\n",
      "epoch: 215, loss: 100.84951, loss1: 0.78511, loss2_3: 100.06440\n",
      "\ttrain_acc: 0.8257, test_acc: \u001b[31m0.7984\u001b[0m, time: 36.24\n",
      "epoch: 216, loss: 100.98277, loss1: 0.78276, loss2_3: 100.20001\n",
      "\ttrain_acc: 0.8294, test_acc: \u001b[31m0.8001\u001b[0m, time: 36.19\n",
      "epoch: 217, loss: 100.10986, loss1: 0.77773, loss2_3: 99.33212\n",
      "\ttrain_acc: 0.8329, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.25\n",
      "epoch: 218, loss: 100.67998, loss1: 0.78371, loss2_3: 99.89627\n",
      "\ttrain_acc: 0.8297, test_acc: \u001b[31m0.7818\u001b[0m, time: 36.19\n",
      "epoch: 219, loss: 99.91691, loss1: 0.77858, loss2_3: 99.13833\n",
      "\ttrain_acc: 0.8341, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.19\n",
      "epoch: 220, loss: 99.83529, loss1: 0.77770, loss2_3: 99.05759\n",
      "\ttrain_acc: 0.8232, test_acc: \u001b[31m0.79385\u001b[0m, time: 36.23\n",
      "epoch: 221, loss: 100.07422, loss1: 0.78086, loss2_3: 99.29337\n",
      "\ttrain_acc: 0.7996, test_acc: \u001b[31m0.7846\u001b[0m, time: 36.21\n",
      "epoch: 222, loss: 99.56777, loss1: 0.77936, loss2_3: 98.78841\n",
      "\ttrain_acc: 0.8339, test_acc: \u001b[31m0.78935\u001b[0m, time: 36.24\n",
      "epoch: 223, loss: 99.61186, loss1: 0.77748, loss2_3: 98.83438\n",
      "\ttrain_acc: 0.8254, test_acc: \u001b[31m0.7965\u001b[0m, time: 36.23\n",
      "epoch: 224, loss: 99.87469, loss1: 0.77651, loss2_3: 99.09818\n",
      "\ttrain_acc: 0.7565, test_acc: \u001b[31m0.6999\u001b[0m, time: 36.23\n",
      "epoch: 225, loss: 99.03558, loss1: 0.77425, loss2_3: 98.26132\n",
      "\ttrain_acc: 0.8367, test_acc: \u001b[31m0.7843\u001b[0m, time: 36.24\n",
      "epoch: 226, loss: 98.96083, loss1: 0.77802, loss2_3: 98.18281\n",
      "\ttrain_acc: 0.5260, test_acc: \u001b[31m0.5169\u001b[0m, time: 36.22\n",
      "epoch: 227, loss: 99.03347, loss1: 0.77197, loss2_3: 98.26150\n",
      "\ttrain_acc: 0.6981, test_acc: \u001b[31m0.6454\u001b[0m, time: 36.23\n",
      "epoch: 228, loss: 98.46136, loss1: 0.77226, loss2_3: 97.68911\n",
      "\ttrain_acc: 0.5471, test_acc: \u001b[31m0.53585\u001b[0m, time: 36.21\n",
      "epoch: 229, loss: 98.65224, loss1: 0.77449, loss2_3: 97.87775\n",
      "\ttrain_acc: 0.8396, test_acc: \u001b[31m0.7951\u001b[0m, time: 36.20\n",
      "epoch: 230, loss: 97.99901, loss1: 0.77354, loss2_3: 97.22547\n",
      "\ttrain_acc: 0.8065, test_acc: \u001b[31m0.7865\u001b[0m, time: 36.23\n",
      "epoch: 231, loss: 97.93102, loss1: 0.77291, loss2_3: 97.15811\n",
      "\ttrain_acc: 0.8391, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.19\n",
      "epoch: 232, loss: 97.39318, loss1: 0.76872, loss2_3: 96.62446\n",
      "\ttrain_acc: 0.8373, test_acc: \u001b[31m0.7976\u001b[0m, time: 36.22\n",
      "epoch: 233, loss: 97.78080, loss1: 0.76419, loss2_3: 97.01662\n",
      "\ttrain_acc: 0.7947, test_acc: \u001b[31m0.7765\u001b[0m, time: 36.23\n",
      "epoch: 234, loss: 97.35955, loss1: 0.76711, loss2_3: 96.59244\n",
      "\ttrain_acc: 0.7575, test_acc: \u001b[31m0.6935\u001b[0m, time: 36.21\n",
      "epoch: 235, loss: 96.99942, loss1: 0.76950, loss2_3: 96.22992\n",
      "\ttrain_acc: 0.7650, test_acc: \u001b[31m0.7028\u001b[0m, time: 36.23\n",
      "epoch: 236, loss: 97.01637, loss1: 0.76686, loss2_3: 96.24951\n",
      "\ttrain_acc: 0.8170, test_acc: \u001b[31m0.7911\u001b[0m, time: 36.26\n",
      "epoch: 237, loss: 96.32095, loss1: 0.76400, loss2_3: 95.55695\n",
      "\ttrain_acc: 0.7253, test_acc: \u001b[31m0.671\u001b[0m, time: 36.25\n",
      "epoch: 238, loss: 96.28476, loss1: 0.76262, loss2_3: 95.52214\n",
      "\ttrain_acc: 0.8455, test_acc: \u001b[31m0.79455\u001b[0m, time: 36.26\n",
      "epoch: 239, loss: 96.24649, loss1: 0.76528, loss2_3: 95.48120\n",
      "\ttrain_acc: 0.6743, test_acc: \u001b[31m0.62975\u001b[0m, time: 36.26\n",
      "epoch: 240, loss: 96.01069, loss1: 0.76439, loss2_3: 95.24631\n",
      "\ttrain_acc: 0.8255, test_acc: \u001b[31m0.7929\u001b[0m, time: 36.24\n",
      "epoch: 241, loss: 95.92414, loss1: 0.76313, loss2_3: 95.16101\n",
      "\ttrain_acc: 0.8455, test_acc: \u001b[31m0.78285\u001b[0m, time: 36.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 242, loss: 95.51867, loss1: 0.76409, loss2_3: 94.75459\n",
      "\ttrain_acc: 0.7673, test_acc: \u001b[31m0.7071\u001b[0m, time: 36.20\n",
      "epoch: 243, loss: 95.37652, loss1: 0.76010, loss2_3: 94.61641\n",
      "\ttrain_acc: 0.7926, test_acc: \u001b[31m0.7317\u001b[0m, time: 36.26\n",
      "epoch: 244, loss: 95.05006, loss1: 0.75624, loss2_3: 94.29382\n",
      "\ttrain_acc: 0.8406, test_acc: \u001b[31m0.7963\u001b[0m, time: 36.20\n",
      "epoch: 245, loss: 94.82656, loss1: 0.76150, loss2_3: 94.06505\n",
      "\ttrain_acc: 0.8220, test_acc: \u001b[31m0.74885\u001b[0m, time: 36.23\n",
      "epoch: 246, loss: 94.15462, loss1: 0.75410, loss2_3: 93.40052\n",
      "\ttrain_acc: 0.8294, test_acc: \u001b[31m0.7964\u001b[0m, time: 36.23\n",
      "epoch: 247, loss: 94.19744, loss1: 0.75785, loss2_3: 93.43959\n",
      "\ttrain_acc: 0.8318, test_acc: \u001b[31m0.7985\u001b[0m, time: 36.24\n",
      "epoch: 248, loss: 93.68936, loss1: 0.75135, loss2_3: 92.93800\n",
      "\ttrain_acc: 0.8129, test_acc: \u001b[31m0.7834\u001b[0m, time: 36.22\n",
      "epoch: 249, loss: 93.50427, loss1: 0.75246, loss2_3: 92.75181\n",
      "\ttrain_acc: 0.8494, test_acc: \u001b[31m0.7857\u001b[0m, time: 36.26\n",
      "epoch: 250, loss: 93.04891, loss1: 0.75169, loss2_3: 92.29722\n",
      "\ttrain_acc: 0.8425, test_acc: \u001b[31m0.794\u001b[0m, time: 36.24\n",
      "epoch: 1, loss: 180.83456, loss1: 2.61202, loss2_3: 178.22254\n",
      "\ttrain_acc: 0.5258, test_acc: \u001b[31m0.5236\u001b[0m, time: 36.51\n",
      "best_acc: 0.5236\n",
      "epoch: 2, loss: 173.34002, loss1: 1.02365, loss2_3: 172.31637\n",
      "\ttrain_acc: 0.5816, test_acc: \u001b[31m0.57355\u001b[0m, time: 36.52\n",
      "best_acc: 0.57355\n",
      "epoch: 3, loss: 147.96948, loss1: 1.00228, loss2_3: 146.96720\n",
      "\ttrain_acc: 0.7174, test_acc: \u001b[31m0.7232\u001b[0m, time: 36.50\n",
      "best_acc: 0.7232\n",
      "epoch: 4, loss: 135.50343, loss1: 0.97161, loss2_3: 134.53181\n",
      "\ttrain_acc: 0.6848, test_acc: \u001b[31m0.67775\u001b[0m, time: 36.51\n",
      "epoch: 5, loss: 132.75782, loss1: 0.95834, loss2_3: 131.79948\n",
      "\ttrain_acc: 0.7523, test_acc: \u001b[31m0.7433\u001b[0m, time: 36.50\n",
      "best_acc: 0.7433\n",
      "epoch: 6, loss: 130.40119, loss1: 0.94758, loss2_3: 129.45361\n",
      "\ttrain_acc: 0.7624, test_acc: \u001b[31m0.7648\u001b[0m, time: 36.53\n",
      "best_acc: 0.7648\n",
      "epoch: 7, loss: 128.59467, loss1: 0.93055, loss2_3: 127.66411\n",
      "\ttrain_acc: 0.7533, test_acc: \u001b[31m0.75315\u001b[0m, time: 36.52\n",
      "epoch: 8, loss: 127.56142, loss1: 0.92847, loss2_3: 126.63295\n",
      "\ttrain_acc: 0.7647, test_acc: \u001b[31m0.76485\u001b[0m, time: 36.51\n",
      "best_acc: 0.76485\n",
      "epoch: 9, loss: 126.48520, loss1: 0.92176, loss2_3: 125.56344\n",
      "\ttrain_acc: 0.7631, test_acc: \u001b[31m0.76355\u001b[0m, time: 36.54\n",
      "epoch: 10, loss: 125.13215, loss1: 0.91855, loss2_3: 124.21361\n",
      "\ttrain_acc: 0.7789, test_acc: \u001b[31m0.77775\u001b[0m, time: 36.51\n",
      "best_acc: 0.77775\n",
      "epoch: 11, loss: 125.89529, loss1: 0.92440, loss2_3: 124.97089\n",
      "\ttrain_acc: 0.7602, test_acc: \u001b[31m0.76075\u001b[0m, time: 36.51\n",
      "epoch: 12, loss: 124.50163, loss1: 0.91112, loss2_3: 123.59051\n",
      "\ttrain_acc: 0.7806, test_acc: \u001b[31m0.77855\u001b[0m, time: 36.53\n",
      "best_acc: 0.77855\n",
      "epoch: 13, loss: 124.15136, loss1: 0.90668, loss2_3: 123.24468\n",
      "\ttrain_acc: 0.7651, test_acc: \u001b[31m0.76585\u001b[0m, time: 36.50\n",
      "epoch: 14, loss: 123.37762, loss1: 0.90527, loss2_3: 122.47235\n",
      "\ttrain_acc: 0.7819, test_acc: \u001b[31m0.7814\u001b[0m, time: 36.49\n",
      "best_acc: 0.7814\n",
      "epoch: 15, loss: 123.44302, loss1: 0.91212, loss2_3: 122.53090\n",
      "\ttrain_acc: 0.7692, test_acc: \u001b[31m0.7672\u001b[0m, time: 36.51\n",
      "epoch: 16, loss: 123.26776, loss1: 0.90137, loss2_3: 122.36639\n",
      "\ttrain_acc: 0.7823, test_acc: \u001b[31m0.78185\u001b[0m, time: 36.46\n",
      "best_acc: 0.78185\n",
      "epoch: 17, loss: 122.36106, loss1: 0.90189, loss2_3: 121.45918\n",
      "\ttrain_acc: 0.7695, test_acc: \u001b[31m0.7698\u001b[0m, time: 36.48\n",
      "epoch: 18, loss: 123.00636, loss1: 0.90578, loss2_3: 122.10058\n",
      "\ttrain_acc: 0.7802, test_acc: \u001b[31m0.774\u001b[0m, time: 36.50\n",
      "epoch: 19, loss: 121.86072, loss1: 0.89801, loss2_3: 120.96271\n",
      "\ttrain_acc: 0.7794, test_acc: \u001b[31m0.781\u001b[0m, time: 36.49\n",
      "epoch: 20, loss: 121.12157, loss1: 0.89066, loss2_3: 120.23091\n",
      "\ttrain_acc: 0.7749, test_acc: \u001b[31m0.77695\u001b[0m, time: 36.53\n",
      "epoch: 21, loss: 120.97353, loss1: 0.88704, loss2_3: 120.08649\n",
      "\ttrain_acc: 0.7831, test_acc: \u001b[31m0.7841\u001b[0m, time: 36.49\n",
      "best_acc: 0.7841\n",
      "epoch: 22, loss: 121.24770, loss1: 0.89043, loss2_3: 120.35727\n",
      "\ttrain_acc: 0.7814, test_acc: \u001b[31m0.7744\u001b[0m, time: 36.50\n",
      "epoch: 23, loss: 120.80260, loss1: 0.88396, loss2_3: 119.91864\n",
      "\ttrain_acc: 0.7885, test_acc: \u001b[31m0.7879\u001b[0m, time: 36.47\n",
      "best_acc: 0.7879\n",
      "epoch: 24, loss: 120.24130, loss1: 0.88866, loss2_3: 119.35264\n",
      "\ttrain_acc: 0.7835, test_acc: \u001b[31m0.78455\u001b[0m, time: 36.46\n",
      "epoch: 25, loss: 120.57792, loss1: 0.87909, loss2_3: 119.69883\n",
      "\ttrain_acc: 0.7899, test_acc: \u001b[31m0.78645\u001b[0m, time: 36.47\n",
      "epoch: 26, loss: 120.23004, loss1: 0.88387, loss2_3: 119.34617\n",
      "\ttrain_acc: 0.7897, test_acc: \u001b[31m0.78945\u001b[0m, time: 36.43\n",
      "best_acc: 0.78945\n",
      "epoch: 27, loss: 119.72989, loss1: 0.88075, loss2_3: 118.84914\n",
      "\ttrain_acc: 0.7901, test_acc: \u001b[31m0.7893\u001b[0m, time: 36.44\n",
      "epoch: 28, loss: 119.32695, loss1: 0.87219, loss2_3: 118.45476\n",
      "\ttrain_acc: 0.7889, test_acc: \u001b[31m0.78805\u001b[0m, time: 36.44\n",
      "epoch: 29, loss: 119.16831, loss1: 0.87150, loss2_3: 118.29681\n",
      "\ttrain_acc: 0.7890, test_acc: \u001b[31m0.78855\u001b[0m, time: 36.44\n",
      "epoch: 30, loss: 119.18265, loss1: 0.87665, loss2_3: 118.30600\n",
      "\ttrain_acc: 0.7888, test_acc: \u001b[31m0.7871\u001b[0m, time: 36.41\n",
      "epoch: 31, loss: 119.04626, loss1: 0.86843, loss2_3: 118.17782\n",
      "\ttrain_acc: 0.7960, test_acc: \u001b[31m0.7939\u001b[0m, time: 36.48\n",
      "best_acc: 0.7939\n",
      "epoch: 32, loss: 118.84425, loss1: 0.87288, loss2_3: 117.97137\n",
      "\ttrain_acc: 0.7909, test_acc: \u001b[31m0.7887\u001b[0m, time: 36.41\n",
      "epoch: 33, loss: 118.58398, loss1: 0.87262, loss2_3: 117.71136\n",
      "\ttrain_acc: 0.7960, test_acc: \u001b[31m0.7939\u001b[0m, time: 36.46\n",
      "epoch: 34, loss: 118.21202, loss1: 0.87078, loss2_3: 117.34124\n",
      "\ttrain_acc: 0.7966, test_acc: \u001b[31m0.7945\u001b[0m, time: 36.44\n",
      "best_acc: 0.7945\n",
      "epoch: 35, loss: 118.54498, loss1: 0.86878, loss2_3: 117.67620\n",
      "\ttrain_acc: 0.7976, test_acc: \u001b[31m0.79585\u001b[0m, time: 36.45\n",
      "best_acc: 0.79585\n",
      "epoch: 36, loss: 118.31294, loss1: 0.86798, loss2_3: 117.44497\n",
      "\ttrain_acc: 0.8008, test_acc: \u001b[31m0.79865\u001b[0m, time: 36.42\n",
      "best_acc: 0.79865\n",
      "epoch: 37, loss: 117.95917, loss1: 0.86766, loss2_3: 117.09150\n",
      "\ttrain_acc: 0.7930, test_acc: \u001b[31m0.7923\u001b[0m, time: 36.44\n",
      "epoch: 38, loss: 117.94307, loss1: 0.86691, loss2_3: 117.07616\n",
      "\ttrain_acc: 0.7984, test_acc: \u001b[31m0.7974\u001b[0m, time: 36.38\n",
      "epoch: 39, loss: 118.15269, loss1: 0.86341, loss2_3: 117.28928\n",
      "\ttrain_acc: 0.7906, test_acc: \u001b[31m0.7896\u001b[0m, time: 36.44\n",
      "epoch: 40, loss: 118.20349, loss1: 0.86484, loss2_3: 117.33866\n",
      "\ttrain_acc: 0.7929, test_acc: \u001b[31m0.79105\u001b[0m, time: 36.39\n",
      "epoch: 41, loss: 117.81600, loss1: 0.86214, loss2_3: 116.95386\n",
      "\ttrain_acc: 0.7955, test_acc: \u001b[31m0.7944\u001b[0m, time: 36.44\n",
      "epoch: 42, loss: 117.77409, loss1: 0.86577, loss2_3: 116.90832\n",
      "\ttrain_acc: 0.7978, test_acc: \u001b[31m0.79705\u001b[0m, time: 36.41\n",
      "epoch: 43, loss: 117.51190, loss1: 0.85460, loss2_3: 116.65730\n",
      "\ttrain_acc: 0.7974, test_acc: \u001b[31m0.7963\u001b[0m, time: 36.42\n",
      "epoch: 44, loss: 117.30484, loss1: 0.86289, loss2_3: 116.44195\n",
      "\ttrain_acc: 0.7974, test_acc: \u001b[31m0.79715\u001b[0m, time: 36.44\n",
      "epoch: 45, loss: 117.58471, loss1: 0.86326, loss2_3: 116.72145\n",
      "\ttrain_acc: 0.7961, test_acc: \u001b[31m0.7943\u001b[0m, time: 36.41\n",
      "epoch: 46, loss: 117.17341, loss1: 0.86322, loss2_3: 116.31019\n",
      "\ttrain_acc: 0.8008, test_acc: \u001b[31m0.7999\u001b[0m, time: 36.39\n",
      "best_acc: 0.7999\n",
      "epoch: 47, loss: 116.97737, loss1: 0.85983, loss2_3: 116.11754\n",
      "\ttrain_acc: 0.7994, test_acc: \u001b[31m0.7975\u001b[0m, time: 36.41\n",
      "epoch: 48, loss: 116.95724, loss1: 0.86388, loss2_3: 116.09336\n",
      "\ttrain_acc: 0.8009, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.37\n",
      "epoch: 49, loss: 116.94997, loss1: 0.85413, loss2_3: 116.09584\n",
      "\ttrain_acc: 0.8006, test_acc: \u001b[31m0.79865\u001b[0m, time: 36.38\n",
      "epoch: 50, loss: 116.55832, loss1: 0.85830, loss2_3: 115.70002\n",
      "\ttrain_acc: 0.8010, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.37\n",
      "epoch: 51, loss: 116.73529, loss1: 0.85632, loss2_3: 115.87897\n",
      "\ttrain_acc: 0.7976, test_acc: \u001b[31m0.79555\u001b[0m, time: 36.37\n",
      "epoch: 52, loss: 116.06199, loss1: 0.85940, loss2_3: 115.20259\n",
      "\ttrain_acc: 0.8017, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.34\n",
      "best_acc: 0.79995\n",
      "epoch: 53, loss: 116.79425, loss1: 0.84786, loss2_3: 115.94638\n",
      "\ttrain_acc: 0.8013, test_acc: \u001b[31m0.7984\u001b[0m, time: 36.36\n",
      "epoch: 54, loss: 116.43978, loss1: 0.84833, loss2_3: 115.59144\n",
      "\ttrain_acc: 0.7949, test_acc: \u001b[31m0.7934\u001b[0m, time: 36.30\n",
      "epoch: 55, loss: 116.23262, loss1: 0.85081, loss2_3: 115.38181\n",
      "\ttrain_acc: 0.7973, test_acc: \u001b[31m0.7936\u001b[0m, time: 36.36\n",
      "epoch: 56, loss: 116.09972, loss1: 0.85732, loss2_3: 115.24241\n",
      "\ttrain_acc: 0.7958, test_acc: \u001b[31m0.7939\u001b[0m, time: 36.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 57, loss: 115.99847, loss1: 0.85362, loss2_3: 115.14485\n",
      "\ttrain_acc: 0.8022, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.33\n",
      "epoch: 58, loss: 116.45910, loss1: 0.85539, loss2_3: 115.60370\n",
      "\ttrain_acc: 0.8005, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.29\n",
      "epoch: 59, loss: 116.21013, loss1: 0.85217, loss2_3: 115.35797\n",
      "\ttrain_acc: 0.8003, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.29\n",
      "epoch: 60, loss: 115.75204, loss1: 0.84639, loss2_3: 114.90565\n",
      "\ttrain_acc: 0.7994, test_acc: \u001b[31m0.79725\u001b[0m, time: 36.30\n",
      "epoch: 61, loss: 116.13879, loss1: 0.85420, loss2_3: 115.28460\n",
      "\ttrain_acc: 0.8001, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.27\n",
      "epoch: 62, loss: 115.72387, loss1: 0.84719, loss2_3: 114.87668\n",
      "\ttrain_acc: 0.7966, test_acc: \u001b[31m0.7951\u001b[0m, time: 36.27\n",
      "epoch: 63, loss: 115.98597, loss1: 0.84908, loss2_3: 115.13689\n",
      "\ttrain_acc: 0.8024, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.51\n",
      "best_acc: 0.8015\n",
      "epoch: 64, loss: 115.79832, loss1: 0.84864, loss2_3: 114.94968\n",
      "\ttrain_acc: 0.8025, test_acc: \u001b[31m0.7993\u001b[0m, time: 36.63\n",
      "epoch: 65, loss: 115.49550, loss1: 0.84639, loss2_3: 114.64911\n",
      "\ttrain_acc: 0.8011, test_acc: \u001b[31m0.7991\u001b[0m, time: 36.62\n",
      "epoch: 66, loss: 115.79045, loss1: 0.84323, loss2_3: 114.94722\n",
      "\ttrain_acc: 0.8025, test_acc: \u001b[31m0.799\u001b[0m, time: 36.36\n",
      "epoch: 67, loss: 115.20923, loss1: 0.84395, loss2_3: 114.36529\n",
      "\ttrain_acc: 0.8019, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.30\n",
      "epoch: 68, loss: 115.46905, loss1: 0.84454, loss2_3: 114.62451\n",
      "\ttrain_acc: 0.8025, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.30\n",
      "epoch: 69, loss: 115.44277, loss1: 0.84553, loss2_3: 114.59723\n",
      "\ttrain_acc: 0.8027, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.56\n",
      "epoch: 70, loss: 115.19375, loss1: 0.84472, loss2_3: 114.34903\n",
      "\ttrain_acc: 0.8019, test_acc: \u001b[31m0.79975\u001b[0m, time: 37.32\n",
      "epoch: 71, loss: 115.21319, loss1: 0.84693, loss2_3: 114.36626\n",
      "\ttrain_acc: 0.8027, test_acc: \u001b[31m0.8014\u001b[0m, time: 37.36\n",
      "epoch: 72, loss: 115.15609, loss1: 0.84821, loss2_3: 114.30788\n",
      "\ttrain_acc: 0.8041, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.47\n",
      "epoch: 73, loss: 114.95197, loss1: 0.83753, loss2_3: 114.11444\n",
      "\ttrain_acc: 0.8031, test_acc: \u001b[31m0.79935\u001b[0m, time: 36.28\n",
      "epoch: 74, loss: 114.94616, loss1: 0.83936, loss2_3: 114.10681\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.23\n",
      "epoch: 75, loss: 114.94487, loss1: 0.84301, loss2_3: 114.10186\n",
      "\ttrain_acc: 0.8054, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.24\n",
      "best_acc: 0.8021\n",
      "epoch: 76, loss: 114.61403, loss1: 0.84219, loss2_3: 113.77184\n",
      "\ttrain_acc: 0.8038, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.25\n",
      "epoch: 77, loss: 114.93039, loss1: 0.84303, loss2_3: 114.08735\n",
      "\ttrain_acc: 0.8048, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.24\n",
      "best_acc: 0.80255\n",
      "epoch: 78, loss: 114.65158, loss1: 0.83466, loss2_3: 113.81692\n",
      "\ttrain_acc: 0.8035, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.23\n",
      "epoch: 79, loss: 114.83273, loss1: 0.84009, loss2_3: 113.99264\n",
      "\ttrain_acc: 0.8010, test_acc: \u001b[31m0.797\u001b[0m, time: 36.26\n",
      "epoch: 80, loss: 114.62252, loss1: 0.84179, loss2_3: 113.78073\n",
      "\ttrain_acc: 0.8044, test_acc: \u001b[31m0.802\u001b[0m, time: 36.23\n",
      "epoch: 81, loss: 114.50300, loss1: 0.84071, loss2_3: 113.66230\n",
      "\ttrain_acc: 0.8044, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.24\n",
      "epoch: 82, loss: 114.05710, loss1: 0.83829, loss2_3: 113.21881\n",
      "\ttrain_acc: 0.8052, test_acc: \u001b[31m0.8016\u001b[0m, time: 36.25\n",
      "epoch: 83, loss: 114.85336, loss1: 0.84169, loss2_3: 114.01167\n",
      "\ttrain_acc: 0.8024, test_acc: \u001b[31m0.7976\u001b[0m, time: 36.24\n",
      "epoch: 84, loss: 114.42801, loss1: 0.83540, loss2_3: 113.59261\n",
      "\ttrain_acc: 0.8053, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.26\n",
      "epoch: 85, loss: 114.50109, loss1: 0.83542, loss2_3: 113.66567\n",
      "\ttrain_acc: 0.8053, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.25\n",
      "epoch: 86, loss: 114.38476, loss1: 0.83585, loss2_3: 113.54891\n",
      "\ttrain_acc: 0.8038, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.27\n",
      "epoch: 87, loss: 114.28635, loss1: 0.83284, loss2_3: 113.45351\n",
      "\ttrain_acc: 0.8050, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.26\n",
      "epoch: 88, loss: 114.10310, loss1: 0.83369, loss2_3: 113.26941\n",
      "\ttrain_acc: 0.8069, test_acc: \u001b[31m0.8024\u001b[0m, time: 36.22\n",
      "epoch: 89, loss: 113.92790, loss1: 0.83451, loss2_3: 113.09340\n",
      "\ttrain_acc: 0.8033, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.26\n",
      "epoch: 90, loss: 114.21057, loss1: 0.83550, loss2_3: 113.37508\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.22\n",
      "epoch: 91, loss: 114.10931, loss1: 0.84099, loss2_3: 113.26832\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.79865\u001b[0m, time: 36.24\n",
      "epoch: 92, loss: 113.76783, loss1: 0.83119, loss2_3: 112.93664\n",
      "\ttrain_acc: 0.8036, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.24\n",
      "epoch: 93, loss: 113.90660, loss1: 0.83222, loss2_3: 113.07439\n",
      "\ttrain_acc: 0.8059, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.24\n",
      "epoch: 94, loss: 113.69867, loss1: 0.83180, loss2_3: 112.86687\n",
      "\ttrain_acc: 0.8066, test_acc: \u001b[31m0.8027\u001b[0m, time: 36.23\n",
      "best_acc: 0.8027\n",
      "epoch: 95, loss: 113.78896, loss1: 0.83174, loss2_3: 112.95722\n",
      "\ttrain_acc: 0.8062, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.29\n",
      "epoch: 96, loss: 113.63887, loss1: 0.83288, loss2_3: 112.80599\n",
      "\ttrain_acc: 0.8055, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.25\n",
      "epoch: 97, loss: 113.38565, loss1: 0.83620, loss2_3: 112.54945\n",
      "\ttrain_acc: 0.8067, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.26\n",
      "epoch: 98, loss: 113.43853, loss1: 0.83286, loss2_3: 112.60567\n",
      "\ttrain_acc: 0.8059, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.28\n",
      "epoch: 99, loss: 113.43946, loss1: 0.83215, loss2_3: 112.60731\n",
      "\ttrain_acc: 0.8061, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.25\n",
      "best_acc: 0.80295\n",
      "epoch: 100, loss: 113.12991, loss1: 0.82859, loss2_3: 112.30131\n",
      "\ttrain_acc: 0.8077, test_acc: \u001b[31m0.8029\u001b[0m, time: 36.26\n",
      "epoch: 101, loss: 113.42222, loss1: 0.82948, loss2_3: 112.59275\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.25\n",
      "epoch: 102, loss: 113.06378, loss1: 0.83334, loss2_3: 112.23044\n",
      "\ttrain_acc: 0.8046, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.25\n",
      "epoch: 103, loss: 113.15843, loss1: 0.82827, loss2_3: 112.33016\n",
      "\ttrain_acc: 0.8060, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.25\n",
      "epoch: 104, loss: 113.14785, loss1: 0.82580, loss2_3: 112.32205\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.8019\u001b[0m, time: 36.22\n",
      "epoch: 105, loss: 112.86558, loss1: 0.82825, loss2_3: 112.03733\n",
      "\ttrain_acc: 0.8059, test_acc: \u001b[31m0.79925\u001b[0m, time: 36.27\n",
      "epoch: 106, loss: 112.88353, loss1: 0.82793, loss2_3: 112.05561\n",
      "\ttrain_acc: 0.8067, test_acc: \u001b[31m0.8029\u001b[0m, time: 36.24\n",
      "epoch: 107, loss: 112.83906, loss1: 0.82605, loss2_3: 112.01301\n",
      "\ttrain_acc: 0.8073, test_acc: \u001b[31m0.801\u001b[0m, time: 36.25\n",
      "epoch: 108, loss: 112.60789, loss1: 0.82594, loss2_3: 111.78195\n",
      "\ttrain_acc: 0.8077, test_acc: \u001b[31m0.8032\u001b[0m, time: 36.28\n",
      "best_acc: 0.8032\n",
      "epoch: 109, loss: 112.65058, loss1: 0.82766, loss2_3: 111.82291\n",
      "\ttrain_acc: 0.8081, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.25\n",
      "epoch: 110, loss: 112.24866, loss1: 0.82393, loss2_3: 111.42472\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.24\n",
      "epoch: 111, loss: 112.39619, loss1: 0.82510, loss2_3: 111.57109\n",
      "\ttrain_acc: 0.8083, test_acc: \u001b[31m0.8025\u001b[0m, time: 36.27\n",
      "epoch: 112, loss: 112.54196, loss1: 0.82551, loss2_3: 111.71645\n",
      "\ttrain_acc: 0.8091, test_acc: \u001b[31m0.8037\u001b[0m, time: 36.21\n",
      "best_acc: 0.8037\n",
      "epoch: 113, loss: 112.25845, loss1: 0.82316, loss2_3: 111.43528\n",
      "\ttrain_acc: 0.8068, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.23\n",
      "epoch: 114, loss: 112.11429, loss1: 0.82764, loss2_3: 111.28666\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.799\u001b[0m, time: 36.23\n",
      "epoch: 115, loss: 112.27255, loss1: 0.82474, loss2_3: 111.44781\n",
      "\ttrain_acc: 0.8072, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.21\n",
      "epoch: 116, loss: 112.14092, loss1: 0.82644, loss2_3: 111.31448\n",
      "\ttrain_acc: 0.8072, test_acc: \u001b[31m0.8004\u001b[0m, time: 36.22\n",
      "epoch: 117, loss: 111.76229, loss1: 0.82303, loss2_3: 110.93925\n",
      "\ttrain_acc: 0.8081, test_acc: \u001b[31m0.8012\u001b[0m, time: 36.22\n",
      "epoch: 118, loss: 111.98308, loss1: 0.82384, loss2_3: 111.15924\n",
      "\ttrain_acc: 0.8084, test_acc: \u001b[31m0.8026\u001b[0m, time: 36.22\n",
      "epoch: 119, loss: 112.13975, loss1: 0.82501, loss2_3: 111.31475\n",
      "\ttrain_acc: 0.8060, test_acc: \u001b[31m0.798\u001b[0m, time: 36.21\n",
      "epoch: 120, loss: 111.88929, loss1: 0.82875, loss2_3: 111.06054\n",
      "\ttrain_acc: 0.8036, test_acc: \u001b[31m0.79695\u001b[0m, time: 36.19\n",
      "epoch: 121, loss: 111.62724, loss1: 0.81979, loss2_3: 110.80745\n",
      "\ttrain_acc: 0.8078, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.21\n",
      "epoch: 122, loss: 111.39327, loss1: 0.81991, loss2_3: 110.57336\n",
      "\ttrain_acc: 0.8071, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 123, loss: 111.10738, loss1: 0.81879, loss2_3: 110.28859\n",
      "\ttrain_acc: 0.8055, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.21\n",
      "epoch: 124, loss: 111.34861, loss1: 0.81988, loss2_3: 110.52873\n",
      "\ttrain_acc: 0.8093, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.26\n",
      "epoch: 125, loss: 110.94272, loss1: 0.81714, loss2_3: 110.12558\n",
      "\ttrain_acc: 0.8110, test_acc: \u001b[31m0.80445\u001b[0m, time: 36.22\n",
      "best_acc: 0.80445\n",
      "epoch: 126, loss: 111.05497, loss1: 0.81706, loss2_3: 110.23791\n",
      "\ttrain_acc: 0.8108, test_acc: \u001b[31m0.80465\u001b[0m, time: 36.24\n",
      "best_acc: 0.80465\n",
      "epoch: 127, loss: 110.82743, loss1: 0.81278, loss2_3: 110.01465\n",
      "\ttrain_acc: 0.8111, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.22\n",
      "epoch: 128, loss: 111.03116, loss1: 0.81920, loss2_3: 110.21196\n",
      "\ttrain_acc: 0.8099, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.22\n",
      "epoch: 129, loss: 110.81044, loss1: 0.81921, loss2_3: 109.99124\n",
      "\ttrain_acc: 0.8092, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.19\n",
      "epoch: 130, loss: 110.80125, loss1: 0.81607, loss2_3: 109.98518\n",
      "\ttrain_acc: 0.8095, test_acc: \u001b[31m0.8004\u001b[0m, time: 36.23\n",
      "epoch: 131, loss: 110.51217, loss1: 0.81659, loss2_3: 109.69558\n",
      "\ttrain_acc: 0.8066, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.18\n",
      "epoch: 132, loss: 110.64103, loss1: 0.82051, loss2_3: 109.82052\n",
      "\ttrain_acc: 0.8034, test_acc: \u001b[31m0.79695\u001b[0m, time: 36.23\n",
      "epoch: 133, loss: 110.31536, loss1: 0.81578, loss2_3: 109.49958\n",
      "\ttrain_acc: 0.8069, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.19\n",
      "epoch: 134, loss: 110.60062, loss1: 0.82084, loss2_3: 109.77978\n",
      "\ttrain_acc: 0.8151, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.19\n",
      "epoch: 135, loss: 110.10641, loss1: 0.81731, loss2_3: 109.28910\n",
      "\ttrain_acc: 0.8133, test_acc: \u001b[31m0.8045\u001b[0m, time: 36.24\n",
      "epoch: 136, loss: 110.35463, loss1: 0.81565, loss2_3: 109.53898\n",
      "\ttrain_acc: 0.8122, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.20\n",
      "epoch: 137, loss: 109.55216, loss1: 0.81672, loss2_3: 108.73544\n",
      "\ttrain_acc: 0.8138, test_acc: \u001b[31m0.8038\u001b[0m, time: 36.27\n",
      "epoch: 138, loss: 109.78582, loss1: 0.81347, loss2_3: 108.97235\n",
      "\ttrain_acc: 0.8087, test_acc: \u001b[31m0.79855\u001b[0m, time: 36.22\n",
      "epoch: 139, loss: 109.92308, loss1: 0.81719, loss2_3: 109.10589\n",
      "\ttrain_acc: 0.8143, test_acc: \u001b[31m0.8035\u001b[0m, time: 36.23\n",
      "epoch: 140, loss: 109.64199, loss1: 0.81277, loss2_3: 108.82922\n",
      "\ttrain_acc: 0.8116, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.24\n",
      "epoch: 141, loss: 109.38111, loss1: 0.81129, loss2_3: 108.56982\n",
      "\ttrain_acc: 0.8097, test_acc: \u001b[31m0.7993\u001b[0m, time: 36.23\n",
      "epoch: 142, loss: 109.42079, loss1: 0.81285, loss2_3: 108.60794\n",
      "\ttrain_acc: 0.8158, test_acc: \u001b[31m0.804\u001b[0m, time: 36.22\n",
      "epoch: 143, loss: 109.22362, loss1: 0.80902, loss2_3: 108.41460\n",
      "\ttrain_acc: 0.8156, test_acc: \u001b[31m0.80535\u001b[0m, time: 36.25\n",
      "best_acc: 0.80535\n",
      "epoch: 144, loss: 108.89227, loss1: 0.80999, loss2_3: 108.08228\n",
      "\ttrain_acc: 0.8127, test_acc: \u001b[31m0.80265\u001b[0m, time: 36.22\n",
      "epoch: 145, loss: 109.22943, loss1: 0.80977, loss2_3: 108.41966\n",
      "\ttrain_acc: 0.8132, test_acc: \u001b[31m0.8012\u001b[0m, time: 36.22\n",
      "epoch: 146, loss: 109.01833, loss1: 0.81020, loss2_3: 108.20814\n",
      "\ttrain_acc: 0.8148, test_acc: \u001b[31m0.80375\u001b[0m, time: 36.24\n",
      "epoch: 147, loss: 108.76800, loss1: 0.81304, loss2_3: 107.95496\n",
      "\ttrain_acc: 0.8159, test_acc: \u001b[31m0.80275\u001b[0m, time: 36.22\n",
      "epoch: 148, loss: 108.46774, loss1: 0.81263, loss2_3: 107.65510\n",
      "\ttrain_acc: 0.8177, test_acc: \u001b[31m0.8034\u001b[0m, time: 36.24\n",
      "epoch: 149, loss: 108.44478, loss1: 0.81109, loss2_3: 107.63369\n",
      "\ttrain_acc: 0.8193, test_acc: \u001b[31m0.8031\u001b[0m, time: 36.23\n",
      "epoch: 150, loss: 108.43883, loss1: 0.80911, loss2_3: 107.62972\n",
      "\ttrain_acc: 0.8086, test_acc: \u001b[31m0.7968\u001b[0m, time: 36.23\n",
      "epoch: 151, loss: 108.53263, loss1: 0.81096, loss2_3: 107.72167\n",
      "\ttrain_acc: 0.8181, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.27\n",
      "epoch: 152, loss: 108.41077, loss1: 0.80934, loss2_3: 107.60143\n",
      "\ttrain_acc: 0.8179, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.22\n",
      "epoch: 153, loss: 108.01625, loss1: 0.81066, loss2_3: 107.20559\n",
      "\ttrain_acc: 0.8144, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.22\n",
      "epoch: 154, loss: 107.89072, loss1: 0.81009, loss2_3: 107.08063\n",
      "\ttrain_acc: 0.8174, test_acc: \u001b[31m0.80425\u001b[0m, time: 36.23\n",
      "epoch: 155, loss: 107.56243, loss1: 0.80736, loss2_3: 106.75507\n",
      "\ttrain_acc: 0.8177, test_acc: \u001b[31m0.8041\u001b[0m, time: 36.19\n",
      "epoch: 156, loss: 107.63999, loss1: 0.81118, loss2_3: 106.82881\n",
      "\ttrain_acc: 0.8190, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.24\n",
      "epoch: 157, loss: 107.64516, loss1: 0.80498, loss2_3: 106.84018\n",
      "\ttrain_acc: 0.8181, test_acc: \u001b[31m0.8003\u001b[0m, time: 36.19\n",
      "epoch: 158, loss: 107.38682, loss1: 0.80377, loss2_3: 106.58304\n",
      "\ttrain_acc: 0.8213, test_acc: \u001b[31m0.8025\u001b[0m, time: 36.21\n",
      "epoch: 159, loss: 107.52173, loss1: 0.80915, loss2_3: 106.71258\n",
      "\ttrain_acc: 0.8185, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.23\n",
      "epoch: 160, loss: 107.68287, loss1: 0.80581, loss2_3: 106.87707\n",
      "\ttrain_acc: 0.8190, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.22\n",
      "epoch: 161, loss: 107.11685, loss1: 0.80419, loss2_3: 106.31266\n",
      "\ttrain_acc: 0.8192, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.22\n",
      "epoch: 162, loss: 107.02204, loss1: 0.80310, loss2_3: 106.21894\n",
      "\ttrain_acc: 0.8146, test_acc: \u001b[31m0.7991\u001b[0m, time: 36.25\n",
      "epoch: 163, loss: 106.67238, loss1: 0.80814, loss2_3: 105.86424\n",
      "\ttrain_acc: 0.8227, test_acc: \u001b[31m0.8011\u001b[0m, time: 36.22\n",
      "epoch: 164, loss: 106.58109, loss1: 0.80760, loss2_3: 105.77349\n",
      "\ttrain_acc: 0.8167, test_acc: \u001b[31m0.7922\u001b[0m, time: 36.23\n",
      "epoch: 165, loss: 106.54823, loss1: 0.80469, loss2_3: 105.74355\n",
      "\ttrain_acc: 0.8215, test_acc: \u001b[31m0.8029\u001b[0m, time: 36.22\n",
      "epoch: 166, loss: 106.38190, loss1: 0.80600, loss2_3: 105.57590\n",
      "\ttrain_acc: 0.8219, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.20\n",
      "epoch: 167, loss: 106.32044, loss1: 0.80944, loss2_3: 105.51100\n",
      "\ttrain_acc: 0.8237, test_acc: \u001b[31m0.8044\u001b[0m, time: 36.23\n",
      "epoch: 168, loss: 106.38440, loss1: 0.80087, loss2_3: 105.58353\n",
      "\ttrain_acc: 0.8236, test_acc: \u001b[31m0.804\u001b[0m, time: 36.19\n",
      "epoch: 169, loss: 106.57454, loss1: 0.80369, loss2_3: 105.77084\n",
      "\ttrain_acc: 0.8188, test_acc: \u001b[31m0.80175\u001b[0m, time: 36.20\n",
      "epoch: 170, loss: 106.06016, loss1: 0.79987, loss2_3: 105.26029\n",
      "\ttrain_acc: 0.8210, test_acc: \u001b[31m0.80375\u001b[0m, time: 36.22\n",
      "epoch: 171, loss: 105.91500, loss1: 0.79970, loss2_3: 105.11530\n",
      "\ttrain_acc: 0.8230, test_acc: \u001b[31m0.80305\u001b[0m, time: 36.19\n",
      "epoch: 172, loss: 105.52083, loss1: 0.80438, loss2_3: 104.71645\n",
      "\ttrain_acc: 0.8198, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.25\n",
      "epoch: 173, loss: 105.37282, loss1: 0.80138, loss2_3: 104.57144\n",
      "\ttrain_acc: 0.8157, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.21\n",
      "epoch: 174, loss: 105.39453, loss1: 0.79760, loss2_3: 104.59692\n",
      "\ttrain_acc: 0.8236, test_acc: \u001b[31m0.79165\u001b[0m, time: 36.22\n",
      "epoch: 175, loss: 105.13587, loss1: 0.80087, loss2_3: 104.33501\n",
      "\ttrain_acc: 0.8162, test_acc: \u001b[31m0.7881\u001b[0m, time: 36.25\n",
      "epoch: 176, loss: 105.26447, loss1: 0.79879, loss2_3: 104.46569\n",
      "\ttrain_acc: 0.8130, test_acc: \u001b[31m0.7979\u001b[0m, time: 36.20\n",
      "epoch: 177, loss: 105.07268, loss1: 0.80003, loss2_3: 104.27265\n",
      "\ttrain_acc: 0.8217, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.23\n",
      "epoch: 178, loss: 105.10035, loss1: 0.80149, loss2_3: 104.29886\n",
      "\ttrain_acc: 0.8137, test_acc: \u001b[31m0.7982\u001b[0m, time: 36.23\n",
      "epoch: 179, loss: 104.58734, loss1: 0.79331, loss2_3: 103.79402\n",
      "\ttrain_acc: 0.8164, test_acc: \u001b[31m0.79875\u001b[0m, time: 36.20\n",
      "epoch: 180, loss: 105.00078, loss1: 0.80447, loss2_3: 104.19631\n",
      "\ttrain_acc: 0.8228, test_acc: \u001b[31m0.7899\u001b[0m, time: 36.22\n",
      "epoch: 181, loss: 104.52527, loss1: 0.79716, loss2_3: 103.72811\n",
      "\ttrain_acc: 0.8271, test_acc: \u001b[31m0.80335\u001b[0m, time: 36.20\n",
      "epoch: 182, loss: 104.29080, loss1: 0.79903, loss2_3: 103.49177\n",
      "\ttrain_acc: 0.8272, test_acc: \u001b[31m0.801\u001b[0m, time: 36.22\n",
      "epoch: 183, loss: 104.09285, loss1: 0.79364, loss2_3: 103.29921\n",
      "\ttrain_acc: 0.8274, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.22\n",
      "epoch: 184, loss: 104.07373, loss1: 0.79710, loss2_3: 103.27663\n",
      "\ttrain_acc: 0.8265, test_acc: \u001b[31m0.7938\u001b[0m, time: 36.20\n",
      "epoch: 185, loss: 103.98577, loss1: 0.79761, loss2_3: 103.18817\n",
      "\ttrain_acc: 0.8243, test_acc: \u001b[31m0.80445\u001b[0m, time: 36.25\n",
      "epoch: 186, loss: 103.49745, loss1: 0.79710, loss2_3: 102.70035\n",
      "\ttrain_acc: 0.8294, test_acc: \u001b[31m0.80275\u001b[0m, time: 36.20\n",
      "epoch: 187, loss: 103.49293, loss1: 0.79688, loss2_3: 102.69605\n",
      "\ttrain_acc: 0.8277, test_acc: \u001b[31m0.80315\u001b[0m, time: 36.21\n",
      "epoch: 188, loss: 103.20255, loss1: 0.79491, loss2_3: 102.40764\n",
      "\ttrain_acc: 0.8291, test_acc: \u001b[31m0.79895\u001b[0m, time: 36.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 189, loss: 103.04141, loss1: 0.79787, loss2_3: 102.24354\n",
      "\ttrain_acc: 0.8309, test_acc: \u001b[31m0.7985\u001b[0m, time: 36.21\n",
      "epoch: 190, loss: 102.99310, loss1: 0.78849, loss2_3: 102.20461\n",
      "\ttrain_acc: 0.8177, test_acc: \u001b[31m0.79665\u001b[0m, time: 36.19\n",
      "epoch: 191, loss: 102.53679, loss1: 0.79280, loss2_3: 101.74399\n",
      "\ttrain_acc: 0.8277, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.22\n",
      "epoch: 192, loss: 102.55701, loss1: 0.78938, loss2_3: 101.76762\n",
      "\ttrain_acc: 0.8331, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.17\n",
      "epoch: 193, loss: 102.45532, loss1: 0.79441, loss2_3: 101.66091\n",
      "\ttrain_acc: 0.8323, test_acc: \u001b[31m0.8\u001b[0m, time: 36.20\n",
      "epoch: 194, loss: 102.35808, loss1: 0.78974, loss2_3: 101.56833\n",
      "\ttrain_acc: 0.8142, test_acc: \u001b[31m0.79795\u001b[0m, time: 36.23\n",
      "epoch: 195, loss: 101.62177, loss1: 0.78892, loss2_3: 100.83285\n",
      "\ttrain_acc: 0.8184, test_acc: \u001b[31m0.7958\u001b[0m, time: 36.22\n",
      "epoch: 196, loss: 102.06107, loss1: 0.79185, loss2_3: 101.26922\n",
      "\ttrain_acc: 0.8260, test_acc: \u001b[31m0.7997\u001b[0m, time: 36.25\n",
      "epoch: 197, loss: 101.68960, loss1: 0.78324, loss2_3: 100.90636\n",
      "\ttrain_acc: 0.8120, test_acc: \u001b[31m0.7912\u001b[0m, time: 36.21\n",
      "epoch: 198, loss: 101.39848, loss1: 0.78381, loss2_3: 100.61467\n",
      "\ttrain_acc: 0.8346, test_acc: \u001b[31m0.79315\u001b[0m, time: 36.23\n",
      "epoch: 199, loss: 101.32818, loss1: 0.78737, loss2_3: 100.54082\n",
      "\ttrain_acc: 0.8327, test_acc: \u001b[31m0.80305\u001b[0m, time: 36.18\n",
      "epoch: 200, loss: 100.72092, loss1: 0.79037, loss2_3: 99.93055\n",
      "\ttrain_acc: 0.8326, test_acc: \u001b[31m0.80335\u001b[0m, time: 36.21\n",
      "epoch: 201, loss: 101.04327, loss1: 0.78512, loss2_3: 100.25815\n",
      "\ttrain_acc: 0.8357, test_acc: \u001b[31m0.79865\u001b[0m, time: 36.21\n",
      "epoch: 202, loss: 101.07507, loss1: 0.78528, loss2_3: 100.28979\n",
      "\ttrain_acc: 0.8292, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.21\n",
      "epoch: 203, loss: 100.51661, loss1: 0.78363, loss2_3: 99.73299\n",
      "\ttrain_acc: 0.8236, test_acc: \u001b[31m0.79805\u001b[0m, time: 36.19\n",
      "epoch: 204, loss: 100.30300, loss1: 0.78128, loss2_3: 99.52172\n",
      "\ttrain_acc: 0.8345, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.23\n",
      "epoch: 205, loss: 100.26620, loss1: 0.78145, loss2_3: 99.48475\n",
      "\ttrain_acc: 0.8121, test_acc: \u001b[31m0.75945\u001b[0m, time: 37.20\n",
      "epoch: 206, loss: 99.82037, loss1: 0.78495, loss2_3: 99.03542\n",
      "\ttrain_acc: 0.8314, test_acc: \u001b[31m0.80035\u001b[0m, time: 36.63\n",
      "epoch: 207, loss: 99.68602, loss1: 0.78470, loss2_3: 98.90132\n",
      "\ttrain_acc: 0.8345, test_acc: \u001b[31m0.79265\u001b[0m, time: 36.30\n",
      "epoch: 208, loss: 99.64925, loss1: 0.78543, loss2_3: 98.86382\n",
      "\ttrain_acc: 0.8331, test_acc: \u001b[31m0.78415\u001b[0m, time: 36.24\n",
      "epoch: 209, loss: 98.65511, loss1: 0.77985, loss2_3: 97.87526\n",
      "\ttrain_acc: 0.8356, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.28\n",
      "epoch: 210, loss: 99.11952, loss1: 0.78091, loss2_3: 98.33861\n",
      "\ttrain_acc: 0.8377, test_acc: \u001b[31m0.7874\u001b[0m, time: 36.24\n",
      "epoch: 211, loss: 99.02814, loss1: 0.77906, loss2_3: 98.24908\n",
      "\ttrain_acc: 0.8348, test_acc: \u001b[31m0.79615\u001b[0m, time: 36.27\n",
      "epoch: 212, loss: 98.38155, loss1: 0.77488, loss2_3: 97.60667\n",
      "\ttrain_acc: 0.8411, test_acc: \u001b[31m0.79105\u001b[0m, time: 36.24\n",
      "epoch: 213, loss: 98.65524, loss1: 0.77659, loss2_3: 97.87866\n",
      "\ttrain_acc: 0.8328, test_acc: \u001b[31m0.7935\u001b[0m, time: 36.25\n",
      "epoch: 214, loss: 98.32684, loss1: 0.77470, loss2_3: 97.55214\n",
      "\ttrain_acc: 0.8275, test_acc: \u001b[31m0.79515\u001b[0m, time: 36.23\n",
      "epoch: 215, loss: 98.02872, loss1: 0.77517, loss2_3: 97.25355\n",
      "\ttrain_acc: 0.7678, test_acc: \u001b[31m0.7104\u001b[0m, time: 36.26\n",
      "epoch: 216, loss: 97.71341, loss1: 0.77029, loss2_3: 96.94312\n",
      "\ttrain_acc: 0.8238, test_acc: \u001b[31m0.7949\u001b[0m, time: 36.20\n",
      "epoch: 217, loss: 97.95519, loss1: 0.77554, loss2_3: 97.17965\n",
      "\ttrain_acc: 0.8442, test_acc: \u001b[31m0.79125\u001b[0m, time: 36.28\n",
      "epoch: 218, loss: 97.37792, loss1: 0.77103, loss2_3: 96.60688\n",
      "\ttrain_acc: 0.8233, test_acc: \u001b[31m0.7955\u001b[0m, time: 36.21\n",
      "epoch: 219, loss: 97.20956, loss1: 0.77074, loss2_3: 96.43882\n",
      "\ttrain_acc: 0.8474, test_acc: \u001b[31m0.79625\u001b[0m, time: 36.27\n",
      "epoch: 220, loss: 96.96799, loss1: 0.77660, loss2_3: 96.19139\n",
      "\ttrain_acc: 0.8283, test_acc: \u001b[31m0.7952\u001b[0m, time: 36.25\n",
      "epoch: 221, loss: 96.42583, loss1: 0.76627, loss2_3: 95.65956\n",
      "\ttrain_acc: 0.8150, test_acc: \u001b[31m0.75215\u001b[0m, time: 36.28\n",
      "epoch: 222, loss: 96.06474, loss1: 0.76642, loss2_3: 95.29833\n",
      "\ttrain_acc: 0.8347, test_acc: \u001b[31m0.7764\u001b[0m, time: 36.23\n",
      "epoch: 223, loss: 96.25036, loss1: 0.76506, loss2_3: 95.48529\n",
      "\ttrain_acc: 0.8442, test_acc: \u001b[31m0.79705\u001b[0m, time: 36.30\n",
      "epoch: 224, loss: 95.82586, loss1: 0.76655, loss2_3: 95.05931\n",
      "\ttrain_acc: 0.8402, test_acc: \u001b[31m0.79355\u001b[0m, time: 36.21\n",
      "epoch: 225, loss: 95.55717, loss1: 0.76234, loss2_3: 94.79483\n",
      "\ttrain_acc: 0.8357, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.25\n",
      "epoch: 226, loss: 95.56281, loss1: 0.76099, loss2_3: 94.80182\n",
      "\ttrain_acc: 0.8345, test_acc: \u001b[31m0.7956\u001b[0m, time: 36.23\n",
      "epoch: 227, loss: 94.98097, loss1: 0.76257, loss2_3: 94.21840\n",
      "\ttrain_acc: 0.8320, test_acc: \u001b[31m0.793\u001b[0m, time: 36.26\n",
      "epoch: 228, loss: 94.92121, loss1: 0.76263, loss2_3: 94.15858\n",
      "\ttrain_acc: 0.8389, test_acc: \u001b[31m0.7764\u001b[0m, time: 36.25\n",
      "epoch: 229, loss: 95.07830, loss1: 0.76567, loss2_3: 94.31262\n",
      "\ttrain_acc: 0.6772, test_acc: \u001b[31m0.6246\u001b[0m, time: 36.26\n",
      "epoch: 230, loss: 94.56789, loss1: 0.76537, loss2_3: 93.80252\n",
      "\ttrain_acc: 0.8496, test_acc: \u001b[31m0.7912\u001b[0m, time: 36.25\n",
      "epoch: 231, loss: 94.24864, loss1: 0.75625, loss2_3: 93.49239\n",
      "\ttrain_acc: 0.5103, test_acc: \u001b[31m0.50265\u001b[0m, time: 36.28\n",
      "epoch: 232, loss: 93.90721, loss1: 0.76394, loss2_3: 93.14328\n",
      "\ttrain_acc: 0.8074, test_acc: \u001b[31m0.73685\u001b[0m, time: 36.25\n",
      "epoch: 233, loss: 93.63344, loss1: 0.75768, loss2_3: 92.87577\n",
      "\ttrain_acc: 0.8396, test_acc: \u001b[31m0.79685\u001b[0m, time: 36.27\n",
      "epoch: 234, loss: 93.48432, loss1: 0.75813, loss2_3: 92.72620\n",
      "\ttrain_acc: 0.8118, test_acc: \u001b[31m0.7371\u001b[0m, time: 36.23\n",
      "epoch: 235, loss: 93.29621, loss1: 0.75130, loss2_3: 92.54491\n",
      "\ttrain_acc: 0.8299, test_acc: \u001b[31m0.79085\u001b[0m, time: 36.25\n",
      "epoch: 236, loss: 93.26813, loss1: 0.75573, loss2_3: 92.51240\n",
      "\ttrain_acc: 0.8108, test_acc: \u001b[31m0.7332\u001b[0m, time: 36.25\n",
      "epoch: 237, loss: 92.66743, loss1: 0.75270, loss2_3: 91.91473\n",
      "\ttrain_acc: 0.8549, test_acc: \u001b[31m0.7833\u001b[0m, time: 36.23\n",
      "epoch: 238, loss: 92.53939, loss1: 0.75029, loss2_3: 91.78910\n",
      "\ttrain_acc: 0.8587, test_acc: \u001b[31m0.7938\u001b[0m, time: 36.21\n",
      "epoch: 239, loss: 92.16825, loss1: 0.75362, loss2_3: 91.41463\n",
      "\ttrain_acc: 0.8123, test_acc: \u001b[31m0.7315\u001b[0m, time: 36.26\n",
      "epoch: 240, loss: 92.15989, loss1: 0.74948, loss2_3: 91.41041\n",
      "\ttrain_acc: 0.8598, test_acc: \u001b[31m0.7937\u001b[0m, time: 36.21\n",
      "epoch: 241, loss: 91.47757, loss1: 0.74901, loss2_3: 90.72856\n",
      "\ttrain_acc: 0.8538, test_acc: \u001b[31m0.79515\u001b[0m, time: 36.27\n",
      "epoch: 242, loss: 91.18425, loss1: 0.74933, loss2_3: 90.43491\n",
      "\ttrain_acc: 0.8268, test_acc: \u001b[31m0.7422\u001b[0m, time: 36.26\n",
      "epoch: 243, loss: 90.98069, loss1: 0.74641, loss2_3: 90.23428\n",
      "\ttrain_acc: 0.8251, test_acc: \u001b[31m0.78605\u001b[0m, time: 36.28\n",
      "epoch: 244, loss: 90.96880, loss1: 0.75105, loss2_3: 90.21775\n",
      "\ttrain_acc: 0.8170, test_acc: \u001b[31m0.78585\u001b[0m, time: 36.25\n",
      "epoch: 245, loss: 90.75776, loss1: 0.74193, loss2_3: 90.01583\n",
      "\ttrain_acc: 0.8480, test_acc: \u001b[31m0.7976\u001b[0m, time: 36.27\n",
      "epoch: 246, loss: 90.09006, loss1: 0.74457, loss2_3: 89.34549\n",
      "\ttrain_acc: 0.7466, test_acc: \u001b[31m0.6709\u001b[0m, time: 36.21\n",
      "epoch: 247, loss: 90.33190, loss1: 0.73554, loss2_3: 89.59636\n",
      "\ttrain_acc: 0.8459, test_acc: \u001b[31m0.7972\u001b[0m, time: 36.28\n",
      "epoch: 248, loss: 89.73519, loss1: 0.74001, loss2_3: 88.99518\n",
      "\ttrain_acc: 0.8614, test_acc: \u001b[31m0.7849\u001b[0m, time: 36.21\n",
      "epoch: 249, loss: 89.03649, loss1: 0.73837, loss2_3: 88.29812\n",
      "\ttrain_acc: 0.8019, test_acc: \u001b[31m0.7222\u001b[0m, time: 36.28\n",
      "epoch: 250, loss: 89.07362, loss1: 0.73843, loss2_3: 88.33518\n",
      "\ttrain_acc: 0.8637, test_acc: \u001b[31m0.7952\u001b[0m, time: 36.21\n",
      "epoch: 1, loss: 180.41867, loss1: 2.58571, loss2_3: 177.83295\n",
      "\ttrain_acc: 0.5422, test_acc: \u001b[31m0.5366\u001b[0m, time: 36.47\n",
      "best_acc: 0.5366\n",
      "epoch: 2, loss: 175.42389, loss1: 1.02179, loss2_3: 174.40210\n",
      "\ttrain_acc: 0.5575, test_acc: \u001b[31m0.55145\u001b[0m, time: 36.48\n",
      "best_acc: 0.55145\n",
      "epoch: 3, loss: 172.80997, loss1: 1.02754, loss2_3: 171.78243\n",
      "\ttrain_acc: 0.5835, test_acc: \u001b[31m0.57\u001b[0m, time: 36.46\n",
      "best_acc: 0.57\n",
      "epoch: 4, loss: 158.43839, loss1: 1.01482, loss2_3: 157.42358\n",
      "\ttrain_acc: 0.7133, test_acc: \u001b[31m0.7142\u001b[0m, time: 36.48\n",
      "best_acc: 0.7142\n",
      "epoch: 5, loss: 139.09849, loss1: 0.98419, loss2_3: 138.11430\n",
      "\ttrain_acc: 0.7494, test_acc: \u001b[31m0.75215\u001b[0m, time: 36.50\n",
      "best_acc: 0.75215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, loss: 132.65455, loss1: 0.95347, loss2_3: 131.70109\n",
      "\ttrain_acc: 0.7515, test_acc: \u001b[31m0.75025\u001b[0m, time: 36.50\n",
      "epoch: 7, loss: 131.20668, loss1: 0.94417, loss2_3: 130.26251\n",
      "\ttrain_acc: 0.7438, test_acc: \u001b[31m0.7447\u001b[0m, time: 36.50\n",
      "epoch: 8, loss: 128.93461, loss1: 0.92982, loss2_3: 128.00479\n",
      "\ttrain_acc: 0.7477, test_acc: \u001b[31m0.75165\u001b[0m, time: 36.52\n",
      "epoch: 9, loss: 127.80379, loss1: 0.93088, loss2_3: 126.87291\n",
      "\ttrain_acc: 0.7716, test_acc: \u001b[31m0.7715\u001b[0m, time: 36.49\n",
      "best_acc: 0.7715\n",
      "epoch: 10, loss: 126.11510, loss1: 0.91590, loss2_3: 125.19919\n",
      "\ttrain_acc: 0.7694, test_acc: \u001b[31m0.7704\u001b[0m, time: 36.50\n",
      "epoch: 11, loss: 126.23224, loss1: 0.91168, loss2_3: 125.32056\n",
      "\ttrain_acc: 0.7799, test_acc: \u001b[31m0.77945\u001b[0m, time: 36.46\n",
      "best_acc: 0.77945\n",
      "epoch: 12, loss: 124.39598, loss1: 0.90778, loss2_3: 123.48821\n",
      "\ttrain_acc: 0.7786, test_acc: \u001b[31m0.77835\u001b[0m, time: 36.47\n",
      "epoch: 13, loss: 124.26610, loss1: 0.90663, loss2_3: 123.35947\n",
      "\ttrain_acc: 0.7711, test_acc: \u001b[31m0.7696\u001b[0m, time: 36.48\n",
      "epoch: 14, loss: 123.33616, loss1: 0.89856, loss2_3: 122.43760\n",
      "\ttrain_acc: 0.7844, test_acc: \u001b[31m0.7844\u001b[0m, time: 36.44\n",
      "best_acc: 0.7844\n",
      "epoch: 15, loss: 122.85589, loss1: 0.89821, loss2_3: 121.95768\n",
      "\ttrain_acc: 0.7824, test_acc: \u001b[31m0.78145\u001b[0m, time: 36.47\n",
      "epoch: 16, loss: 122.77814, loss1: 0.90127, loss2_3: 121.87687\n",
      "\ttrain_acc: 0.7839, test_acc: \u001b[31m0.78325\u001b[0m, time: 36.42\n",
      "epoch: 17, loss: 122.51336, loss1: 0.89112, loss2_3: 121.62223\n",
      "\ttrain_acc: 0.7884, test_acc: \u001b[31m0.7882\u001b[0m, time: 36.45\n",
      "best_acc: 0.7882\n",
      "epoch: 18, loss: 122.54699, loss1: 0.89372, loss2_3: 121.65327\n",
      "\ttrain_acc: 0.7798, test_acc: \u001b[31m0.77915\u001b[0m, time: 36.47\n",
      "epoch: 19, loss: 122.27377, loss1: 0.88986, loss2_3: 121.38391\n",
      "\ttrain_acc: 0.7854, test_acc: \u001b[31m0.78515\u001b[0m, time: 36.47\n",
      "epoch: 20, loss: 121.77790, loss1: 0.88948, loss2_3: 120.88843\n",
      "\ttrain_acc: 0.7853, test_acc: \u001b[31m0.78265\u001b[0m, time: 36.45\n",
      "epoch: 21, loss: 121.60980, loss1: 0.88797, loss2_3: 120.72183\n",
      "\ttrain_acc: 0.7787, test_acc: \u001b[31m0.77865\u001b[0m, time: 36.50\n",
      "epoch: 22, loss: 121.51359, loss1: 0.88407, loss2_3: 120.62952\n",
      "\ttrain_acc: 0.7862, test_acc: \u001b[31m0.78655\u001b[0m, time: 36.43\n",
      "epoch: 23, loss: 121.48848, loss1: 0.87995, loss2_3: 120.60854\n",
      "\ttrain_acc: 0.7853, test_acc: \u001b[31m0.7852\u001b[0m, time: 36.45\n",
      "epoch: 24, loss: 120.66760, loss1: 0.87495, loss2_3: 119.79265\n",
      "\ttrain_acc: 0.7803, test_acc: \u001b[31m0.78035\u001b[0m, time: 36.44\n",
      "epoch: 25, loss: 120.97374, loss1: 0.89107, loss2_3: 120.08266\n",
      "\ttrain_acc: 0.7828, test_acc: \u001b[31m0.78365\u001b[0m, time: 36.44\n",
      "epoch: 26, loss: 120.18581, loss1: 0.88120, loss2_3: 119.30462\n",
      "\ttrain_acc: 0.7871, test_acc: \u001b[31m0.78595\u001b[0m, time: 36.43\n",
      "epoch: 27, loss: 119.78318, loss1: 0.87657, loss2_3: 118.90662\n",
      "\ttrain_acc: 0.7873, test_acc: \u001b[31m0.78755\u001b[0m, time: 36.40\n",
      "epoch: 28, loss: 119.61693, loss1: 0.87195, loss2_3: 118.74498\n",
      "\ttrain_acc: 0.7910, test_acc: \u001b[31m0.79005\u001b[0m, time: 36.44\n",
      "best_acc: 0.79005\n",
      "epoch: 29, loss: 119.47585, loss1: 0.88127, loss2_3: 118.59458\n",
      "\ttrain_acc: 0.7903, test_acc: \u001b[31m0.7887\u001b[0m, time: 36.41\n",
      "epoch: 30, loss: 119.32784, loss1: 0.87363, loss2_3: 118.45421\n",
      "\ttrain_acc: 0.7949, test_acc: \u001b[31m0.7928\u001b[0m, time: 36.42\n",
      "best_acc: 0.7928\n",
      "epoch: 31, loss: 119.38513, loss1: 0.86750, loss2_3: 118.51762\n",
      "\ttrain_acc: 0.7926, test_acc: \u001b[31m0.7918\u001b[0m, time: 36.42\n",
      "epoch: 32, loss: 119.57702, loss1: 0.87039, loss2_3: 118.70663\n",
      "\ttrain_acc: 0.7841, test_acc: \u001b[31m0.78345\u001b[0m, time: 36.40\n",
      "epoch: 33, loss: 118.07625, loss1: 0.87396, loss2_3: 117.20229\n",
      "\ttrain_acc: 0.7913, test_acc: \u001b[31m0.78785\u001b[0m, time: 36.38\n",
      "epoch: 34, loss: 118.88963, loss1: 0.87300, loss2_3: 118.01664\n",
      "\ttrain_acc: 0.7940, test_acc: \u001b[31m0.7936\u001b[0m, time: 36.40\n",
      "best_acc: 0.7936\n",
      "epoch: 35, loss: 118.87336, loss1: 0.86885, loss2_3: 118.00451\n",
      "\ttrain_acc: 0.7931, test_acc: \u001b[31m0.79125\u001b[0m, time: 36.36\n",
      "epoch: 36, loss: 118.07768, loss1: 0.86825, loss2_3: 117.20942\n",
      "\ttrain_acc: 0.7929, test_acc: \u001b[31m0.79095\u001b[0m, time: 36.36\n",
      "epoch: 37, loss: 118.74971, loss1: 0.87600, loss2_3: 117.87371\n",
      "\ttrain_acc: 0.7942, test_acc: \u001b[31m0.79325\u001b[0m, time: 36.36\n",
      "epoch: 38, loss: 118.00510, loss1: 0.86780, loss2_3: 117.13730\n",
      "\ttrain_acc: 0.7971, test_acc: \u001b[31m0.7929\u001b[0m, time: 36.35\n",
      "epoch: 39, loss: 117.89950, loss1: 0.86499, loss2_3: 117.03451\n",
      "\ttrain_acc: 0.7975, test_acc: \u001b[31m0.79505\u001b[0m, time: 36.36\n",
      "best_acc: 0.79505\n",
      "epoch: 40, loss: 117.92671, loss1: 0.87029, loss2_3: 117.05642\n",
      "\ttrain_acc: 0.7893, test_acc: \u001b[31m0.7879\u001b[0m, time: 36.39\n",
      "epoch: 41, loss: 117.96063, loss1: 0.86181, loss2_3: 117.09881\n",
      "\ttrain_acc: 0.7970, test_acc: \u001b[31m0.7954\u001b[0m, time: 36.37\n",
      "best_acc: 0.7954\n",
      "epoch: 42, loss: 118.05225, loss1: 0.86947, loss2_3: 117.18277\n",
      "\ttrain_acc: 0.7920, test_acc: \u001b[31m0.79105\u001b[0m, time: 36.40\n",
      "epoch: 43, loss: 117.79303, loss1: 0.86197, loss2_3: 116.93106\n",
      "\ttrain_acc: 0.7910, test_acc: \u001b[31m0.7898\u001b[0m, time: 36.38\n",
      "epoch: 44, loss: 117.03809, loss1: 0.85949, loss2_3: 116.17860\n",
      "\ttrain_acc: 0.7942, test_acc: \u001b[31m0.79255\u001b[0m, time: 36.39\n",
      "epoch: 45, loss: 117.33207, loss1: 0.86077, loss2_3: 116.47129\n",
      "\ttrain_acc: 0.7968, test_acc: \u001b[31m0.795\u001b[0m, time: 36.39\n",
      "epoch: 46, loss: 117.36915, loss1: 0.86435, loss2_3: 116.50481\n",
      "\ttrain_acc: 0.7907, test_acc: \u001b[31m0.7891\u001b[0m, time: 36.34\n",
      "epoch: 47, loss: 117.12937, loss1: 0.86026, loss2_3: 116.26911\n",
      "\ttrain_acc: 0.7978, test_acc: \u001b[31m0.797\u001b[0m, time: 36.40\n",
      "best_acc: 0.797\n",
      "epoch: 48, loss: 116.62677, loss1: 0.85119, loss2_3: 115.77558\n",
      "\ttrain_acc: 0.7995, test_acc: \u001b[31m0.79705\u001b[0m, time: 36.33\n",
      "best_acc: 0.79705\n",
      "epoch: 49, loss: 117.39398, loss1: 0.85946, loss2_3: 116.53451\n",
      "\ttrain_acc: 0.7948, test_acc: \u001b[31m0.79485\u001b[0m, time: 36.37\n",
      "epoch: 50, loss: 116.77699, loss1: 0.85501, loss2_3: 115.92198\n",
      "\ttrain_acc: 0.7987, test_acc: \u001b[31m0.798\u001b[0m, time: 36.32\n",
      "best_acc: 0.798\n",
      "epoch: 51, loss: 116.76760, loss1: 0.85640, loss2_3: 115.91120\n",
      "\ttrain_acc: 0.7965, test_acc: \u001b[31m0.7952\u001b[0m, time: 36.37\n",
      "epoch: 52, loss: 117.09073, loss1: 0.85717, loss2_3: 116.23356\n",
      "\ttrain_acc: 0.7989, test_acc: \u001b[31m0.79605\u001b[0m, time: 36.28\n",
      "epoch: 53, loss: 116.79829, loss1: 0.85279, loss2_3: 115.94550\n",
      "\ttrain_acc: 0.7990, test_acc: \u001b[31m0.79685\u001b[0m, time: 36.36\n",
      "epoch: 54, loss: 116.55313, loss1: 0.85447, loss2_3: 115.69867\n",
      "\ttrain_acc: 0.8005, test_acc: \u001b[31m0.7985\u001b[0m, time: 36.28\n",
      "best_acc: 0.7985\n",
      "epoch: 55, loss: 116.35780, loss1: 0.84819, loss2_3: 115.50961\n",
      "\ttrain_acc: 0.7989, test_acc: \u001b[31m0.79755\u001b[0m, time: 36.32\n",
      "epoch: 56, loss: 116.46942, loss1: 0.85272, loss2_3: 115.61669\n",
      "\ttrain_acc: 0.7984, test_acc: \u001b[31m0.79565\u001b[0m, time: 36.30\n",
      "epoch: 57, loss: 116.07270, loss1: 0.85601, loss2_3: 115.21669\n",
      "\ttrain_acc: 0.8002, test_acc: \u001b[31m0.79625\u001b[0m, time: 36.32\n",
      "epoch: 58, loss: 116.29765, loss1: 0.84933, loss2_3: 115.44831\n",
      "\ttrain_acc: 0.7994, test_acc: \u001b[31m0.7956\u001b[0m, time: 36.29\n",
      "epoch: 59, loss: 115.83370, loss1: 0.84858, loss2_3: 114.98511\n",
      "\ttrain_acc: 0.8000, test_acc: \u001b[31m0.79735\u001b[0m, time: 36.31\n",
      "epoch: 60, loss: 116.25400, loss1: 0.84703, loss2_3: 115.40697\n",
      "\ttrain_acc: 0.7998, test_acc: \u001b[31m0.79705\u001b[0m, time: 36.27\n",
      "epoch: 61, loss: 116.19639, loss1: 0.85099, loss2_3: 115.34540\n",
      "\ttrain_acc: 0.7990, test_acc: \u001b[31m0.79675\u001b[0m, time: 36.30\n",
      "epoch: 62, loss: 115.83851, loss1: 0.84486, loss2_3: 114.99365\n",
      "\ttrain_acc: 0.8016, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.23\n",
      "best_acc: 0.79905\n",
      "epoch: 63, loss: 115.44681, loss1: 0.84418, loss2_3: 114.60263\n",
      "\ttrain_acc: 0.7997, test_acc: \u001b[31m0.79805\u001b[0m, time: 36.31\n",
      "epoch: 64, loss: 115.62445, loss1: 0.84332, loss2_3: 114.78113\n",
      "\ttrain_acc: 0.8026, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.26\n",
      "best_acc: 0.8002\n",
      "epoch: 65, loss: 115.77299, loss1: 0.85266, loss2_3: 114.92033\n",
      "\ttrain_acc: 0.8034, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.30\n",
      "best_acc: 0.8008\n",
      "epoch: 66, loss: 115.99576, loss1: 0.85227, loss2_3: 115.14350\n",
      "\ttrain_acc: 0.8031, test_acc: \u001b[31m0.801\u001b[0m, time: 36.28\n",
      "best_acc: 0.801\n",
      "epoch: 67, loss: 115.55308, loss1: 0.84722, loss2_3: 114.70586\n",
      "\ttrain_acc: 0.7981, test_acc: \u001b[31m0.795\u001b[0m, time: 36.32\n",
      "epoch: 68, loss: 115.38956, loss1: 0.84517, loss2_3: 114.54439\n",
      "\ttrain_acc: 0.8016, test_acc: \u001b[31m0.7976\u001b[0m, time: 36.24\n",
      "epoch: 69, loss: 115.62264, loss1: 0.83740, loss2_3: 114.78524\n",
      "\ttrain_acc: 0.8010, test_acc: \u001b[31m0.79775\u001b[0m, time: 36.36\n",
      "epoch: 70, loss: 115.62241, loss1: 0.84460, loss2_3: 114.77781\n",
      "\ttrain_acc: 0.7987, test_acc: \u001b[31m0.79585\u001b[0m, time: 36.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 71, loss: 115.35528, loss1: 0.84562, loss2_3: 114.50966\n",
      "\ttrain_acc: 0.7973, test_acc: \u001b[31m0.79475\u001b[0m, time: 36.32\n",
      "epoch: 72, loss: 115.19379, loss1: 0.84433, loss2_3: 114.34945\n",
      "\ttrain_acc: 0.8037, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.26\n",
      "epoch: 73, loss: 115.15601, loss1: 0.84317, loss2_3: 114.31283\n",
      "\ttrain_acc: 0.8002, test_acc: \u001b[31m0.7986\u001b[0m, time: 36.31\n",
      "epoch: 74, loss: 114.81974, loss1: 0.84269, loss2_3: 113.97704\n",
      "\ttrain_acc: 0.8032, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.26\n",
      "epoch: 75, loss: 114.90808, loss1: 0.84496, loss2_3: 114.06312\n",
      "\ttrain_acc: 0.8013, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.33\n",
      "epoch: 76, loss: 115.20662, loss1: 0.84400, loss2_3: 114.36263\n",
      "\ttrain_acc: 0.8008, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.23\n",
      "epoch: 77, loss: 114.97557, loss1: 0.84054, loss2_3: 114.13503\n",
      "\ttrain_acc: 0.7990, test_acc: \u001b[31m0.79535\u001b[0m, time: 36.34\n",
      "epoch: 78, loss: 114.94628, loss1: 0.84232, loss2_3: 114.10396\n",
      "\ttrain_acc: 0.7995, test_acc: \u001b[31m0.7964\u001b[0m, time: 36.23\n",
      "epoch: 79, loss: 114.34667, loss1: 0.84027, loss2_3: 113.50640\n",
      "\ttrain_acc: 0.8021, test_acc: \u001b[31m0.79875\u001b[0m, time: 36.35\n",
      "epoch: 80, loss: 114.58873, loss1: 0.84383, loss2_3: 113.74490\n",
      "\ttrain_acc: 0.8011, test_acc: \u001b[31m0.79685\u001b[0m, time: 36.25\n",
      "epoch: 81, loss: 114.61769, loss1: 0.84092, loss2_3: 113.77677\n",
      "\ttrain_acc: 0.8030, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.33\n",
      "epoch: 82, loss: 114.46292, loss1: 0.83737, loss2_3: 113.62554\n",
      "\ttrain_acc: 0.8030, test_acc: \u001b[31m0.79845\u001b[0m, time: 36.29\n",
      "epoch: 83, loss: 114.68921, loss1: 0.83995, loss2_3: 113.84926\n",
      "\ttrain_acc: 0.8045, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.31\n",
      "epoch: 84, loss: 114.56029, loss1: 0.83342, loss2_3: 113.72688\n",
      "\ttrain_acc: 0.8030, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.27\n",
      "epoch: 85, loss: 114.66711, loss1: 0.83523, loss2_3: 113.83188\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.33\n",
      "epoch: 86, loss: 114.14667, loss1: 0.83828, loss2_3: 113.30838\n",
      "\ttrain_acc: 0.8008, test_acc: \u001b[31m0.79745\u001b[0m, time: 36.26\n",
      "epoch: 87, loss: 114.45417, loss1: 0.83946, loss2_3: 113.61470\n",
      "\ttrain_acc: 0.8023, test_acc: \u001b[31m0.7983\u001b[0m, time: 36.30\n",
      "epoch: 88, loss: 114.23433, loss1: 0.83448, loss2_3: 113.39985\n",
      "\ttrain_acc: 0.8065, test_acc: \u001b[31m0.80265\u001b[0m, time: 36.27\n",
      "best_acc: 0.80265\n",
      "epoch: 89, loss: 114.02113, loss1: 0.83475, loss2_3: 113.18638\n",
      "\ttrain_acc: 0.8052, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.29\n",
      "epoch: 90, loss: 113.77964, loss1: 0.83657, loss2_3: 112.94307\n",
      "\ttrain_acc: 0.8042, test_acc: \u001b[31m0.7988\u001b[0m, time: 36.27\n",
      "epoch: 91, loss: 113.93357, loss1: 0.83332, loss2_3: 113.10025\n",
      "\ttrain_acc: 0.8044, test_acc: \u001b[31m0.8\u001b[0m, time: 36.31\n",
      "epoch: 92, loss: 113.94737, loss1: 0.83706, loss2_3: 113.11031\n",
      "\ttrain_acc: 0.8042, test_acc: \u001b[31m0.8011\u001b[0m, time: 36.26\n",
      "epoch: 93, loss: 113.92705, loss1: 0.83138, loss2_3: 113.09566\n",
      "\ttrain_acc: 0.8027, test_acc: \u001b[31m0.7977\u001b[0m, time: 36.35\n",
      "epoch: 94, loss: 113.76163, loss1: 0.83785, loss2_3: 112.92379\n",
      "\ttrain_acc: 0.8055, test_acc: \u001b[31m0.80145\u001b[0m, time: 36.24\n",
      "epoch: 95, loss: 113.71902, loss1: 0.83305, loss2_3: 112.88597\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.8\u001b[0m, time: 36.36\n",
      "epoch: 96, loss: 113.68235, loss1: 0.83509, loss2_3: 112.84725\n",
      "\ttrain_acc: 0.8022, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.24\n",
      "epoch: 97, loss: 113.49484, loss1: 0.83094, loss2_3: 112.66390\n",
      "\ttrain_acc: 0.8060, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.33\n",
      "epoch: 98, loss: 113.41096, loss1: 0.82932, loss2_3: 112.58165\n",
      "\ttrain_acc: 0.8065, test_acc: \u001b[31m0.802\u001b[0m, time: 36.26\n",
      "epoch: 99, loss: 113.42424, loss1: 0.82889, loss2_3: 112.59534\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.80245\u001b[0m, time: 36.32\n",
      "epoch: 100, loss: 113.25299, loss1: 0.83003, loss2_3: 112.42297\n",
      "\ttrain_acc: 0.8041, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.23\n",
      "epoch: 101, loss: 113.52193, loss1: 0.83126, loss2_3: 112.69067\n",
      "\ttrain_acc: 0.8050, test_acc: \u001b[31m0.8019\u001b[0m, time: 36.34\n",
      "epoch: 102, loss: 113.32469, loss1: 0.83156, loss2_3: 112.49313\n",
      "\ttrain_acc: 0.8053, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.23\n",
      "epoch: 103, loss: 113.34730, loss1: 0.83043, loss2_3: 112.51687\n",
      "\ttrain_acc: 0.8039, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.30\n",
      "epoch: 104, loss: 113.01243, loss1: 0.82994, loss2_3: 112.18249\n",
      "\ttrain_acc: 0.8045, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.28\n",
      "epoch: 105, loss: 113.09560, loss1: 0.82497, loss2_3: 112.27064\n",
      "\ttrain_acc: 0.8054, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.30\n",
      "epoch: 106, loss: 112.93441, loss1: 0.82602, loss2_3: 112.10839\n",
      "\ttrain_acc: 0.8044, test_acc: \u001b[31m0.7991\u001b[0m, time: 36.28\n",
      "epoch: 107, loss: 112.80301, loss1: 0.82572, loss2_3: 111.97729\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.80205\u001b[0m, time: 36.30\n",
      "epoch: 108, loss: 112.71753, loss1: 0.82965, loss2_3: 111.88789\n",
      "\ttrain_acc: 0.8046, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.24\n",
      "epoch: 109, loss: 113.05681, loss1: 0.82711, loss2_3: 112.22970\n",
      "\ttrain_acc: 0.8055, test_acc: \u001b[31m0.7984\u001b[0m, time: 36.34\n",
      "epoch: 110, loss: 113.13329, loss1: 0.82786, loss2_3: 112.30544\n",
      "\ttrain_acc: 0.8058, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.26\n",
      "epoch: 111, loss: 112.77836, loss1: 0.82596, loss2_3: 111.95241\n",
      "\ttrain_acc: 0.8064, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.33\n",
      "epoch: 112, loss: 112.89691, loss1: 0.82305, loss2_3: 112.07385\n",
      "\ttrain_acc: 0.8070, test_acc: \u001b[31m0.8009\u001b[0m, time: 36.24\n",
      "epoch: 113, loss: 112.44574, loss1: 0.82496, loss2_3: 111.62078\n",
      "\ttrain_acc: 0.8069, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.30\n",
      "epoch: 114, loss: 112.44657, loss1: 0.82172, loss2_3: 111.62485\n",
      "\ttrain_acc: 0.8081, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.26\n",
      "epoch: 115, loss: 112.34065, loss1: 0.82282, loss2_3: 111.51783\n",
      "\ttrain_acc: 0.8048, test_acc: \u001b[31m0.7988\u001b[0m, time: 36.28\n",
      "epoch: 116, loss: 112.54727, loss1: 0.82829, loss2_3: 111.71898\n",
      "\ttrain_acc: 0.8027, test_acc: \u001b[31m0.7975\u001b[0m, time: 36.22\n",
      "epoch: 117, loss: 112.09509, loss1: 0.82356, loss2_3: 111.27153\n",
      "\ttrain_acc: 0.8069, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.34\n",
      "epoch: 118, loss: 112.31018, loss1: 0.82537, loss2_3: 111.48481\n",
      "\ttrain_acc: 0.8088, test_acc: \u001b[31m0.80145\u001b[0m, time: 36.21\n",
      "epoch: 119, loss: 112.20887, loss1: 0.82310, loss2_3: 111.38578\n",
      "\ttrain_acc: 0.8076, test_acc: \u001b[31m0.8026\u001b[0m, time: 36.32\n",
      "epoch: 120, loss: 112.20662, loss1: 0.82385, loss2_3: 111.38277\n",
      "\ttrain_acc: 0.8028, test_acc: \u001b[31m0.7956\u001b[0m, time: 36.24\n",
      "epoch: 121, loss: 112.03886, loss1: 0.82161, loss2_3: 111.21725\n",
      "\ttrain_acc: 0.8092, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.31\n",
      "epoch: 122, loss: 112.06505, loss1: 0.82374, loss2_3: 111.24131\n",
      "\ttrain_acc: 0.8057, test_acc: \u001b[31m0.79835\u001b[0m, time: 36.23\n",
      "epoch: 123, loss: 112.17082, loss1: 0.82487, loss2_3: 111.34595\n",
      "\ttrain_acc: 0.8086, test_acc: \u001b[31m0.803\u001b[0m, time: 36.27\n",
      "best_acc: 0.803\n",
      "epoch: 124, loss: 111.68379, loss1: 0.82312, loss2_3: 110.86067\n",
      "\ttrain_acc: 0.8095, test_acc: \u001b[31m0.805\u001b[0m, time: 36.23\n",
      "best_acc: 0.805\n",
      "epoch: 125, loss: 111.50541, loss1: 0.82290, loss2_3: 110.68251\n",
      "\ttrain_acc: 0.8076, test_acc: \u001b[31m0.80225\u001b[0m, time: 36.26\n",
      "epoch: 126, loss: 111.47588, loss1: 0.82014, loss2_3: 110.65575\n",
      "\ttrain_acc: 0.8104, test_acc: \u001b[31m0.8037\u001b[0m, time: 36.22\n",
      "epoch: 127, loss: 111.42712, loss1: 0.81316, loss2_3: 110.61397\n",
      "\ttrain_acc: 0.8124, test_acc: \u001b[31m0.80405\u001b[0m, time: 36.28\n",
      "epoch: 128, loss: 111.22149, loss1: 0.82028, loss2_3: 110.40121\n",
      "\ttrain_acc: 0.8090, test_acc: \u001b[31m0.8031\u001b[0m, time: 36.22\n",
      "epoch: 129, loss: 111.20502, loss1: 0.81801, loss2_3: 110.38702\n",
      "\ttrain_acc: 0.8095, test_acc: \u001b[31m0.8026\u001b[0m, time: 36.25\n",
      "epoch: 130, loss: 111.06469, loss1: 0.82252, loss2_3: 110.24216\n",
      "\ttrain_acc: 0.8102, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.24\n",
      "epoch: 131, loss: 111.40839, loss1: 0.82303, loss2_3: 110.58536\n",
      "\ttrain_acc: 0.8110, test_acc: \u001b[31m0.8026\u001b[0m, time: 36.24\n",
      "epoch: 132, loss: 111.17582, loss1: 0.81301, loss2_3: 110.36281\n",
      "\ttrain_acc: 0.8104, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.21\n",
      "epoch: 133, loss: 111.09169, loss1: 0.82170, loss2_3: 110.26999\n",
      "\ttrain_acc: 0.8104, test_acc: \u001b[31m0.8034\u001b[0m, time: 36.26\n",
      "epoch: 134, loss: 110.96869, loss1: 0.81713, loss2_3: 110.15155\n",
      "\ttrain_acc: 0.8116, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.20\n",
      "epoch: 135, loss: 110.80404, loss1: 0.81748, loss2_3: 109.98656\n",
      "\ttrain_acc: 0.8123, test_acc: \u001b[31m0.80465\u001b[0m, time: 36.24\n",
      "epoch: 136, loss: 110.65302, loss1: 0.81900, loss2_3: 109.83402\n",
      "\ttrain_acc: 0.8122, test_acc: \u001b[31m0.803\u001b[0m, time: 36.23\n",
      "epoch: 137, loss: 110.66856, loss1: 0.81840, loss2_3: 109.85016\n",
      "\ttrain_acc: 0.8113, test_acc: \u001b[31m0.8058\u001b[0m, time: 36.27\n",
      "best_acc: 0.8058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 138, loss: 110.60511, loss1: 0.81644, loss2_3: 109.78867\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.22\n",
      "epoch: 139, loss: 110.21766, loss1: 0.81473, loss2_3: 109.40293\n",
      "\ttrain_acc: 0.8124, test_acc: \u001b[31m0.80085\u001b[0m, time: 36.26\n",
      "epoch: 140, loss: 110.27005, loss1: 0.81347, loss2_3: 109.45658\n",
      "\ttrain_acc: 0.8126, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.21\n",
      "epoch: 141, loss: 110.29959, loss1: 0.81389, loss2_3: 109.48570\n",
      "\ttrain_acc: 0.8129, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.26\n",
      "epoch: 142, loss: 110.35131, loss1: 0.81686, loss2_3: 109.53445\n",
      "\ttrain_acc: 0.8105, test_acc: \u001b[31m0.802\u001b[0m, time: 36.18\n",
      "epoch: 143, loss: 110.38405, loss1: 0.81694, loss2_3: 109.56711\n",
      "\ttrain_acc: 0.8135, test_acc: \u001b[31m0.8047\u001b[0m, time: 36.27\n",
      "epoch: 144, loss: 110.51005, loss1: 0.81331, loss2_3: 109.69675\n",
      "\ttrain_acc: 0.8129, test_acc: \u001b[31m0.8025\u001b[0m, time: 37.23\n",
      "epoch: 145, loss: 109.92682, loss1: 0.81457, loss2_3: 109.11225\n",
      "\ttrain_acc: 0.8150, test_acc: \u001b[31m0.80325\u001b[0m, time: 37.29\n",
      "epoch: 146, loss: 109.94417, loss1: 0.81313, loss2_3: 109.13104\n",
      "\ttrain_acc: 0.8127, test_acc: \u001b[31m0.80315\u001b[0m, time: 37.34\n",
      "epoch: 147, loss: 109.84396, loss1: 0.81659, loss2_3: 109.02737\n",
      "\ttrain_acc: 0.8138, test_acc: \u001b[31m0.8033\u001b[0m, time: 37.32\n",
      "epoch: 148, loss: 109.92351, loss1: 0.81654, loss2_3: 109.10697\n",
      "\ttrain_acc: 0.8136, test_acc: \u001b[31m0.804\u001b[0m, time: 37.33\n",
      "epoch: 149, loss: 109.69642, loss1: 0.81337, loss2_3: 108.88305\n",
      "\ttrain_acc: 0.8139, test_acc: \u001b[31m0.8031\u001b[0m, time: 37.33\n",
      "epoch: 150, loss: 109.65800, loss1: 0.81065, loss2_3: 108.84736\n",
      "\ttrain_acc: 0.8130, test_acc: \u001b[31m0.80275\u001b[0m, time: 37.31\n",
      "epoch: 151, loss: 109.30072, loss1: 0.81565, loss2_3: 108.48507\n",
      "\ttrain_acc: 0.8156, test_acc: \u001b[31m0.80355\u001b[0m, time: 37.29\n",
      "epoch: 152, loss: 109.31117, loss1: 0.81316, loss2_3: 108.49801\n",
      "\ttrain_acc: 0.8138, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.66\n",
      "epoch: 153, loss: 109.18159, loss1: 0.80711, loss2_3: 108.37448\n",
      "\ttrain_acc: 0.8121, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.25\n",
      "epoch: 154, loss: 109.11144, loss1: 0.81132, loss2_3: 108.30013\n",
      "\ttrain_acc: 0.8151, test_acc: \u001b[31m0.80275\u001b[0m, time: 36.29\n",
      "epoch: 155, loss: 109.08334, loss1: 0.81069, loss2_3: 108.27264\n",
      "\ttrain_acc: 0.8145, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.25\n",
      "epoch: 156, loss: 109.07659, loss1: 0.80943, loss2_3: 108.26716\n",
      "\ttrain_acc: 0.8145, test_acc: \u001b[31m0.79795\u001b[0m, time: 36.30\n",
      "epoch: 157, loss: 109.03526, loss1: 0.81426, loss2_3: 108.22100\n",
      "\ttrain_acc: 0.8163, test_acc: \u001b[31m0.802\u001b[0m, time: 36.27\n",
      "epoch: 158, loss: 109.04257, loss1: 0.80741, loss2_3: 108.23516\n",
      "\ttrain_acc: 0.8167, test_acc: \u001b[31m0.80345\u001b[0m, time: 36.27\n",
      "epoch: 159, loss: 108.94976, loss1: 0.80835, loss2_3: 108.14142\n",
      "\ttrain_acc: 0.8156, test_acc: \u001b[31m0.80135\u001b[0m, time: 36.29\n",
      "epoch: 160, loss: 108.82122, loss1: 0.81111, loss2_3: 108.01011\n",
      "\ttrain_acc: 0.8174, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.24\n",
      "epoch: 161, loss: 108.69801, loss1: 0.80848, loss2_3: 107.88953\n",
      "\ttrain_acc: 0.8180, test_acc: \u001b[31m0.8033\u001b[0m, time: 36.28\n",
      "epoch: 162, loss: 108.43719, loss1: 0.80905, loss2_3: 107.62814\n",
      "\ttrain_acc: 0.8152, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.27\n",
      "epoch: 163, loss: 108.12966, loss1: 0.81152, loss2_3: 107.31815\n",
      "\ttrain_acc: 0.8188, test_acc: \u001b[31m0.80135\u001b[0m, time: 36.25\n",
      "epoch: 164, loss: 108.43403, loss1: 0.80630, loss2_3: 107.62773\n",
      "\ttrain_acc: 0.8163, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.23\n",
      "epoch: 165, loss: 108.13734, loss1: 0.81082, loss2_3: 107.32651\n",
      "\ttrain_acc: 0.8165, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.30\n",
      "epoch: 166, loss: 107.91055, loss1: 0.80724, loss2_3: 107.10331\n",
      "\ttrain_acc: 0.8176, test_acc: \u001b[31m0.803\u001b[0m, time: 36.22\n",
      "epoch: 167, loss: 107.70788, loss1: 0.81058, loss2_3: 106.89729\n",
      "\ttrain_acc: 0.8184, test_acc: \u001b[31m0.8026\u001b[0m, time: 36.27\n",
      "epoch: 168, loss: 107.76067, loss1: 0.80872, loss2_3: 106.95195\n",
      "\ttrain_acc: 0.8182, test_acc: \u001b[31m0.79965\u001b[0m, time: 36.26\n",
      "epoch: 169, loss: 107.84205, loss1: 0.80847, loss2_3: 107.03358\n",
      "\ttrain_acc: 0.8174, test_acc: \u001b[31m0.8026\u001b[0m, time: 36.28\n",
      "epoch: 170, loss: 107.78565, loss1: 0.80668, loss2_3: 106.97897\n",
      "\ttrain_acc: 0.8198, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.26\n",
      "epoch: 171, loss: 107.91281, loss1: 0.80216, loss2_3: 107.11065\n",
      "\ttrain_acc: 0.8164, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.28\n",
      "epoch: 172, loss: 107.82688, loss1: 0.80944, loss2_3: 107.01744\n",
      "\ttrain_acc: 0.8184, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.23\n",
      "epoch: 173, loss: 107.52708, loss1: 0.80940, loss2_3: 106.71768\n",
      "\ttrain_acc: 0.8188, test_acc: \u001b[31m0.801\u001b[0m, time: 36.30\n",
      "epoch: 174, loss: 107.73141, loss1: 0.80770, loss2_3: 106.92371\n",
      "\ttrain_acc: 0.8164, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.23\n",
      "epoch: 175, loss: 107.31371, loss1: 0.80831, loss2_3: 106.50541\n",
      "\ttrain_acc: 0.8212, test_acc: \u001b[31m0.8023\u001b[0m, time: 36.29\n",
      "epoch: 176, loss: 107.15381, loss1: 0.80507, loss2_3: 106.34873\n",
      "\ttrain_acc: 0.8191, test_acc: \u001b[31m0.8042\u001b[0m, time: 36.23\n",
      "epoch: 177, loss: 107.39209, loss1: 0.80666, loss2_3: 106.58543\n",
      "\ttrain_acc: 0.8145, test_acc: \u001b[31m0.7982\u001b[0m, time: 36.24\n",
      "epoch: 178, loss: 107.16982, loss1: 0.80698, loss2_3: 106.36284\n",
      "\ttrain_acc: 0.8207, test_acc: \u001b[31m0.80275\u001b[0m, time: 36.26\n",
      "epoch: 179, loss: 106.99306, loss1: 0.80279, loss2_3: 106.19028\n",
      "\ttrain_acc: 0.8217, test_acc: \u001b[31m0.80325\u001b[0m, time: 36.23\n",
      "epoch: 180, loss: 106.66021, loss1: 0.80099, loss2_3: 105.85922\n",
      "\ttrain_acc: 0.8228, test_acc: \u001b[31m0.8026\u001b[0m, time: 36.24\n",
      "epoch: 181, loss: 106.95514, loss1: 0.80620, loss2_3: 106.14894\n",
      "\ttrain_acc: 0.8228, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.27\n",
      "epoch: 182, loss: 106.23565, loss1: 0.80420, loss2_3: 105.43145\n",
      "\ttrain_acc: 0.8188, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.26\n",
      "epoch: 183, loss: 106.61469, loss1: 0.80804, loss2_3: 105.80666\n",
      "\ttrain_acc: 0.8208, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.27\n",
      "epoch: 184, loss: 106.69959, loss1: 0.80026, loss2_3: 105.89933\n",
      "\ttrain_acc: 0.8234, test_acc: \u001b[31m0.8038\u001b[0m, time: 36.30\n",
      "epoch: 185, loss: 106.71220, loss1: 0.80011, loss2_3: 105.91209\n",
      "\ttrain_acc: 0.8175, test_acc: \u001b[31m0.7972\u001b[0m, time: 36.26\n",
      "epoch: 186, loss: 106.43628, loss1: 0.80227, loss2_3: 105.63401\n",
      "\ttrain_acc: 0.8220, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.27\n",
      "epoch: 187, loss: 106.27791, loss1: 0.80590, loss2_3: 105.47201\n",
      "\ttrain_acc: 0.8219, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.25\n",
      "epoch: 188, loss: 106.04433, loss1: 0.80349, loss2_3: 105.24084\n",
      "\ttrain_acc: 0.8223, test_acc: \u001b[31m0.80355\u001b[0m, time: 36.21\n",
      "epoch: 189, loss: 106.29601, loss1: 0.80263, loss2_3: 105.49338\n",
      "\ttrain_acc: 0.8156, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.29\n",
      "epoch: 190, loss: 106.08545, loss1: 0.79911, loss2_3: 105.28634\n",
      "\ttrain_acc: 0.8231, test_acc: \u001b[31m0.80165\u001b[0m, time: 36.21\n",
      "epoch: 191, loss: 105.77311, loss1: 0.80286, loss2_3: 104.97025\n",
      "\ttrain_acc: 0.8241, test_acc: \u001b[31m0.80255\u001b[0m, time: 36.28\n",
      "epoch: 192, loss: 106.11762, loss1: 0.80529, loss2_3: 105.31233\n",
      "\ttrain_acc: 0.8258, test_acc: \u001b[31m0.8016\u001b[0m, time: 36.21\n",
      "epoch: 193, loss: 105.70702, loss1: 0.80229, loss2_3: 104.90473\n",
      "\ttrain_acc: 0.8262, test_acc: \u001b[31m0.80145\u001b[0m, time: 36.25\n",
      "epoch: 194, loss: 105.83404, loss1: 0.79813, loss2_3: 105.03592\n",
      "\ttrain_acc: 0.8226, test_acc: \u001b[31m0.8017\u001b[0m, time: 36.23\n",
      "epoch: 195, loss: 105.66138, loss1: 0.79979, loss2_3: 104.86159\n",
      "\ttrain_acc: 0.8187, test_acc: \u001b[31m0.8019\u001b[0m, time: 36.27\n",
      "epoch: 196, loss: 105.63425, loss1: 0.80014, loss2_3: 104.83411\n",
      "\ttrain_acc: 0.8243, test_acc: \u001b[31m0.8027\u001b[0m, time: 36.22\n",
      "epoch: 197, loss: 105.48873, loss1: 0.79527, loss2_3: 104.69345\n",
      "\ttrain_acc: 0.8215, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.30\n",
      "epoch: 198, loss: 105.89261, loss1: 0.80131, loss2_3: 105.09130\n",
      "\ttrain_acc: 0.8235, test_acc: \u001b[31m0.8004\u001b[0m, time: 36.23\n",
      "epoch: 199, loss: 105.45329, loss1: 0.79920, loss2_3: 104.65409\n",
      "\ttrain_acc: 0.8264, test_acc: \u001b[31m0.80385\u001b[0m, time: 36.27\n",
      "epoch: 200, loss: 105.22417, loss1: 0.79529, loss2_3: 104.42888\n",
      "\ttrain_acc: 0.8221, test_acc: \u001b[31m0.80285\u001b[0m, time: 36.25\n",
      "epoch: 201, loss: 105.32820, loss1: 0.80227, loss2_3: 104.52593\n",
      "\ttrain_acc: 0.8257, test_acc: \u001b[31m0.8032\u001b[0m, time: 36.24\n",
      "epoch: 202, loss: 105.28514, loss1: 0.80154, loss2_3: 104.48360\n",
      "\ttrain_acc: 0.8240, test_acc: \u001b[31m0.80165\u001b[0m, time: 36.24\n",
      "epoch: 203, loss: 105.22019, loss1: 0.79650, loss2_3: 104.42369\n",
      "\ttrain_acc: 0.8279, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.23\n",
      "epoch: 204, loss: 104.70708, loss1: 0.79587, loss2_3: 103.91122\n",
      "\ttrain_acc: 0.8213, test_acc: \u001b[31m0.801\u001b[0m, time: 36.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 205, loss: 104.62420, loss1: 0.79986, loss2_3: 103.82434\n",
      "\ttrain_acc: 0.8148, test_acc: \u001b[31m0.79575\u001b[0m, time: 36.25\n",
      "epoch: 206, loss: 104.62783, loss1: 0.79599, loss2_3: 103.83184\n",
      "\ttrain_acc: 0.8263, test_acc: \u001b[31m0.80315\u001b[0m, time: 36.23\n",
      "epoch: 207, loss: 104.56583, loss1: 0.79876, loss2_3: 103.76707\n",
      "\ttrain_acc: 0.8274, test_acc: \u001b[31m0.8053\u001b[0m, time: 36.25\n",
      "epoch: 208, loss: 104.21758, loss1: 0.79526, loss2_3: 103.42232\n",
      "\ttrain_acc: 0.8289, test_acc: \u001b[31m0.80475\u001b[0m, time: 36.23\n",
      "epoch: 209, loss: 104.26859, loss1: 0.79736, loss2_3: 103.47123\n",
      "\ttrain_acc: 0.8266, test_acc: \u001b[31m0.8038\u001b[0m, time: 36.25\n",
      "epoch: 210, loss: 104.08888, loss1: 0.79768, loss2_3: 103.29120\n",
      "\ttrain_acc: 0.8267, test_acc: \u001b[31m0.80135\u001b[0m, time: 36.27\n",
      "epoch: 211, loss: 104.20048, loss1: 0.79788, loss2_3: 103.40260\n",
      "\ttrain_acc: 0.8284, test_acc: \u001b[31m0.80165\u001b[0m, time: 36.25\n",
      "epoch: 212, loss: 104.17699, loss1: 0.79936, loss2_3: 103.37762\n",
      "\ttrain_acc: 0.8268, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.26\n",
      "epoch: 213, loss: 104.30755, loss1: 0.79418, loss2_3: 103.51338\n",
      "\ttrain_acc: 0.8288, test_acc: \u001b[31m0.8012\u001b[0m, time: 36.28\n",
      "epoch: 214, loss: 103.80736, loss1: 0.79444, loss2_3: 103.01292\n",
      "\ttrain_acc: 0.8298, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.24\n",
      "epoch: 215, loss: 104.10959, loss1: 0.79624, loss2_3: 103.31334\n",
      "\ttrain_acc: 0.8268, test_acc: \u001b[31m0.8016\u001b[0m, time: 36.26\n",
      "epoch: 216, loss: 103.49859, loss1: 0.79724, loss2_3: 102.70135\n",
      "\ttrain_acc: 0.8225, test_acc: \u001b[31m0.79895\u001b[0m, time: 36.27\n",
      "epoch: 217, loss: 103.47434, loss1: 0.79386, loss2_3: 102.68048\n",
      "\ttrain_acc: 0.8279, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.24\n",
      "epoch: 218, loss: 103.91071, loss1: 0.79209, loss2_3: 103.11862\n",
      "\ttrain_acc: 0.8302, test_acc: \u001b[31m0.80135\u001b[0m, time: 36.27\n",
      "epoch: 219, loss: 103.29422, loss1: 0.79543, loss2_3: 102.49879\n",
      "\ttrain_acc: 0.8285, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.25\n",
      "epoch: 220, loss: 103.65782, loss1: 0.78871, loss2_3: 102.86912\n",
      "\ttrain_acc: 0.8304, test_acc: \u001b[31m0.8024\u001b[0m, time: 36.28\n",
      "epoch: 221, loss: 103.42011, loss1: 0.79007, loss2_3: 102.63004\n",
      "\ttrain_acc: 0.8211, test_acc: \u001b[31m0.7878\u001b[0m, time: 36.26\n",
      "epoch: 222, loss: 103.21687, loss1: 0.79330, loss2_3: 102.42358\n",
      "\ttrain_acc: 0.8288, test_acc: \u001b[31m0.80135\u001b[0m, time: 36.25\n",
      "epoch: 223, loss: 102.84097, loss1: 0.79331, loss2_3: 102.04767\n",
      "\ttrain_acc: 0.8307, test_acc: \u001b[31m0.79995\u001b[0m, time: 36.28\n",
      "epoch: 224, loss: 102.83560, loss1: 0.78981, loss2_3: 102.04580\n",
      "\ttrain_acc: 0.8299, test_acc: \u001b[31m0.79805\u001b[0m, time: 36.25\n",
      "epoch: 225, loss: 103.22258, loss1: 0.79273, loss2_3: 102.42984\n",
      "\ttrain_acc: 0.8315, test_acc: \u001b[31m0.80335\u001b[0m, time: 36.25\n",
      "epoch: 226, loss: 102.88440, loss1: 0.78880, loss2_3: 102.09560\n",
      "\ttrain_acc: 0.8213, test_acc: \u001b[31m0.79775\u001b[0m, time: 36.27\n",
      "epoch: 227, loss: 102.36854, loss1: 0.79081, loss2_3: 101.57773\n",
      "\ttrain_acc: 0.8279, test_acc: \u001b[31m0.80085\u001b[0m, time: 36.24\n",
      "epoch: 228, loss: 102.16117, loss1: 0.79388, loss2_3: 101.36729\n",
      "\ttrain_acc: 0.8318, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.24\n",
      "epoch: 229, loss: 102.42334, loss1: 0.79116, loss2_3: 101.63218\n",
      "\ttrain_acc: 0.8313, test_acc: \u001b[31m0.7928\u001b[0m, time: 36.27\n",
      "epoch: 230, loss: 102.18816, loss1: 0.79188, loss2_3: 101.39628\n",
      "\ttrain_acc: 0.8346, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.24\n",
      "epoch: 231, loss: 101.81773, loss1: 0.79068, loss2_3: 101.02705\n",
      "\ttrain_acc: 0.8335, test_acc: \u001b[31m0.80215\u001b[0m, time: 36.26\n",
      "epoch: 232, loss: 101.93920, loss1: 0.78670, loss2_3: 101.15250\n",
      "\ttrain_acc: 0.8296, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.28\n",
      "epoch: 233, loss: 102.04312, loss1: 0.78243, loss2_3: 101.26070\n",
      "\ttrain_acc: 0.8311, test_acc: \u001b[31m0.8018\u001b[0m, time: 36.26\n",
      "epoch: 234, loss: 101.66431, loss1: 0.78597, loss2_3: 100.87834\n",
      "\ttrain_acc: 0.8359, test_acc: \u001b[31m0.8018\u001b[0m, time: 36.26\n",
      "epoch: 235, loss: 101.67699, loss1: 0.79046, loss2_3: 100.88654\n",
      "\ttrain_acc: 0.8337, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.27\n",
      "epoch: 236, loss: 101.26405, loss1: 0.78975, loss2_3: 100.47430\n",
      "\ttrain_acc: 0.8323, test_acc: \u001b[31m0.79735\u001b[0m, time: 36.25\n",
      "epoch: 237, loss: 101.13886, loss1: 0.78148, loss2_3: 100.35738\n",
      "\ttrain_acc: 0.8344, test_acc: \u001b[31m0.7973\u001b[0m, time: 36.26\n",
      "epoch: 238, loss: 100.95040, loss1: 0.78728, loss2_3: 100.16312\n",
      "\ttrain_acc: 0.8297, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.21\n",
      "epoch: 239, loss: 101.34411, loss1: 0.78800, loss2_3: 100.55611\n",
      "\ttrain_acc: 0.8304, test_acc: \u001b[31m0.7887\u001b[0m, time: 36.28\n",
      "epoch: 240, loss: 100.69688, loss1: 0.78097, loss2_3: 99.91592\n",
      "\ttrain_acc: 0.8352, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.22\n",
      "epoch: 241, loss: 100.89381, loss1: 0.78772, loss2_3: 100.10609\n",
      "\ttrain_acc: 0.8313, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.24\n",
      "epoch: 242, loss: 101.03953, loss1: 0.78408, loss2_3: 100.25545\n",
      "\ttrain_acc: 0.8369, test_acc: \u001b[31m0.7993\u001b[0m, time: 36.25\n",
      "epoch: 243, loss: 100.73891, loss1: 0.78792, loss2_3: 99.95100\n",
      "\ttrain_acc: 0.8297, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.25\n",
      "epoch: 244, loss: 100.60210, loss1: 0.78415, loss2_3: 99.81796\n",
      "\ttrain_acc: 0.8372, test_acc: \u001b[31m0.79495\u001b[0m, time: 36.26\n",
      "epoch: 245, loss: 100.39026, loss1: 0.78564, loss2_3: 99.60462\n",
      "\ttrain_acc: 0.8296, test_acc: \u001b[31m0.781\u001b[0m, time: 36.26\n",
      "epoch: 246, loss: 100.56988, loss1: 0.78417, loss2_3: 99.78571\n",
      "\ttrain_acc: 0.8325, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.23\n",
      "epoch: 247, loss: 100.10087, loss1: 0.78126, loss2_3: 99.31962\n",
      "\ttrain_acc: 0.8369, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.22\n",
      "epoch: 248, loss: 100.46171, loss1: 0.78717, loss2_3: 99.67454\n",
      "\ttrain_acc: 0.8394, test_acc: \u001b[31m0.798\u001b[0m, time: 36.24\n",
      "epoch: 249, loss: 99.84054, loss1: 0.77876, loss2_3: 99.06178\n",
      "\ttrain_acc: 0.8167, test_acc: \u001b[31m0.7679\u001b[0m, time: 36.22\n",
      "epoch: 250, loss: 99.57700, loss1: 0.78339, loss2_3: 98.79361\n",
      "\ttrain_acc: 0.8358, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.24\n"
     ]
    }
   ],
   "source": [
    "for num_model in range(10):\n",
    "    net=newModel().to(device)\n",
    "    lr = 0.0001\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr,weight_decay=5e-4)\n",
    "    criterion = ContrastiveLoss()\n",
    "    criterion_model = nn.CrossEntropyLoss(reduction='sum')\n",
    "    \n",
    "    best_acc=0\n",
    "    EPOCH=250\n",
    "    for epoch in range(EPOCH):\n",
    "        loss_ls=[]\n",
    "        loss1_ls=[]\n",
    "        loss2_3_ls=[]\n",
    "        t0=time.time()\n",
    "        net.train()\n",
    "        for seq1,seq2,label,label1,label2 in train_iter_cont:\n",
    "                output1=net(seq1)\n",
    "                output2=net(seq2)\n",
    "                output3=net.trainModel(seq1)\n",
    "                output4=net.trainModel(seq2)\n",
    "                \n",
    "                loss1=criterion(output1, output2, label)\n",
    "                loss2=criterion_model(output3,label1)\n",
    "                loss3=criterion_model(output4,label2)\n",
    "                loss=loss1+loss2+loss3\n",
    "    #             print(loss)\n",
    "                optimizer.zero_grad() \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_ls.append(loss.item())\n",
    "                loss1_ls.append(loss1.item())\n",
    "                loss2_3_ls.append((loss2+loss3).item())\n",
    "\n",
    "\n",
    "        net.eval() \n",
    "        with torch.no_grad(): \n",
    "            train_acc=evaluate_accuracy(train_iter,net)\n",
    "            test_acc=evaluate_accuracy(test_iter,net)\n",
    "            \n",
    "        results=f\"epoch: {epoch+1}, loss: {np.mean(loss_ls):.5f}, loss1: {np.mean(loss1_ls):.5f}, loss2_3: {np.mean(loss2_3_ls):.5f}\\n\"\n",
    "        results+=f'\\ttrain_acc: {train_acc:.4f}, test_acc: {colored(test_acc,\"red\")}, time: {time.time()-t0:.2f}'\n",
    "        print(results)\n",
    "#         to_log(results)\n",
    "        if test_acc>best_acc:\n",
    "            best_acc=test_acc\n",
    "#             torch.save({\"best_acc\":best_acc,\"model\":net.state_dict()},f'compareModel/2021ACS_PepFormer/Model/{num_model}.pl')\n",
    "            print(f\"best_acc: {best_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Data X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T21:29:27.310382Z",
     "start_time": "2021-08-30T21:29:26.383533Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T21:29:32.561604Z",
     "start_time": "2021-08-30T21:29:30.743803Z"
    }
   },
   "outputs": [],
   "source": [
    "df_detect_peptide_train = pd.read_csv('data/df_detect_peptide_train.csv')\n",
    "df_detect_peptide_test = pd.read_csv('data/df_detect_peptide_test.csv')\n",
    "\n",
    "tra, val = train_test_split(df_detect_peptide_train[['PEP', 'ID']], test_size=0.2, random_state=7)\n",
    "tra.to_csv('compareModel/2021ACS_PepFormer/detect_peptide_train.csv', header=False, index=False)\n",
    "val.to_csv('compareModel/2021ACS_PepFormer/detect_peptide_val.csv', header=False, index=False)\n",
    "df_detect_peptide_test[['PEP', 'ID']].to_csv('compareModel/2021ACS_PepFormer/detect_peptide_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T21:30:56.460546Z",
     "start_time": "2021-08-30T21:30:49.144762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length > 30: 0\n",
      "torch.Size([215352, 30]) torch.Size([215352])\n",
      "length > 30: 0\n",
      "torch.Size([53838, 30]) torch.Size([53838])\n",
      "length > 30: 0\n",
      "torch.Size([67298, 30]) torch.Size([67298])\n"
     ]
    }
   ],
   "source": [
    "train_data,train_label=genData(\"compareModel/2021ACS_PepFormer/detect_peptide_train.csv\",30)\n",
    "print(train_data.shape, train_label.shape)\n",
    "train_dataset = Data.TensorDataset(train_data, train_label)\n",
    "\n",
    "val_data,val_label=genData(\"compareModel/2021ACS_PepFormer/detect_peptide_val.csv\",30)\n",
    "print(val_data.shape, val_label.shape)\n",
    "val_dataset = Data.TensorDataset(val_data, val_label)\n",
    "\n",
    "test_data,test_label=genData(\"compareModel/2021ACS_PepFormer/detect_peptide_test.csv\",30)\n",
    "print(test_data.shape, test_label.shape)\n",
    "test_dataset = Data.TensorDataset(test_data, test_label)\n",
    "\n",
    "batch_size=256\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_iter_cont = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                                                  shuffle=True, collate_fn=collate)\n",
    "val_iter = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T21:38:23.235474Z",
     "start_time": "2021-08-30T21:38:23.217948Z"
    }
   },
   "outputs": [],
   "source": [
    "class newModel(nn.Module):\n",
    "    def __init__(self, vocab_size=24):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 25\n",
    "        self.batch_size = 256\n",
    "        self.emb_dim = 512\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, self.emb_dim, padding_idx=0)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.gru = nn.GRU(self.emb_dim, self.hidden_dim, num_layers=2, \n",
    "                               bidirectional=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.block1=nn.Sequential(nn.Linear(1600,1024),\n",
    "                                            nn.BatchNorm1d(1024),\n",
    "                                            nn.LeakyReLU(),\n",
    "                                            nn.Linear(1024,256),\n",
    "                                 )\n",
    "\n",
    "        self.block2=nn.Sequential(\n",
    "                                               nn.BatchNorm1d(256),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(256,128),\n",
    "                                               nn.BatchNorm1d(128),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(128,64),\n",
    "                                               nn.BatchNorm1d(64),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(64,2)\n",
    "                                            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.embedding(x)\n",
    "        output=self.transformer_encoder(x).permute(1, 0, 2)\n",
    "        output,hn=self.gru(output)\n",
    "        output=output.permute(1,0,2)\n",
    "        hn=hn.permute(1,0,2)\n",
    "        output=output.reshape(output.shape[0],-1)\n",
    "        hn=hn.reshape(output.shape[0],-1)\n",
    "        output=torch.cat([output,hn],1)\n",
    "        return self.block1(output)\n",
    "\n",
    "    def trainModel(self, x):\n",
    "        with torch.no_grad():\n",
    "            output=self.forward(x)\n",
    "        return self.block2(output)\n",
    "\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # euclidean_distance: [128]\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +     # calmp夹断用法\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))     \n",
    "        \n",
    "        return loss_contrastive\n",
    "    \n",
    "    \n",
    "def collate(batch):\n",
    "    seq1_ls=[]\n",
    "    seq2_ls=[]\n",
    "    label1_ls=[]\n",
    "    label2_ls=[]\n",
    "    label_ls=[]\n",
    "    batch_size=len(batch)\n",
    "    for i in range(int(batch_size/2)):\n",
    "        seq1,label1=batch[i][0],batch[i][1]\n",
    "        seq2,label2=batch[i+int(batch_size/2)][0],batch[i+int(batch_size/2)][1]\n",
    "        label1_ls.append(label1.unsqueeze(0))\n",
    "        label2_ls.append(label2.unsqueeze(0))\n",
    "        label=(label1^label2)\n",
    "        seq1_ls.append(seq1.unsqueeze(0))\n",
    "        seq2_ls.append(seq2.unsqueeze(0))\n",
    "        label_ls.append(label.unsqueeze(0))\n",
    "    seq1=torch.cat(seq1_ls).to(device)\n",
    "    seq2=torch.cat(seq2_ls).to(device)\n",
    "    label=torch.cat(label_ls).to(device)\n",
    "    label1=torch.cat(label1_ls).to(device)\n",
    "    label2=torch.cat(label2_ls).to(device)\n",
    "    return seq1,seq2,label,label1,label2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T01:27:34.173866Z",
     "start_time": "2021-08-30T21:38:23.696487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 157.79544, loss1: 1.45590, loss2_3: 156.33954\n",
      "\ttrain_acc: 0.7599, test_acc: \u001b[31m0.7590549426055946\u001b[0m, time: 64.05\n",
      "best_acc: 0.7590549426055946\n",
      "epoch: 2, loss: 124.56889, loss1: 0.92612, loss2_3: 123.64277\n",
      "\ttrain_acc: 0.7897, test_acc: \u001b[31m0.7894795497603923\u001b[0m, time: 63.93\n",
      "best_acc: 0.7894795497603923\n",
      "epoch: 3, loss: 118.81992, loss1: 0.90422, loss2_3: 117.91570\n",
      "\ttrain_acc: 0.7891, test_acc: \u001b[31m0.7878450165310747\u001b[0m, time: 65.07\n",
      "epoch: 4, loss: 115.51865, loss1: 0.88433, loss2_3: 114.63432\n",
      "\ttrain_acc: 0.7891, test_acc: \u001b[31m0.7902225194100821\u001b[0m, time: 64.20\n",
      "best_acc: 0.7902225194100821\n",
      "epoch: 5, loss: 114.16350, loss1: 0.87263, loss2_3: 113.29087\n",
      "\ttrain_acc: 0.7854, test_acc: \u001b[31m0.7858018499944277\u001b[0m, time: 63.56\n",
      "epoch: 6, loss: 111.80736, loss1: 0.86087, loss2_3: 110.94649\n",
      "\ttrain_acc: 0.8099, test_acc: \u001b[31m0.8092611166833835\u001b[0m, time: 64.21\n",
      "best_acc: 0.8092611166833835\n",
      "epoch: 7, loss: 109.85247, loss1: 0.84179, loss2_3: 109.01068\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.8107099075002786\u001b[0m, time: 63.84\n",
      "best_acc: 0.8107099075002786\n",
      "epoch: 8, loss: 109.44311, loss1: 0.83591, loss2_3: 108.60720\n",
      "\ttrain_acc: 0.8121, test_acc: \u001b[31m0.8101155317805268\u001b[0m, time: 63.35\n",
      "epoch: 9, loss: 108.64083, loss1: 0.83127, loss2_3: 107.80956\n",
      "\ttrain_acc: 0.8157, test_acc: \u001b[31m0.8125859058657454\u001b[0m, time: 63.35\n",
      "best_acc: 0.8125859058657454\n",
      "epoch: 10, loss: 107.68807, loss1: 0.82630, loss2_3: 106.86178\n",
      "\ttrain_acc: 0.8129, test_acc: \u001b[31m0.8102269772279802\u001b[0m, time: 64.41\n",
      "epoch: 11, loss: 106.59012, loss1: 0.81937, loss2_3: 105.77074\n",
      "\ttrain_acc: 0.8102, test_acc: \u001b[31m0.8079423455551841\u001b[0m, time: 63.33\n",
      "epoch: 12, loss: 106.29528, loss1: 0.81450, loss2_3: 105.48077\n",
      "\ttrain_acc: 0.8202, test_acc: \u001b[31m0.8178795646197853\u001b[0m, time: 63.95\n",
      "best_acc: 0.8178795646197853\n",
      "epoch: 13, loss: 105.69258, loss1: 0.81075, loss2_3: 104.88183\n",
      "\ttrain_acc: 0.8216, test_acc: \u001b[31m0.8202199190163082\u001b[0m, time: 63.72\n",
      "best_acc: 0.8202199190163082\n",
      "epoch: 14, loss: 105.56074, loss1: 0.80635, loss2_3: 104.75439\n",
      "\ttrain_acc: 0.8208, test_acc: \u001b[31m0.8203313644637616\u001b[0m, time: 63.49\n",
      "best_acc: 0.8203313644637616\n",
      "epoch: 15, loss: 104.82173, loss1: 0.80000, loss2_3: 104.02173\n",
      "\ttrain_acc: 0.8188, test_acc: \u001b[31m0.816876555592704\u001b[0m, time: 63.69\n",
      "epoch: 16, loss: 104.74118, loss1: 0.79869, loss2_3: 103.94249\n",
      "\ttrain_acc: 0.8210, test_acc: \u001b[31m0.8181210297559345\u001b[0m, time: 64.41\n",
      "epoch: 17, loss: 104.40565, loss1: 0.79728, loss2_3: 103.60837\n",
      "\ttrain_acc: 0.8226, test_acc: \u001b[31m0.8205542553586685\u001b[0m, time: 64.14\n",
      "best_acc: 0.8205542553586685\n",
      "epoch: 18, loss: 104.03009, loss1: 0.79043, loss2_3: 103.23965\n",
      "\ttrain_acc: 0.8220, test_acc: \u001b[31m0.8184925145807794\u001b[0m, time: 65.44\n",
      "epoch: 19, loss: 103.98417, loss1: 0.79414, loss2_3: 103.19003\n",
      "\ttrain_acc: 0.8208, test_acc: \u001b[31m0.8181396039971767\u001b[0m, time: 64.01\n",
      "epoch: 20, loss: 103.31940, loss1: 0.78592, loss2_3: 102.53348\n",
      "\ttrain_acc: 0.8170, test_acc: \u001b[31m0.8147219436086036\u001b[0m, time: 63.62\n",
      "epoch: 21, loss: 103.35687, loss1: 0.78521, loss2_3: 102.57166\n",
      "\ttrain_acc: 0.8247, test_acc: \u001b[31m0.8223373825179241\u001b[0m, time: 64.06\n",
      "best_acc: 0.8223373825179241\n",
      "epoch: 22, loss: 102.95613, loss1: 0.78336, loss2_3: 102.17277\n",
      "\ttrain_acc: 0.8254, test_acc: \u001b[31m0.8229874809614027\u001b[0m, time: 64.33\n",
      "best_acc: 0.8229874809614027\n",
      "epoch: 23, loss: 102.85393, loss1: 0.78581, loss2_3: 102.06812\n",
      "\ttrain_acc: 0.8255, test_acc: \u001b[31m0.8230432036851295\u001b[0m, time: 63.83\n",
      "best_acc: 0.8230432036851295\n",
      "epoch: 24, loss: 102.48990, loss1: 0.78079, loss2_3: 101.70910\n",
      "\ttrain_acc: 0.8251, test_acc: \u001b[31m0.8230246294438872\u001b[0m, time: 63.94\n",
      "epoch: 25, loss: 102.27278, loss1: 0.77890, loss2_3: 101.49389\n",
      "\ttrain_acc: 0.8257, test_acc: \u001b[31m0.8235075597161856\u001b[0m, time: 63.53\n",
      "best_acc: 0.8235075597161856\n",
      "epoch: 26, loss: 102.25274, loss1: 0.77592, loss2_3: 101.47682\n",
      "\ttrain_acc: 0.8278, test_acc: \u001b[31m0.8255321520115904\u001b[0m, time: 64.22\n",
      "best_acc: 0.8255321520115904\n",
      "epoch: 27, loss: 101.82918, loss1: 0.77328, loss2_3: 101.05590\n",
      "\ttrain_acc: 0.8252, test_acc: \u001b[31m0.8220587688992904\u001b[0m, time: 64.68\n",
      "epoch: 28, loss: 101.76433, loss1: 0.77129, loss2_3: 100.99304\n",
      "\ttrain_acc: 0.8262, test_acc: \u001b[31m0.8243805490545711\u001b[0m, time: 63.84\n",
      "epoch: 29, loss: 101.33173, loss1: 0.76861, loss2_3: 100.56312\n",
      "\ttrain_acc: 0.8241, test_acc: \u001b[31m0.8215386901445076\u001b[0m, time: 63.98\n",
      "epoch: 30, loss: 101.14114, loss1: 0.77040, loss2_3: 100.37074\n",
      "\ttrain_acc: 0.8302, test_acc: \u001b[31m0.827482447342026\u001b[0m, time: 65.00\n",
      "best_acc: 0.827482447342026\n",
      "epoch: 31, loss: 100.89879, loss1: 0.76650, loss2_3: 100.13229\n",
      "\ttrain_acc: 0.8274, test_acc: \u001b[31m0.8243991232958133\u001b[0m, time: 63.89\n",
      "epoch: 32, loss: 100.83164, loss1: 0.76545, loss2_3: 100.06619\n",
      "\ttrain_acc: 0.8300, test_acc: \u001b[31m0.8276867639956907\u001b[0m, time: 63.37\n",
      "best_acc: 0.8276867639956907\n",
      "epoch: 33, loss: 100.61932, loss1: 0.76453, loss2_3: 99.85479\n",
      "\ttrain_acc: 0.8285, test_acc: \u001b[31m0.8270552397934544\u001b[0m, time: 63.67\n",
      "epoch: 34, loss: 100.45152, loss1: 0.76553, loss2_3: 99.68599\n",
      "\ttrain_acc: 0.8289, test_acc: \u001b[31m0.8270180913109699\u001b[0m, time: 64.22\n",
      "epoch: 35, loss: 100.33909, loss1: 0.76277, loss2_3: 99.57633\n",
      "\ttrain_acc: 0.8255, test_acc: \u001b[31m0.8233403915450054\u001b[0m, time: 63.94\n",
      "epoch: 36, loss: 100.12471, loss1: 0.75728, loss2_3: 99.36743\n",
      "\ttrain_acc: 0.8320, test_acc: \u001b[31m0.8287454957464988\u001b[0m, time: 63.68\n",
      "best_acc: 0.8287454957464988\n",
      "epoch: 37, loss: 99.89057, loss1: 0.75921, loss2_3: 99.13136\n",
      "\ttrain_acc: 0.8300, test_acc: \u001b[31m0.8284483078866228\u001b[0m, time: 63.25\n",
      "epoch: 38, loss: 99.92323, loss1: 0.76034, loss2_3: 99.16289\n",
      "\ttrain_acc: 0.8311, test_acc: \u001b[31m0.8262751216612801\u001b[0m, time: 63.34\n",
      "epoch: 39, loss: 99.73129, loss1: 0.75574, loss2_3: 98.97555\n",
      "\ttrain_acc: 0.8313, test_acc: \u001b[31m0.8297113562910955\u001b[0m, time: 64.21\n",
      "best_acc: 0.8297113562910955\n",
      "epoch: 40, loss: 99.57385, loss1: 0.75391, loss2_3: 98.81994\n",
      "\ttrain_acc: 0.8328, test_acc: \u001b[31m0.829674207808611\u001b[0m, time: 63.95\n",
      "epoch: 41, loss: 99.30772, loss1: 0.75407, loss2_3: 98.55365\n",
      "\ttrain_acc: 0.8313, test_acc: \u001b[31m0.82974850477358\u001b[0m, time: 63.83\n",
      "best_acc: 0.82974850477358\n",
      "epoch: 42, loss: 99.18516, loss1: 0.75338, loss2_3: 98.43178\n",
      "\ttrain_acc: 0.8320, test_acc: \u001b[31m0.8296184850848842\u001b[0m, time: 63.60\n",
      "epoch: 43, loss: 99.16088, loss1: 0.75075, loss2_3: 98.41012\n",
      "\ttrain_acc: 0.8321, test_acc: \u001b[31m0.8292841487425239\u001b[0m, time: 63.72\n",
      "epoch: 44, loss: 99.08377, loss1: 0.75126, loss2_3: 98.33251\n",
      "\ttrain_acc: 0.8323, test_acc: \u001b[31m0.8286526245402875\u001b[0m, time: 63.67\n",
      "epoch: 45, loss: 98.94970, loss1: 0.75116, loss2_3: 98.19854\n",
      "\ttrain_acc: 0.8316, test_acc: \u001b[31m0.8295256138786731\u001b[0m, time: 52.80\n",
      "epoch: 46, loss: 98.95309, loss1: 0.75186, loss2_3: 98.20124\n",
      "\ttrain_acc: 0.8335, test_acc: \u001b[31m0.8311229986255061\u001b[0m, time: 52.51\n",
      "best_acc: 0.8311229986255061\n",
      "epoch: 47, loss: 98.79001, loss1: 0.74996, loss2_3: 98.04005\n",
      "\ttrain_acc: 0.8325, test_acc: \u001b[31m0.8286154760578031\u001b[0m, time: 52.56\n",
      "epoch: 48, loss: 98.72106, loss1: 0.74574, loss2_3: 97.97532\n",
      "\ttrain_acc: 0.8344, test_acc: \u001b[31m0.8302685835283629\u001b[0m, time: 53.32\n",
      "epoch: 49, loss: 98.63181, loss1: 0.74941, loss2_3: 97.88241\n",
      "\ttrain_acc: 0.8344, test_acc: \u001b[31m0.8304357516995431\u001b[0m, time: 53.52\n",
      "epoch: 50, loss: 98.48596, loss1: 0.74820, loss2_3: 97.73777\n",
      "\ttrain_acc: 0.8349, test_acc: \u001b[31m0.8319959879638916\u001b[0m, time: 54.36\n",
      "best_acc: 0.8319959879638916\n",
      "epoch: 51, loss: 98.53916, loss1: 0.74496, loss2_3: 97.79420\n",
      "\ttrain_acc: 0.8336, test_acc: \u001b[31m0.8296370593261265\u001b[0m, time: 52.53\n",
      "epoch: 52, loss: 98.40668, loss1: 0.74694, loss2_3: 97.65974\n",
      "\ttrain_acc: 0.8346, test_acc: \u001b[31m0.8324046212712211\u001b[0m, time: 52.56\n",
      "best_acc: 0.8324046212712211\n",
      "epoch: 53, loss: 98.37763, loss1: 0.74560, loss2_3: 97.63203\n",
      "\ttrain_acc: 0.8339, test_acc: \u001b[31m0.8301014153571826\u001b[0m, time: 52.52\n",
      "epoch: 54, loss: 98.38744, loss1: 0.74528, loss2_3: 97.64216\n",
      "\ttrain_acc: 0.8351, test_acc: \u001b[31m0.8305657713882388\u001b[0m, time: 52.43\n",
      "epoch: 55, loss: 98.11198, loss1: 0.74422, loss2_3: 97.36776\n",
      "\ttrain_acc: 0.8353, test_acc: \u001b[31m0.8319774137226494\u001b[0m, time: 52.49\n",
      "epoch: 56, loss: 98.02468, loss1: 0.74504, loss2_3: 97.27963\n",
      "\ttrain_acc: 0.8351, test_acc: \u001b[31m0.8318845425164382\u001b[0m, time: 52.43\n",
      "epoch: 57, loss: 97.92789, loss1: 0.74289, loss2_3: 97.18501\n",
      "\ttrain_acc: 0.8322, test_acc: \u001b[31m0.8304543259407853\u001b[0m, time: 52.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 58, loss: 97.93607, loss1: 0.74302, loss2_3: 97.19305\n",
      "\ttrain_acc: 0.8348, test_acc: \u001b[31m0.8316059288978045\u001b[0m, time: 52.46\n",
      "epoch: 59, loss: 97.90876, loss1: 0.74537, loss2_3: 97.16339\n",
      "\ttrain_acc: 0.8345, test_acc: \u001b[31m0.8321445818938297\u001b[0m, time: 54.71\n",
      "epoch: 60, loss: 97.88411, loss1: 0.74297, loss2_3: 97.14114\n",
      "\ttrain_acc: 0.8354, test_acc: \u001b[31m0.8314201864853821\u001b[0m, time: 57.76\n",
      "epoch: 61, loss: 97.77314, loss1: 0.74127, loss2_3: 97.03187\n",
      "\ttrain_acc: 0.8361, test_acc: \u001b[31m0.8315130576915933\u001b[0m, time: 52.58\n",
      "epoch: 62, loss: 97.64517, loss1: 0.74038, loss2_3: 96.90479\n",
      "\ttrain_acc: 0.8362, test_acc: \u001b[31m0.8320888591701029\u001b[0m, time: 52.42\n",
      "epoch: 63, loss: 97.55289, loss1: 0.74046, loss2_3: 96.81243\n",
      "\ttrain_acc: 0.8361, test_acc: \u001b[31m0.8321445818938297\u001b[0m, time: 52.51\n",
      "epoch: 64, loss: 97.61019, loss1: 0.73968, loss2_3: 96.87050\n",
      "\ttrain_acc: 0.8347, test_acc: \u001b[31m0.8298228017385489\u001b[0m, time: 52.42\n",
      "epoch: 65, loss: 97.58285, loss1: 0.73981, loss2_3: 96.84304\n",
      "\ttrain_acc: 0.8356, test_acc: \u001b[31m0.8322003046175563\u001b[0m, time: 52.46\n",
      "epoch: 66, loss: 97.39326, loss1: 0.74050, loss2_3: 96.65276\n",
      "\ttrain_acc: 0.8361, test_acc: \u001b[31m0.8316616516215313\u001b[0m, time: 52.40\n",
      "epoch: 67, loss: 97.35506, loss1: 0.74038, loss2_3: 96.61468\n",
      "\ttrain_acc: 0.8354, test_acc: \u001b[31m0.8307143653181768\u001b[0m, time: 52.46\n",
      "epoch: 68, loss: 97.32439, loss1: 0.73874, loss2_3: 96.58566\n",
      "\ttrain_acc: 0.8364, test_acc: \u001b[31m0.8325160667186745\u001b[0m, time: 52.40\n",
      "best_acc: 0.8325160667186745\n",
      "epoch: 69, loss: 97.32128, loss1: 0.74081, loss2_3: 96.58046\n",
      "\ttrain_acc: 0.8370, test_acc: \u001b[31m0.8329247000260039\u001b[0m, time: 52.39\n",
      "best_acc: 0.8329247000260039\n",
      "epoch: 70, loss: 97.26047, loss1: 0.73722, loss2_3: 96.52324\n",
      "\ttrain_acc: 0.8369, test_acc: \u001b[31m0.8332404621271221\u001b[0m, time: 52.41\n",
      "best_acc: 0.8332404621271221\n",
      "epoch: 71, loss: 97.00196, loss1: 0.73794, loss2_3: 96.26402\n",
      "\ttrain_acc: 0.8374, test_acc: \u001b[31m0.8333704818158179\u001b[0m, time: 52.46\n",
      "best_acc: 0.8333704818158179\n",
      "epoch: 72, loss: 97.09941, loss1: 0.73551, loss2_3: 96.36390\n",
      "\ttrain_acc: 0.8373, test_acc: \u001b[31m0.8319588394814071\u001b[0m, time: 52.42\n",
      "epoch: 73, loss: 96.99932, loss1: 0.73519, loss2_3: 96.26413\n",
      "\ttrain_acc: 0.8367, test_acc: \u001b[31m0.8308443850068725\u001b[0m, time: 52.47\n",
      "epoch: 74, loss: 96.99363, loss1: 0.73887, loss2_3: 96.25477\n",
      "\ttrain_acc: 0.8380, test_acc: \u001b[31m0.8321260076525874\u001b[0m, time: 52.50\n",
      "epoch: 75, loss: 96.86909, loss1: 0.73622, loss2_3: 96.13286\n",
      "\ttrain_acc: 0.8374, test_acc: \u001b[31m0.8314759092091089\u001b[0m, time: 52.49\n",
      "epoch: 76, loss: 96.78281, loss1: 0.73841, loss2_3: 96.04440\n",
      "\ttrain_acc: 0.8383, test_acc: \u001b[31m0.8328318288197927\u001b[0m, time: 52.47\n",
      "epoch: 77, loss: 96.85661, loss1: 0.73925, loss2_3: 96.11735\n",
      "\ttrain_acc: 0.8386, test_acc: \u001b[31m0.8326460864073703\u001b[0m, time: 52.46\n",
      "epoch: 78, loss: 96.73911, loss1: 0.73664, loss2_3: 96.00247\n",
      "\ttrain_acc: 0.8382, test_acc: \u001b[31m0.8334262045395445\u001b[0m, time: 52.45\n",
      "best_acc: 0.8334262045395445\n",
      "epoch: 79, loss: 96.75872, loss1: 0.73514, loss2_3: 96.02358\n",
      "\ttrain_acc: 0.8379, test_acc: \u001b[31m0.8320888591701029\u001b[0m, time: 52.51\n",
      "epoch: 80, loss: 96.72022, loss1: 0.73443, loss2_3: 95.98579\n",
      "\ttrain_acc: 0.8381, test_acc: \u001b[31m0.8328875515435195\u001b[0m, time: 52.46\n",
      "epoch: 81, loss: 96.75742, loss1: 0.73646, loss2_3: 96.02096\n",
      "\ttrain_acc: 0.8385, test_acc: \u001b[31m0.8325903636836435\u001b[0m, time: 52.45\n",
      "epoch: 82, loss: 96.68767, loss1: 0.73763, loss2_3: 95.95003\n",
      "\ttrain_acc: 0.8384, test_acc: \u001b[31m0.8329247000260039\u001b[0m, time: 52.51\n",
      "epoch: 83, loss: 96.53015, loss1: 0.73509, loss2_3: 95.79506\n",
      "\ttrain_acc: 0.8379, test_acc: \u001b[31m0.8319031167576805\u001b[0m, time: 55.91\n",
      "epoch: 84, loss: 96.70912, loss1: 0.73314, loss2_3: 95.97598\n",
      "\ttrain_acc: 0.8391, test_acc: \u001b[31m0.8325346409599168\u001b[0m, time: 55.95\n",
      "epoch: 85, loss: 96.25515, loss1: 0.73506, loss2_3: 95.52009\n",
      "\ttrain_acc: 0.8380, test_acc: \u001b[31m0.8309186819718415\u001b[0m, time: 52.54\n",
      "epoch: 86, loss: 96.36998, loss1: 0.73472, loss2_3: 95.63526\n",
      "\ttrain_acc: 0.8380, test_acc: \u001b[31m0.8333519075745756\u001b[0m, time: 52.50\n",
      "epoch: 87, loss: 96.28254, loss1: 0.73235, loss2_3: 95.55019\n",
      "\ttrain_acc: 0.8389, test_acc: \u001b[31m0.8339462832943274\u001b[0m, time: 52.59\n",
      "best_acc: 0.8339462832943274\n",
      "epoch: 88, loss: 96.38784, loss1: 0.73600, loss2_3: 95.65184\n",
      "\ttrain_acc: 0.8370, test_acc: \u001b[31m0.8325903636836435\u001b[0m, time: 52.53\n",
      "epoch: 89, loss: 96.25942, loss1: 0.73455, loss2_3: 95.52487\n",
      "\ttrain_acc: 0.8392, test_acc: \u001b[31m0.8339462832943274\u001b[0m, time: 52.52\n",
      "epoch: 90, loss: 96.19857, loss1: 0.73380, loss2_3: 95.46477\n",
      "\ttrain_acc: 0.8390, test_acc: \u001b[31m0.8331475909209108\u001b[0m, time: 52.74\n",
      "epoch: 91, loss: 96.24048, loss1: 0.73324, loss2_3: 95.50725\n",
      "\ttrain_acc: 0.8369, test_acc: \u001b[31m0.8305100486645121\u001b[0m, time: 52.61\n",
      "epoch: 92, loss: 96.05423, loss1: 0.73113, loss2_3: 95.32310\n",
      "\ttrain_acc: 0.8380, test_acc: \u001b[31m0.8328875515435195\u001b[0m, time: 52.55\n",
      "epoch: 93, loss: 96.14985, loss1: 0.73317, loss2_3: 95.41668\n",
      "\ttrain_acc: 0.8402, test_acc: \u001b[31m0.832850403061035\u001b[0m, time: 52.56\n",
      "epoch: 94, loss: 96.18420, loss1: 0.73408, loss2_3: 95.45012\n",
      "\ttrain_acc: 0.8371, test_acc: \u001b[31m0.8316245031390468\u001b[0m, time: 52.52\n",
      "epoch: 95, loss: 96.06983, loss1: 0.73140, loss2_3: 95.33844\n",
      "\ttrain_acc: 0.8397, test_acc: \u001b[31m0.8334076302983023\u001b[0m, time: 52.59\n",
      "epoch: 96, loss: 96.09753, loss1: 0.73265, loss2_3: 95.36487\n",
      "\ttrain_acc: 0.8389, test_acc: \u001b[31m0.8327389576135815\u001b[0m, time: 52.53\n",
      "epoch: 97, loss: 96.02184, loss1: 0.73480, loss2_3: 95.28704\n",
      "\ttrain_acc: 0.8385, test_acc: \u001b[31m0.8322374531000408\u001b[0m, time: 52.53\n",
      "epoch: 98, loss: 96.04901, loss1: 0.72863, loss2_3: 95.32038\n",
      "\ttrain_acc: 0.8391, test_acc: \u001b[31m0.8332033136446376\u001b[0m, time: 53.09\n",
      "epoch: 99, loss: 96.08040, loss1: 0.73323, loss2_3: 95.34717\n",
      "\ttrain_acc: 0.8391, test_acc: \u001b[31m0.832701809131097\u001b[0m, time: 57.32\n",
      "epoch: 100, loss: 95.86203, loss1: 0.73122, loss2_3: 95.13081\n",
      "\ttrain_acc: 0.8406, test_acc: \u001b[31m0.8337233923994205\u001b[0m, time: 57.77\n",
      "epoch: 101, loss: 95.90877, loss1: 0.73228, loss2_3: 95.17648\n",
      "\ttrain_acc: 0.8405, test_acc: \u001b[31m0.8342434711542034\u001b[0m, time: 57.81\n",
      "best_acc: 0.8342434711542034\n",
      "epoch: 102, loss: 95.78635, loss1: 0.73068, loss2_3: 95.05568\n",
      "\ttrain_acc: 0.8402, test_acc: \u001b[31m0.8324046212712211\u001b[0m, time: 57.73\n",
      "epoch: 103, loss: 95.91354, loss1: 0.72974, loss2_3: 95.18380\n",
      "\ttrain_acc: 0.8396, test_acc: \u001b[31m0.8307515138006613\u001b[0m, time: 57.77\n",
      "epoch: 104, loss: 95.93679, loss1: 0.73209, loss2_3: 95.20469\n",
      "\ttrain_acc: 0.8406, test_acc: \u001b[31m0.8328689773022772\u001b[0m, time: 59.33\n",
      "epoch: 105, loss: 95.84766, loss1: 0.72887, loss2_3: 95.11879\n",
      "\ttrain_acc: 0.8401, test_acc: \u001b[31m0.8331290166796687\u001b[0m, time: 57.75\n",
      "epoch: 106, loss: 95.62153, loss1: 0.73064, loss2_3: 94.89089\n",
      "\ttrain_acc: 0.8392, test_acc: \u001b[31m0.8321445818938297\u001b[0m, time: 57.80\n",
      "epoch: 107, loss: 95.71000, loss1: 0.73074, loss2_3: 94.97926\n",
      "\ttrain_acc: 0.8387, test_acc: \u001b[31m0.8311972955904752\u001b[0m, time: 57.76\n",
      "epoch: 108, loss: 95.61592, loss1: 0.73237, loss2_3: 94.88355\n",
      "\ttrain_acc: 0.8394, test_acc: \u001b[31m0.8319774137226494\u001b[0m, time: 53.67\n",
      "epoch: 109, loss: 95.50032, loss1: 0.72998, loss2_3: 94.77034\n",
      "\ttrain_acc: 0.8413, test_acc: \u001b[31m0.8334819272632713\u001b[0m, time: 52.47\n",
      "epoch: 110, loss: 95.48872, loss1: 0.72780, loss2_3: 94.76092\n",
      "\ttrain_acc: 0.8412, test_acc: \u001b[31m0.833686243916936\u001b[0m, time: 52.53\n",
      "epoch: 111, loss: 95.64311, loss1: 0.72733, loss2_3: 94.91578\n",
      "\ttrain_acc: 0.8361, test_acc: \u001b[31m0.8285783275753186\u001b[0m, time: 52.40\n",
      "epoch: 112, loss: 95.43595, loss1: 0.72778, loss2_3: 94.70816\n",
      "\ttrain_acc: 0.8406, test_acc: \u001b[31m0.8336490954344515\u001b[0m, time: 52.47\n",
      "epoch: 113, loss: 95.65360, loss1: 0.72934, loss2_3: 94.92426\n",
      "\ttrain_acc: 0.8407, test_acc: \u001b[31m0.8334447787807868\u001b[0m, time: 52.53\n",
      "epoch: 114, loss: 95.50430, loss1: 0.72881, loss2_3: 94.77550\n",
      "\ttrain_acc: 0.8390, test_acc: \u001b[31m0.8308443850068725\u001b[0m, time: 52.52\n",
      "epoch: 115, loss: 95.56274, loss1: 0.72758, loss2_3: 94.83515\n",
      "\ttrain_acc: 0.8418, test_acc: \u001b[31m0.833834837846874\u001b[0m, time: 52.42\n",
      "epoch: 116, loss: 95.46252, loss1: 0.72914, loss2_3: 94.73339\n",
      "\ttrain_acc: 0.8423, test_acc: \u001b[31m0.8340205802592964\u001b[0m, time: 53.25\n",
      "epoch: 117, loss: 95.48120, loss1: 0.73222, loss2_3: 94.74897\n",
      "\ttrain_acc: 0.8422, test_acc: \u001b[31m0.8340205802592964\u001b[0m, time: 54.24\n",
      "epoch: 118, loss: 95.40636, loss1: 0.72932, loss2_3: 94.67704\n",
      "\ttrain_acc: 0.8405, test_acc: \u001b[31m0.8322746015825253\u001b[0m, time: 52.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 119, loss: 95.33489, loss1: 0.72742, loss2_3: 94.60747\n",
      "\ttrain_acc: 0.8414, test_acc: \u001b[31m0.833463353022029\u001b[0m, time: 52.35\n",
      "epoch: 120, loss: 95.33681, loss1: 0.73146, loss2_3: 94.60535\n",
      "\ttrain_acc: 0.8420, test_acc: \u001b[31m0.8334447787807868\u001b[0m, time: 52.36\n",
      "epoch: 121, loss: 95.09032, loss1: 0.72746, loss2_3: 94.36286\n",
      "\ttrain_acc: 0.8417, test_acc: \u001b[31m0.8340020060180542\u001b[0m, time: 52.36\n",
      "epoch: 122, loss: 95.23723, loss1: 0.72858, loss2_3: 94.50865\n",
      "\ttrain_acc: 0.8420, test_acc: \u001b[31m0.8338719863293584\u001b[0m, time: 52.43\n",
      "epoch: 123, loss: 95.05418, loss1: 0.72834, loss2_3: 94.32585\n",
      "\ttrain_acc: 0.8394, test_acc: \u001b[31m0.8307143653181768\u001b[0m, time: 52.34\n",
      "epoch: 124, loss: 95.18640, loss1: 0.72980, loss2_3: 94.45660\n",
      "\ttrain_acc: 0.8427, test_acc: \u001b[31m0.8339277090530852\u001b[0m, time: 52.39\n",
      "epoch: 125, loss: 95.14426, loss1: 0.72512, loss2_3: 94.41913\n",
      "\ttrain_acc: 0.8421, test_acc: \u001b[31m0.8337791151231472\u001b[0m, time: 52.68\n",
      "epoch: 126, loss: 95.11126, loss1: 0.72836, loss2_3: 94.38290\n",
      "\ttrain_acc: 0.8417, test_acc: \u001b[31m0.8322188788587986\u001b[0m, time: 54.37\n",
      "epoch: 127, loss: 95.04984, loss1: 0.72629, loss2_3: 94.32355\n",
      "\ttrain_acc: 0.8413, test_acc: \u001b[31m0.832701809131097\u001b[0m, time: 54.25\n",
      "epoch: 128, loss: 95.08507, loss1: 0.72945, loss2_3: 94.35562\n",
      "\ttrain_acc: 0.8426, test_acc: \u001b[31m0.83338905605706\u001b[0m, time: 54.26\n",
      "epoch: 129, loss: 94.94318, loss1: 0.72702, loss2_3: 94.21616\n",
      "\ttrain_acc: 0.8428, test_acc: \u001b[31m0.8339277090530852\u001b[0m, time: 54.25\n",
      "epoch: 130, loss: 94.97938, loss1: 0.72799, loss2_3: 94.25139\n",
      "\ttrain_acc: 0.8407, test_acc: \u001b[31m0.8312901667966863\u001b[0m, time: 54.35\n",
      "epoch: 131, loss: 94.89668, loss1: 0.72523, loss2_3: 94.17145\n",
      "\ttrain_acc: 0.8412, test_acc: \u001b[31m0.831643077380289\u001b[0m, time: 54.25\n",
      "epoch: 132, loss: 94.76573, loss1: 0.72548, loss2_3: 94.04025\n",
      "\ttrain_acc: 0.8406, test_acc: \u001b[31m0.8306400683532078\u001b[0m, time: 54.28\n",
      "epoch: 133, loss: 94.81209, loss1: 0.72743, loss2_3: 94.08466\n",
      "\ttrain_acc: 0.8431, test_acc: \u001b[31m0.8332776106096066\u001b[0m, time: 53.25\n",
      "epoch: 134, loss: 94.82476, loss1: 0.73003, loss2_3: 94.09473\n",
      "\ttrain_acc: 0.8368, test_acc: \u001b[31m0.8286154760578031\u001b[0m, time: 56.41\n",
      "epoch: 135, loss: 94.90576, loss1: 0.72674, loss2_3: 94.17902\n",
      "\ttrain_acc: 0.8433, test_acc: \u001b[31m0.8330547197146997\u001b[0m, time: 54.56\n",
      "epoch: 136, loss: 94.77706, loss1: 0.72646, loss2_3: 94.05060\n",
      "\ttrain_acc: 0.8418, test_acc: \u001b[31m0.8332961848508489\u001b[0m, time: 52.47\n",
      "epoch: 137, loss: 94.82577, loss1: 0.72436, loss2_3: 94.10141\n",
      "\ttrain_acc: 0.8410, test_acc: \u001b[31m0.831940265240165\u001b[0m, time: 52.44\n",
      "epoch: 138, loss: 94.80904, loss1: 0.72380, loss2_3: 94.08524\n",
      "\ttrain_acc: 0.8437, test_acc: \u001b[31m0.834373490842899\u001b[0m, time: 52.52\n",
      "best_acc: 0.834373490842899\n",
      "epoch: 139, loss: 94.75224, loss1: 0.72575, loss2_3: 94.02649\n",
      "\ttrain_acc: 0.8431, test_acc: \u001b[31m0.8353579256287381\u001b[0m, time: 52.47\n",
      "best_acc: 0.8353579256287381\n",
      "epoch: 140, loss: 94.69401, loss1: 0.72627, loss2_3: 93.96774\n",
      "\ttrain_acc: 0.8434, test_acc: \u001b[31m0.8340391545005387\u001b[0m, time: 53.08\n",
      "epoch: 141, loss: 94.67321, loss1: 0.72680, loss2_3: 93.94642\n",
      "\ttrain_acc: 0.8435, test_acc: \u001b[31m0.833463353022029\u001b[0m, time: 54.33\n",
      "epoch: 142, loss: 94.56387, loss1: 0.72655, loss2_3: 93.83732\n",
      "\ttrain_acc: 0.8433, test_acc: \u001b[31m0.8348192726327129\u001b[0m, time: 54.33\n",
      "epoch: 143, loss: 94.61810, loss1: 0.72550, loss2_3: 93.89260\n",
      "\ttrain_acc: 0.8434, test_acc: \u001b[31m0.83247891823619\u001b[0m, time: 54.30\n",
      "epoch: 144, loss: 94.68913, loss1: 0.72737, loss2_3: 93.96177\n",
      "\ttrain_acc: 0.8435, test_acc: \u001b[31m0.8333704818158179\u001b[0m, time: 54.31\n",
      "epoch: 145, loss: 94.52749, loss1: 0.72626, loss2_3: 93.80123\n",
      "\ttrain_acc: 0.8433, test_acc: \u001b[31m0.83338905605706\u001b[0m, time: 53.52\n",
      "epoch: 146, loss: 94.55204, loss1: 0.72409, loss2_3: 93.82795\n",
      "\ttrain_acc: 0.8446, test_acc: \u001b[31m0.8337419666406627\u001b[0m, time: 52.47\n",
      "epoch: 147, loss: 94.54032, loss1: 0.72320, loss2_3: 93.81712\n",
      "\ttrain_acc: 0.8430, test_acc: \u001b[31m0.832776106096066\u001b[0m, time: 52.36\n",
      "epoch: 148, loss: 94.55565, loss1: 0.72449, loss2_3: 93.83116\n",
      "\ttrain_acc: 0.8434, test_acc: \u001b[31m0.8342620453954456\u001b[0m, time: 52.42\n",
      "epoch: 149, loss: 94.39657, loss1: 0.72179, loss2_3: 93.67478\n",
      "\ttrain_acc: 0.8398, test_acc: \u001b[31m0.8315502061740778\u001b[0m, time: 52.43\n",
      "epoch: 150, loss: 94.33267, loss1: 0.72525, loss2_3: 93.60742\n",
      "\ttrain_acc: 0.8433, test_acc: \u001b[31m0.8332590363683644\u001b[0m, time: 52.39\n",
      "epoch: 151, loss: 94.39896, loss1: 0.72387, loss2_3: 93.67510\n",
      "\ttrain_acc: 0.8432, test_acc: \u001b[31m0.8343549166016568\u001b[0m, time: 52.40\n",
      "epoch: 152, loss: 94.38510, loss1: 0.72175, loss2_3: 93.66336\n",
      "\ttrain_acc: 0.8445, test_acc: \u001b[31m0.8344292135666258\u001b[0m, time: 52.41\n",
      "epoch: 153, loss: 94.42646, loss1: 0.72458, loss2_3: 93.70188\n",
      "\ttrain_acc: 0.8437, test_acc: \u001b[31m0.833686243916936\u001b[0m, time: 52.41\n",
      "epoch: 154, loss: 94.30263, loss1: 0.72541, loss2_3: 93.57721\n",
      "\ttrain_acc: 0.8433, test_acc: \u001b[31m0.8329618485084884\u001b[0m, time: 52.41\n",
      "epoch: 155, loss: 94.30482, loss1: 0.72341, loss2_3: 93.58141\n",
      "\ttrain_acc: 0.8412, test_acc: \u001b[31m0.8308629592481147\u001b[0m, time: 52.39\n",
      "epoch: 156, loss: 94.35579, loss1: 0.72302, loss2_3: 93.63277\n",
      "\ttrain_acc: 0.8400, test_acc: \u001b[31m0.8298970987035179\u001b[0m, time: 52.41\n",
      "epoch: 157, loss: 94.20632, loss1: 0.71859, loss2_3: 93.48773\n",
      "\ttrain_acc: 0.8444, test_acc: \u001b[31m0.8335747984694826\u001b[0m, time: 52.41\n",
      "epoch: 158, loss: 94.22488, loss1: 0.72421, loss2_3: 93.50068\n",
      "\ttrain_acc: 0.8439, test_acc: \u001b[31m0.8345778074965637\u001b[0m, time: 52.43\n",
      "epoch: 159, loss: 94.23811, loss1: 0.72281, loss2_3: 93.51530\n",
      "\ttrain_acc: 0.8428, test_acc: \u001b[31m0.831865968275196\u001b[0m, time: 52.38\n",
      "epoch: 160, loss: 94.13886, loss1: 0.72085, loss2_3: 93.41801\n",
      "\ttrain_acc: 0.8439, test_acc: \u001b[31m0.8335190757457558\u001b[0m, time: 52.44\n",
      "epoch: 161, loss: 94.12059, loss1: 0.72058, loss2_3: 93.40001\n",
      "\ttrain_acc: 0.8444, test_acc: \u001b[31m0.8338905605706007\u001b[0m, time: 52.38\n",
      "epoch: 162, loss: 94.27898, loss1: 0.72450, loss2_3: 93.55448\n",
      "\ttrain_acc: 0.8447, test_acc: \u001b[31m0.8324046212712211\u001b[0m, time: 52.43\n",
      "epoch: 163, loss: 94.06173, loss1: 0.72174, loss2_3: 93.34000\n",
      "\ttrain_acc: 0.8440, test_acc: \u001b[31m0.8324231955124634\u001b[0m, time: 52.38\n",
      "epoch: 164, loss: 94.02340, loss1: 0.72127, loss2_3: 93.30213\n",
      "\ttrain_acc: 0.8444, test_acc: \u001b[31m0.8327203833723392\u001b[0m, time: 52.46\n",
      "epoch: 165, loss: 94.00985, loss1: 0.72213, loss2_3: 93.28771\n",
      "\ttrain_acc: 0.8451, test_acc: \u001b[31m0.8337419666406627\u001b[0m, time: 52.49\n",
      "epoch: 166, loss: 93.98303, loss1: 0.72110, loss2_3: 93.26193\n",
      "\ttrain_acc: 0.8432, test_acc: \u001b[31m0.8322374531000408\u001b[0m, time: 52.49\n",
      "epoch: 167, loss: 94.04860, loss1: 0.72422, loss2_3: 93.32438\n",
      "\ttrain_acc: 0.8451, test_acc: \u001b[31m0.8326089379248858\u001b[0m, time: 52.50\n",
      "epoch: 168, loss: 93.86122, loss1: 0.71985, loss2_3: 93.14137\n",
      "\ttrain_acc: 0.8450, test_acc: \u001b[31m0.8324974924774323\u001b[0m, time: 52.58\n",
      "epoch: 169, loss: 94.09880, loss1: 0.72348, loss2_3: 93.37532\n",
      "\ttrain_acc: 0.8432, test_acc: \u001b[31m0.8323860470299789\u001b[0m, time: 52.42\n",
      "epoch: 170, loss: 93.81921, loss1: 0.72143, loss2_3: 93.09777\n",
      "\ttrain_acc: 0.8451, test_acc: \u001b[31m0.8331104424384264\u001b[0m, time: 52.46\n",
      "epoch: 171, loss: 93.88815, loss1: 0.71927, loss2_3: 93.16888\n",
      "\ttrain_acc: 0.8440, test_acc: \u001b[31m0.8319774137226494\u001b[0m, time: 52.46\n",
      "epoch: 172, loss: 94.01088, loss1: 0.72232, loss2_3: 93.28856\n",
      "\ttrain_acc: 0.8452, test_acc: \u001b[31m0.8333704818158179\u001b[0m, time: 52.47\n",
      "epoch: 173, loss: 94.14170, loss1: 0.72343, loss2_3: 93.41827\n",
      "\ttrain_acc: 0.8447, test_acc: \u001b[31m0.8331104424384264\u001b[0m, time: 52.52\n",
      "epoch: 174, loss: 93.97086, loss1: 0.72015, loss2_3: 93.25071\n",
      "\ttrain_acc: 0.8441, test_acc: \u001b[31m0.8323674727887366\u001b[0m, time: 52.48\n",
      "epoch: 175, loss: 93.74365, loss1: 0.71897, loss2_3: 93.02468\n",
      "\ttrain_acc: 0.8437, test_acc: \u001b[31m0.8323117500650098\u001b[0m, time: 52.45\n",
      "epoch: 176, loss: 93.83653, loss1: 0.71949, loss2_3: 93.11704\n",
      "\ttrain_acc: 0.8454, test_acc: \u001b[31m0.8328132545785505\u001b[0m, time: 52.54\n",
      "epoch: 177, loss: 93.86746, loss1: 0.72258, loss2_3: 93.14488\n",
      "\ttrain_acc: 0.8448, test_acc: \u001b[31m0.8326832348898547\u001b[0m, time: 52.47\n",
      "epoch: 178, loss: 93.80838, loss1: 0.72259, loss2_3: 93.08578\n",
      "\ttrain_acc: 0.8452, test_acc: \u001b[31m0.8330547197146997\u001b[0m, time: 52.46\n",
      "epoch: 179, loss: 93.71669, loss1: 0.71902, loss2_3: 92.99767\n",
      "\ttrain_acc: 0.8452, test_acc: \u001b[31m0.8327389576135815\u001b[0m, time: 52.42\n",
      "epoch: 180, loss: 93.66033, loss1: 0.72206, loss2_3: 92.93827\n",
      "\ttrain_acc: 0.8462, test_acc: \u001b[31m0.8335747984694826\u001b[0m, time: 52.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 181, loss: 93.72417, loss1: 0.72062, loss2_3: 93.00355\n",
      "\ttrain_acc: 0.8459, test_acc: \u001b[31m0.8329247000260039\u001b[0m, time: 52.43\n",
      "epoch: 182, loss: 93.65479, loss1: 0.71982, loss2_3: 92.93498\n",
      "\ttrain_acc: 0.8460, test_acc: \u001b[31m0.8332218878858798\u001b[0m, time: 52.41\n",
      "epoch: 183, loss: 93.58247, loss1: 0.72006, loss2_3: 92.86241\n",
      "\ttrain_acc: 0.8429, test_acc: \u001b[31m0.8301199895984249\u001b[0m, time: 52.40\n",
      "epoch: 184, loss: 93.58211, loss1: 0.71739, loss2_3: 92.86472\n",
      "\ttrain_acc: 0.8465, test_acc: \u001b[31m0.8331847394033953\u001b[0m, time: 52.47\n",
      "epoch: 185, loss: 93.47166, loss1: 0.71804, loss2_3: 92.75362\n",
      "\ttrain_acc: 0.8460, test_acc: \u001b[31m0.8339462832943274\u001b[0m, time: 52.41\n",
      "epoch: 186, loss: 93.43593, loss1: 0.71773, loss2_3: 92.71821\n",
      "\ttrain_acc: 0.8464, test_acc: \u001b[31m0.8341134514655076\u001b[0m, time: 52.53\n",
      "epoch: 187, loss: 93.60323, loss1: 0.72176, loss2_3: 92.88148\n",
      "\ttrain_acc: 0.8440, test_acc: \u001b[31m0.8302500092871207\u001b[0m, time: 52.55\n",
      "epoch: 188, loss: 93.46640, loss1: 0.71807, loss2_3: 92.74833\n",
      "\ttrain_acc: 0.8458, test_acc: \u001b[31m0.8342248969129611\u001b[0m, time: 52.52\n",
      "epoch: 189, loss: 93.42841, loss1: 0.71722, loss2_3: 92.71120\n",
      "\ttrain_acc: 0.8440, test_acc: \u001b[31m0.8309744046955682\u001b[0m, time: 52.51\n",
      "epoch: 190, loss: 93.55653, loss1: 0.71895, loss2_3: 92.83758\n",
      "\ttrain_acc: 0.8452, test_acc: \u001b[31m0.8321631561350719\u001b[0m, time: 52.50\n",
      "epoch: 191, loss: 93.56081, loss1: 0.71908, loss2_3: 92.84173\n",
      "\ttrain_acc: 0.8456, test_acc: \u001b[31m0.8334447787807868\u001b[0m, time: 52.47\n",
      "epoch: 192, loss: 93.52119, loss1: 0.71786, loss2_3: 92.80333\n",
      "\ttrain_acc: 0.8436, test_acc: \u001b[31m0.831940265240165\u001b[0m, time: 52.58\n",
      "epoch: 193, loss: 93.29860, loss1: 0.71859, loss2_3: 92.58001\n",
      "\ttrain_acc: 0.8456, test_acc: \u001b[31m0.833760540881905\u001b[0m, time: 52.46\n",
      "epoch: 194, loss: 93.44741, loss1: 0.71769, loss2_3: 92.72972\n",
      "\ttrain_acc: 0.8473, test_acc: \u001b[31m0.8354322225937071\u001b[0m, time: 52.51\n",
      "best_acc: 0.8354322225937071\n",
      "epoch: 195, loss: 93.45271, loss1: 0.71793, loss2_3: 92.73477\n",
      "\ttrain_acc: 0.8465, test_acc: \u001b[31m0.8354879453174338\u001b[0m, time: 57.76\n",
      "best_acc: 0.8354879453174338\n",
      "epoch: 196, loss: 93.39852, loss1: 0.72036, loss2_3: 92.67815\n",
      "\ttrain_acc: 0.8466, test_acc: \u001b[31m0.8330918681971842\u001b[0m, time: 59.44\n",
      "epoch: 197, loss: 93.36438, loss1: 0.71727, loss2_3: 92.64710\n",
      "\ttrain_acc: 0.8461, test_acc: \u001b[31m0.8320517106876184\u001b[0m, time: 59.41\n",
      "epoch: 198, loss: 93.26634, loss1: 0.71555, loss2_3: 92.55080\n",
      "\ttrain_acc: 0.8473, test_acc: \u001b[31m0.8335005015045135\u001b[0m, time: 57.75\n",
      "epoch: 199, loss: 93.16812, loss1: 0.71839, loss2_3: 92.44974\n",
      "\ttrain_acc: 0.8462, test_acc: \u001b[31m0.8337791151231472\u001b[0m, time: 53.70\n",
      "epoch: 200, loss: 93.32385, loss1: 0.71912, loss2_3: 92.60472\n",
      "\ttrain_acc: 0.8434, test_acc: \u001b[31m0.8305100486645121\u001b[0m, time: 52.46\n",
      "epoch: 201, loss: 93.12757, loss1: 0.71628, loss2_3: 92.41129\n",
      "\ttrain_acc: 0.8474, test_acc: \u001b[31m0.8335376499869981\u001b[0m, time: 52.41\n",
      "epoch: 202, loss: 93.07766, loss1: 0.71832, loss2_3: 92.35934\n",
      "\ttrain_acc: 0.8459, test_acc: \u001b[31m0.8325346409599168\u001b[0m, time: 52.40\n",
      "epoch: 203, loss: 93.28048, loss1: 0.71825, loss2_3: 92.56223\n",
      "\ttrain_acc: 0.8467, test_acc: \u001b[31m0.8336305211932092\u001b[0m, time: 52.41\n",
      "epoch: 204, loss: 93.10541, loss1: 0.71775, loss2_3: 92.38765\n",
      "\ttrain_acc: 0.8482, test_acc: \u001b[31m0.833760540881905\u001b[0m, time: 52.43\n",
      "epoch: 205, loss: 93.03826, loss1: 0.71687, loss2_3: 92.32139\n",
      "\ttrain_acc: 0.8462, test_acc: \u001b[31m0.8326646606486126\u001b[0m, time: 52.41\n",
      "epoch: 206, loss: 93.06372, loss1: 0.71697, loss2_3: 92.34675\n",
      "\ttrain_acc: 0.8480, test_acc: \u001b[31m0.8333333333333334\u001b[0m, time: 52.42\n",
      "epoch: 207, loss: 93.01958, loss1: 0.71231, loss2_3: 92.30727\n",
      "\ttrain_acc: 0.8471, test_acc: \u001b[31m0.8333147590920911\u001b[0m, time: 52.40\n",
      "epoch: 208, loss: 93.07243, loss1: 0.71460, loss2_3: 92.35784\n",
      "\ttrain_acc: 0.8474, test_acc: \u001b[31m0.8325903636836435\u001b[0m, time: 52.48\n",
      "epoch: 209, loss: 92.91583, loss1: 0.71373, loss2_3: 92.20209\n",
      "\ttrain_acc: 0.8470, test_acc: \u001b[31m0.8325903636836435\u001b[0m, time: 52.39\n",
      "epoch: 210, loss: 92.90214, loss1: 0.71743, loss2_3: 92.18472\n",
      "\ttrain_acc: 0.8457, test_acc: \u001b[31m0.8314201864853821\u001b[0m, time: 52.47\n",
      "epoch: 211, loss: 92.93850, loss1: 0.71723, loss2_3: 92.22127\n",
      "\ttrain_acc: 0.8476, test_acc: \u001b[31m0.8340391545005387\u001b[0m, time: 52.48\n",
      "epoch: 212, loss: 92.93066, loss1: 0.71419, loss2_3: 92.21647\n",
      "\ttrain_acc: 0.8479, test_acc: \u001b[31m0.8344477878078681\u001b[0m, time: 52.45\n",
      "epoch: 213, loss: 93.02541, loss1: 0.71597, loss2_3: 92.30945\n",
      "\ttrain_acc: 0.8472, test_acc: \u001b[31m0.834373490842899\u001b[0m, time: 52.39\n",
      "epoch: 214, loss: 92.88344, loss1: 0.71415, loss2_3: 92.16930\n",
      "\ttrain_acc: 0.8466, test_acc: \u001b[31m0.832776106096066\u001b[0m, time: 52.39\n",
      "epoch: 215, loss: 92.88472, loss1: 0.71684, loss2_3: 92.16788\n",
      "\ttrain_acc: 0.8467, test_acc: \u001b[31m0.8314387607266244\u001b[0m, time: 52.40\n",
      "epoch: 216, loss: 92.79627, loss1: 0.71498, loss2_3: 92.08129\n",
      "\ttrain_acc: 0.8471, test_acc: \u001b[31m0.8333333333333334\u001b[0m, time: 52.48\n",
      "epoch: 217, loss: 92.61399, loss1: 0.71271, loss2_3: 91.90128\n",
      "\ttrain_acc: 0.8486, test_acc: \u001b[31m0.8340577287417809\u001b[0m, time: 52.43\n",
      "epoch: 218, loss: 92.69980, loss1: 0.71482, loss2_3: 91.98499\n",
      "\ttrain_acc: 0.8474, test_acc: \u001b[31m0.833686243916936\u001b[0m, time: 52.52\n",
      "epoch: 219, loss: 92.60337, loss1: 0.71409, loss2_3: 91.88929\n",
      "\ttrain_acc: 0.8475, test_acc: \u001b[31m0.8342806196366879\u001b[0m, time: 52.51\n",
      "epoch: 220, loss: 92.68709, loss1: 0.71474, loss2_3: 91.97235\n",
      "\ttrain_acc: 0.8490, test_acc: \u001b[31m0.8336490954344515\u001b[0m, time: 52.49\n",
      "epoch: 221, loss: 92.80565, loss1: 0.71380, loss2_3: 92.09186\n",
      "\ttrain_acc: 0.8474, test_acc: \u001b[31m0.8345406590140793\u001b[0m, time: 52.45\n",
      "epoch: 222, loss: 92.74655, loss1: 0.71472, loss2_3: 92.03183\n",
      "\ttrain_acc: 0.8499, test_acc: \u001b[31m0.834596381737806\u001b[0m, time: 52.47\n",
      "epoch: 223, loss: 92.68037, loss1: 0.71243, loss2_3: 91.96794\n",
      "\ttrain_acc: 0.8484, test_acc: \u001b[31m0.8330361454734574\u001b[0m, time: 52.38\n",
      "epoch: 224, loss: 92.65444, loss1: 0.71269, loss2_3: 91.94176\n",
      "\ttrain_acc: 0.8454, test_acc: \u001b[31m0.8305100486645121\u001b[0m, time: 52.47\n",
      "epoch: 225, loss: 92.67102, loss1: 0.71383, loss2_3: 91.95719\n",
      "\ttrain_acc: 0.8474, test_acc: \u001b[31m0.8336305211932092\u001b[0m, time: 52.44\n",
      "epoch: 226, loss: 92.63501, loss1: 0.71421, loss2_3: 91.92080\n",
      "\ttrain_acc: 0.8484, test_acc: \u001b[31m0.8335190757457558\u001b[0m, time: 52.44\n",
      "epoch: 227, loss: 92.64542, loss1: 0.71797, loss2_3: 91.92744\n",
      "\ttrain_acc: 0.8489, test_acc: \u001b[31m0.8337419666406627\u001b[0m, time: 52.46\n",
      "epoch: 228, loss: 92.61348, loss1: 0.71316, loss2_3: 91.90033\n",
      "\ttrain_acc: 0.8483, test_acc: \u001b[31m0.8338534120881163\u001b[0m, time: 52.44\n",
      "epoch: 229, loss: 92.54264, loss1: 0.71419, loss2_3: 91.82845\n",
      "\ttrain_acc: 0.8478, test_acc: \u001b[31m0.8327203833723392\u001b[0m, time: 52.32\n",
      "epoch: 230, loss: 92.48453, loss1: 0.71097, loss2_3: 91.77356\n",
      "\ttrain_acc: 0.8481, test_acc: \u001b[31m0.8343177681191724\u001b[0m, time: 52.34\n",
      "epoch: 231, loss: 92.37837, loss1: 0.71201, loss2_3: 91.66636\n",
      "\ttrain_acc: 0.8493, test_acc: \u001b[31m0.83338905605706\u001b[0m, time: 52.37\n",
      "epoch: 232, loss: 92.48307, loss1: 0.71461, loss2_3: 91.76846\n",
      "\ttrain_acc: 0.8447, test_acc: \u001b[31m0.8292470002600394\u001b[0m, time: 52.48\n",
      "epoch: 233, loss: 92.53990, loss1: 0.71495, loss2_3: 91.82495\n",
      "\ttrain_acc: 0.8450, test_acc: \u001b[31m0.8285040306103496\u001b[0m, time: 52.49\n",
      "epoch: 234, loss: 92.25991, loss1: 0.71206, loss2_3: 91.54785\n",
      "\ttrain_acc: 0.8489, test_acc: \u001b[31m0.8329989969909729\u001b[0m, time: 52.54\n",
      "epoch: 235, loss: 92.32300, loss1: 0.71270, loss2_3: 91.61030\n",
      "\ttrain_acc: 0.8491, test_acc: \u001b[31m0.8322931758237676\u001b[0m, time: 52.43\n",
      "epoch: 236, loss: 92.31842, loss1: 0.71439, loss2_3: 91.60403\n",
      "\ttrain_acc: 0.8496, test_acc: \u001b[31m0.8335005015045135\u001b[0m, time: 52.36\n",
      "epoch: 237, loss: 92.21382, loss1: 0.71278, loss2_3: 91.50104\n",
      "\ttrain_acc: 0.8481, test_acc: \u001b[31m0.8336676696756937\u001b[0m, time: 52.44\n",
      "epoch: 238, loss: 92.24204, loss1: 0.71472, loss2_3: 91.52732\n",
      "\ttrain_acc: 0.8499, test_acc: \u001b[31m0.8340391545005387\u001b[0m, time: 52.46\n",
      "epoch: 239, loss: 92.22173, loss1: 0.71222, loss2_3: 91.50951\n",
      "\ttrain_acc: 0.8495, test_acc: \u001b[31m0.8335376499869981\u001b[0m, time: 52.47\n",
      "epoch: 240, loss: 92.16162, loss1: 0.71355, loss2_3: 91.44807\n",
      "\ttrain_acc: 0.8489, test_acc: \u001b[31m0.8332404621271221\u001b[0m, time: 52.48\n",
      "epoch: 241, loss: 91.99868, loss1: 0.71037, loss2_3: 91.28831\n",
      "\ttrain_acc: 0.8507, test_acc: \u001b[31m0.833834837846874\u001b[0m, time: 52.44\n",
      "epoch: 242, loss: 92.30057, loss1: 0.71210, loss2_3: 91.58847\n",
      "\ttrain_acc: 0.8488, test_acc: \u001b[31m0.8337048181581782\u001b[0m, time: 52.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 243, loss: 92.16288, loss1: 0.71311, loss2_3: 91.44977\n",
      "\ttrain_acc: 0.8502, test_acc: \u001b[31m0.8332033136446376\u001b[0m, time: 52.51\n",
      "epoch: 244, loss: 92.16328, loss1: 0.71116, loss2_3: 91.45212\n",
      "\ttrain_acc: 0.8505, test_acc: \u001b[31m0.8340020060180542\u001b[0m, time: 52.44\n",
      "epoch: 245, loss: 92.10089, loss1: 0.71129, loss2_3: 91.38961\n",
      "\ttrain_acc: 0.8499, test_acc: \u001b[31m0.8326832348898547\u001b[0m, time: 52.40\n",
      "epoch: 246, loss: 92.10872, loss1: 0.71049, loss2_3: 91.39823\n",
      "\ttrain_acc: 0.8497, test_acc: \u001b[31m0.8335376499869981\u001b[0m, time: 52.52\n",
      "epoch: 247, loss: 92.10155, loss1: 0.71293, loss2_3: 91.38862\n",
      "\ttrain_acc: 0.8496, test_acc: \u001b[31m0.8324046212712211\u001b[0m, time: 52.41\n",
      "epoch: 248, loss: 91.97077, loss1: 0.71179, loss2_3: 91.25898\n",
      "\ttrain_acc: 0.8486, test_acc: \u001b[31m0.8322560273412831\u001b[0m, time: 52.44\n",
      "epoch: 249, loss: 91.87891, loss1: 0.70966, loss2_3: 91.16925\n",
      "\ttrain_acc: 0.8483, test_acc: \u001b[31m0.8313830380028976\u001b[0m, time: 52.43\n",
      "epoch: 250, loss: 91.99666, loss1: 0.71218, loss2_3: 91.28448\n",
      "\ttrain_acc: 0.8507, test_acc: \u001b[31m0.8332218878858798\u001b[0m, time: 52.43\n"
     ]
    }
   ],
   "source": [
    "for num_model in range(1):  # just one train\n",
    "    net=newModel().to(device)\n",
    "    lr = 0.0001\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr,weight_decay=5e-4)\n",
    "    criterion = ContrastiveLoss()\n",
    "    criterion_model = nn.CrossEntropyLoss(reduction='sum')\n",
    "    \n",
    "    best_acc=0\n",
    "    EPOCH=250\n",
    "    for epoch in range(EPOCH):\n",
    "        loss_ls=[]\n",
    "        loss1_ls=[]\n",
    "        loss2_3_ls=[]\n",
    "        t0=time.time()\n",
    "        net.train()\n",
    "        for seq1,seq2,label,label1,label2 in train_iter_cont:\n",
    "                output1=net(seq1)\n",
    "                output2=net(seq2)\n",
    "                output3=net.trainModel(seq1)\n",
    "                output4=net.trainModel(seq2)\n",
    "                \n",
    "                loss1=criterion(output1, output2, label)\n",
    "                loss2=criterion_model(output3,label1)\n",
    "                loss3=criterion_model(output4,label2)\n",
    "                loss=loss1+loss2+loss3\n",
    "    #             print(loss)\n",
    "                optimizer.zero_grad() \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_ls.append(loss.item())\n",
    "                loss1_ls.append(loss1.item())\n",
    "                loss2_3_ls.append((loss2+loss3).item())\n",
    "\n",
    "\n",
    "        net.eval() \n",
    "        with torch.no_grad(): \n",
    "            train_acc=evaluate_accuracy(train_iter,net)\n",
    "            test_acc=evaluate_accuracy(val_iter,net)\n",
    "            \n",
    "        results=f\"epoch: {epoch+1}, loss: {np.mean(loss_ls):.5f}, loss1: {np.mean(loss1_ls):.5f}, loss2_3: {np.mean(loss2_3_ls):.5f}\\n\"\n",
    "        results+=f'\\ttrain_acc: {train_acc:.4f}, test_acc: {colored(test_acc,\"red\")}, time: {time.time()-t0:.2f}'\n",
    "        print(results)\n",
    "        to_log(results)\n",
    "        if test_acc>best_acc:\n",
    "            best_acc=test_acc\n",
    "            torch.save({\"best_acc\":best_acc,\"model\":net.state_dict()},f'compareModel/2021ACS_PepFormer/Model/{num_model}.pl')\n",
    "            print(f\"best_acc: {best_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T01:36:17.469265Z",
     "start_time": "2021-08-31T01:36:17.433429Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T02:00:14.432919Z",
     "start_time": "2021-08-31T02:00:14.429626Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs.argmax(dim=1):\n",
    "            y_pred.append(int(_))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T02:15:44.725526Z",
     "start_time": "2021-08-31T02:15:44.722214Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred_prob(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs:\n",
    "            y_pred.append(list(map(float, _)))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T06:49:10.807011Z",
     "start_time": "2021-09-02T06:49:02.742919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.832639900145621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83     33706\n",
      "           1       0.82      0.86      0.84     33592\n",
      "\n",
      "    accuracy                           0.83     67298\n",
      "   macro avg       0.83      0.83      0.83     67298\n",
      "weighted avg       0.83      0.83      0.83     67298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate_accuracy(test_iter,net)\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "# prediction\n",
    "y_pred = pred(test_iter, net)\n",
    "print(classification_report(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T06:49:35.584254Z",
     "start_time": "2021-09-02T06:49:29.066467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf auc : 0.9064775173821029\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AUC\n",
    "probs = np.array(pred_prob(test_iter, net))[:, 1]\n",
    "\n",
    "rf_auc = roc_auc_score(test_label, probs)\n",
    "print('rf auc : {}'.format(rf_auc))\n",
    "# plot the roc curve for the model81\n",
    "rf_fpr, rf_tpr, _ = roc_curve(test_label, probs)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='RF AUC = {:.4f}'.format(rf_auc), color='orange')\n",
    "plt.title('ROC curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "cf_matrix = confusion_matrix(test_label, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=',.0f')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
