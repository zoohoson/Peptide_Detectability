{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T19:44:02.908277Z",
     "start_time": "2021-12-19T19:44:02.904448Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:49:44.730985Z",
     "start_time": "2021-12-14T13:49:44.719236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 21)\n"
     ]
    }
   ],
   "source": [
    "df_aaindex = pd.read_csv('../data/aaindex/df_aaindex19.csv')\n",
    "print(df_aaindex.shape)\n",
    "df_aaindex.head(1)\n",
    "tmp = df_aaindex.drop('Unnamed: 0',axis=1).T\n",
    "aa2val = dict()\n",
    "for aa, val in zip(tmp.index, tmp.values):\n",
    "    aa2val[aa]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:52:48.733756Z",
     "start_time": "2021-12-14T13:52:45.951473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide</th>\n",
       "      <th>En</th>\n",
       "      <th>Ec</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>protein</th>\n",
       "      <th>PEP</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>595411</th>\n",
       "      <td>K.QELNEPPKQSTSFLVLQEILESEEKGDPNK.P</td>\n",
       "      <td>VYKMLQEKQELNEPP</td>\n",
       "      <td>EEKGDPNKPSGFRSV</td>\n",
       "      <td>QELNEPPKQSTSFLV</td>\n",
       "      <td>EILESEEKGDPNKPS</td>\n",
       "      <td>sp|O00151|PDLI1_HUMAN</td>\n",
       "      <td>QELNEPPKQSTSFLVLQEILESEEKGDPNK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   peptide               En               Ec  \\\n",
       "595411  K.QELNEPPKQSTSFLVLQEILESEEKGDPNK.P  VYKMLQEKQELNEPP  EEKGDPNKPSGFRSV   \n",
       "\n",
       "                     E1               E2                protein  \\\n",
       "595411  QELNEPPKQSTSFLV  EILESEEKGDPNKPS  sp|O00151|PDLI1_HUMAN   \n",
       "\n",
       "                                   PEP  ID  \n",
       "595411  QELNEPPKQSTSFLVLQEILESEEKGDPNK   0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detect_peptide_train = pd.read_csv('../data/df_detect_peptide_train.csv')\n",
    "test = pd.read_csv('../data/df_detect_peptide_test.csv')\n",
    "train, val = train_test_split(df_detect_peptide_train, test_size=0.2, random_state=7)\n",
    "\n",
    "df = pd.concat([train, val, test], axis=0).reset_index(drop=True)\n",
    "\n",
    "train_idx = df.iloc[:len(train), :].index\n",
    "val_idx = df.iloc[len(train):len(train)+len(val), :].index\n",
    "test_idx = df.iloc[len(train)+len(val):, :].index\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:53:11.863274Z",
     "start_time": "2021-12-14T13:53:11.116391Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "PATH_TO_REPO = \"/home/bis/2021_AIhub/esm/\"\n",
    "sys.path.append(PATH_TO_REPO)\n",
    "\n",
    "import torch\n",
    "import esm\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import time\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AdamW\n",
    "# from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from transformers import WarmupLinearSchedule as get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:53:13.771046Z",
     "start_time": "2021-12-14T13:53:13.768299Z"
    }
   },
   "outputs": [],
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:53:26.411525Z",
     "start_time": "2021-12-14T13:53:14.507095Z"
    }
   },
   "outputs": [],
   "source": [
    "esm_model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "batch_converter = alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:53:26.419301Z",
     "start_time": "2021-12-14T13:53:26.413176Z"
    }
   },
   "outputs": [],
   "source": [
    "ct = 0\n",
    "for child in esm_model.children():\n",
    "    ct += 1\n",
    "#     print(ct, child)\n",
    "#     if ct < 7:\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:53:26.432526Z",
     "start_time": "2021-12-14T13:53:26.420531Z"
    }
   },
   "outputs": [],
   "source": [
    "class ESMDataset(Dataset):\n",
    "    def __init__(self, datasets, idxes):\n",
    "        pep_idx, nterm_idx, cterm_idx, m1term_idx, m2term_idx, label_idx = idxes\n",
    "        pep_data = [(label, seq) for label, seq in zip(datasets[:, label_idx], datasets[:, pep_idx])]\n",
    "        nterm_data = [(label, seq) for label, seq in zip(datasets[:, label_idx], datasets[:, nterm_idx])]\n",
    "        cterm_data = [(label, seq) for label, seq in zip(datasets[:, label_idx], datasets[:, cterm_idx])]\n",
    "        m1_data = [(label, seq) for label, seq in zip(datasets[:, label_idx], datasets[:, m1term_idx])]\n",
    "        m2_data = [(label, seq) for label, seq in zip(datasets[:, label_idx], datasets[:, m2term_idx])]\n",
    "        \n",
    "        labels, pep_strs, pep_tokens = batch_converter(pep_data)\n",
    "        _, n_strs, n_tokens = batch_converter(nterm_data)\n",
    "        _, c_strs, c_tokens = batch_converter(cterm_data)\n",
    "        _, m1_strs, m1_tokens = batch_converter(m1_data)\n",
    "        _, m2_strs, m2_tokens = batch_converter(m2_data)\n",
    "\n",
    "        self.sentences = [pep_tokens, n_tokens, c_tokens, m1_tokens, m2_tokens]\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (\n",
    "                (self.sentences[0][i], ) + (self.sentences[1][i],) \\\n",
    "                + (self.sentences[2][i], ) + (self.sentences[3][i], ) + (self.sentences[4][i], ) \\\n",
    "                + (self.labels[i], )\n",
    "               )\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n",
    "\n",
    "# [PAD] = 1, [MASK] = 21  [CLS] = 0 (special classification token), [SEP] = 2 (seperate segment), Z = 27, '-' = 30, .=29, ,=28\n",
    "# J 없음\n",
    "# A 2, B 25, C 23, D 13, E 9, F 18, G 6, H 21, I 12, K 15, L 4, M 20, N 17, \n",
    "# O 28, P 14, Q 16, R 10, S 8, T 11, U 26, V 7, W 22, X 24, Y 19, Z 27\n",
    "# 3 5 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:53:33.230745Z",
     "start_time": "2021-12-14T13:53:33.228315Z"
    }
   },
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 30\n",
    "batch_size = 256\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T14:01:27.249021Z",
     "start_time": "2021-12-14T13:53:41.965376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465.28 sec\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "dataset_train = train[['PEP', 'En', 'Ec', 'E1', 'E2', 'ID']].values\n",
    "dataset_valid = val[['PEP', 'En', 'Ec', 'E1', 'E2', 'ID']].values\n",
    "dataset_test = test[['PEP', 'En', 'Ec', 'E1', 'E2', 'ID']].values\n",
    "\n",
    "data_train = ESMDataset(dataset_train, [0, 1, 2, 3, 4, 5])\n",
    "data_valid = ESMDataset(dataset_valid, [0, 1, 2, 3, 4, 5])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=48)\n",
    "valid_dataloader = torch.utils.data.DataLoader(data_valid, batch_size=batch_size, num_workers=48)\n",
    "\n",
    "e = time.time()\n",
    "print(round(e-s, 2),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T14:02:56.698151Z",
     "start_time": "2021-12-14T14:01:27.250346Z"
    }
   },
   "outputs": [],
   "source": [
    "data_test = ESMDataset(dataset_test, [0, 1, 2, 3, 4, 5])\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T20:23:11.486306Z",
     "start_time": "2021-12-19T20:23:11.482209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  7,  5, 17, 11,  8, 11, 16, 11, 20,  6, 14, 10, 14,  5,  5,  5,  5,\n",
       "          5,  5,  5, 11, 14,  5,  7, 10,  2,  1,  1,  1,  1,  1]),\n",
       " tensor([ 0, 14, 10,  7, 20,  8, 11, 16, 10,  7,  5, 17, 11,  8, 11, 16,  2]),\n",
       " tensor([ 0,  5,  5,  5, 11, 14,  5,  7, 10, 11,  7, 14, 16, 19, 15, 19,  2]),\n",
       " tensor([ 0,  8, 11, 16, 11, 20,  6, 14, 10, 14,  5,  5,  5,  5,  5,  5,  2]),\n",
       " tensor([ 0, 30,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]),\n",
       " 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T20:25:50.008748Z",
     "start_time": "2021-12-19T20:25:49.876507Z"
    }
   },
   "outputs": [],
   "source": [
    "zero_miss_site = torch.tensor([[ 0, 30,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
    "                               [ 0, 30,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])  # '-'\n",
    "result = esm_model(zero_miss_site, repr_layers=[33])['representations'][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T20:25:55.668370Z",
     "start_time": "2021-12-19T20:25:55.665324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 1280])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T19:37:07.042160Z",
     "start_time": "2021-12-04T19:37:07.030533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True],\n",
      "         [True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True],\n",
      "         [True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True]]])\n",
      "torch.Size([5, 3, 40]) torch.Size([2, 3, 20]) torch.Size([2, 3, 20])\n",
      "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True]])\n",
      "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, 1, bidirectional=False)\n",
    "inputs = torch.randn(5, 3, 10)\n",
    "fwoutput, (fwhn, fwcn) = rnn(inputs)\n",
    "\n",
    "print(fwoutput[-1, :, :]==fwhn)\n",
    "\n",
    "rnn = nn.LSTM(10, 20, 1, bidirectional=True)\n",
    "output, (hn, cn) = rnn(inputs)\n",
    "# LSTM param : input_size, hidden_size, num_layers\n",
    "# input shape : (seq_len, batch, input_size)\n",
    "# output shape : (seq_len, batch, num_directions * hidden_size)\n",
    "# hn, cn shape : (num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "print(output.shape, hn.shape, cn.shape)\n",
    "\n",
    "print(output[0, :, 20:] == hn[1])  # 0번 unit의 뒤 20 vector 가 reverse seq 의 output(hn)\n",
    "\n",
    "print(output[-1, :, :20] == hn[0])  # 끝번 unit의 앞 20 vector가 forward seq 의 output(hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:06:00.146084Z",
     "start_time": "2021-12-06T03:06:00.136158Z"
    }
   },
   "outputs": [],
   "source": [
    "class ESMClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 esm,\n",
    "                 num_classes=1,\n",
    "                 params=None):\n",
    "        \n",
    "        super(ESMClassifier, self).__init__()\n",
    "        self.esm = esm\n",
    "        self.pep_lstm1 = nn.LSTM(input_size=1280, hidden_size=128, batch_first=True)\n",
    "        self.pep_drop1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.ts_lstm1 = nn.LSTM(input_size=1280, hidden_size=64, batch_first=True)\n",
    "        self.ts_drop1 = nn.Dropout(p=0.2)\n",
    "                \n",
    "        self.fc1 = nn.Linear(384, 128)\n",
    "        self.fc_drop1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "\n",
    "#     def gen_attention_mask(self, token_ids, valid_length):\n",
    "#         attention_mask = torch.zeros_like(token_ids)\n",
    "#         for i, v in enumerate(valid_length):\n",
    "#             attention_mask[i][:v] = 1\n",
    "#         return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, en_token_ids, ec_token_ids, e1_token_ids, e2_token_ids):\n",
    "#         attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        pep_embed = self.esm(token_ids, repr_layers=[33])['representations'][33]\n",
    "        pep_lstm, (pep_hn, __) = self.pep_lstm1(pep_embed)\n",
    "        pep_hn = self.pep_drop1(pep_hn)\n",
    "        \n",
    "        en_embed = self.esm(en_token_ids, repr_layers=[33])['representations'][33]\n",
    "        ec_embed = self.esm(ec_token_ids, repr_layers=[33])['representations'][33]\n",
    "        e1_embed = self.esm(e1_token_ids, repr_layers=[33])['representations'][33]\n",
    "        e2_embed = self.esm(e2_token_ids, repr_layers=[33])['representations'][33]\n",
    "        \n",
    "        en_lstm, (en_hn, __) = self.ts_lstm1(en_embed)\n",
    "        en_lstm = self.ts_drop1(en_hn)\n",
    "        \n",
    "        ec_lstm, (ec_hn, __) = self.ts_lstm1(ec_embed)\n",
    "        ec_lstm = self.ts_drop1(ec_hn)\n",
    "        \n",
    "        e1_lstm, (e1_hn, __) = self.ts_lstm1(e1_embed)\n",
    "        e1_lstm = self.ts_drop1(e1_hn)\n",
    "        \n",
    "        e2_lstm, (e2_hn, __) = self.ts_lstm1(e2_embed)\n",
    "        e2_lstm = self.ts_drop1(e2_hn)\n",
    "        \n",
    "        merge = torch.cat([pep_hn[0], en_hn[0], ec_hn[0], e1_hn[0], e2_hn[0]], dim=1)\n",
    "\n",
    "        merge = self.fc1(merge)\n",
    "        merge = self.fc_drop1(merge)\n",
    "        merge = self.fc2(merge)\n",
    "        \n",
    "        out = torch.sigmoid(merge)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:06:09.240527Z",
     "start_time": "2021-12-06T03:06:00.147294Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ESMClassifier(esm_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:06:09.248949Z",
     "start_time": "2021-12-06T03:06:09.241780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESMClassifier(\n",
       "  (esm): ProteinBertModel(\n",
       "    (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (12): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (13): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (14): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (15): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (16): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (17): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (18): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (19): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (20): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (21): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (22): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (23): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (24): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (25): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (26): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (27): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (28): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (29): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (30): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (31): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (32): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (contact_head): ContactPredictionHead(\n",
       "      (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (embed_positions): LearnedPositionalEmbedding(1026, 1280, padding_idx=1)\n",
       "    (emb_layer_norm_before): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_head): RobertaLMHead(\n",
       "      (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pep_lstm1): LSTM(1280, 128, batch_first=True)\n",
       "  (pep_drop1): Dropout(p=0.2, inplace=False)\n",
       "  (ts_lstm1): LSTM(1280, 64, batch_first=True)\n",
       "  (ts_drop1): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=384, out_features=128, bias=True)\n",
       "  (fc_drop1): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:06:09.272123Z",
     "start_time": "2021-12-06T03:06:09.249953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------+\n",
      "|        Modules         | Parameters |\n",
      "+------------------------+------------+\n",
      "| pep_lstm1.weight_ih_l0 |   655360   |\n",
      "| pep_lstm1.weight_hh_l0 |   65536    |\n",
      "|  pep_lstm1.bias_ih_l0  |    512     |\n",
      "|  pep_lstm1.bias_hh_l0  |    512     |\n",
      "| ts_lstm1.weight_ih_l0  |   327680   |\n",
      "| ts_lstm1.weight_hh_l0  |   16384    |\n",
      "|  ts_lstm1.bias_ih_l0   |    256     |\n",
      "|  ts_lstm1.bias_hh_l0   |    256     |\n",
      "|       fc1.weight       |   49152    |\n",
      "|        fc1.bias        |    128     |\n",
      "|       fc2.weight       |    128     |\n",
      "|        fc2.bias        |     1      |\n",
      "+------------------------+------------+\n",
      "Total Trainable Params: 1115905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1115905"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)  # 1,115,905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:06:09.289727Z",
     "start_time": "2021-12-06T03:06:09.273446Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "# optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCELoss()\n",
    "# loss_fn = F.binary_cross_entropy()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "# warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps=warmup_step, t_total=t_total)\n",
    "\n",
    "def calc_accuracy(X,Y):\n",
    "    train_acc = ((X>0.5)==Y).sum().data.cpu().numpy() / len(Y)\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T06:38:18.863184Z",
     "start_time": "2021-12-06T03:06:09.290833Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 0.7014474272727966 train acc 0.484375 time 13.23\n",
      "epoch 1 batch id 201 loss 0.47278064489364624 train acc 0.734491604477612 time 2903.05\n",
      "epoch 1 batch id 401 loss 0.46440577507019043 train acc 0.7491817331670823 time 5813.78\n",
      "epoch 1 batch id 601 loss 0.4463101923465729 train acc 0.760412333610649 time 8728.18\n",
      "epoch 1 batch id 801 loss 0.45861536264419556 train acc 0.7678341526217228 time 11642.14\n",
      "epoch 1 batch id 1001 loss 0.47250211238861084 train acc 0.7724658154345654 time 14541.81\n",
      "epoch 1 batch id 1201 loss 0.42056262493133545 train acc 0.7769729652373022 time 17461.81\n",
      "epoch 1 batch id 1401 loss 0.4988987147808075 train acc 0.7810910733404711 time 20497.99\n",
      "epoch 1 batch id 1601 loss 0.4582826495170593 train acc 0.784377927857589 time 23535.84\n",
      "epoch 1 batch id 1801 loss 0.43541669845581055 train acc 0.7872904809827873 time 26573.63\n",
      "epoch 1 batch id 2001 loss 0.422135591506958 train acc 0.7895427286356822 time 29612.9\n",
      "epoch 1 train acc 0.7909517819309928 time 31468.17\n",
      "best_acc: 433.866875\n",
      "epoch 1 test acc 0.8170750941619586\n",
      "epoch 2 batch id 1 loss 0.3736893832683563 train acc 0.8359375 time 17.92\n",
      "epoch 2 batch id 201 loss 0.3700731098651886 train acc 0.8169504042288557 time 3053.3\n",
      "epoch 2 batch id 401 loss 0.37491655349731445 train acc 0.817448566084788 time 6102.82\n",
      "epoch 2 batch id 601 loss 0.39702171087265015 train acc 0.8181936356073212 time 9151.98\n",
      "epoch 2 batch id 801 loss 0.4369521141052246 train acc 0.8186349094881398 time 12201.6\n",
      "epoch 2 batch id 1001 loss 0.4158242344856262 train acc 0.8178969468031968 time 15250.3\n",
      "epoch 2 batch id 1201 loss 0.4134819805622101 train acc 0.8183089612822648 time 18298.35\n",
      "epoch 2 batch id 1401 loss 0.47545090317726135 train acc 0.8191554023911491 time 21344.84\n",
      "epoch 2 batch id 1601 loss 0.44242435693740845 train acc 0.8193951046221112 time 24391.93\n",
      "epoch 2 batch id 1801 loss 0.4147038757801056 train acc 0.8199329365630206 time 27439.41\n",
      "epoch 2 batch id 2001 loss 0.407921701669693 train acc 0.8202168447026487 time 30485.8\n",
      "epoch 2 train acc 0.8205229456719129 time 32346.17\n",
      "best_acc: 436.99296875\n",
      "epoch 2 test acc 0.8229622763653484\n",
      "epoch 3 batch id 1 loss 0.35581982135772705 train acc 0.8671875 time 17.8\n",
      "epoch 3 batch id 201 loss 0.35294631123542786 train acc 0.8275808457711443 time 2979.19\n",
      "epoch 3 batch id 401 loss 0.3576151132583618 train acc 0.8273262157107232 time 5916.01\n",
      "epoch 3 batch id 601 loss 0.4109393358230591 train acc 0.8272865536605657 time 8728.84\n",
      "epoch 3 batch id 801 loss 0.4137064814567566 train acc 0.8276958489388264 time 11541.65\n",
      "epoch 3 batch id 1001 loss 0.4045116603374481 train acc 0.8268645417082917 time 14354.13\n",
      "epoch 3 batch id 1201 loss 0.39971399307250977 train acc 0.827136240632806 time 17166.74\n",
      "epoch 3 batch id 1401 loss 0.4617411196231842 train acc 0.827595244468237 time 19979.24\n",
      "epoch 3 batch id 1601 loss 0.40063610672950745 train acc 0.8276516630231106 time 22790.82\n",
      "epoch 3 batch id 1801 loss 0.3941279649734497 train acc 0.8279493163520266 time 25601.36\n",
      "epoch 3 batch id 2001 loss 0.39050227403640747 train acc 0.8279844452773614 time 28412.09\n",
      "epoch 3 train acc 0.8282713398742265 time 30127.01\n",
      "best_acc: 438.3890625\n",
      "epoch 3 test acc 0.8255914548022599\n",
      "epoch 4 batch id 1 loss 0.35813984274864197 train acc 0.84375 time 16.55\n",
      "epoch 4 batch id 201 loss 0.3458420932292938 train acc 0.8332750310945274 time 2825.67\n",
      "epoch 4 batch id 401 loss 0.34281444549560547 train acc 0.8329664120947631 time 5637.24\n",
      "epoch 4 batch id 601 loss 0.3958311676979065 train acc 0.8331491784525791 time 8447.38\n",
      "epoch 4 batch id 801 loss 0.40512028336524963 train acc 0.8333382100499376 time 11257.43\n",
      "epoch 4 batch id 1001 loss 0.381834477186203 train acc 0.8324370941558441 time 14066.42\n",
      "epoch 4 batch id 1201 loss 0.3875032663345337 train acc 0.8325028621981682 time 16876.44\n",
      "epoch 4 batch id 1401 loss 0.4491596221923828 train acc 0.8331047019985724 time 19685.78\n",
      "epoch 4 batch id 1601 loss 0.3945976495742798 train acc 0.8331023579013117 time 22495.43\n",
      "epoch 4 batch id 1801 loss 0.38570436835289 train acc 0.8334497327873404 time 25305.07\n",
      "epoch 4 batch id 2001 loss 0.39159709215164185 train acc 0.8333509026736632 time 28116.0\n",
      "epoch 4 train acc 0.83358660377993 time 29831.09\n",
      "best_acc: 438.455\n",
      "epoch 4 test acc 0.8257156308851223\n",
      "epoch 5 batch id 1 loss 0.34961816668510437 train acc 0.84765625 time 16.56\n",
      "epoch 5 batch id 201 loss 0.3371316194534302 train acc 0.8377448694029851 time 2822.61\n",
      "epoch 5 batch id 401 loss 0.3299207091331482 train acc 0.8368726620947631 time 5632.28\n",
      "epoch 5 batch id 601 loss 0.3702012896537781 train acc 0.8377248856073212 time 8441.97\n",
      "epoch 5 batch id 801 loss 0.398671954870224 train acc 0.837712624843945 time 11250.72\n",
      "epoch 5 batch id 1001 loss 0.37484514713287354 train acc 0.8371433254245755 time 14060.08\n",
      "epoch 5 batch id 1201 loss 0.38097184896469116 train acc 0.8372157316819318 time 16869.3\n",
      "epoch 5 batch id 1401 loss 0.43144088983535767 train acc 0.8378334671663098 time 19678.62\n",
      "epoch 5 batch id 1601 loss 0.3680703341960907 train acc 0.8377942496876952 time 22485.83\n",
      "epoch 5 batch id 1801 loss 0.37337666749954224 train acc 0.8380760688506386 time 25292.9\n",
      "epoch 5 batch id 2001 loss 0.37638264894485474 train acc 0.8382410357321339 time 28099.72\n",
      "epoch 5 train acc 0.8385742450228678 time 29813.66\n",
      "best_acc: 438.501875\n",
      "epoch 5 test acc 0.8258039077212805\n",
      "epoch 6 batch id 1 loss 0.3367752432823181 train acc 0.8671875 time 16.74\n",
      "epoch 6 batch id 201 loss 0.3211454153060913 train acc 0.8432058457711443 time 2819.36\n",
      "epoch 6 batch id 401 loss 0.3416682481765747 train acc 0.8429025093516209 time 5612.96\n",
      "epoch 6 batch id 601 loss 0.36162111163139343 train acc 0.8431715370216306 time 8408.52\n",
      "epoch 6 batch id 801 loss 0.40250730514526367 train acc 0.8433013420724095 time 11206.55\n",
      "epoch 6 batch id 1001 loss 0.37087902426719666 train acc 0.8425753933566433 time 14003.9\n",
      "epoch 6 batch id 1201 loss 0.3508021831512451 train acc 0.8428197855953372 time 16800.36\n",
      "epoch 6 batch id 1401 loss 0.4169788360595703 train acc 0.8433680183797287 time 19607.35\n",
      "epoch 6 batch id 1601 loss 0.36928221583366394 train acc 0.8432644636164897 time 22416.16\n",
      "epoch 6 batch id 1801 loss 0.368892103433609 train acc 0.8435114172681843 time 25225.72\n",
      "epoch 6 batch id 2001 loss 0.3703499138355255 train acc 0.8435411200649675 time 28036.19\n",
      "epoch 6 train acc 0.8437108534268226 time 29751.66\n",
      "epoch 6 test acc 0.8254128413370999\n",
      "epoch 7 batch id 1 loss 0.33563271164894104 train acc 0.84375 time 16.57\n",
      "epoch 7 batch id 201 loss 0.32739490270614624 train acc 0.8471315298507462 time 2825.04\n",
      "epoch 7 batch id 401 loss 0.31559231877326965 train acc 0.8468477244389028 time 5631.72\n",
      "epoch 7 batch id 601 loss 0.3444342613220215 train acc 0.8471427828618968 time 8439.65\n",
      "epoch 7 batch id 801 loss 0.3882299065589905 train acc 0.8474611813358303 time 11246.47\n",
      "epoch 7 batch id 1001 loss 0.367300808429718 train acc 0.8468835851648352 time 14014.03\n",
      "epoch 7 batch id 1201 loss 0.34440672397613525 train acc 0.8470024979184013 time 16712.46\n",
      "epoch 7 batch id 1401 loss 0.42346838116645813 train acc 0.8477482601713062 time 19499.98\n",
      "epoch 7 batch id 1601 loss 0.33912795782089233 train acc 0.847641610712055 time 22286.86\n",
      "epoch 7 batch id 1801 loss 0.3533640205860138 train acc 0.8479403803442532 time 25106.01\n",
      "epoch 7 batch id 2001 loss 0.35235971212387085 train acc 0.8479744502748626 time 27892.34\n",
      "epoch 7 train acc 0.8481982592648641 time 29597.12\n",
      "epoch 7 test acc 0.8237882532956685\n",
      "epoch 8 batch id 1 loss 0.3315165638923645 train acc 0.8515625 time 16.47\n",
      "epoch 8 batch id 201 loss 0.317898690700531 train acc 0.8516402363184079 time 2810.67\n",
      "epoch 8 batch id 401 loss 0.31536391377449036 train acc 0.8513871571072319 time 5605.57\n",
      "epoch 8 batch id 601 loss 0.3314294219017029 train acc 0.8516729929284526 time 8401.86\n",
      "epoch 8 batch id 801 loss 0.37941446900367737 train acc 0.8519477606117354 time 11194.13\n",
      "epoch 8 batch id 1001 loss 0.34509900212287903 train acc 0.8511683628871128 time 13975.1\n",
      "epoch 8 batch id 1201 loss 0.32436156272888184 train acc 0.8513413301415487 time 16755.23\n",
      "epoch 8 batch id 1401 loss 0.4184137284755707 train acc 0.8519863044254105 time 19534.97\n",
      "epoch 8 batch id 1601 loss 0.3422645330429077 train acc 0.8519626405371643 time 22313.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch id 1801 loss 0.3338266909122467 train acc 0.8522760792615214 time 25092.12\n",
      "epoch 8 batch id 2001 loss 0.35759472846984863 train acc 0.852351168165917 time 27870.33\n",
      "epoch 8 train acc 0.8526160420029594 time 29440.64\n",
      "epoch 8 test acc 0.8223631709039547\n",
      "epoch 9 batch id 1 loss 0.32649242877960205 train acc 0.85546875 time 13.27\n",
      "epoch 9 batch id 201 loss 0.3079838752746582 train acc 0.8559351679104478 time 2169.78\n",
      "epoch 9 batch id 401 loss 0.32092398405075073 train acc 0.8559168485037406 time 4325.0\n",
      "epoch 9 batch id 601 loss 0.3183908760547638 train acc 0.8558457258735441 time 6481.06\n",
      "epoch 9 batch id 801 loss 0.38080787658691406 train acc 0.8565903948189763 time 8636.99\n",
      "epoch 9 batch id 1001 loss 0.32872018218040466 train acc 0.855726304945055 time 10792.85\n",
      "epoch 9 batch id 1201 loss 0.31729385256767273 train acc 0.8559598771856786 time 12948.38\n",
      "epoch 9 batch id 1401 loss 0.4225287437438965 train acc 0.8564808618843683 time 15104.64\n",
      "epoch 9 batch id 1601 loss 0.3275820016860962 train acc 0.8562153536851967 time 17261.07\n",
      "epoch 9 batch id 1801 loss 0.33029139041900635 train acc 0.8565532169627984 time 19418.04\n",
      "epoch 9 batch id 2001 loss 0.3456750512123108 train acc 0.8566341829085458 time 21575.19\n",
      "epoch 9 train acc 0.856812607193301 time 22890.82\n",
      "epoch 9 test acc 0.8219974105461393\n",
      "epoch 10 batch id 1 loss 0.3267788290977478 train acc 0.859375 time 13.24\n",
      "epoch 10 batch id 201 loss 0.308490514755249 train acc 0.859355565920398 time 2170.13\n",
      "epoch 10 batch id 401 loss 0.326839417219162 train acc 0.8598133572319202 time 4325.07\n",
      "epoch 10 batch id 601 loss 0.30198755860328674 train acc 0.859771474625624 time 6481.96\n",
      "epoch 10 batch id 801 loss 0.35966062545776367 train acc 0.860491768102372 time 8638.75\n",
      "epoch 10 batch id 1001 loss 0.3148542046546936 train acc 0.8599213286713286 time 10795.36\n",
      "epoch 10 batch id 1201 loss 0.3172857165336609 train acc 0.8599116621565362 time 12951.44\n",
      "epoch 10 batch id 1401 loss 0.406475305557251 train acc 0.8602867371520343 time 15108.01\n",
      "epoch 10 batch id 1601 loss 0.30958858132362366 train acc 0.8602850757339163 time 17264.61\n",
      "epoch 10 batch id 1801 loss 0.32609716057777405 train acc 0.8604876631038312 time 19421.22\n",
      "epoch 10 batch id 2001 loss 0.36527979373931885 train acc 0.8603588830584707 time 21577.15\n",
      "epoch 10 train acc 0.8604729431497176 time 22892.42\n",
      "epoch 10 test acc 0.819579213747646\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "for e in range(num_epochs):\n",
    "    t0 = time.time()\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for batch_id, (pep_token_ids, n_token_ids, c_token_ids, m1_token_ids, m2_token_ids, label) in enumerate(train_dataloader):\n",
    "#         print(batch_id, round(time.time()-t0, 2))  # batch256->2100 loop, each 5 sec -> per 1 epoch, 3h\n",
    "        \n",
    "        pep_token_ids = pep_token_ids.long().to(device)\n",
    "        n_token_ids = n_token_ids.long().to(device)\n",
    "        c_token_ids = c_token_ids.long().to(device)\n",
    "        m1_token_ids = m1_token_ids.long().to(device)\n",
    "        m2_token_ids = m2_token_ids.long().to(device)\n",
    "        label = torch.reshape(label.float(), (-1, 1)).to(device)\n",
    "        \n",
    "        pred = model(pep_token_ids, n_token_ids, c_token_ids, m1_token_ids, m2_token_ids)\n",
    "        loss = F.binary_cross_entropy(pred, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_acc += calc_accuracy(pred, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {} time {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1), round(time.time()-t0, 2)))\n",
    "        \n",
    "    print(\"epoch {} train acc {} time {}\".format(e+1, train_acc / (batch_id+1), round(time.time()-t0,2)))\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_id, (pep_token_ids, n_token_ids, c_token_ids, m1_token_ids, m2_token_ids, label) in enumerate(valid_dataloader):\n",
    "        pep_token_ids = pep_token_ids.long().to(device)\n",
    "        n_token_ids = n_token_ids.long().to(device)\n",
    "        c_token_ids = c_token_ids.long().to(device)\n",
    "        m1_token_ids = m1_token_ids.long().to(device)\n",
    "        m2_token_ids = m2_token_ids.long().to(device)\n",
    "        label = label.long().to(device)\n",
    "        label = torch.reshape(label, (-1, 1))\n",
    "        pred = model(pep_token_ids, n_token_ids, c_token_ids, m1_token_ids, m2_token_ids)\n",
    "        \n",
    "        test_acc += calc_accuracy(pred, label)\n",
    "    if (test_acc / (batch_id+1))> best_acc:\n",
    "        best_acc=test_acc\n",
    "        torch.save({\"best_acc\":best_acc / (batch_id+1),\"model\":model.state_dict()},f'./lowParam/low.pl')\n",
    "        print(f\"best_acc: {best_acc}\")\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T18:57:35.166975Z",
     "start_time": "2021-12-12T17:57:34.610557Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_id, (pep_token_ids, n_token_ids, c_token_ids, m1_token_ids, m2_token_ids, label) in enumerate(test_dataloader):\n",
    "        pep_token_ids = pep_token_ids.long().to(device)\n",
    "        n_token_ids = n_token_ids.long().to(device)\n",
    "        c_token_ids = c_token_ids.long().to(device)\n",
    "        m1_token_ids = m1_token_ids.long().to(device)\n",
    "        m2_token_ids = m2_token_ids.long().to(device)\n",
    "        label = label.long().to(device)\n",
    "        label = torch.reshape(label, (-1, 1))\n",
    "\n",
    "        pred_batch = model(pep_token_ids, n_token_ids, c_token_ids, m1_token_ids, m2_token_ids)\n",
    "        pred += list(pred_batch)\n",
    "        test_acc += calc_accuracy(pred_batch, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T20:02:18.912957Z",
     "start_time": "2021-12-12T20:02:00.318783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83     66996\n",
      "           1       0.82      0.83      0.83     66996\n",
      "\n",
      "    accuracy                           0.83    133992\n",
      "   macro avg       0.83      0.83      0.83    133992\n",
      "weighted avg       0.83      0.83      0.83    133992\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAADCCAYAAADTjffnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVe0lEQVR4nO3deXwUVbbA8d/pJBA2EcQwGkbEUVlkGRV0EFDBEMBhEZAd2cUNFJV1YHDQERQVBQEVHUARWUTCKoiCb5BdGGQbNmV5g/BYlGEzCUnnvj86hCbpdFXSlaQ6nK+f+ki66nTd4pPDvXX71mkxxqCUCp2noBugVGGhyaSUQzSZlHKIJpNSDtFkUsohmkxKOSQyr09QrPbzOvee7pd14wq6Ca5RvIhIsP3F7uxn+XuTuHVi0PfIb3meTErliieioFuQY5pMyp0k/O5ANJmUO4VhzxR+6a+uDiLWm+VbSFMR2SsiP4rI0CDH1RERr4g8mtNYf5pMyp08EdZbECISAUwCmgHVgE4iUi2b414HvsppbJYm5+DylMo/4rHegrsH+NEYc8AYcxGYDbQKcFx/4AvgRC5ir6DJpNzJRs8kIn1FZLPf1tfvHWKB//j9fCT9tQwiEgu0Bt7PdHbL2EB0AkK5k40JCGPMFGBKNrsD3VRl/uzqHWCIMcYrV96D2YnNQpNJuVPoU+NHgN/7/VwBOJrpmNrA7PREKgc8LCKpNmOz0GRS7hQR8tT498BtIlIJ+BnoCHT2P8AYU+nSn0VkOrDEGLNARCKtYgPRZFLuZGPqOxhjTKqI9MM3SxcBTDXG7BKRJ9P3Z75Psoy1Oqcmk3InBz60NcZ8CXyZ6bWASWSM6WEVa0WTSbmTLidSyiFhuJxIk0m5U4j3TAVBk0m5k/ZMSjnEE36/muHXYnV10GGeUg7RYZ5SDtGpcaWcIR5NJqUcIXrPpJQzxKPJpJQjPDrMU8oZOsxTyiE6zFPKIeHYM4XfwFRdFTwej+Vmxar2nYi0EpHtIvJDekGW+n77DonIjkv77LRZeyblTiF2TH617xrjq+nwvYgsMsb82++wlcAiY4wRkZrAXKCK3/6GxphTds+pyaRcyYHZvIzadwAicqn2XUYyGWPO+x1fAhsViILRYZ5yJfGI5WbBVu07EWktInuApUAvv10GWCEiWzLV48uWJpNyJRGxswUrQmmr9p0xJsEYUwV4BHjFb1c9Y8xd+EokPyMi91u1WYd5ypXsDPMsilDmqPadMWa1iPxBRMoZY04ZY46mv35CRBLwDRtXB22zZYuVKgB2eiYLGXXzRKQIvtp3izKd41ZJfyMRuQsoAvwiIiVEpFT66yWAeGCn1Qm1Z1KuFOqHtjbr5rUFuolICpAIdEif2SsPJKTnWSTwmTFmudU5wyKZPB5h7YwXOHriDG2f/4g2D9VieN+mVKkUQ4Pu7/Cv3f8JGPf+yI40q1+Nk6fPU7vD2IzXRz/bgofvv4OLKV4OHjlF31GzOHM+ibq1KjF+6KNcvJhKt+EzOHDkFKVLRjNjTHda9v8gvy7Xlk8/mU7C/HmICLfedhujXhlD0aJFM/afO3eOEcMGcezYMbxeL92696RV67ZBY8ePe5O1a1Zze5Wq/H306wAsWbyQs2fO0Llrt3y9Pic+tLWqm2eMeR3f18lkjjsA1Mrp+cJimNev0/3sPXg84+ddPx2j4+CprNl6IGjcjMWbaNU/65B65cZ93N1hLPd0eoP9/3uSQT3jAHiuy4N0GjyNkZOX0vfR+wAY1ieesdO+cfBqQnfi+HFmfTaDmbPnMS9hMWneNL5atvSKY+bOnsktt9zK3C8W8uHUTxj35lhSUi5mG3vu3Dm2bdvK3PmLSPN62b9vL0lJSSxemEC7Dp3y/RodmM3Ld65PptiY0jStV41pCzZkvLb30An2Hz5pGbt26wF+PXshy+srN+7F600DYNOOw8TGXAtASqqXYkWjKB5dhJTUNCrFXseNMaVZ86+fnLkYB3lTvSQnJ5GamkpSUiLXx8RceYAIF367gDGGxN9+o3Tp0kRERGYb6/EIKSkpGGNITk4mMjKKj6f9g46dHyMqKirfr8+JFRD5zXKYJyJV8H3YFYtvavEovk+Nd+dx2wB448XWDJ+wmJIlilofnAvdWt7LvK+3+s41/RsmDW9PYnIKvUfOZMyAlox6b1menDcUMeXL061HL5o1bkTR6KLUrVuPuvfVv+KYjp26MKD/08Q3up8LFy7w+pvj8Hg8QWMfiounY7vW3HPvnyhZqiT/3rWDJ556piAusfCtzRORIfi+NU2ATfhmSASYZfEdoRnz/6knd+S6cc3qV+PEr+fYuudIrt8jmMG94vB6vcxetgWA7fuO8kDP8TR9cjI3x17HsZNnERFmjO7G1Je7EFO2ZJ60I6fOnjnD/3y7kiXLv2HFytUkJiaydPEVE1WsW7uGypWrsmLVambPS+C10a9w/vz5oLE9evVhzrwFvDhoKJMnTuCpZ55l/hefM/jFAXz4wXv5eo2FcZjXG6hjjHnNGPNp+vYavjn33tkFGWOmGGNqG2NqR15fI9eNq1urEs3vr86eRX/lk1e78WCd25j6cpdcv5+/Ln+uw8P176DHiE8D7h/aO54xH61g+ONNeOWD5cxatoWnO1p+bpcvNm5Yz42xFShbtixRUVE0imvMtm1brzhm0YIEGsU1RkS46aaKxMZW4NDBA7Zi9+z2rbipWPFmlixayNi33uHHH/dz+PCh/LpEJ6bG853VMC8NuBE4nOn1G9L35amRk5YycpLvxrrB3X9gQNeG9Bo5M+T3bVy3Ci92b0R834kkJqdk2d+1eR2Wr/k3/z2XSPHoKNKMIS3NUDy6SMjndsLvbriBHdu3kZiYSHR0NJs2rqdatepZjtm0cT133V2bX06d4tChg8RW+D3GGMvYyRPHM+Kll0lNTSUtzQuAR4SkpKR8u0aPC3seK1bJNABYKSL7ubzO6SbgVqBfHrYrqJYP1mDcoDaUK1OS+e88zvZ9P9Oy/wfcUO4aJv+1A62f+xCAj199jAZ330q5a0vw49KXeGXKcj5euJG3B7ehaFQkSyY9BcCmnYd5dsznABQrGkXX5nVo/oxvBnXCzH8ya2wPLqZ46T58RsFccCY1atYirnE8ndu3ISIykipVqtK2XQc+nzsbgHbtO/L4E0/x0ohhtGvdAgM8N2AgZcqUoUyZMgFjL/l25TfcUb0GMTHlAahZ64+0a92C226vTOXKVQI1J0+4seexIsYEXygrIh58w7pYfPdLR4DvjTFeOycoVvv5kFbiFia/rBtX0E1wjeJFgmdL5SFfWf7e7H29iasyznI2zxiTBmywOk4pJ0VEuCpPbAmLFRDq6hOGozxNJuVOhXECQqkCEY4TEJpMypW0Z1LKIdozKeUQ7ZmUckg4JpP71rErhW9q3Gqzfo+QilAGjQ1EeyblSqH2TKEUobQZm7XNIbVYqTziwKrxjCKUxpiL+B4lauV/gDHmvLm8ns6/CKVlbCCaTMqVPB6x3CyEUoTSVmyWNlsdoFRBsHPPlIdFKG3FZqb3TMqVCrIIZU5jM9ps2WKlCoADw7xcF6G0ExuI9kzKlUJdABFKEUogYKzVOTWZlCs58aFtbotQZhdrRZNJuZJH1+Yp5YxwXE6kyaRcKQxzSZNJuZP2TEo5JELvmZRyhj4cqJRDInSYp5QzwrBj0mRS7qQTEEo5RD+0VcohmkxKOUQnIJRySBh2TJpMyp20Z1LKIfqhrVIOCcflRPrYunKlfCpC2SW9COV2EVknIrX89h0SkR2XClTaabP2TMqV8qkI5UHgAWPMaRFphq84y71++xsaY07ZPacmk3IlByYgMgpJAojIpUKSGclkjFnnd/wGfFWIci3Pk+n0hrfz+hRho0ydAvuCetdJ3Dox6H47ExDpdfL8a+VNSS//BYELSfr3Opn1Bpb5/WyAFSJigA/83jdb2jMpV7IzAWFRN892IUkRaYgvmer7vVzPGHNURGKAr0VkjzFmdbD26ASEciWPWG8WbBWSTC/Y/xHQyhjzy6XXjTFH0/9/AkjAN2wM3mbLJilVACI8YrlZsFOE8iZgPvCYMWaf3+slRKTUpT8D8cBOqxPqME+5UqjzDzaLUI4ErgMmp9+jpRpjagPlgYT01yKBz4wxy63OqcmkXMmJ5UQ2ilD2AfoEiDsA1Mr8uhVNJuVKEeG3AEKTSbmTPs+klEMiwnBqTJNJuZL2TEo5RHsmpRwiARcwuJsmk3KlSO2ZlHKGPraulEPCcP5Bk0m5U6T2TEo5Q3smpRwSjgVVNJmUK4XhKE+TSbmTzuYp5ZBwXE4Uhh+NqatBhFhvVkKsmxc0NhDtmZQrhdozhVI3z2Zs1jaH1GKl8ohHxHKzkFE3zxhzEbhUNy+DMWadMeZ0+o/+dfMsYwO2OQfXp1S+caA6UaC6ebFBjvevm5fTWECHecqlHChCGUrdPNux/jSZlCs5UIQyp3XzmvnVzbMVm5kO85QriY3NQq7r5tmJDUR7JuVKoS4nCqVuXnaxVufUZFKu5MSHtrmtm5ddrBVNJuVKYbgAQpNJuZOuGlfKIVpQRSmHaM+klEPCMJc0mZQ7heMjGJpMypXCcZgXVisgZnw8ndYt/0ybVs0ZMvAFkpOTAx63c8d27qxRla+/Wm4Z+/Zbb/Bo6xYMHzY449jFixYwc8bHeXsxueTxCOtnDeGL8U8C0CbuTrbMG86FLRO4q9pN2cbtWTqK7+f+hQ2zh7Jm5uVrHT3gEX6YP4JNc4Yx563HKV2yGAB1a93CpjnDWPPpIG75fTkASpcsxqJJz+Th1V0mYr25Tdgk0/Hjx/ls5ifMmvsF8xcuIS3Ny/Ivl2Y5zuv18s64N7mvXn3L2HPnzrHth63MS1hMmtfL/n17SUpKYtGCBNp37Jyfl2dbv84N2XvweMbPu346SscXP2TNv36yjG3adzx/6vga9buMzXht5YY93N1uNPd0GMP+wycY1CsegOcea0SnQR8x8t3F9G3XAIBhfZsydupXDl9RYBEilpvbhE0ygS9RkpOSSE1NJTEpietjYrIcM2vmDOIaN6Fs2essYz0eISUlBWMMScnJREZGMn3qR3Tu+hhRUVH5dVm2xcZcS9P6dzAtYV3Ga3sPHmf/4RO5fs+VG/bg9aYBsGnHQWLLXwtASqqXYkWjKF4sipRUL5UqlOPGmGtZs+XHkK7BLrHxn9uETTKVL1+e7j160SSuIXEP1qdUyZJX9D7g64FWrfyGdh062ootUaIkcY3j6dD2EWJjK1CyVCl27dxJw0Zx+Xlptr0xqC3Dxy8gLc3yaYAsjDEsntyPtTMH06tNvYDHdGtVl6/W+h4mfWPqCiaN6ES/zg15f/ZqRvVrwajJS0Jqf0448DxTvst1MolIzyD7+orIZhHZ/I8Ps1shnzNnz5zh21Ur+XLFSr7+9jsSExNZsnjhFce88dqrDHhhIBEREbZje/Z+nLnzFzJw8FAmvTuep/s/y/x5nzPoheeY8v5kR9ruhGYNqnPi13Ns3f0f64MDaNTzbe7r/DqP9JvMEx0aUO+uP1yxf3DvJni9acz+8nsAtu/7mQe6v0XTvhO4ucJ1HDt5BkGY8VpPpv69GzFlS4V8TcE48KRtvgtlNm8UMC3QDv/nTJJSrR+qsmPDhnXEVqhA2bJlAXgoLp5tW7fSvMXlp4l37drJkIEvAHD69Gm+++6fRERGkpqaYhm7e7fvX+SKFW9m7JhXmfbJTAYPfJ7Dhw9RseLNTlxCSOr+8RaaP1CDpvXvoGiRKK4pEc3Uv3ej14hPbMUfO3kGgJOnz7No1Xbq3HEza9Pvs7q0uJeH769OsycmBIwd2qcpjw2ZyttD2/PK+19S8cayPN3pQf42abEzFxeAC3PFUtBkEpHt2e3C9/Xu+eZ3N9zI9m3bSExMJDo6mo0b1lOtevUrjlm2YlXGn//6l6Hc/8CDNHooju3bt1nGTnp3PCP/9jKpqamkeb0AeMRDUmJS3l+cDSPfXcTId32P1DS4+zYGdHvIdiIVjy6CxyOc/y2Z4tFFiKtbhdFTfE9oN76vKi/2iCO+z3gSk1KyxHZtcS/Lv9vFf88lUjy6CGlphrQ0Q/HovL2ndGPPY8WqZyoPNAFOZ3pdgHVZD887NWvWonF8Ezq2a01ERCRVqlbl0XYdmDtnFgDtO3TKcewlq1Z+Q/XqNYiJ8f37UPOPd9L2kRbcfvvtVK5SJW8vLEQtG9Zk3JB2lCtTkvkTnmT73p9p+cwkbri+NJNHdqZ1//eIua4Uc8Y9DkBkRARzlm3m63W7AXh7SHuKFolkyXv9ANi04xDPvjobgGLRUXRtcS/Nn54IwIRPVzHrzT5cTEml+7DpeXpd4ZdKIMZkPwoTkX8A04wxawLs+8wYYzl/7NQwrzAoU6dfQTfBNRK3TgyaL5sPnrX8vald6RpX5VzQCQhjTO9AiZS+z50fxKhCwYkPbW0UoawiIutFJFlEBmbad0hEdojIDyKy2U6bdTmRcqVQb5lsFpL8FXgWeCSbt2lojDll95xh8zmTuro48KGtnSKUJ4wx3wNZZ15yQZNJuVIBFKHMzAArRGRLen0+SzrMU66Un0Uos1HPGHNURGKAr0VkjzFmdbAATSblSnbumZwoQhnkvY+m//+EiCTgGzYGTSYd5ilXcmA2L1eFJH3nlhIiUurSn4F4YKdVnPZMypVCXRVupwiliPwO2AxcA6SJyACgGlAOSEgfakYCnxljlgc4zRU0mZQrObEq3EYRyv/j8tfI+DsL1ArwelCaTMqdXLW2wR5NJuVKhXGhq1IFIgxzSZNJuZMbH0u3osmkXMmNj6Vb0WRS7qTJpJQzdAJCKYeEXyppMimXsrPQ1W00mZQr6QSEUg4Jw45Jk0m5kw7zlHJI+KWSJpNyKZ0aV8op4ZdLmkzKncJxNk8fW1euJCKWm433CKUIZdDYQDSZlCuJjS1o/OUilM3wPYreSUSqZTrsUhHKN3MRm4Umk3IlB76fKZQilJaxAdts9+KUyk92qhP5f6le+uZfQy+UIpS5itUJCOVKDtTNC6UIZa5iNZmUKznwpG0oRShzFavDPOVKDtQaz3URytzGas+kXCnUtXmhFKE0xpwNFGvZ5mDfHOgE/ebAy/SbAy+z+ubACxetfzFLFHHXmiPtmZQruStN7NFkUq4UjqW+8nyY5xYi0tfvu3uuavp3kTeuptk8W9/+dpXQv4s8cDUlk1J5SpNJKYdcTcmk9wiX6d9FHrhqJiCUymtXU8+kVJ4q9MmUmycmCysRmSoiJ0TE8suOVc4V6mTK7ROThdh0oGlBN6KwKtTJRC6fmCysjDGr8T2qrfJAYU+mUJ62VCpHCnsyhfK0pVI5UtiTKZSnLZXKkcKeTKE8balUjhTqZDLGpAKXnpjcDcy188RkYSUis4D1QGUROSIivQu6TYWJroBQyiGFumdSKj9pMinlEE0mpRyiyaSUQzSZlHKIJpNSDtFkUsohmkxKOeT/AaMXNc9EyQxTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8263254522658069\n"
     ]
    }
   ],
   "source": [
    "y_test = test.ID.values\n",
    "y_pred = [1 if _ >= 0.5 else 0 for _ in pred]\n",
    "print(classification_report(y_test, y_pred))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=',.0f')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "plt.show()\n",
    "\n",
    "print('accuracy:', sum(np.array(y_pred)==y_test)/ len (y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T21:15:32.413197Z",
     "start_time": "2021-12-12T21:15:30.601250Z"
    }
   },
   "outputs": [],
   "source": [
    "probs = [_.cpu().numpy() for _ in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T21:15:37.451749Z",
     "start_time": "2021-12-12T21:15:36.969540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf auc : 0.9022046666888106\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_auc = roc_auc_score(y_test, probs)\n",
    "\n",
    "\n",
    "print('rf auc : {}'.format(rf_auc))\n",
    "# plot the roc curve for the model_high\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, probs)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='RF AUC = {:.4f}'.format(rf_auc), color='orange')\n",
    "plt.title('ROC curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T21:17:31.695340Z",
     "start_time": "2021-12-12T21:17:24.921111Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({\"model\":model.state_dict()},f'./lowParam/low2.pl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProtEmbedding",
   "language": "python",
   "name": "protembedding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
