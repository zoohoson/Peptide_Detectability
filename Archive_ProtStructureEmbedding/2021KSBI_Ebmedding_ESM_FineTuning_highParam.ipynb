{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T02:58:48.207342Z",
     "start_time": "2021-12-06T02:58:47.362184Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T02:58:48.857548Z",
     "start_time": "2021-12-06T02:58:48.846788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 21)\n"
     ]
    }
   ],
   "source": [
    "df_aaindex = pd.read_csv('../data/aaindex/df_aaindex19.csv')\n",
    "print(df_aaindex.shape)\n",
    "df_aaindex.head(1)\n",
    "tmp = df_aaindex.drop('Unnamed: 0',axis=1).T\n",
    "aa2val = dict()\n",
    "for aa, val in zip(tmp.index, tmp.values):\n",
    "    aa2val[aa]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T02:58:51.800190Z",
     "start_time": "2021-12-06T02:58:49.047389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide</th>\n",
       "      <th>En</th>\n",
       "      <th>Ec</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>protein</th>\n",
       "      <th>PEP</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>595411</th>\n",
       "      <td>K.QELNEPPKQSTSFLVLQEILESEEKGDPNK.P</td>\n",
       "      <td>VYKMLQEKQELNEPP</td>\n",
       "      <td>EEKGDPNKPSGFRSV</td>\n",
       "      <td>QELNEPPKQSTSFLV</td>\n",
       "      <td>EILESEEKGDPNKPS</td>\n",
       "      <td>sp|O00151|PDLI1_HUMAN</td>\n",
       "      <td>QELNEPPKQSTSFLVLQEILESEEKGDPNK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   peptide               En               Ec  \\\n",
       "595411  K.QELNEPPKQSTSFLVLQEILESEEKGDPNK.P  VYKMLQEKQELNEPP  EEKGDPNKPSGFRSV   \n",
       "\n",
       "                     E1               E2                protein  \\\n",
       "595411  QELNEPPKQSTSFLV  EILESEEKGDPNKPS  sp|O00151|PDLI1_HUMAN   \n",
       "\n",
       "                                   PEP  ID  \n",
       "595411  QELNEPPKQSTSFLVLQEILESEEKGDPNK   0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detect_peptide_train = pd.read_csv('../data/df_detect_peptide_train.csv')\n",
    "test = pd.read_csv('../data/df_detect_peptide_test.csv')\n",
    "train, val = train_test_split(df_detect_peptide_train, test_size=0.2, random_state=7)\n",
    "\n",
    "df = pd.concat([train, val, test], axis=0).reset_index(drop=True)\n",
    "\n",
    "train_idx = df.iloc[:len(train), :].index\n",
    "val_idx = df.iloc[len(train):len(train)+len(val), :].index\n",
    "test_idx = df.iloc[len(train)+len(val):, :].index\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T02:58:52.562349Z",
     "start_time": "2021-12-06T02:58:51.801420Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "PATH_TO_REPO = \"/home/bis/2021_AIhub/esm/\"\n",
    "sys.path.append(PATH_TO_REPO)\n",
    "\n",
    "import torch\n",
    "import esm\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import time\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AdamW\n",
    "# from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from transformers import WarmupLinearSchedule as get_linear_schedule_with_warmup\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T02:58:52.566621Z",
     "start_time": "2021-12-06T02:58:52.564236Z"
    }
   },
   "outputs": [],
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T02:59:05.420761Z",
     "start_time": "2021-12-06T02:58:52.567824Z"
    }
   },
   "outputs": [],
   "source": [
    "esm_model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "batch_converter = alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T02:59:05.429469Z",
     "start_time": "2021-12-06T02:59:05.422641Z"
    }
   },
   "outputs": [],
   "source": [
    "ct = 0\n",
    "for child in esm_model.children():\n",
    "    ct += 1\n",
    "#     print(ct, child)\n",
    "    if ct < 7:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T02:59:05.442711Z",
     "start_time": "2021-12-06T02:59:05.430548Z"
    }
   },
   "outputs": [],
   "source": [
    "class ESMDataset(Dataset):\n",
    "    def __init__(self, datasets, idxes):\n",
    "        pep_idx, nterm_idx, cterm_idx, m1term_idx, m2term_idx, label_idx = idxes\n",
    "        pep_data = [(label, seq) for label, seq in zip(datasets[:, label_idx], datasets[:, pep_idx])]\n",
    "        nterm_data = [(label, seq) for label, seq in zip(datasets[:, label_idx], datasets[:, nterm_idx])]\n",
    "        cterm_data = [(label, seq) for label, seq in zip(datasets[:, label_idx], datasets[:, cterm_idx])]\n",
    "        m1_data = [(label, seq) for label, seq in zip(datasets[:, label_idx], datasets[:, m1term_idx])]\n",
    "        m2_data = [(label, seq) for label, seq in zip(datasets[:, label_idx], datasets[:, m2term_idx])]\n",
    "        \n",
    "        labels, pep_strs, pep_tokens = batch_converter(pep_data)\n",
    "        _, n_strs, n_tokens = batch_converter(nterm_data)\n",
    "        _, c_strs, c_tokens = batch_converter(cterm_data)\n",
    "        _, m1_strs, m1_tokens = batch_converter(m1_data)\n",
    "        _, m2_strs, m2_tokens = batch_converter(m2_data)\n",
    "\n",
    "        self.sentences = [pep_tokens, n_tokens, c_tokens, m1_tokens, m2_tokens]\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (\n",
    "                (self.sentences[0][i], ) + (self.sentences[1][i],) \\\n",
    "                + (self.sentences[2][i], ) + (self.sentences[3][i], ) + (self.sentences[4][i], ) \\\n",
    "                + (self.labels[i], )\n",
    "               )\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n",
    "\n",
    "# [PAD] = 1, [MASK] = 21  [CLS] = 0 (special classification token), [SEP] = 2 (seperate segment), Z = 27, '-' = 30, .=29, ,=28\n",
    "# J 없음\n",
    "# A 2, B 25, C 23, D 13, E 9, F 18, G 6, H 21, I 12, K 15, L 4, M 20, N 17, \n",
    "# O 28, P 14, Q 16, R 10, S 8, T 11, U 26, V 7, W 22, X 24, Y 19, Z 27\n",
    "# 3 5 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T02:59:05.450051Z",
     "start_time": "2021-12-06T02:59:05.444133Z"
    }
   },
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 30\n",
    "batch_size = 256\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:07:00.388999Z",
     "start_time": "2021-12-06T02:59:05.451268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474.93 sec\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "dataset_train = train[['PEP', 'En', 'Ec', 'E1', 'E2', 'ID']].values\n",
    "dataset_valid = val[['PEP', 'En', 'Ec', 'E1', 'E2', 'ID']].values\n",
    "dataset_test = test[['PEP', 'En', 'Ec', 'E1', 'E2', 'ID']].values\n",
    "\n",
    "data_train = ESMDataset(dataset_train, [0, 1, 2, 3, 4, 5])\n",
    "data_valid = ESMDataset(dataset_valid, [0, 1, 2, 3, 4, 5])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=48)\n",
    "valid_dataloader = torch.utils.data.DataLoader(data_valid, batch_size=batch_size, num_workers=48)\n",
    "\n",
    "e = time.time()\n",
    "print(round(e-s, 2),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T16:05:04.992798Z",
     "start_time": "2021-12-12T16:03:34.317342Z"
    }
   },
   "outputs": [],
   "source": [
    "data_test = ESMDataset(dataset_test, [0, 1, 2, 3, 4, 5])\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:07:00.407120Z",
     "start_time": "2021-12-06T03:07:00.390437Z"
    }
   },
   "outputs": [],
   "source": [
    "class ESMClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 esm,\n",
    "                 num_classes=1,\n",
    "                 params=None):\n",
    "        \n",
    "        super(ESMClassifier, self).__init__()\n",
    "        self.esm = esm\n",
    "        self.pep_lstm1 = nn.LSTM(input_size=1280, hidden_size=512, batch_first=True)\n",
    "        self.pep_drop1 = nn.Dropout(p=0.2)\n",
    "        self.pep_lstm2 = nn.LSTM(input_size=512, hidden_size=256, batch_first=True)\n",
    "        self.pep_drop2 = nn.Dropout(p=0.2)\n",
    "        self.pep_lstm3 = nn.LSTM(input_size=256, hidden_size=128, batch_first=True)\n",
    "        self.pep_drop3 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.ts_lstm1 = nn.LSTM(input_size=1280, hidden_size=512, batch_first=True)\n",
    "        self.ts_drop1 = nn.Dropout(p=0.2)\n",
    "        self.ts_lstm2 = nn.LSTM(input_size=512, hidden_size=128, batch_first=True)\n",
    "        self.ts_drop2 = nn.Dropout(p=0.2)\n",
    "        self.ts_lstm3 = nn.LSTM(input_size=128, hidden_size=64,  batch_first=True)\n",
    "        self.ts_drop3 = nn.Dropout(p=0.2)\n",
    "                \n",
    "        self.fc1 = nn.Linear(384, 256)\n",
    "        self.fc_drop1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc_drop2 = nn.Dropout(p=0.2)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "\n",
    "#     def gen_attention_mask(self, token_ids, valid_length):\n",
    "#         attention_mask = torch.zeros_like(token_ids)\n",
    "#         for i, v in enumerate(valid_length):\n",
    "#             attention_mask[i][:v] = 1\n",
    "#         return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, en_token_ids, ec_token_ids, e1_token_ids, e2_token_ids):\n",
    "#         attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        pep_embed = self.esm(token_ids, repr_layers=[33])['representations'][33]\n",
    "        pep_lstm, (pep_hn, __) = self.pep_lstm1(pep_embed)\n",
    "        pep_hn = self.pep_drop1(pep_hn)\n",
    "        pep_lstm, (_, __) = self.pep_lstm2(pep_lstm)\n",
    "        pep_lstm = self.pep_drop2(pep_lstm)\n",
    "        _, (pep_hn, __) = self.pep_lstm3(pep_lstm)\n",
    "        pep_hn = self.pep_drop3(pep_hn)\n",
    "        \n",
    "        en_embed = self.esm(en_token_ids, repr_layers=[33])['representations'][33]\n",
    "        ec_embed = self.esm(ec_token_ids, repr_layers=[33])['representations'][33]\n",
    "        e1_embed = self.esm(e1_token_ids, repr_layers=[33])['representations'][33]\n",
    "        e2_embed = self.esm(e2_token_ids, repr_layers=[33])['representations'][33]\n",
    "        \n",
    "        en_lstm, (_, __) = self.ts_lstm1(en_embed)\n",
    "        en_lstm = self.ts_drop1(en_lstm)\n",
    "        en_lstm, (_, __) = self.ts_lstm2(en_lstm)\n",
    "        en_lstm = self.ts_drop2(en_lstm)\n",
    "        _, (en_hn, __) = self.ts_lstm3(en_lstm)\n",
    "        en_hn = self.ts_drop3(en_hn)\n",
    "        \n",
    "        ec_lstm, (_, __) = self.ts_lstm1(ec_embed)\n",
    "        ec_lstm = self.ts_drop1(ec_lstm)\n",
    "        ec_lstm, (_, __) = self.ts_lstm2(ec_lstm)\n",
    "        ec_lstm = self.ts_drop2(ec_lstm)\n",
    "        _, (ec_hn, __) = self.ts_lstm3(ec_lstm)\n",
    "        ec_hn = self.ts_drop3(ec_hn)\n",
    "        \n",
    "        e1_lstm, (_, __) = self.ts_lstm1(e1_embed)\n",
    "        e1_lstm = self.ts_drop1(e1_lstm)\n",
    "        e1_lstm, (_, __) = self.ts_lstm2(e1_lstm)\n",
    "        e1_lstm = self.ts_drop2(e1_lstm)\n",
    "        _, (e1_hn, __) = self.ts_lstm3(e1_lstm)\n",
    "        e1_hn = self.ts_drop3(e1_hn)\n",
    "        \n",
    "        e2_lstm, (_, __) = self.ts_lstm1(e2_embed)\n",
    "        e2_lstm = self.ts_drop1(e2_lstm)\n",
    "        e2_lstm, (_, __) = self.ts_lstm2(e2_lstm)\n",
    "        e2_lstm = self.ts_drop2(e2_lstm)\n",
    "        _, (e2_hn, __) = self.ts_lstm3(e2_lstm)\n",
    "        e2_hn = self.ts_drop3(e2_hn)\n",
    "        \n",
    "        merge = torch.cat([pep_hn[0], en_hn[0], ec_hn[0], e1_hn[0], e2_hn[0]], dim=1)\n",
    "\n",
    "        merge = self.fc1(merge)\n",
    "        merge = self.fc_drop1(merge)\n",
    "        merge = self.fc2(merge)\n",
    "        merge = self.fc_drop2(merge)\n",
    "        merge = self.fc3(merge)\n",
    "        \n",
    "        out = torch.sigmoid(merge)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:07:12.651527Z",
     "start_time": "2021-12-06T03:07:00.408153Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ESMClassifier(esm_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:07:12.660288Z",
     "start_time": "2021-12-06T03:07:12.652829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESMClassifier(\n",
       "  (esm): ProteinBertModel(\n",
       "    (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (12): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (13): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (14): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (15): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (16): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (17): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (18): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (19): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (20): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (21): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (22): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (23): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (24): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (25): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (26): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (27): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (28): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (29): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (30): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (31): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (32): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (contact_head): ContactPredictionHead(\n",
       "      (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (embed_positions): LearnedPositionalEmbedding(1026, 1280, padding_idx=1)\n",
       "    (emb_layer_norm_before): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_head): RobertaLMHead(\n",
       "      (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pep_lstm1): LSTM(1280, 512, batch_first=True)\n",
       "  (pep_drop1): Dropout(p=0.2, inplace=False)\n",
       "  (pep_lstm2): LSTM(512, 256, batch_first=True)\n",
       "  (pep_drop2): Dropout(p=0.2, inplace=False)\n",
       "  (pep_lstm3): LSTM(256, 128, batch_first=True)\n",
       "  (pep_drop3): Dropout(p=0.2, inplace=False)\n",
       "  (ts_lstm1): LSTM(1280, 512, batch_first=True)\n",
       "  (ts_drop1): Dropout(p=0.2, inplace=False)\n",
       "  (ts_lstm2): LSTM(512, 128, batch_first=True)\n",
       "  (ts_drop2): Dropout(p=0.2, inplace=False)\n",
       "  (ts_lstm3): LSTM(128, 64, batch_first=True)\n",
       "  (ts_drop3): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=384, out_features=256, bias=True)\n",
       "  (fc_drop1): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc_drop2): Dropout(p=0.2, inplace=False)\n",
       "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:07:12.685585Z",
     "start_time": "2021-12-06T03:07:12.661289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------------+\n",
      "|            Modules            | Parameters |\n",
      "+-------------------------------+------------+\n",
      "|        esm.lm_head.bias       |     33     |\n",
      "|    esm.lm_head.dense.weight   |  1638400   |\n",
      "|     esm.lm_head.dense.bias    |    1280    |\n",
      "| esm.lm_head.layer_norm.weight |    1280    |\n",
      "|  esm.lm_head.layer_norm.bias  |    1280    |\n",
      "|     pep_lstm1.weight_ih_l0    |  2621440   |\n",
      "|     pep_lstm1.weight_hh_l0    |  1048576   |\n",
      "|      pep_lstm1.bias_ih_l0     |    2048    |\n",
      "|      pep_lstm1.bias_hh_l0     |    2048    |\n",
      "|     pep_lstm2.weight_ih_l0    |   524288   |\n",
      "|     pep_lstm2.weight_hh_l0    |   262144   |\n",
      "|      pep_lstm2.bias_ih_l0     |    1024    |\n",
      "|      pep_lstm2.bias_hh_l0     |    1024    |\n",
      "|     pep_lstm3.weight_ih_l0    |   131072   |\n",
      "|     pep_lstm3.weight_hh_l0    |   65536    |\n",
      "|      pep_lstm3.bias_ih_l0     |    512     |\n",
      "|      pep_lstm3.bias_hh_l0     |    512     |\n",
      "|     ts_lstm1.weight_ih_l0     |  2621440   |\n",
      "|     ts_lstm1.weight_hh_l0     |  1048576   |\n",
      "|      ts_lstm1.bias_ih_l0      |    2048    |\n",
      "|      ts_lstm1.bias_hh_l0      |    2048    |\n",
      "|     ts_lstm2.weight_ih_l0     |   262144   |\n",
      "|     ts_lstm2.weight_hh_l0     |   65536    |\n",
      "|      ts_lstm2.bias_ih_l0      |    512     |\n",
      "|      ts_lstm2.bias_hh_l0      |    512     |\n",
      "|     ts_lstm3.weight_ih_l0     |   32768    |\n",
      "|     ts_lstm3.weight_hh_l0     |   16384    |\n",
      "|      ts_lstm3.bias_ih_l0      |    256     |\n",
      "|      ts_lstm3.bias_hh_l0      |    256     |\n",
      "|           fc1.weight          |   98304    |\n",
      "|            fc1.bias           |    256     |\n",
      "|           fc2.weight          |   32768    |\n",
      "|            fc2.bias           |    128     |\n",
      "|           fc3.weight          |    128     |\n",
      "|            fc3.bias           |     1      |\n",
      "+-------------------------------+------------+\n",
      "Total Trainable Params: 10486562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10486562"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T03:07:12.703595Z",
     "start_time": "2021-12-06T03:07:12.686575Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "# optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCELoss()\n",
    "# loss_fn = F.binary_cross_entropy()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "# warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps=warmup_step, t_total=t_total)\n",
    "\n",
    "def calc_accuracy(X,Y):\n",
    "    train_acc = ((X>0.5)==Y).sum().data.cpu().numpy() / len(Y)\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T07:02:37.744766Z",
     "start_time": "2021-12-06T03:07:12.705081Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 0.6928390264511108 train acc 0.5078125 time 17.11\n",
      "epoch 1 batch id 201 loss 0.49028047919273376 train acc 0.7259600435323383 time 2979.81\n",
      "epoch 1 batch id 401 loss 0.493201345205307 train acc 0.7393722724438903 time 5946.12\n",
      "epoch 1 batch id 601 loss 0.4335503578186035 train acc 0.753028806156406 time 8916.09\n",
      "epoch 1 batch id 801 loss 0.47761186957359314 train acc 0.76359140917603 time 11883.25\n",
      "epoch 1 batch id 1001 loss 0.44172394275665283 train acc 0.7701946491008991 time 14837.89\n",
      "epoch 1 batch id 1201 loss 0.4154757857322693 train acc 0.7765956754787677 time 17831.74\n",
      "epoch 1 batch id 1401 loss 0.4932558238506317 train acc 0.7818661893290507 time 20926.19\n",
      "epoch 1 batch id 1601 loss 0.44332221150398254 train acc 0.7860297275140538 time 24021.96\n",
      "epoch 1 batch id 1801 loss 0.43403589725494385 train acc 0.7894290498334259 time 27117.55\n",
      "epoch 1 batch id 2001 loss 0.40549710392951965 train acc 0.7920336706646677 time 30215.09\n",
      "epoch 1 train acc 0.7936641928134248 time 32105.18\n",
      "best_acc: 435.30203125\n",
      "epoch 1 test acc 0.8197778366290019\n",
      "epoch 2 batch id 1 loss 0.38555264472961426 train acc 0.8359375 time 18.53\n",
      "epoch 2 batch id 201 loss 0.386933833360672 train acc 0.8231887437810945 time 3125.01\n",
      "epoch 2 batch id 401 loss 0.37615466117858887 train acc 0.8220172225685786 time 6229.93\n",
      "epoch 2 batch id 601 loss 0.41092216968536377 train acc 0.8224898606489185 time 9335.72\n",
      "epoch 2 batch id 801 loss 0.4369138181209564 train acc 0.8228483926342073 time 12440.84\n",
      "epoch 2 batch id 1001 loss 0.4252755045890808 train acc 0.8222675761738262 time 15545.86\n",
      "epoch 2 batch id 1201 loss 0.40266674757003784 train acc 0.8224103611573689 time 18648.98\n",
      "epoch 2 batch id 1401 loss 0.48561811447143555 train acc 0.8231285688793719 time 21751.36\n",
      "epoch 2 batch id 1601 loss 0.40772122144699097 train acc 0.8237063749219238 time 24854.65\n",
      "epoch 2 batch id 1801 loss 0.3932834565639496 train acc 0.8241319926429761 time 27957.22\n",
      "epoch 2 batch id 2001 loss 0.39831966161727905 train acc 0.824302692403798 time 31060.47\n",
      "epoch 2 train acc 0.8245634500269035 time 32952.13\n",
      "best_acc: 438.156875\n",
      "epoch 2 test acc 0.8251541902071563\n",
      "epoch 3 batch id 1 loss 0.3655019700527191 train acc 0.83984375 time 18.63\n",
      "epoch 3 batch id 201 loss 0.3812653720378876 train acc 0.8309235074626866 time 3027.2\n",
      "epoch 3 batch id 401 loss 0.3699676990509033 train acc 0.8296348971321695 time 5917.5\n",
      "epoch 3 batch id 601 loss 0.39620882272720337 train acc 0.8301918677204659 time 8782.57\n",
      "epoch 3 batch id 801 loss 0.4289989471435547 train acc 0.8304658239700374 time 11647.35\n",
      "epoch 3 batch id 1001 loss 0.41636765003204346 train acc 0.8297288648851149 time 14512.09\n",
      "epoch 3 batch id 1201 loss 0.38826698064804077 train acc 0.8297414914654455 time 17376.38\n",
      "epoch 3 batch id 1401 loss 0.4644293785095215 train acc 0.8302468103140613 time 20240.7\n",
      "epoch 3 batch id 1601 loss 0.4006310701370239 train acc 0.8302525765146783 time 23103.91\n",
      "epoch 3 batch id 1801 loss 0.37942102551460266 train acc 0.8306669905607995 time 25967.13\n",
      "epoch 3 batch id 2001 loss 0.39035165309906006 train acc 0.8307408795602199 time 28827.27\n",
      "epoch 3 train acc 0.8309900562449556 time 30575.21\n",
      "best_acc: 439.8571875\n",
      "epoch 3 test acc 0.8283562853107345\n",
      "epoch 4 batch id 1 loss 0.34747517108917236 train acc 0.83984375 time 17.38\n",
      "epoch 4 batch id 201 loss 0.3627292215824127 train acc 0.8370258084577115 time 2882.02\n",
      "epoch 4 batch id 401 loss 0.367355614900589 train acc 0.8355381078553616 time 5744.74\n",
      "epoch 4 batch id 601 loss 0.38369736075401306 train acc 0.8358075083194676 time 8607.1\n",
      "epoch 4 batch id 801 loss 0.4008139669895172 train acc 0.8360350343320849 time 11468.52\n",
      "epoch 4 batch id 1001 loss 0.37855473160743713 train acc 0.8353365384615384 time 14330.82\n",
      "epoch 4 batch id 1201 loss 0.37471169233322144 train acc 0.8353097679017485 time 17192.65\n",
      "epoch 4 batch id 1401 loss 0.4549267888069153 train acc 0.8356280112419701 time 20054.47\n",
      "epoch 4 batch id 1601 loss 0.38560807704925537 train acc 0.8357301100874454 time 22916.39\n",
      "epoch 4 batch id 1801 loss 0.36836689710617065 train acc 0.8361218593836758 time 25779.38\n",
      "epoch 4 batch id 2001 loss 0.3644201159477234 train acc 0.8361170977011494 time 28639.7\n",
      "epoch 4 train acc 0.8363179311272532 time 30388.06\n",
      "best_acc: 441.7478125\n",
      "epoch 4 test acc 0.8319167843691149\n",
      "epoch 5 batch id 1 loss 0.3409677743911743 train acc 0.84765625 time 17.38\n",
      "epoch 5 batch id 201 loss 0.34817397594451904 train acc 0.841923196517413 time 2878.93\n",
      "epoch 5 batch id 401 loss 0.34815478324890137 train acc 0.8409932200748129 time 5740.22\n",
      "epoch 5 batch id 601 loss 0.38455402851104736 train acc 0.8410851705490848 time 8600.78\n",
      "epoch 5 batch id 801 loss 0.3986603021621704 train acc 0.841438436329588 time 11462.13\n",
      "epoch 5 batch id 1001 loss 0.3821146488189697 train acc 0.8407568993506493 time 14323.04\n",
      "epoch 5 batch id 1201 loss 0.3652575612068176 train acc 0.8407154194421316 time 17184.19\n",
      "epoch 5 batch id 1401 loss 0.43835556507110596 train acc 0.8410510349750179 time 20043.08\n",
      "epoch 5 batch id 1601 loss 0.3756466805934906 train acc 0.8411076085259213 time 22902.17\n",
      "epoch 5 batch id 1801 loss 0.34565719962120056 train acc 0.8413923688228762 time 25760.93\n",
      "epoch 5 batch id 2001 loss 0.3472314476966858 train acc 0.8414035169915043 time 28618.24\n",
      "epoch 5 train acc 0.8416657733891578 time 30364.52\n",
      "epoch 5 test acc 0.8307830155367232\n",
      "epoch 6 batch id 1 loss 0.33950531482696533 train acc 0.84375 time 17.74\n",
      "epoch 6 batch id 201 loss 0.3482131361961365 train acc 0.8466845460199005 time 2864.83\n",
      "epoch 6 batch id 401 loss 0.32357341051101685 train acc 0.8450455891521197 time 5713.18\n",
      "epoch 6 batch id 601 loss 0.3451835513114929 train acc 0.8452579034941764 time 8563.31\n",
      "epoch 6 batch id 801 loss 0.4093638062477112 train acc 0.8457494538077404 time 11412.75\n",
      "epoch 6 batch id 1001 loss 0.36495324969291687 train acc 0.8451977709790209 time 14263.49\n",
      "epoch 6 batch id 1201 loss 0.3543195128440857 train acc 0.8452786740216486 time 17122.64\n",
      "epoch 6 batch id 1401 loss 0.4282822012901306 train acc 0.8456459671663098 time 19984.02\n",
      "epoch 6 batch id 1601 loss 0.34730207920074463 train acc 0.845887336039975 time 22846.28\n",
      "epoch 6 batch id 1801 loss 0.33223485946655273 train acc 0.8462225846751804 time 25708.95\n",
      "epoch 6 batch id 2001 loss 0.34971070289611816 train acc 0.8464771520489756 time 28570.59\n",
      "epoch 6 train acc 0.8466886202750875 time 30320.05\n",
      "epoch 6 test acc 0.8297919609227873\n",
      "epoch 7 batch id 1 loss 0.32710981369018555 train acc 0.828125 time 17.43\n",
      "epoch 7 batch id 201 loss 0.31198441982269287 train acc 0.8507268345771144 time 2877.35\n",
      "epoch 7 batch id 401 loss 0.3157990574836731 train acc 0.8500233790523691 time 5737.28\n",
      "epoch 7 batch id 601 loss 0.34034860134124756 train acc 0.8505420653078203 time 8595.82\n",
      "epoch 7 batch id 801 loss 0.40327486395835876 train acc 0.851343047752809 time 11290.56\n",
      "epoch 7 batch id 1001 loss 0.3581429421901703 train acc 0.8506805694305695 time 14158.67\n",
      "epoch 7 batch id 1201 loss 0.3349698781967163 train acc 0.8510225853455454 time 16997.63\n",
      "epoch 7 batch id 1401 loss 0.4054197371006012 train acc 0.851423090649536 time 19835.38\n",
      "epoch 7 batch id 1601 loss 0.33913254737854004 train acc 0.8515307815427857 time 22705.89\n",
      "epoch 7 batch id 1801 loss 0.32929229736328125 train acc 0.8517815623264853 time 25546.06\n",
      "epoch 7 batch id 2001 loss 0.3362106680870056 train acc 0.8518807002748626 time 28390.17\n",
      "epoch 7 train acc 0.8521102892958031 time 30128.0\n",
      "epoch 7 test acc 0.8272119232580039\n",
      "epoch 8 batch id 1 loss 0.3191072344779968 train acc 0.85546875 time 17.32\n",
      "epoch 8 batch id 201 loss 0.297004371881485 train acc 0.8566736629353234 time 2864.33\n",
      "epoch 8 batch id 401 loss 0.30941420793533325 train acc 0.8561798628428927 time 5714.13\n",
      "epoch 8 batch id 601 loss 0.32685351371765137 train acc 0.8560992096505824 time 8549.18\n",
      "epoch 8 batch id 801 loss 0.3881266117095947 train acc 0.856463600187266 time 11380.24\n",
      "epoch 8 batch id 1001 loss 0.35379403829574585 train acc 0.8560267857142857 time 14211.44\n",
      "epoch 8 batch id 1201 loss 0.327523410320282 train acc 0.8560737146128227 time 17041.13\n",
      "epoch 8 batch id 1401 loss 0.40382203459739685 train acc 0.8567234341541756 time 19870.89\n",
      "epoch 8 batch id 1601 loss 0.3226124048233032 train acc 0.8567155293566521 time 22700.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch id 1801 loss 0.3108729124069214 train acc 0.8571865456690727 time 25346.05\n",
      "epoch 8 batch id 2001 loss 0.3131878077983856 train acc 0.8571417416291854 time 27543.68\n",
      "epoch 8 train acc 0.8575264410142588 time 28885.71\n",
      "epoch 8 test acc 0.826023422787194\n",
      "epoch 9 batch id 1 loss 0.2986278831958771 train acc 0.8671875 time 13.98\n",
      "epoch 9 batch id 201 loss 0.29229071736335754 train acc 0.8611823694029851 time 2210.9\n",
      "epoch 9 batch id 401 loss 0.3056081235408783 train acc 0.8602906795511222 time 4407.32\n",
      "epoch 9 batch id 601 loss 0.3218837380409241 train acc 0.8606619176372712 time 6603.61\n",
      "epoch 9 batch id 801 loss 0.39903324842453003 train acc 0.8620962078651685 time 8799.59\n",
      "epoch 9 batch id 1001 loss 0.32957977056503296 train acc 0.8614042207792207 time 10996.21\n",
      "epoch 9 batch id 1201 loss 0.31590208411216736 train acc 0.8616875260199833 time 13193.14\n",
      "epoch 9 batch id 1401 loss 0.35987457633018494 train acc 0.8620990587080657 time 15390.43\n",
      "epoch 9 batch id 1601 loss 0.3068535029888153 train acc 0.8618295206121174 time 17587.98\n",
      "epoch 9 batch id 1801 loss 0.30053699016571045 train acc 0.8621143635480288 time 19782.78\n",
      "epoch 9 batch id 2001 loss 0.2904505133628845 train acc 0.8621958551974013 time 21981.32\n",
      "epoch 9 train acc 0.8624754611413775 time 23323.85\n",
      "epoch 9 test acc 0.8277824858757062\n",
      "epoch 10 batch id 1 loss 0.30908942222595215 train acc 0.87109375 time 13.93\n",
      "epoch 10 batch id 201 loss 0.28310757875442505 train acc 0.8680231654228856 time 2211.87\n",
      "epoch 10 batch id 401 loss 0.27313145995140076 train acc 0.8660282886533666 time 4409.64\n",
      "epoch 10 batch id 601 loss 0.30821749567985535 train acc 0.8658160877703827 time 6607.09\n",
      "epoch 10 batch id 801 loss 0.36597082018852234 train acc 0.86667056803995 time 8803.95\n",
      "epoch 10 batch id 1001 loss 0.3465448021888733 train acc 0.866176791958042 time 11001.41\n",
      "epoch 10 batch id 1201 loss 0.3111479878425598 train acc 0.8661694681515404 time 13198.68\n",
      "epoch 10 batch id 1401 loss 0.33229780197143555 train acc 0.8668947403640257 time 15396.3\n",
      "epoch 10 batch id 1601 loss 0.3003790080547333 train acc 0.8669337523422861 time 17593.3\n",
      "epoch 10 batch id 1801 loss 0.2880244851112366 train acc 0.8672135272071072 time 19787.91\n",
      "epoch 10 batch id 2001 loss 0.31199994683265686 train acc 0.8670742753623188 time 21988.08\n",
      "epoch 10 train acc 0.867435778601695 time 23331.81\n",
      "epoch 10 test acc 0.8272413488700565\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "for e in range(num_epochs):\n",
    "    t0=time.time()\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for batch_id, (pep_token_ids, n_token_ids, c_token_ids, m1_token_ids, m2_token_ids, label) in enumerate(train_dataloader):\n",
    "#         print(batch_id, round(time.time()-t0,2))\n",
    "        \n",
    "        pep_token_ids = pep_token_ids.long().to(device)\n",
    "        n_token_ids = n_token_ids.long().to(device)\n",
    "        c_token_ids = c_token_ids.long().to(device)\n",
    "        m1_token_ids = m1_token_ids.long().to(device)\n",
    "        m2_token_ids = m2_token_ids.long().to(device)\n",
    "        label = torch.reshape(label.float(), (-1, 1)).to(device)\n",
    "        \n",
    "        pred = model(pep_token_ids, n_token_ids, c_token_ids, m1_token_ids, m2_token_ids)\n",
    "        loss = F.binary_cross_entropy(pred, label)\n",
    "#         print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_acc += calc_accuracy(pred, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {} time {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1), round(time.time()-t0, 2)))\n",
    "        \n",
    "    print(\"epoch {} train acc {} time {}\".format(e+1, train_acc / (batch_id+1), round(time.time()-t0,2)))\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_id, (pep_token_ids, n_token_ids, c_token_ids, m1_token_ids, m2_token_ids, label) in enumerate(valid_dataloader):\n",
    "        pep_token_ids = pep_token_ids.long().to(device)\n",
    "        n_token_ids = n_token_ids.long().to(device)\n",
    "        c_token_ids = c_token_ids.long().to(device)\n",
    "        m1_token_ids = m1_token_ids.long().to(device)\n",
    "        m2_token_ids = m2_token_ids.long().to(device)\n",
    "        label = label.long().to(device)\n",
    "        label = torch.reshape(label, (-1, 1))\n",
    "        pred = model(pep_token_ids, n_token_ids, c_token_ids, m1_token_ids, m2_token_ids)\n",
    "        \n",
    "        test_acc += calc_accuracy(pred, label)\n",
    "    if (test_acc / (batch_id+1)) > best_acc:\n",
    "        best_acc=test_acc\n",
    "        torch.save({\"best_acc\":best_acc / (batch_id+1),\"model\":model.state_dict()},f'./highParam/high.pl')\n",
    "        print(f\"best_acc: {best_acc}\")\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T17:58:59.356874Z",
     "start_time": "2021-12-12T17:58:59.353950Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T18:59:52.312542Z",
     "start_time": "2021-12-12T17:59:35.562135Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_id, (pep_token_ids, n_token_ids, c_token_ids, m1_token_ids, m2_token_ids, label) in enumerate(test_dataloader):\n",
    "        pep_token_ids = pep_token_ids.long().to(device)\n",
    "        n_token_ids = n_token_ids.long().to(device)\n",
    "        c_token_ids = c_token_ids.long().to(device)\n",
    "        m1_token_ids = m1_token_ids.long().to(device)\n",
    "        m2_token_ids = m2_token_ids.long().to(device)\n",
    "        label = label.long().to(device)\n",
    "        label = torch.reshape(label, (-1, 1))\n",
    "\n",
    "        pred_batch = model(pep_token_ids, n_token_ids, c_token_ids, m1_token_ids, m2_token_ids)\n",
    "        pred += list(pred_batch)\n",
    "        test_acc += calc_accuracy(pred_batch, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T19:59:22.769950Z",
     "start_time": "2021-12-12T19:59:22.767352Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = test.ID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T19:59:43.984049Z",
     "start_time": "2021-12-12T19:59:39.558470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83     66996\n",
      "           1       0.82      0.85      0.83     66996\n",
      "\n",
      "    accuracy                           0.83    133992\n",
      "   macro avg       0.83      0.83      0.83    133992\n",
      "weighted avg       0.83      0.83      0.83    133992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [1 if _ >= 0.5 else 0 for _ in pred]\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T19:59:50.487621Z",
     "start_time": "2021-12-12T19:59:50.103316Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=',.0f')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T20:00:59.331663Z",
     "start_time": "2021-12-12T20:00:59.053884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8321019165323303\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:', sum(np.array(y_pred)==y_test)/ len (y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T21:15:53.892283Z",
     "start_time": "2021-12-12T21:15:51.530047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf auc : 0.9069939676441866\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARIAAAEWCAYAAACqphg1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgP0lEQVR4nO3de7xVdZ3/8ddbLoGKgEAXuQQiGmCAcZTByQkyb6gVEwbYdJvpoZY22cwUdpliqqlpcro4msaoY/YTqDTNHNISMyqvaIiAl7gGJIqopCgh8Pn9sdY5bDb7nLPOWWftc/Y57+fjcR5nr72/a63PPrrffNd3rfXdigjMzPI4qL0LMLPa5yAxs9wcJGaWm4PEzHJzkJhZbg4SM8vNQWJmuTlIuiBJ6yW9IuklSVskXSfp0LI2J0q6S9KLkrZL+pmkMWVtDpP0bUl/TLe1Ol0eWN13ZO3NQdJ1nR0RhwITgOOAz9S/IGky8Avgp8ARwAjgEeB3ko5M2/QEFgNjgdOBw4ATgW3ACUUVLal7Udu21nOQdHERsQW4gyRQ6v0ncH1EfCciXoyI5yLi88B9wNy0zQeAYcD0iFgVEXsj4pmI+HJELKq0L0ljJf1S0nOSnpb02fT56yR9paTdFEmbSpbXS5ojaTmwQ9LnJd1Ytu3vSLosfdxX0jWSnpK0WdJXJHXL95eypjhIujhJQ4AzgNXp8sEkPYsfV2j+I+CU9PE7gNsj4qWM++kD3AncTtLLOYqkR5PVbOBMoB/wA2CapMPSbXcD3gvMT9t+H9id7uM44FTgIy3Yl7WQg6TrukXSi8BG4Bngi+nzh5P8f/FUhXWeAurHPwY00qYxZwFbIuK/ImJn2tO5vwXrXxYRGyPilYjYADwMvDt97e3AyxFxn6TXkQTjxRGxIyKeAb4FzGrBvqyFHCRd17sjog8wBXgT+wLieWAv8IYK67wBeDZ9vK2RNo0ZCqxpVaWJjWXL80l6KQDnsq838kagB/CUpBckvQB8D3htjn1bMxwkXVxE/Bq4Drg0Xd4B3AucU6H5e9l3OHIncJqkQzLuaiMwspHXdgAHlyy/vlKpZcs/Bqakh2bT2RckG4G/AAMjol/6c1hEjM1Yp7WCg8QAvg2cImlCunwJ8EFJ/yipj6T+6WDoZODf0jY/IPnQ3iTpTZIOkjRA0mclTauwj9uA10u6WNJr0u1OSl9bRjLmcbik1wMXN1dwRGwF7gb+F1gXEY+lzz9Fcsbpv9LT0wdJGinpbS38m1gLOEis/kN5PfCv6fJvgdOAvyUZB9lAMmj51oj4Q9rmLyQDro8DvwT+DDxAcoh0wNhHRLxIMlB7NrAF+AMwNX35BySnl9eThMAPM5Y+P61hftnzHwB6AqtIDtVupGWHYdZC8sRGZpaXeyRmlpuDxMxyc5CYWW4OEjPLreZugBo4cGAMHz68vcsw63IeeuihZyNiUKXXai5Ihg8fztKlS9u7DLMuR9KGxl7zoY2Z5eYgMbPcHCRmlpuDxMxyc5CYWW6FBYmkayU9I2lFI69L0mXphMHLJb2lqFrMrFhFnv69Dric5K7SSs4ARqU/k4Ar099m1pyt98IvT8yxgYNI5q8Cuh8Koz4Gx3291VsrLEgiYomk4U00eRfJBMMB3Cepn6Q3pPNJmHV8v58Dj/1ne1fRSnv3Pdz90r730cowac8L0gaz//R5m9LnDggSSecB5wEMGzasKsVZJzdf7V1Bx7PxJzUZJJX+S1acHCUi5gHzAOrq6jyBiu3jQGg7Q/+21au2Z5BsIpkQuN4Q4E/tVIt1NA6IgtXIGEkGtwIXSVpIMsi63eMjXYiDom3oNTB7Z3tXUVyQSFpA8lUHA9NvTfsiydcEEBFXAYuAaSRfzPQy8OGiarF21FUC49yufcRd5Fmb2c28HsCFRe3fqmx+d2BPe1fRcn1Gw9mr2ruKmldz0whYB9BRexldvFfQnhwk1rz2Dg4HRIfnILEDVTs4HBQ1z0Fi1QsOB0an5SDpqooMDwdGl+Mg6UqKCA+HhuEg6fzaOjwcHFaBg6SzaqsAcXBYBg6SzqQtwsPBYa3gIOkM8gaIw8NycpDUKoeHdSAOklqTJ0AcHlYQB0mtaG2AjP50rnkmzLJwkHR0rQ0Q9z6sihwkHVVrAuQ1r4f3eG4oqz4HSUfU0hBx78PamYOkI3GAWI1ykHQEDhCrcQ6S9taSEHGAWAflIGlPWUPEAWIdnIOkPbgXYp2Mg6Ta3AuxTshBUk1ZQsQBYjXIQVIN7oVYJ3dQexfQ6WUJkW59HCJW09wjKZIPZayLcI+kKA4R60IcJEVwiFgX40ObttZciDhArBNyj6QtOUSsi3KQtBWHiHVhhQaJpNMlPSFptaRLKrzeV9LPJD0iaaWkDxdZT2EcItbFFRYkkroBVwBnAGOA2ZLGlDW7EFgVEeOBKcB/SepZVE3twiFiXUCRPZITgNURsTYidgELgXeVtQmgjyQBhwLPAbsLrKntNdUbcYhYF1FkkAwGNpYsb0qfK3U5MBr4E/Ao8ImI2Fu+IUnnSVoqaenWrVuLqrflHCJmQLFBUulTVv7pOg1YBhwBTAAul3TYAStFzIuIuoioGzRoUFvX2Tpt/eXcZjWsyCDZBAwtWR5C0vMo9WHgJ5FYDawD3lRgTdXh3oh1MUUGyYPAKEkj0gHUWcCtZW3+CJwMIOl1wDHA2gJrahs+pDHbT2FXtkbEbkkXAXcA3YBrI2KlpAvS168CvgxcJ+lRkkOhORHxbFE1Fc4hYl1UoZfIR8QiYFHZc1eVPP4TcGqRNbQ5j42YHcBXtraED2nMKnKQmFluDpKs3Bsxa5SDJC+HiJmDJBMPsJo1yUGSh3sjZoCDpHnujZg1y0HSWu6NmDVwkDTFvRGzTBwkreHeiNl+MgeJpEOKLKTDcW/ELLNmg0TSiZJWAY+ly+Mlfbfwyjoq90bMDpClR/ItkgmItgFExCPA3xRZVLtzb8SsRTId2kTExrKn9hRQS8fn3ohZRVmmEdgo6UQg0gmK/pH0MMfMDLL1SC4g+dqIwSTTJ04APlZgTe2rscMa90bMGpWlR3JMRLyv9AlJfw38rpiSzKzWZOmR/HfG52qfB1nNWqXRHomkycCJwCBJ/1Ty0mEkc7B2HT6sMWtSU4c2PUm+/a470Kfk+T8DM4osysxqS6NBEhG/Bn4t6bqI2FDFmtqHB1nNWi3LYOvLkr4BjAV61T8ZEW8vrCozqylZBltvAB4HRgD/Bqwn+fIrMzMgW5AMiIhrgFcj4tcR8ffAXxVcV3X5sMYslyyHNq+mv5+SdCbJ9/cOKa4kM6s1WYLkK5L6Av9Mcv3IYcDFRRZlZrWl2SCJiNvSh9uBqdBwZWvn5sMas8yauiCtG/Bekntsbo+IFZLOAj4L9AaOq06JBfPVrGa5NdUjuQYYCjwAXCZpAzAZuCQibqlCbWZWI5oKkjpgXETsldQLeBY4KiK2VKc0M6sVTZ3+3RURewEiYifwZEtDRNLpkp6QtFrSJY20mSJpmaSVkn7dku0XxuMjZi3SVI/kTZKWp48FjEyXBUREjGtqw+kYyxXAKSTzmDwo6daIWFXSph/wXeD0iPijpNe2/q20gsdHzNpEU0EyOue2TwBWR8RaAEkLgXcBq0ranAv8JCL+CBARz+Tcp5m1g6Zu2st7o95goHSu103ApLI2RwM9JN1NcofxdyLi+vINSToPOA9g2LBhOcsys7ZW5BdkVTpuKB986A5MBM4kman+XyUdfcBKEfMioi4i6gYNGtT2lZby+IhZi2W5srW1NpGcPq43hOTy+vI2z0bEDmCHpCXAeODJAutKeHzErM1k6pFI6i3pmBZu+0FglKQR6ezzs4Bby9r8FDhJUndJB5Mc+niGerMak+Wb9s4GlgG3p8sTJJUHwgEiYjdwEXAHSTj8KCJWSrpA0gVpm8fS7S4nufDt6ohY0cr3YmbtJMuhzVySMzB3A0TEMknDs2w8IhYBi8qeu6ps+RvAN7Jsr3AeHzFrlSyHNrsjYnvhlZhZzcrSI1kh6Vygm6RRJN+0d0+xZZlZLcnSI/k4yXytfwHmk0wncHGBNRXPZ2zM2lTWb9r7HPC5oosxs9qUpUfyTUmPS/qypLGFV2RmNafZIImIqcAUYCswT9Kjkj5fdGFV5zM2Zq2W6YK0iNgSEZcBF5BcU/KFIosys9qS5YK00ZLmSloBXE5yxqZ2Z5H3QKtZm8sy2Pq/wALg1Igov1fGzCzTLPKd68uwzKzNNTWL/I8i4r2SHmX/2/8zzZBWUzzQapZLUz2ST6S/z6pGIWZWuxodbI2Ip9KHH4uIDaU/wMeqU56Z1YIsp39PqfDcGW1diJnVrqbGSD5K0vM4smQ2eUjmVv1d0YUVwqd+zQrR1BjJfODnwNeA0u+keTEiniu0KjOrKU0FSUTEekkXlr8g6XCHiZnVa65HchbwEMnp39LjggCOLLCu6vGpX7Pcmvpem7PS3yOqV46Z1aIs99r8taRD0sd/J+mbkvwtVWbWIMvp3yuBlyWNBz4NbAB+UGhVZlZTsk7+HCTf2/udiPgOySng2uJTv2aFyXL374uSPgO8n+TLrLoBPYoty8xqSZYeyUySiZ//PiK2kHw5eMf4Hhoz6xCyTLW4BbgB6CvpLGBnRFxfeGXV4FO/Zm0iy1mb95J8neY5wHuB+yXNKLowM6sdWcZIPgccHxHPAEgaBNwJ3FhkYWZWO7KMkRxUHyKpbRnXM7MuIkuP5HZJd5DM2wrJ4OuiJtqbWReTZc7WT0n6W+CtJPfbzIuImwuvzMxqRlPzkYwCLgVGAo8C/xIRm6tVmJnVjqbGOq4FbgPeQ3IH8H+3dOOSTpf0hKTVki5pot3xkvYUdjbIV7WaFaqpQ5s+EfE/6eMnJD3ckg2nV8BeQTJV4ybgQUm3RsSqCu2+DtzRku2bWcfRVJD0knQc++Yh6V26HBHNBcsJwOqIWAsgaSHJ/Tqrytp9HLgJOL6Ftedzyj1V3Z1ZZ9ZUkDwFfLNkeUvJcgBvb2bbg4GNJcubgEmlDSQNBqan22o0SCSdB5wHMGxYG81gMGhy22zHzJqc2Ghqzm1XGpgovyb928CciNgjNT6OERHzgHkAdXV1vq7drIPJch1Ja20ChpYsDwHKvzu4DliYhshAYJqk3RFxS4F1mVkbKzJIHgRGSRoBbAZmAeeWNiidxlHSdcBtDhGz2lNYkETEbkkXkZyN6QZcGxErJV2Qvn5VUfs2s+pqNkiUHHe8DzgyIr6Uztf6+oh4oLl1I2IRZZfTNxYgEfGhTBWbWYeT5ea77wKTgdnp8osk14eYmQHZDm0mRcRbJP0eICKel9Sz4Lrazg8Pa+8KzDq9LD2SV9OrTwMa5iPZW2hVbWnPi+1dgVmnlyVILgNuBl4r6d+B3wJfLbQqM6spWaYRuEHSQ8DJJBeZvTsiHiu8siJ5rlazNpXlrM0w4GXgZ6XPRcQfiyzMzGpHlsHW/2Pfl4j3AkYATwBjC6zLzGpIlkObN5cuS3oLcH5hFZlZzWnxJM7p9AHVveXfzDq0LGMk/1SyeBDwFmBrYRWZWc3JMkZS+oXhu0nGTG4qphwzq0VNBkl6IdqhEfGpKtVjZjWo0TESSd0jYg/JoYyZWaOa6pE8QBIiyyTdCvwY2FH/YkT8pODa8vPs8WZVkWWM5HCSr+l8O/uuJwmg4weJmVVFU0Hy2vSMzQr2BUg9X2NuZg2aCpJuwKFkm8S5dvg+G7M21+TXUUTEl6pWiZnVrKaubPVIpZll0lSQnFy1KsyspjUaJBHxXDULMbPa1eKb9szMyjlIzCw3B4mZ5eYgMbPcHCRmlpuDxMxyc5CYWW4OEjPLrfMGieciMauaQoNE0umSnpC0WtIlFV5/n6Tl6c89ksYXWY+ZFaOwIEnne70COAMYA8yWNKas2TrgbRExDvgyMK+oesysOEX2SE4AVkfE2ojYBSwE3lXaICLuiYjn08X7gCEF1uO5SMwKUmSQDAY2lixvSp9rzD8AP6/0gqTzJC2VtHTrVn+ljllHU2SQZJ5ZTdJUkiCZU+n1iJgXEXURUTdo0KA2LNHM2kKWyZ9baxMwtGR5CPCn8kaSxgFXA2dExLYC6zGzghTZI3kQGCVphKSewCzg1tIGkoaRzEb//oh4ssBazKxAhfVIImK3pIuAO0gmkr42IlZKuiB9/SrgC8AA4LuSAHZHRF1RNZlZMYo8tCEiFgGLyp67quTxR4CPFFmDmRWv817ZamZV4yAxs9wcJGaWm4PEzHJzkJhZbg4SM8vNQWJmuTlIzCw3B4mZ5eYgMbPcHCRmllvnDBJP/GxWVZ0zSMysqhwkZpZb1wkST/xsVpiuEyRmVhgHiZnl5iAxs9wcJGaWm4PEzHJzkJhZboXOIm+dz6uvvsqmTZvYuXNne5diBenVqxdDhgyhR48emddxkFiLbNq0iT59+jB8+HDS7yKyTiQi2LZtG5s2bWLEiBGZ1/OhjbXIzp07GTBggEOkk5LEgAEDWtzjdJBYizlEOrfW/Pd1kJhZbg4SqzndunVjwoQJHHvssZx99tm88MILAKxfv57evXszYcKEhp9du3ZV3MYnPvEJBg8ezN69exuemzt3Lpdeeul+7YYPH86zzz4LwJYtW5g1axYjR45kzJgxTJs2jSeffDLXe/nLX/7CzJkzOeqoo5g0aRLr16+v2O6HP/wh48aNY+zYsXz6059udv1f/epX+/0devXqxS233ALAunXrmDRpEqNGjWLmzJmN/o1awkFixdt6L6z8WvK7DfTu3Ztly5axYsUKDj/8cK644oqG10aOHMmyZcsafnr27HnA+nv37uXmm29m6NChLFmyJNM+I4Lp06czZcoU1qxZw6pVq/jqV7/K008/neu9XHPNNfTv35/Vq1fzyU9+kjlz5hzQZtu2bXzqU59i8eLFrFy5kqeffprFixc3uf7UqVMb/gZ33XUXBx98MKeeeioAc+bM4ZOf/CR/+MMf6N+/P9dcc02u9wA+a2N5PHQxPL+s6TavbofnlwN7gYOg/zjo0bfx9v0nwMRvZy5h8uTJLF++PHN7SP61PvbYY5k5cyYLFixgypQpmdbp0aMHF1xwQcNzEyZMaNF+K/npT3/K3LlzAZgxYwYXXXQREbHfOMXatWs5+uijGTRoEADveMc7uOmmmzj55JMzrX/jjTdyxhlncPDBBxMR3HXXXcyfPx+AD37wg8ydO5ePfvSjud6HeyRWrF3bSUKE5Peu7W226T179rB48WLe+c53Njy3Zs2ahu78hRdeWHG9BQsWMHv2bKZPn85tt93Gq6++2uy+VqxYwcSJEzPVddJJJ+13WFH/c+eddx7QdvPmzQwdOhSA7t2707dvX7Zt27Zfm6OOOorHH3+c9evXs3v3bm655RY2btyYef2FCxcye/ZsIOnd9OvXj+7dkz7EkCFD2Lx5c6b31RT3SKz1svQctt4Ld50Me3fBQT3hxBtg0ORcu33llVeYMGEC69evZ+LEiZxyyikNr9Uf2jRm165dLFq0iG9961v06dOHSZMm8Ytf/IIzzzyz0bMVLT2L8Zvf/CZz24gD58kp31///v258sormTlzJgcddBAnnngia9euzbT+U089xaOPPsppp52WeX+tUWiPRNLpkp6QtFrSJRVel6TL0teXS3pL7p16vtaOZdBkePtiGPfl5HfOEIF9YyQbNmxg165d+42RNOf2229n+/btvPnNb2b48OH89re/ZcGCBQAMGDCA559/fr/2L774Iv369WPs2LE89NBDmfbRkh7JkCFDGnoXu3fvZvv27Rx++OEHtDv77LO5//77uffeeznmmGMYNWpUpvV/9KMfMX369IarVAcOHMgLL7zA7t27geQCwyOOOCLT+2pSRBTyA3QD1gBHAj2BR4AxZW2mAT8HBPwVcH9z2504cWI06QYq/1ibWLVqVXuXEIccckjD44cffjiGDh0au3btinXr1sXYsWObXHfWrFkxf/78huWXXnopBg0aFDt27IhHHnkkjj322Pjzn/8cERE33XRTTJ06NSIi9u7dGyeccELMmzevYd0HHngg7r777lzv5fLLL4/zzz8/IiIWLFgQ55xzTsV2Tz/9dEREPPfcczF+/Ph44oknMq0/adKkuOuuu/Z7bsaMGbFgwYKIiDj//PPjiiuuOGB/lf47A0ujsc97Yy/k/QEmA3eULH8G+ExZm+8Bs0uWnwDe0NR2HSTtq6MFSUTEWWedFddff32zQbJjx47o379/bN++fb/np0+fHgsXLoyIiKuuuirGjRsX48ePj1NOOSXWrFnT0G7z5s1xzjnnxJFHHhljxoyJadOmxZNPPpnrvbzyyisxY8aMGDlyZBx//PH77W/8+PENj2fNmhWjR4+O0aNHN4RAc+uvW7cujjjiiNizZ89++1yzZk0cf/zxMXLkyJgxY0bs3LnzgLpaGiSKCsdMbUHSDOD0iPhIuvx+YFJEXFTS5jbgPyLit+nyYmBORCwt29Z5wHkAw4YNm7hhw4bGd1zp0MbztbaZxx57jNGjR7d3GVawSv+dJT0UEXWV2hc5RlJpsKL8E52lDRExLyLqIqKu/hSYmXUcRQbJJmBoyfIQ4E+taNMy5b0P90bMClfk6d8HgVGSRgCbgVnAuWVtbgUukrQQmARsj4incu/Z4VGoKLvgyTqX1gx3FBYkEbFb0kXAHSRncK6NiJWSLkhfvwpYRHLmZjXwMvDhouqxttGrVy+2bdvmqQQ6qUjnI+nVq1eL1itssLUodXV1sXTp0uYbWiE8Q1rn19gMaU0NtvrKVmuRHj16tGjmLOsafK+NmeXmIDGz3BwkZpZbzQ22StoKNHFpa4OBwLMFl5OXa8yvo9cHHb/GrPW9MSIqXhFac0GSlaSljY0wdxSuMb+OXh90/Brboj4f2phZbg4SM8utMwfJvPYuIAPXmF9Hrw86fo256+u0YyRmVj2duUdiZlXiIDGz3Go+SNplgum2r/F9aW3LJd0jaXxHqq+k3fGS9qSz31VVlholTZG0TNJKSb/uSPVJ6ivpZ5IeSeur6p3ukq6V9IykFY28nu9z0tgcjLXwQ0ETTLdDjScC/dPHZ1Szxiz1lbS7i2Tqhxkd8G/YD1gFDEuXX9vB6vss8PX08SDgOaBnFWv8G+AtwIpGXs/1Oan1HskJwOqIWBsRu4CFwLvK2rwLuD4S9wH9JL2hI9UYEfdERP33INxHMlNch6kv9XHgJuCZKtZWL0uN5wI/iYg/AkRENevMUl8AfZRM4nIoSZDsrlaBEbEk3Wdjcn1Oaj1IBgMbS5Y3pc+1tE2RWrr/fyD5l6Famq1P0mBgOnBVFesqleVveDTQX9Ldkh6S9IGqVZetvsuB0SRTiT4KfCIi9tJx5Pqc1Pp8JG02wXSBMu9f0lSSIHlroRWV7bbCc+X1fZtkdv897TQrWpYauwMTgZOB3sC9ku6LiCeLLo5s9Z0GLAPeDowEfinpNxHx54JryyrX56TWg6R9JphumUz7lzQOuBo4IyK2lb9eoCz11QEL0xAZCEyTtDsibqlKhdn/Oz8bETuAHZKWAOOBagRJlvo+TPLVKwGslrQOeBPwQBXqyyLf56Ragz0FDSB1B9YCI9g3yDW2rM2Z7D+I9EAHrHEYyby1J3bEv2FZ++uo/mBrlr/haGBx2vZgYAVwbAeq70pgbvr4dSQTog+s8t9xOI0Ptub6nNR0jyRqYILpjDV+ARgAfDf9V393VOlu0Yz1tassNUbEY5JuB5YDe4GrI6Liqc72qA/4MnCdpEdJPqxzIqJqUwtIWgBMAQZK2gR8EehRUl+uz4kvkTez3Gr9rI2ZdQAOEjPLzUFiZrk5SMwsNweJmeXmIKlR6V24y0p+hjfR9qU22N91ktal+3pY0uRWbONqSWPSx58te+2evDWm26n/u6xI77bt10z7CZKmtcW+uzKf/q1Rkl6KiEPbum0T27gOuC0ibpR0KnBpRIzLsb3cNTW3XUnfB56MiH9vov2HgLqIuKita+lK3CPpJCQdKmlx2lt4VNIBd/BKeoOkJSX/Yp+UPn+qpHvTdX8sqbkP+BLgqHTdf0q3tULSxelzh0j6v3TujRWSZqbP3y2pTtJ/AL3TOm5IX3sp/f3D0h5C2hN6j6Rukr4h6cF0vozzM/xZ7iW98UzSCUrmevl9+vsYST2BLwEz01pmprVfm+7n95X+jlZBNS/R9U+bXu68h+QmsGXAzSSXaR+WvjaQ5ArF+h7nS+nvfwY+lz7uBvRJ2y4BDkmfnwN8ocL+riO9NB44B7if5Ca5R4FDSG6NXwkcB7wH+J+Sdfumv+8m+de/oaaSNvU1Tge+nz7uSXJHam/gPODz6fOvAZYCIyrU+VLJ+/sxcHq6fBjQPX38DuCm9PGHgMtL1v8q8Hfp434k9+oc0t7/vTv6T01fIt/FvRIRE+oXJPUAvirpb0guER9Mck/HlpJ1HgSuTdveEhHLJL0NGAP8Lr08vyfJv+SVfEPS54GtJHcpnwzcHMmNckj6CXAScDtwqaSvkxwO/aYF7+vnwGWSXgOcDiyJiFfSw6lx2jc7W19gFLCubP3ekpaR3FfyEPDLkvbflzSK5K7WHo3s/1TgnZL+JV3uRXIv1GMteA9djoOk83gfycxbEyPiVUnrST4EDSJiSRo0ZwI/kPQN4HnglxExO8M+PhURN9YvSHpHpUYR8aSkiST3bnxN0i8i4ktZ3kRE7JR0N8lt9zOBBfW7Az4eEXc0s4lXImKCpL7AbcCFwGUk97r8KiKmpwPTdzeyvoD3RMQTWeq1hMdIOo++wDNpiEwF3ljeQNIb0zb/A1xDMvXefcBfS6of8zhY0tEZ97kEeHe6ziEkhyW/kXQE8HJE/D/g0nQ/5V5Ne0aVLCS5aewkkhvhSH9/tH4dSUen+6woIrYD/wj8S7pOX5I7biE5nKn3IskhXr07gI8r7Z5JOq6xfdg+DpLO4wagTtJSkt7J4xXaTAGWSfo9yTjGdyJiK8kHa4Gk5STB8qYsO4yIh0nGTh4gGTO5OiJ+D7wZeCA9xPgc8JUKq88DltcPtpb5Bckco3dGMnUhJHO1rAIeVjKB8fdopked1vIIMAv4T5Le0e9Ixk/q/QoYUz/YStJz6ZHWtiJdtmb49K+Z5eYeiZnl5iAxs9wcJGaWm4PEzHJzkJhZbg4SM8vNQWJmuf1/aMnAmVUKc0oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AUC\n",
    "probs = [_.cpu().numpy() for _ in pred]\n",
    "rf_auc = roc_auc_score(y_test, probs)\n",
    "\n",
    "\n",
    "print('rf auc : {}'.format(rf_auc))\n",
    "# plot the roc curve for the model_high\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, probs)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='RF AUC = {:.4f}'.format(rf_auc), color='orange')\n",
    "plt.title('ROC curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-12T21:17:12.267449Z",
     "start_time": "2021-12-12T21:17:05.376594Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({\"model\":model.state_dict()}, f'./highParam/high2.pl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습에 사용할 CPU나 GPU 장치를 얻습니다.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(\"Using {} device\".format(device))\n",
    "\n",
    "# # 모델을 정의합니다.\n",
    "# class NeuralNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(NeuralNetwork, self).__init__()\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.linear_relu_stack = nn.Sequential(\n",
    "#             nn.Linear(28*28, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, 10),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.flatten(x)\n",
    "#         logits = self.linear_relu_stack(x)\n",
    "#         return logits\n",
    "\n",
    "# model = NeuralNetwork().to(device)\n",
    "# print(model)\n",
    "\n",
    "# def train(dataloader, model, loss_fn, optimizer):\n",
    "#     size = len(dataloader.dataset)\n",
    "#     for batch, (X, y) in enumerate(dataloader):\n",
    "#         X, y = X.to(device), y.to(device)\n",
    "\n",
    "#         # 예측 오류 계산\n",
    "#         pred = model(X)\n",
    "#         loss = loss_fn(pred, y)\n",
    "\n",
    "#         # 역전파\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if batch % 100 == 0:\n",
    "#             loss, current = loss.item(), batch * len(X)\n",
    "#             print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "# def test(dataloader, model, loss_fn):\n",
    "#     size = len(dataloader.dataset)\n",
    "#     num_batches = len(dataloader)\n",
    "#     model.eval()\n",
    "#     test_loss, correct = 0, 0\n",
    "#     with torch.no_grad():\n",
    "#         for X, y in dataloader:\n",
    "#             X, y = X.to(device), y.to(device)\n",
    "#             pred = model(X)\n",
    "#             test_loss += loss_fn(pred, y).item()\n",
    "#             correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "#     test_loss /= num_batches\n",
    "#     correct /= size\n",
    "#     print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "# epochs = 5\n",
    "# for t in range(epochs):\n",
    "#     print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "#     train(train_dataloader, model, loss_fn, optimizer)\n",
    "#     test(test_dataloader, model, loss_fn)\n",
    "# print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProtEmbedding",
   "language": "python",
   "name": "protembedding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
