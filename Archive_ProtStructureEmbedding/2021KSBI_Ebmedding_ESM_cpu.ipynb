{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:18:08.373179Z",
     "start_time": "2021-12-04T18:18:07.578480Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:18:08.383477Z",
     "start_time": "2021-12-04T18:18:08.374664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 21)\n"
     ]
    }
   ],
   "source": [
    "df_aaindex = pd.read_csv('../data/aaindex/df_aaindex19.csv')\n",
    "print(df_aaindex.shape)\n",
    "df_aaindex.head(1)\n",
    "tmp = df_aaindex.drop('Unnamed: 0',axis=1).T\n",
    "aa2val = dict()\n",
    "for aa, val in zip(tmp.index, tmp.values):\n",
    "    aa2val[aa]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:18:10.837006Z",
     "start_time": "2021-12-04T18:18:08.384653Z"
    }
   },
   "outputs": [],
   "source": [
    "df_detect_peptide_train = pd.read_csv('../data/df_detect_peptide_train.csv')\n",
    "test = pd.read_csv('../data/df_detect_peptide_test.csv')\n",
    "train, val = train_test_split(df_detect_peptide_train, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:18:10.849741Z",
     "start_time": "2021-12-04T18:18:10.838343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide</th>\n",
       "      <th>En</th>\n",
       "      <th>Ec</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>protein</th>\n",
       "      <th>PEP</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>595411</th>\n",
       "      <td>K.QELNEPPKQSTSFLVLQEILESEEKGDPNK.P</td>\n",
       "      <td>VYKMLQEKQELNEPP</td>\n",
       "      <td>EEKGDPNKPSGFRSV</td>\n",
       "      <td>QELNEPPKQSTSFLV</td>\n",
       "      <td>EILESEEKGDPNKPS</td>\n",
       "      <td>sp|O00151|PDLI1_HUMAN</td>\n",
       "      <td>QELNEPPKQSTSFLVLQEILESEEKGDPNK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   peptide               En               Ec  \\\n",
       "595411  K.QELNEPPKQSTSFLVLQEILESEEKGDPNK.P  VYKMLQEKQELNEPP  EEKGDPNKPSGFRSV   \n",
       "\n",
       "                     E1               E2                protein  \\\n",
       "595411  QELNEPPKQSTSFLV  EILESEEKGDPNKPS  sp|O00151|PDLI1_HUMAN   \n",
       "\n",
       "                                   PEP  ID  \n",
       "595411  QELNEPPKQSTSFLVLQEILESEEKGDPNK   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:19:00.989692Z",
     "start_time": "2021-12-04T18:18:59.803008Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*4)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:19:03.061014Z",
     "start_time": "2021-12-04T18:19:03.058228Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# high param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:41:56.726094Z",
     "start_time": "2021-12-04T18:41:55.872668Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "pep_embed (InputLayer)          [(None, 30, 1280)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "n_embed (InputLayer)            [(None, 15, 1280)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c_embed (InputLayer)            [(None, 15, 1280)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "m1_embed (InputLayer)           [(None, 15, 1280)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "m2_embed (InputLayer)           [(None, 15, 1280)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_21 (LSTM)                  (None, 128)          721408      pep_embed[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_20 (LSTM)                  (None, 64)           344320      n_embed[0][0]                    \n",
      "                                                                 c_embed[0][0]                    \n",
      "                                                                 m1_embed[0][0]                   \n",
      "                                                                 m2_embed[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 128)          0           lstm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 64)           0           lstm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 64)           0           lstm_20[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 64)           0           lstm_20[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 64)           0           lstm_20[3][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge (Concatenate)             (None, 384)          0           dropout_83[0][0]                 \n",
      "                                                                 dropout_79[0][0]                 \n",
      "                                                                 dropout_80[0][0]                 \n",
      "                                                                 dropout_81[0][0]                 \n",
      "                                                                 dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 128)          49280       merge[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 128)          0           fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 1)            129         dropout_84[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,115,137\n",
      "Trainable params: 1,115,137\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "# Embedding from ESM\n",
    "pep_embed = tf.keras.layers.Input(shape=((30, 1280,)), name='pep_embed')\n",
    "meta = tf.keras.layers.Input(shape=((39,)))  # peptide info\n",
    "n_embed = tf.keras.layers.Input(shape=((15, 1280,)), name='n_embed')\n",
    "c_embed = tf.keras.layers.Input(shape=((15, 1280,)), name='c_embed')\n",
    "m1_embed = tf.keras.layers.Input(shape=((15, 1280,)), name='m1_embed')\n",
    "m2_embed = tf.keras.layers.Input(shape=((15, 1280,)), name='m2_embed')\n",
    "\n",
    "# LSTM\n",
    "net_meta = tf.keras.layers.Dense(32, activation='relu', name='meta')(meta)\n",
    "net_meta = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_meta)\n",
    "\n",
    "ts_lstm1 = tf.keras.layers.LSTM(64)\n",
    "# ts_lstm2 = tf.keras.layers.LSTM(64)\n",
    "# ts_lstm3 = tf.keras.layers.LSTM(64)\n",
    "pep_lstm1 = tf.keras.layers.LSTM(128)\n",
    "# pep_lstm2 = tf.keras.layers.LSTM(128)\n",
    "# pep_lstm3 = tf.keras.layers.LSTM(128, name='pep_lstm3')\n",
    "\n",
    "# tf.keras.layers.Bidirectional()\n",
    "n_lstm = ts_lstm1(n_embed)\n",
    "n_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(n_lstm)\n",
    "# n_lstm = ts_lstm2(n_lstm)\n",
    "# n_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(n_lstm)\n",
    "# n_lstm = ts_lstm3(n_lstm)\n",
    "# n_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(n_lstm)\n",
    "\n",
    "c_lstm = ts_lstm1(c_embed)\n",
    "c_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(c_lstm)\n",
    "# c_lstm = ts_lstm2(c_lstm)\n",
    "# c_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(c_lstm)\n",
    "# c_lstm = ts_lstm3(c_lstm)\n",
    "# c_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(c_lstm)\n",
    "\n",
    "m1_lstm = ts_lstm1(m1_embed)\n",
    "m1_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(m1_lstm)\n",
    "# m1_lstm = ts_lstm2(m1_lstm)\n",
    "# m1_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(m1_lstm)\n",
    "# m1_lstm = ts_lstm3(m1_lstm)\n",
    "# m1_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(m1_lstm)\n",
    "\n",
    "m2_lstm = ts_lstm1(m2_embed)\n",
    "m2_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(m2_lstm)\n",
    "# m2_lstm = ts_lstm2(m2_lstm)\n",
    "# m2_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(m2_lstm)\n",
    "# m2_lstm = ts_lstm3(m2_lstm)\n",
    "# m2_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(m2_lstm)\n",
    "\n",
    "pep_lstm = pep_lstm1(pep_embed)\n",
    "pep_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(pep_lstm)\n",
    "# pep_lstm = pep_lstm2(pep_lstm)\n",
    "# pep_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(pep_lstm)\n",
    "# pep_lstm = pep_lstm3(pep_lstm)\n",
    "# pep_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(pep_lstm)\n",
    "\n",
    "\n",
    "# Dense\n",
    "merge = tf.keras.layers.concatenate([pep_lstm, \n",
    "#                                      net_meta,\n",
    "                                     n_lstm,\n",
    "                                     c_lstm,\n",
    "                                     m1_lstm,\n",
    "                                     m2_lstm\n",
    "                                    ], name='merge')\n",
    "\n",
    "net_merge = tf.keras.layers.Dense(128, activation='relu', name='fc1')(merge)\n",
    "net_merge = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_merge)\n",
    "# net_merge = tf.keras.layers.Dense(128, activation='relu', name='fc2')(net_merge)\n",
    "# net_merge = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_merge)\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation = 'sigmoid', name='out')(net_merge)\n",
    "\n",
    "model_high = tf.keras.Model(inputs=[pep_embed, n_embed, c_embed, m1_embed, m2_embed],  # meta, \n",
    "                            outputs=[output])\n",
    "\n",
    "model_high.summary()\n",
    "\n",
    "model_high.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                      mode='min', \n",
    "                                      verbose=1,\n",
    "                                      patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T18:24:06.719499Z",
     "start_time": "2021-12-04T18:24:06.716209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8837889"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_high.count_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESM embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T21:56:39.359340Z",
     "start_time": "2021-12-02T21:56:39.052337Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train, val, test], axis=0).reset_index(drop=True)\n",
    "\n",
    "train_idx = df.iloc[:len(train), :].index\n",
    "val_idx = df.iloc[len(train):len(train)+len(val), :].index\n",
    "test_idx = df.iloc[len(train)+len(val):, :].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T23:02:19.237439Z",
     "start_time": "2021-12-02T23:02:19.230743Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "PATH_TO_REPO = \"/home/bis/2021_AIhub/esm/\"\n",
    "sys.path.append(PATH_TO_REPO)\n",
    "\n",
    "import torch\n",
    "import esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T21:38:49.090468Z",
     "start_time": "2021-12-02T21:38:49.075016Z"
    }
   },
   "outputs": [],
   "source": [
    "import os  #for accessing the file system of the system\n",
    "import random\n",
    "from tensorflow import keras\n",
    "import torch\n",
    "\n",
    "\n",
    "# data generator class\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, ids, vecs_dir, labels_dir, batch_size=128, emb_size=1280, n_classes=1, EMB_LAYER=33, shuffle=True):\n",
    "        self.id_names = ids\n",
    "        self.indexes = np.arange(len(self.id_names))\n",
    "        self.vecs_dir = vecs_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.emb_size = emb_size\n",
    "        self.n_classes = n_classes\n",
    "        self.EMB_LAYER = EMB_LAYER\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "        \n",
    "    # for printing the statistics of the function\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.id_names))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "            \n",
    "    def __data_generation__(self, id_name):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        lab_name = id_name.split('.')[0]\n",
    "        label_path = f'{self.labels_dir}{lab_name}'  # idx.pt file to idx\n",
    "        lab = int(open(label_path, 'r').readlines()[0])\n",
    "        \n",
    "        pep_path = self.vecs_dir + 'PEP/'\n",
    "        en_path = self.vecs_dir + 'En/'\n",
    "        ec_path = self.vecs_dir + 'Ec/'\n",
    "        m1_path = self.vecs_dir + 'E1/'\n",
    "        m2_path = self.vecs_dir + 'E2/'\n",
    "        \n",
    "        pep_fn = f'{pep_path}{id_name}'  # vector 1개 경로\n",
    "        en_fn = f'{en_path}{id_name}'\n",
    "        ec_fn = f'{ec_path}{id_name}'\n",
    "        m1_fn = f'{m1_path}{id_name}'\n",
    "        m2_fn = f'{m2_path}{id_name}'\n",
    "        \n",
    "        embs = torch.load(pep_fn)['representations'][self.EMB_LAYER]\n",
    "        pep_zp = torch.nn.ZeroPad2d((0, 0, 30-len(embs), 0))  # zero padding on top\n",
    "        pep_embed = pep_zp(embs).numpy()\n",
    "        en_embed = torch.load(en_fn)['representations'][self.EMB_LAYER].numpy()\n",
    "        ec_embed = torch.load(ec_fn)['representations'][self.EMB_LAYER].numpy()\n",
    "        m1_embed = torch.load(m1_fn)['representations'][self.EMB_LAYER].numpy()\n",
    "        if len(m1_embed)==1:\n",
    "            m1_embed = np.zeros((15, 1280))\n",
    "        m2_embed = torch.load(m2_fn)['representations'][self.EMB_LAYER].numpy()\n",
    "        if len(m2_embed)==1:\n",
    "            m2_embed = np.zeros((15, 1280))\n",
    "\n",
    "        return pep_embed, en_embed, ec_embed, m1_embed, m2_embed, lab\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"Denotes the number of batches per epoch\"\n",
    "        # self.id_names: 존재하는 총 vector 개수를 의미합니다.\n",
    "        # self.batch_size: 배치사이즈를 의미합니다.\n",
    "        return int(np.floor(len(self.id_names) / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):  # index : batch no.\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_ids = [self.id_names[k] for k in indexes]\n",
    "\n",
    "        pep_embeds = list()\n",
    "        en_embeds = list()\n",
    "        ec_embeds = list()\n",
    "        m1_embeds = list()\n",
    "        m2_embeds = list()\n",
    "        labels = list()\n",
    "\n",
    "        for id_name in batch_ids:\n",
    "            pep_embed, en_embed, ec_embed, m1_embed, m2_embed, lab = self.__data_generation__(id_name)\n",
    "            pep_embeds.append(pep_embed)\n",
    "            en_embeds.append(en_embed)\n",
    "            ec_embeds.append(ec_embed)\n",
    "            m1_embeds.append(m1_embed)\n",
    "            m2_embeds.append(m2_embed)\n",
    "            labels.append(lab)\n",
    "\n",
    "        pep_embeds = np.array(pep_embeds)\n",
    "        en_embeds = np.array(en_embeds)\n",
    "        ec_embeds = np.array(ec_embeds)\n",
    "        m1_embeds = np.array(m1_embeds)\n",
    "        m2_embeds = np.array(m2_embeds)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        return [pep_embeds, en_embeds, ec_embeds, m1_embeds, m2_embeds], labels # return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T21:38:50.270836Z",
     "start_time": "2021-12-02T21:38:49.986392Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training batches:  2123\n",
      "total validaton batches:  530\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter\n",
    "emb_size = 1280\n",
    "train_path = '/data/211129_SJH_ESM/ProtStructureEmbedding_emb_esm1b/'  # 벡터 파일들의 경로\n",
    "idname_path = '/data/211129_SJH_ESM/ProtStructureEmbedding_emb_esm1b/PEP'  # 벡터 파일들의 경로\n",
    "labels_path = '/data/211129_SJH_ESM/ProtStructureEmbedding_emb_esm1b/LABEL/'  # 라벨 파일들의 경로\n",
    "epochs = 300  # number of time we need to train dataset\n",
    "lr = 1e-4\n",
    "batch_size = 256  # tarining batch size\n",
    "\n",
    "# train path\n",
    "train_ids = np.array(os.listdir(idname_path))  #[1.pt, 2.pt .....]\n",
    "valid_ids = train_ids[val_idx]\n",
    "train_ids = train_ids[train_idx]\n",
    "\n",
    "# train, validation Datagenerator 클래스를  각각 생성합니다.\n",
    "train_gen = DataGenerator(train_ids, train_path, labels_path, emb_size=emb_size, batch_size=batch_size)\n",
    "valid_gen = DataGenerator(valid_ids, train_path, labels_path, emb_size=emb_size, batch_size=batch_size)\n",
    "# 여기서 ids, train_path는 f'{train_path}{id}이런 식으로 경로로 결합하여, 최종적인 임베딩 벡터의 경로가 됩니다.\n",
    "# 이 경로는 앞서 구현한 DataGenerator클래스에서 벡터 불러들이는데 사용됩니다.\n",
    "\n",
    "print(\"total training batches: \", len(train_gen))\n",
    "print(\"total validaton batches: \", len(valid_gen))\n",
    "train_steps = len(train_ids) // batch_size\n",
    "valid_steps = len(valid_ids) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T21:39:07.760533Z",
     "start_time": "2021-12-02T21:38:51.227519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.53 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s = time.time()\n",
    "\n",
    "tg = train_gen.__getitem__(256)\n",
    "vg = valid_gen.__getitem__(256)\n",
    "\n",
    "e = time.time()\n",
    "print(round(e-s, 2), 'sec')  # read에 10분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T21:39:07.767256Z",
     "start_time": "2021-12-02T21:39:07.762560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.181691666666667"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(e-s, 2)*(train_steps + valid_steps) / 3600  # 1epoch의 read data에 12시간 .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T21:39:07.780052Z",
     "start_time": "2021-12-02T21:39:07.768839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 30, 1280) (256, 15, 1280) (256, 15, 1280) (256, 15, 1280) (256, 15, 1280) (256,)\n",
      "(256, 30, 1280) (256, 15, 1280) (256, 15, 1280) (256, 15, 1280) (256, 15, 1280) (256,)\n"
     ]
    }
   ],
   "source": [
    "[p, en, ec, m1, m2], lab = tg\n",
    "print(p.shape, en.shape, ec.shape, m1.shape, m2.shape, lab.shape)\n",
    "[p, en, ec, m1, m2], lab = vg\n",
    "print(p.shape, en.shape, ec.shape, m1.shape, m2.shape, lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-02T21:38:55.436Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "  69/2123 [..............................] - ETA: 7:40:15 - loss: 0.6263 - accuracy: 0.6793"
     ]
    }
   ],
   "source": [
    "history = model_high.fit_generator(generator=train_gen, validation_data=valid_gen,\n",
    "                                   steps_per_epoch=train_steps, validation_steps=valid_steps,\n",
    "                                   epochs=256,\n",
    "                                   callbacks=[es]\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-29T18:00:57.406Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,2))\n",
    "plt.subplot(1,2,1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.subplot(1,2,2)\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-29T18:00:57.934Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_high.evaluate([pep_test, aa_test, en_test, ec_test, e1_test, e2_test], y_test)\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "# prediction\n",
    "y_pred = [1 if i>=0.5 else 0 for i in model_high.predict([pep_test, aa_test, en_test, ec_test, e1_test, e2_test])]\n",
    "print(classification_report(y_test, y_pred))\n",
    "# AUC\n",
    "probs = model_high.predict([pep_test, aa_test, en_test, ec_test, e1_test, e2_test])\n",
    "rf_auc = roc_auc_score(y_test, probs)\n",
    "print('rf auc : {}'.format(rf_auc))\n",
    "# plot the roc curve for the model_high\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, probs)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='RF AUC = {:.4f}'.format(rf_auc), color='orange')\n",
    "plt.title('ROC curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=',.0f')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2.4",
   "language": "python",
   "name": "tf2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
