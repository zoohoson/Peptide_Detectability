{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T17:31:31.806724Z",
     "start_time": "2021-09-15T17:31:31.803321Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import time\n",
    "import pickle\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T17:31:34.291158Z",
     "start_time": "2021-09-15T17:31:34.283864Z"
    }
   },
   "outputs": [],
   "source": [
    "def genData(file,max_len):\n",
    "    aa_dict={'A':1,'R':2,'N':3,'D':4,'C':5,'Q':6,'E':7,'G':8,'H':9,'I':10,\n",
    "             'L':11,'K':12,'M':13,'F':14,'P':15,'O':16,'S':17,'U':18,'T':19,\n",
    "             'W':20,'Y':21,'V':22,'X':23}\n",
    "    with open(file, 'r') as inf:\n",
    "        lines = inf.read().splitlines()\n",
    "        \n",
    "    long_pep_counter=0\n",
    "    pep_codes=[]\n",
    "    labels=[]\n",
    "    for pep in lines:\n",
    "        pep,label=pep.split(\",\")\n",
    "        labels.append(int(label))\n",
    "        if not len(pep) > max_len:\n",
    "            current_pep=[]\n",
    "            for aa in pep:\n",
    "                current_pep.append(aa_dict[aa])\n",
    "            pep_codes.append(torch.tensor(current_pep))\n",
    "        else:\n",
    "            long_pep_counter += 1\n",
    "    print(\"length > {}:\".format(max_len),long_pep_counter)\n",
    "    data = rnn_utils.pad_sequence(pep_codes, batch_first=True)  # padding\n",
    "    return data,torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T17:32:03.319429Z",
     "start_time": "2021-09-15T17:32:03.315332Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        acc_sum += (outputs.argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "def to_log(log):\n",
    "    with open(\"compareModel/2021ACS_PepFormer/modelLog.log\",\"a+\") as f:\n",
    "        f.write(log+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Data X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T17:32:08.364189Z",
     "start_time": "2021-09-15T17:32:07.492136Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T17:33:08.213825Z",
     "start_time": "2021-09-15T17:33:07.357136Z"
    }
   },
   "outputs": [],
   "source": [
    "df_detect_peptide_train = pd.read_csv('../data/df_detect_peptide_train_noptm.csv')\n",
    "df_detect_peptide_test = pd.read_csv('../data/df_detect_peptide_test_noptm.csv')\n",
    "\n",
    "tra, val = train_test_split(df_detect_peptide_train[['PEP', 'ID']], test_size=0.2, random_state=7)\n",
    "tra.to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_train_noptm.csv', header=False, index=False)\n",
    "val.to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_val_noptm.csv', header=False, index=False)\n",
    "df_detect_peptide_test[['PEP', 'ID']].to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_test_noptm.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T17:33:37.810540Z",
     "start_time": "2021-09-15T17:33:34.194831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length > 30: 0\n",
      "torch.Size([142397, 30]) torch.Size([142397])\n",
      "length > 30: 0\n",
      "torch.Size([35600, 30]) torch.Size([35600])\n",
      "length > 30: 0\n",
      "torch.Size([44499, 30]) torch.Size([44499])\n"
     ]
    }
   ],
   "source": [
    "train_data,train_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_train_noptm.csv\",30)\n",
    "print(train_data.shape, train_label.shape)\n",
    "train_dataset = Data.TensorDataset(train_data, train_label)\n",
    "\n",
    "val_data,val_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_val_noptm.csv\",30)\n",
    "print(val_data.shape, val_label.shape)\n",
    "val_dataset = Data.TensorDataset(val_data, val_label)\n",
    "\n",
    "test_data,test_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_test_noptm.csv\",30)\n",
    "print(test_data.shape, test_label.shape)\n",
    "test_dataset = Data.TensorDataset(test_data, test_label)\n",
    "\n",
    "batch_size=256\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_iter_cont = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                                                  shuffle=True, collate_fn=collate)\n",
    "val_iter = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T17:33:39.980085Z",
     "start_time": "2021-09-15T17:33:39.964261Z"
    }
   },
   "outputs": [],
   "source": [
    "class newModel(nn.Module):\n",
    "    def __init__(self, vocab_size=24):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 25\n",
    "        self.batch_size = 256\n",
    "        self.emb_dim = 512\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, self.emb_dim, padding_idx=0)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.gru = nn.GRU(self.emb_dim, self.hidden_dim, num_layers=2, \n",
    "                               bidirectional=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.block1=nn.Sequential(nn.Linear(1600,1024),\n",
    "                                            nn.BatchNorm1d(1024),\n",
    "                                            nn.LeakyReLU(),\n",
    "                                            nn.Linear(1024,256),\n",
    "                                 )\n",
    "\n",
    "        self.block2=nn.Sequential(\n",
    "                                               nn.BatchNorm1d(256),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(256,128),\n",
    "                                               nn.BatchNorm1d(128),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(128,64),\n",
    "                                               nn.BatchNorm1d(64),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(64,2)\n",
    "                                            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.embedding(x)\n",
    "        output=self.transformer_encoder(x).permute(1, 0, 2)\n",
    "        output,hn=self.gru(output)\n",
    "        output=output.permute(1,0,2)\n",
    "        hn=hn.permute(1,0,2)\n",
    "        output=output.reshape(output.shape[0],-1)\n",
    "        hn=hn.reshape(output.shape[0],-1)\n",
    "        output=torch.cat([output,hn],1)\n",
    "        return self.block1(output)\n",
    "\n",
    "    def trainModel(self, x):\n",
    "        with torch.no_grad():\n",
    "            output=self.forward(x)\n",
    "        return self.block2(output)\n",
    "\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # euclidean_distance: [128]\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +     # calmp夹断用法\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))     \n",
    "        \n",
    "        return loss_contrastive\n",
    "    \n",
    "    \n",
    "def collate(batch):\n",
    "    seq1_ls=[]\n",
    "    seq2_ls=[]\n",
    "    label1_ls=[]\n",
    "    label2_ls=[]\n",
    "    label_ls=[]\n",
    "    batch_size=len(batch)\n",
    "    for i in range(int(batch_size/2)):\n",
    "        seq1,label1=batch[i][0],batch[i][1]\n",
    "        seq2,label2=batch[i+int(batch_size/2)][0],batch[i+int(batch_size/2)][1]\n",
    "        label1_ls.append(label1.unsqueeze(0))\n",
    "        label2_ls.append(label2.unsqueeze(0))\n",
    "        label=(label1^label2)\n",
    "        seq1_ls.append(seq1.unsqueeze(0))\n",
    "        seq2_ls.append(seq2.unsqueeze(0))\n",
    "        label_ls.append(label.unsqueeze(0))\n",
    "    seq1=torch.cat(seq1_ls).to(device)\n",
    "    seq2=torch.cat(seq2_ls).to(device)\n",
    "    label=torch.cat(label_ls).to(device)\n",
    "    label1=torch.cat(label1_ls).to(device)\n",
    "    label2=torch.cat(label2_ls).to(device)\n",
    "    return seq1,seq2,label,label1,label2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T17:34:50.820990Z",
     "start_time": "2021-09-15T17:34:50.811324Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T21:08:12.432722Z",
     "start_time": "2021-09-15T18:15:26.907708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 169.97503, loss1: 1.72843, loss2_3: 168.24660\n",
      "\ttrain_acc: 0.6984, test_acc: \u001b[31m0.6960393258426967\u001b[0m, time: 50.67\n",
      "best_acc: 0.6960393258426967\n",
      "epoch: 2, loss: 115.41453, loss1: 0.91515, loss2_3: 114.49937\n",
      "\ttrain_acc: 0.8114, test_acc: \u001b[31m0.8103651685393258\u001b[0m, time: 50.38\n",
      "best_acc: 0.8103651685393258\n",
      "epoch: 3, loss: 102.23526, loss1: 0.85648, loss2_3: 101.37878\n",
      "\ttrain_acc: 0.8174, test_acc: \u001b[31m0.8175\u001b[0m, time: 50.53\n",
      "best_acc: 0.8175\n",
      "epoch: 4, loss: 97.55190, loss1: 0.81617, loss2_3: 96.73573\n",
      "\ttrain_acc: 0.8449, test_acc: \u001b[31m0.8452808988764045\u001b[0m, time: 50.48\n",
      "best_acc: 0.8452808988764045\n",
      "epoch: 5, loss: 93.61148, loss1: 0.78654, loss2_3: 92.82495\n",
      "\ttrain_acc: 0.8371, test_acc: \u001b[31m0.8367415730337079\u001b[0m, time: 51.03\n",
      "epoch: 6, loss: 92.52162, loss1: 0.77732, loss2_3: 91.74429\n",
      "\ttrain_acc: 0.8298, test_acc: \u001b[31m0.829129213483146\u001b[0m, time: 50.76\n",
      "epoch: 7, loss: 90.64412, loss1: 0.75739, loss2_3: 89.88674\n",
      "\ttrain_acc: 0.8502, test_acc: \u001b[31m0.8513483146067415\u001b[0m, time: 50.59\n",
      "best_acc: 0.8513483146067415\n",
      "epoch: 8, loss: 89.49029, loss1: 0.74470, loss2_3: 88.74559\n",
      "\ttrain_acc: 0.8522, test_acc: \u001b[31m0.8530337078651685\u001b[0m, time: 50.59\n",
      "best_acc: 0.8530337078651685\n",
      "epoch: 9, loss: 88.82825, loss1: 0.73746, loss2_3: 88.09080\n",
      "\ttrain_acc: 0.8539, test_acc: \u001b[31m0.8539325842696629\u001b[0m, time: 50.65\n",
      "best_acc: 0.8539325842696629\n",
      "epoch: 10, loss: 88.40973, loss1: 0.73039, loss2_3: 87.67933\n",
      "\ttrain_acc: 0.8553, test_acc: \u001b[31m0.8548033707865168\u001b[0m, time: 50.15\n",
      "best_acc: 0.8548033707865168\n",
      "epoch: 11, loss: 87.49884, loss1: 0.72396, loss2_3: 86.77488\n",
      "\ttrain_acc: 0.8535, test_acc: \u001b[31m0.851685393258427\u001b[0m, time: 51.16\n",
      "epoch: 12, loss: 87.28370, loss1: 0.71859, loss2_3: 86.56511\n",
      "\ttrain_acc: 0.8565, test_acc: \u001b[31m0.8554213483146067\u001b[0m, time: 50.62\n",
      "best_acc: 0.8554213483146067\n",
      "epoch: 13, loss: 86.58293, loss1: 0.71239, loss2_3: 85.87054\n",
      "\ttrain_acc: 0.8599, test_acc: \u001b[31m0.8600842696629214\u001b[0m, time: 50.65\n",
      "best_acc: 0.8600842696629214\n",
      "epoch: 14, loss: 85.93397, loss1: 0.70365, loss2_3: 85.23032\n",
      "\ttrain_acc: 0.8593, test_acc: \u001b[31m0.8583988764044944\u001b[0m, time: 50.62\n",
      "epoch: 15, loss: 85.30700, loss1: 0.69221, loss2_3: 84.61479\n",
      "\ttrain_acc: 0.8606, test_acc: \u001b[31m0.8602247191011236\u001b[0m, time: 50.78\n",
      "best_acc: 0.8602247191011236\n",
      "epoch: 16, loss: 85.39304, loss1: 0.70005, loss2_3: 84.69299\n",
      "\ttrain_acc: 0.8611, test_acc: \u001b[31m0.8604775280898876\u001b[0m, time: 50.86\n",
      "best_acc: 0.8604775280898876\n",
      "epoch: 17, loss: 85.23003, loss1: 0.68917, loss2_3: 84.54086\n",
      "\ttrain_acc: 0.8512, test_acc: \u001b[31m0.8510955056179775\u001b[0m, time: 51.03\n",
      "epoch: 18, loss: 84.76143, loss1: 0.69301, loss2_3: 84.06843\n",
      "\ttrain_acc: 0.8595, test_acc: \u001b[31m0.8588483146067416\u001b[0m, time: 50.66\n",
      "epoch: 19, loss: 84.55875, loss1: 0.68796, loss2_3: 83.87079\n",
      "\ttrain_acc: 0.8626, test_acc: \u001b[31m0.8620505617977529\u001b[0m, time: 50.68\n",
      "best_acc: 0.8620505617977529\n",
      "epoch: 20, loss: 83.96994, loss1: 0.68494, loss2_3: 83.28500\n",
      "\ttrain_acc: 0.8556, test_acc: \u001b[31m0.854185393258427\u001b[0m, time: 50.68\n",
      "epoch: 21, loss: 83.96875, loss1: 0.68193, loss2_3: 83.28683\n",
      "\ttrain_acc: 0.8640, test_acc: \u001b[31m0.8625\u001b[0m, time: 50.70\n",
      "best_acc: 0.8625\n",
      "epoch: 22, loss: 83.55801, loss1: 0.67879, loss2_3: 82.87922\n",
      "\ttrain_acc: 0.8634, test_acc: \u001b[31m0.8635674157303371\u001b[0m, time: 50.73\n",
      "best_acc: 0.8635674157303371\n",
      "epoch: 23, loss: 83.31523, loss1: 0.67457, loss2_3: 82.64066\n",
      "\ttrain_acc: 0.8666, test_acc: \u001b[31m0.8652247191011236\u001b[0m, time: 50.89\n",
      "best_acc: 0.8652247191011236\n",
      "epoch: 24, loss: 82.88987, loss1: 0.67641, loss2_3: 82.21345\n",
      "\ttrain_acc: 0.8662, test_acc: \u001b[31m0.8644943820224719\u001b[0m, time: 50.43\n",
      "epoch: 25, loss: 82.78691, loss1: 0.67294, loss2_3: 82.11397\n",
      "\ttrain_acc: 0.8663, test_acc: \u001b[31m0.8654775280898876\u001b[0m, time: 50.98\n",
      "best_acc: 0.8654775280898876\n",
      "epoch: 26, loss: 82.69120, loss1: 0.67097, loss2_3: 82.02024\n",
      "\ttrain_acc: 0.8682, test_acc: \u001b[31m0.8674157303370786\u001b[0m, time: 50.42\n",
      "best_acc: 0.8674157303370786\n",
      "epoch: 27, loss: 82.19964, loss1: 0.66681, loss2_3: 81.53283\n",
      "\ttrain_acc: 0.8654, test_acc: \u001b[31m0.8629775280898876\u001b[0m, time: 50.24\n",
      "epoch: 28, loss: 82.29531, loss1: 0.66554, loss2_3: 81.62977\n",
      "\ttrain_acc: 0.8683, test_acc: \u001b[31m0.8671629213483146\u001b[0m, time: 49.66\n",
      "epoch: 29, loss: 82.11407, loss1: 0.66358, loss2_3: 81.45048\n",
      "\ttrain_acc: 0.8676, test_acc: \u001b[31m0.8656741573033708\u001b[0m, time: 48.02\n",
      "epoch: 30, loss: 81.84608, loss1: 0.66022, loss2_3: 81.18586\n",
      "\ttrain_acc: 0.8696, test_acc: \u001b[31m0.8671348314606742\u001b[0m, time: 48.16\n",
      "epoch: 31, loss: 81.92271, loss1: 0.65981, loss2_3: 81.26290\n",
      "\ttrain_acc: 0.8664, test_acc: \u001b[31m0.8643820224719101\u001b[0m, time: 47.78\n",
      "epoch: 32, loss: 81.25130, loss1: 0.65439, loss2_3: 80.59691\n",
      "\ttrain_acc: 0.8681, test_acc: \u001b[31m0.8659831460674158\u001b[0m, time: 48.40\n",
      "epoch: 33, loss: 81.30898, loss1: 0.65660, loss2_3: 80.65239\n",
      "\ttrain_acc: 0.8685, test_acc: \u001b[31m0.8660393258426966\u001b[0m, time: 47.70\n",
      "epoch: 34, loss: 81.10161, loss1: 0.65674, loss2_3: 80.44488\n",
      "\ttrain_acc: 0.8672, test_acc: \u001b[31m0.8662921348314607\u001b[0m, time: 47.70\n",
      "epoch: 35, loss: 81.25620, loss1: 0.65304, loss2_3: 80.60317\n",
      "\ttrain_acc: 0.8683, test_acc: \u001b[31m0.8676966292134831\u001b[0m, time: 47.82\n",
      "best_acc: 0.8676966292134831\n",
      "epoch: 36, loss: 81.01501, loss1: 0.64984, loss2_3: 80.36517\n",
      "\ttrain_acc: 0.8683, test_acc: \u001b[31m0.866629213483146\u001b[0m, time: 48.08\n",
      "epoch: 37, loss: 80.49418, loss1: 0.64973, loss2_3: 79.84444\n",
      "\ttrain_acc: 0.8685, test_acc: \u001b[31m0.866685393258427\u001b[0m, time: 47.74\n",
      "epoch: 38, loss: 80.65324, loss1: 0.64682, loss2_3: 80.00643\n",
      "\ttrain_acc: 0.8692, test_acc: \u001b[31m0.8658707865168539\u001b[0m, time: 48.27\n",
      "epoch: 39, loss: 80.60346, loss1: 0.64541, loss2_3: 79.95806\n",
      "\ttrain_acc: 0.8701, test_acc: \u001b[31m0.8675280898876404\u001b[0m, time: 47.65\n",
      "epoch: 40, loss: 80.52817, loss1: 0.64587, loss2_3: 79.88230\n",
      "\ttrain_acc: 0.8689, test_acc: \u001b[31m0.8649719101123595\u001b[0m, time: 48.07\n",
      "epoch: 41, loss: 80.28968, loss1: 0.64236, loss2_3: 79.64732\n",
      "\ttrain_acc: 0.8716, test_acc: \u001b[31m0.8687640449438202\u001b[0m, time: 47.35\n",
      "best_acc: 0.8687640449438202\n",
      "epoch: 42, loss: 80.28582, loss1: 0.64548, loss2_3: 79.64033\n",
      "\ttrain_acc: 0.8714, test_acc: \u001b[31m0.8677247191011236\u001b[0m, time: 47.91\n",
      "epoch: 43, loss: 79.88240, loss1: 0.64198, loss2_3: 79.24042\n",
      "\ttrain_acc: 0.8722, test_acc: \u001b[31m0.869438202247191\u001b[0m, time: 48.39\n",
      "best_acc: 0.869438202247191\n",
      "epoch: 44, loss: 79.90553, loss1: 0.64022, loss2_3: 79.26531\n",
      "\ttrain_acc: 0.8704, test_acc: \u001b[31m0.8679213483146068\u001b[0m, time: 48.14\n",
      "epoch: 45, loss: 79.98583, loss1: 0.63996, loss2_3: 79.34587\n",
      "\ttrain_acc: 0.8720, test_acc: \u001b[31m0.8681460674157303\u001b[0m, time: 48.28\n",
      "epoch: 46, loss: 79.49337, loss1: 0.63778, loss2_3: 78.85559\n",
      "\ttrain_acc: 0.8716, test_acc: \u001b[31m0.868623595505618\u001b[0m, time: 47.87\n",
      "epoch: 47, loss: 79.29815, loss1: 0.63815, loss2_3: 78.66000\n",
      "\ttrain_acc: 0.8724, test_acc: \u001b[31m0.8691853932584269\u001b[0m, time: 47.66\n",
      "epoch: 48, loss: 79.29434, loss1: 0.63425, loss2_3: 78.66009\n",
      "\ttrain_acc: 0.8706, test_acc: \u001b[31m0.8675561797752809\u001b[0m, time: 47.52\n",
      "epoch: 49, loss: 79.05697, loss1: 0.63558, loss2_3: 78.42140\n",
      "\ttrain_acc: 0.8726, test_acc: \u001b[31m0.869438202247191\u001b[0m, time: 47.51\n",
      "epoch: 50, loss: 79.22785, loss1: 0.63245, loss2_3: 78.59540\n",
      "\ttrain_acc: 0.8736, test_acc: \u001b[31m0.8704213483146067\u001b[0m, time: 47.76\n",
      "best_acc: 0.8704213483146067\n",
      "epoch: 51, loss: 79.05126, loss1: 0.63254, loss2_3: 78.41872\n",
      "\ttrain_acc: 0.8727, test_acc: \u001b[31m0.8691573033707866\u001b[0m, time: 48.06\n",
      "epoch: 52, loss: 78.97113, loss1: 0.63329, loss2_3: 78.33784\n",
      "\ttrain_acc: 0.8732, test_acc: \u001b[31m0.8708146067415731\u001b[0m, time: 47.97\n",
      "best_acc: 0.8708146067415731\n",
      "epoch: 53, loss: 78.68538, loss1: 0.62642, loss2_3: 78.05896\n",
      "\ttrain_acc: 0.8693, test_acc: \u001b[31m0.8644943820224719\u001b[0m, time: 47.80\n",
      "epoch: 54, loss: 78.59690, loss1: 0.62923, loss2_3: 77.96767\n",
      "\ttrain_acc: 0.8738, test_acc: \u001b[31m0.8699157303370787\u001b[0m, time: 47.84\n",
      "epoch: 55, loss: 78.51583, loss1: 0.62570, loss2_3: 77.89014\n",
      "\ttrain_acc: 0.8720, test_acc: \u001b[31m0.866685393258427\u001b[0m, time: 47.88\n",
      "epoch: 56, loss: 78.22248, loss1: 0.62676, loss2_3: 77.59571\n",
      "\ttrain_acc: 0.8742, test_acc: \u001b[31m0.8705337078651686\u001b[0m, time: 48.00\n",
      "epoch: 57, loss: 78.22977, loss1: 0.62622, loss2_3: 77.60355\n",
      "\ttrain_acc: 0.8731, test_acc: \u001b[31m0.8708146067415731\u001b[0m, time: 48.11\n",
      "epoch: 58, loss: 78.32785, loss1: 0.62728, loss2_3: 77.70057\n",
      "\ttrain_acc: 0.8733, test_acc: \u001b[31m0.8700280898876405\u001b[0m, time: 47.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 59, loss: 77.95799, loss1: 0.62634, loss2_3: 77.33166\n",
      "\ttrain_acc: 0.8746, test_acc: \u001b[31m0.8707022471910112\u001b[0m, time: 47.39\n",
      "epoch: 60, loss: 77.77385, loss1: 0.61951, loss2_3: 77.15435\n",
      "\ttrain_acc: 0.8734, test_acc: \u001b[31m0.8691011235955056\u001b[0m, time: 47.44\n",
      "epoch: 61, loss: 77.81653, loss1: 0.62228, loss2_3: 77.19425\n",
      "\ttrain_acc: 0.8739, test_acc: \u001b[31m0.8723876404494382\u001b[0m, time: 47.73\n",
      "best_acc: 0.8723876404494382\n",
      "epoch: 62, loss: 77.81676, loss1: 0.62235, loss2_3: 77.19441\n",
      "\ttrain_acc: 0.8750, test_acc: \u001b[31m0.8712078651685393\u001b[0m, time: 48.19\n",
      "epoch: 63, loss: 77.58611, loss1: 0.62343, loss2_3: 76.96267\n",
      "\ttrain_acc: 0.8753, test_acc: \u001b[31m0.871938202247191\u001b[0m, time: 47.54\n",
      "epoch: 64, loss: 77.57607, loss1: 0.62113, loss2_3: 76.95494\n",
      "\ttrain_acc: 0.8757, test_acc: \u001b[31m0.8713483146067416\u001b[0m, time: 48.36\n",
      "epoch: 65, loss: 77.37984, loss1: 0.62070, loss2_3: 76.75914\n",
      "\ttrain_acc: 0.8737, test_acc: \u001b[31m0.8702808988764045\u001b[0m, time: 47.41\n",
      "epoch: 66, loss: 77.33127, loss1: 0.62108, loss2_3: 76.71019\n",
      "\ttrain_acc: 0.8748, test_acc: \u001b[31m0.8702808988764045\u001b[0m, time: 48.17\n",
      "epoch: 67, loss: 77.14122, loss1: 0.61933, loss2_3: 76.52188\n",
      "\ttrain_acc: 0.8734, test_acc: \u001b[31m0.8675561797752809\u001b[0m, time: 47.78\n",
      "epoch: 68, loss: 77.09999, loss1: 0.61401, loss2_3: 76.48599\n",
      "\ttrain_acc: 0.8756, test_acc: \u001b[31m0.8710955056179776\u001b[0m, time: 48.40\n",
      "epoch: 69, loss: 77.10344, loss1: 0.61577, loss2_3: 76.48767\n",
      "\ttrain_acc: 0.8760, test_acc: \u001b[31m0.8714887640449438\u001b[0m, time: 48.08\n",
      "epoch: 70, loss: 76.92791, loss1: 0.61682, loss2_3: 76.31109\n",
      "\ttrain_acc: 0.8763, test_acc: \u001b[31m0.8703651685393259\u001b[0m, time: 48.14\n",
      "epoch: 71, loss: 76.88058, loss1: 0.61549, loss2_3: 76.26509\n",
      "\ttrain_acc: 0.8743, test_acc: \u001b[31m0.8687359550561797\u001b[0m, time: 47.99\n",
      "epoch: 72, loss: 76.84380, loss1: 0.62029, loss2_3: 76.22351\n",
      "\ttrain_acc: 0.8771, test_acc: \u001b[31m0.8714887640449438\u001b[0m, time: 48.07\n",
      "epoch: 73, loss: 76.98173, loss1: 0.61085, loss2_3: 76.37088\n",
      "\ttrain_acc: 0.8731, test_acc: \u001b[31m0.8682303370786517\u001b[0m, time: 48.32\n",
      "epoch: 74, loss: 76.72293, loss1: 0.61364, loss2_3: 76.10930\n",
      "\ttrain_acc: 0.8764, test_acc: \u001b[31m0.8721348314606742\u001b[0m, time: 48.26\n",
      "epoch: 75, loss: 76.61568, loss1: 0.61325, loss2_3: 76.00243\n",
      "\ttrain_acc: 0.8785, test_acc: \u001b[31m0.8723314606741573\u001b[0m, time: 48.20\n",
      "epoch: 76, loss: 76.44531, loss1: 0.61518, loss2_3: 75.83012\n",
      "\ttrain_acc: 0.8765, test_acc: \u001b[31m0.8714887640449438\u001b[0m, time: 47.95\n",
      "epoch: 77, loss: 76.57325, loss1: 0.61138, loss2_3: 75.96186\n",
      "\ttrain_acc: 0.8776, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 48.49\n",
      "epoch: 78, loss: 76.41433, loss1: 0.61300, loss2_3: 75.80133\n",
      "\ttrain_acc: 0.8785, test_acc: \u001b[31m0.8724438202247191\u001b[0m, time: 47.70\n",
      "best_acc: 0.8724438202247191\n",
      "epoch: 79, loss: 76.31574, loss1: 0.61159, loss2_3: 75.70415\n",
      "\ttrain_acc: 0.8785, test_acc: \u001b[31m0.8712921348314607\u001b[0m, time: 48.27\n",
      "epoch: 80, loss: 76.19623, loss1: 0.61049, loss2_3: 75.58574\n",
      "\ttrain_acc: 0.8772, test_acc: \u001b[31m0.8699157303370787\u001b[0m, time: 47.69\n",
      "epoch: 81, loss: 76.22754, loss1: 0.61139, loss2_3: 75.61615\n",
      "\ttrain_acc: 0.8790, test_acc: \u001b[31m0.8735955056179775\u001b[0m, time: 47.79\n",
      "best_acc: 0.8735955056179775\n",
      "epoch: 82, loss: 76.19489, loss1: 0.61126, loss2_3: 75.58363\n",
      "\ttrain_acc: 0.8776, test_acc: \u001b[31m0.8707584269662921\u001b[0m, time: 47.94\n",
      "epoch: 83, loss: 76.22926, loss1: 0.61222, loss2_3: 75.61704\n",
      "\ttrain_acc: 0.8784, test_acc: \u001b[31m0.8705337078651686\u001b[0m, time: 47.36\n",
      "epoch: 84, loss: 76.01718, loss1: 0.60865, loss2_3: 75.40854\n",
      "\ttrain_acc: 0.8770, test_acc: \u001b[31m0.8696348314606741\u001b[0m, time: 47.30\n",
      "epoch: 85, loss: 75.87414, loss1: 0.60712, loss2_3: 75.26702\n",
      "\ttrain_acc: 0.8765, test_acc: \u001b[31m0.8719101123595505\u001b[0m, time: 47.43\n",
      "epoch: 86, loss: 76.01976, loss1: 0.60960, loss2_3: 75.41017\n",
      "\ttrain_acc: 0.8782, test_acc: \u001b[31m0.8723876404494382\u001b[0m, time: 47.73\n",
      "epoch: 87, loss: 75.81748, loss1: 0.60836, loss2_3: 75.20911\n",
      "\ttrain_acc: 0.8789, test_acc: \u001b[31m0.8731741573033708\u001b[0m, time: 48.19\n",
      "epoch: 88, loss: 75.76802, loss1: 0.60570, loss2_3: 75.16232\n",
      "\ttrain_acc: 0.8790, test_acc: \u001b[31m0.8714887640449438\u001b[0m, time: 47.83\n",
      "epoch: 89, loss: 75.80115, loss1: 0.60706, loss2_3: 75.19408\n",
      "\ttrain_acc: 0.8789, test_acc: \u001b[31m0.8728370786516854\u001b[0m, time: 47.87\n",
      "epoch: 90, loss: 75.60280, loss1: 0.60831, loss2_3: 74.99449\n",
      "\ttrain_acc: 0.8795, test_acc: \u001b[31m0.8722752808988764\u001b[0m, time: 48.36\n",
      "epoch: 91, loss: 75.59283, loss1: 0.60444, loss2_3: 74.98840\n",
      "\ttrain_acc: 0.8788, test_acc: \u001b[31m0.8729213483146068\u001b[0m, time: 48.21\n",
      "epoch: 92, loss: 75.83771, loss1: 0.60823, loss2_3: 75.22948\n",
      "\ttrain_acc: 0.8807, test_acc: \u001b[31m0.8736516853932584\u001b[0m, time: 48.32\n",
      "best_acc: 0.8736516853932584\n",
      "epoch: 93, loss: 75.56083, loss1: 0.60305, loss2_3: 74.95778\n",
      "\ttrain_acc: 0.8804, test_acc: \u001b[31m0.8724157303370786\u001b[0m, time: 47.56\n",
      "epoch: 94, loss: 75.42885, loss1: 0.60648, loss2_3: 74.82236\n",
      "\ttrain_acc: 0.8805, test_acc: \u001b[31m0.8721910112359551\u001b[0m, time: 48.57\n",
      "epoch: 95, loss: 75.35908, loss1: 0.60297, loss2_3: 74.75611\n",
      "\ttrain_acc: 0.8795, test_acc: \u001b[31m0.8706460674157304\u001b[0m, time: 47.85\n",
      "epoch: 96, loss: 75.26391, loss1: 0.60274, loss2_3: 74.66117\n",
      "\ttrain_acc: 0.8791, test_acc: \u001b[31m0.8728370786516854\u001b[0m, time: 48.44\n",
      "epoch: 97, loss: 75.09462, loss1: 0.60508, loss2_3: 74.48954\n",
      "\ttrain_acc: 0.8804, test_acc: \u001b[31m0.8736797752808989\u001b[0m, time: 48.11\n",
      "best_acc: 0.8736797752808989\n",
      "epoch: 98, loss: 75.18385, loss1: 0.60361, loss2_3: 74.58024\n",
      "\ttrain_acc: 0.8800, test_acc: \u001b[31m0.8721348314606742\u001b[0m, time: 47.72\n",
      "epoch: 99, loss: 75.14662, loss1: 0.60228, loss2_3: 74.54434\n",
      "\ttrain_acc: 0.8789, test_acc: \u001b[31m0.8723595505617977\u001b[0m, time: 48.09\n",
      "epoch: 100, loss: 75.17955, loss1: 0.60512, loss2_3: 74.57443\n",
      "\ttrain_acc: 0.8798, test_acc: \u001b[31m0.8718258426966292\u001b[0m, time: 47.98\n",
      "epoch: 101, loss: 74.92820, loss1: 0.60174, loss2_3: 74.32646\n",
      "\ttrain_acc: 0.8805, test_acc: \u001b[31m0.8714606741573033\u001b[0m, time: 47.90\n",
      "epoch: 102, loss: 75.01141, loss1: 0.60379, loss2_3: 74.40762\n",
      "\ttrain_acc: 0.8812, test_acc: \u001b[31m0.8741011235955056\u001b[0m, time: 48.45\n",
      "best_acc: 0.8741011235955056\n",
      "epoch: 103, loss: 74.90754, loss1: 0.59413, loss2_3: 74.31341\n",
      "\ttrain_acc: 0.8806, test_acc: \u001b[31m0.8723314606741573\u001b[0m, time: 48.72\n",
      "epoch: 104, loss: 74.72858, loss1: 0.59942, loss2_3: 74.12916\n",
      "\ttrain_acc: 0.8814, test_acc: \u001b[31m0.8736797752808989\u001b[0m, time: 47.68\n",
      "epoch: 105, loss: 74.63526, loss1: 0.60085, loss2_3: 74.03441\n",
      "\ttrain_acc: 0.8801, test_acc: \u001b[31m0.8733426966292135\u001b[0m, time: 48.15\n",
      "epoch: 106, loss: 74.64965, loss1: 0.60189, loss2_3: 74.04776\n",
      "\ttrain_acc: 0.8810, test_acc: \u001b[31m0.8713483146067416\u001b[0m, time: 48.25\n",
      "epoch: 107, loss: 74.53112, loss1: 0.60235, loss2_3: 73.92877\n",
      "\ttrain_acc: 0.8811, test_acc: \u001b[31m0.8734831460674157\u001b[0m, time: 48.37\n",
      "epoch: 108, loss: 74.58728, loss1: 0.60157, loss2_3: 73.98571\n",
      "\ttrain_acc: 0.8799, test_acc: \u001b[31m0.8735112359550562\u001b[0m, time: 47.99\n",
      "epoch: 109, loss: 74.62128, loss1: 0.60007, loss2_3: 74.02121\n",
      "\ttrain_acc: 0.8808, test_acc: \u001b[31m0.8716573033707865\u001b[0m, time: 48.11\n",
      "epoch: 110, loss: 74.52367, loss1: 0.60107, loss2_3: 73.92260\n",
      "\ttrain_acc: 0.8823, test_acc: \u001b[31m0.8741853932584269\u001b[0m, time: 48.26\n",
      "best_acc: 0.8741853932584269\n",
      "epoch: 111, loss: 74.42934, loss1: 0.59963, loss2_3: 73.82971\n",
      "\ttrain_acc: 0.8825, test_acc: \u001b[31m0.8730337078651685\u001b[0m, time: 47.99\n",
      "epoch: 112, loss: 74.47830, loss1: 0.59923, loss2_3: 73.87906\n",
      "\ttrain_acc: 0.8796, test_acc: \u001b[31m0.8693820224719101\u001b[0m, time: 48.32\n",
      "epoch: 113, loss: 74.23026, loss1: 0.59852, loss2_3: 73.63174\n",
      "\ttrain_acc: 0.8804, test_acc: \u001b[31m0.8716011235955056\u001b[0m, time: 48.19\n",
      "epoch: 114, loss: 74.39136, loss1: 0.59648, loss2_3: 73.79487\n",
      "\ttrain_acc: 0.8786, test_acc: \u001b[31m0.8690449438202247\u001b[0m, time: 47.98\n",
      "epoch: 115, loss: 74.36635, loss1: 0.59832, loss2_3: 73.76803\n",
      "\ttrain_acc: 0.8798, test_acc: \u001b[31m0.8705337078651686\u001b[0m, time: 47.47\n",
      "epoch: 116, loss: 74.34467, loss1: 0.59818, loss2_3: 73.74649\n",
      "\ttrain_acc: 0.8805, test_acc: \u001b[31m0.8698595505617978\u001b[0m, time: 47.87\n",
      "epoch: 117, loss: 74.02451, loss1: 0.59409, loss2_3: 73.43042\n",
      "\ttrain_acc: 0.8819, test_acc: \u001b[31m0.8728370786516854\u001b[0m, time: 47.27\n",
      "epoch: 118, loss: 74.06745, loss1: 0.59306, loss2_3: 73.47438\n",
      "\ttrain_acc: 0.8830, test_acc: \u001b[31m0.8737078651685394\u001b[0m, time: 48.00\n",
      "epoch: 119, loss: 73.98821, loss1: 0.59715, loss2_3: 73.39106\n",
      "\ttrain_acc: 0.8824, test_acc: \u001b[31m0.8709550561797753\u001b[0m, time: 47.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 120, loss: 73.96951, loss1: 0.59505, loss2_3: 73.37446\n",
      "\ttrain_acc: 0.8812, test_acc: \u001b[31m0.8710955056179776\u001b[0m, time: 48.36\n",
      "epoch: 121, loss: 73.83865, loss1: 0.59547, loss2_3: 73.24317\n",
      "\ttrain_acc: 0.8832, test_acc: \u001b[31m0.8732865168539325\u001b[0m, time: 47.36\n",
      "epoch: 122, loss: 73.71773, loss1: 0.59175, loss2_3: 73.12597\n",
      "\ttrain_acc: 0.8823, test_acc: \u001b[31m0.8720786516853932\u001b[0m, time: 47.94\n",
      "epoch: 123, loss: 73.66012, loss1: 0.59473, loss2_3: 73.06538\n",
      "\ttrain_acc: 0.8837, test_acc: \u001b[31m0.873314606741573\u001b[0m, time: 48.09\n",
      "epoch: 124, loss: 73.73861, loss1: 0.59302, loss2_3: 73.14558\n",
      "\ttrain_acc: 0.8837, test_acc: \u001b[31m0.8736516853932584\u001b[0m, time: 44.83\n",
      "epoch: 125, loss: 73.59672, loss1: 0.59468, loss2_3: 73.00204\n",
      "\ttrain_acc: 0.8831, test_acc: \u001b[31m0.8728089887640449\u001b[0m, time: 39.53\n",
      "epoch: 126, loss: 73.58880, loss1: 0.59451, loss2_3: 72.99429\n",
      "\ttrain_acc: 0.8825, test_acc: \u001b[31m0.8719662921348315\u001b[0m, time: 34.49\n",
      "epoch: 127, loss: 73.51181, loss1: 0.59086, loss2_3: 72.92095\n",
      "\ttrain_acc: 0.8822, test_acc: \u001b[31m0.8729775280898876\u001b[0m, time: 34.48\n",
      "epoch: 128, loss: 73.63064, loss1: 0.59190, loss2_3: 73.03874\n",
      "\ttrain_acc: 0.8802, test_acc: \u001b[31m0.8682865168539325\u001b[0m, time: 34.46\n",
      "epoch: 129, loss: 73.39623, loss1: 0.59248, loss2_3: 72.80375\n",
      "\ttrain_acc: 0.8838, test_acc: \u001b[31m0.871938202247191\u001b[0m, time: 34.44\n",
      "epoch: 130, loss: 73.47880, loss1: 0.59406, loss2_3: 72.88474\n",
      "\ttrain_acc: 0.8837, test_acc: \u001b[31m0.871629213483146\u001b[0m, time: 34.45\n",
      "epoch: 131, loss: 73.23328, loss1: 0.59224, loss2_3: 72.64104\n",
      "\ttrain_acc: 0.8841, test_acc: \u001b[31m0.8722191011235955\u001b[0m, time: 34.46\n",
      "epoch: 132, loss: 73.16196, loss1: 0.59233, loss2_3: 72.56963\n",
      "\ttrain_acc: 0.8829, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 34.41\n",
      "epoch: 133, loss: 73.25525, loss1: 0.59195, loss2_3: 72.66330\n",
      "\ttrain_acc: 0.8857, test_acc: \u001b[31m0.8722191011235955\u001b[0m, time: 34.41\n",
      "epoch: 134, loss: 73.13861, loss1: 0.58789, loss2_3: 72.55072\n",
      "\ttrain_acc: 0.8849, test_acc: \u001b[31m0.8710955056179776\u001b[0m, time: 34.35\n",
      "epoch: 135, loss: 73.04494, loss1: 0.58948, loss2_3: 72.45546\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8677808988764045\u001b[0m, time: 34.61\n",
      "epoch: 136, loss: 73.10481, loss1: 0.58728, loss2_3: 72.51752\n",
      "\ttrain_acc: 0.8808, test_acc: \u001b[31m0.8678651685393258\u001b[0m, time: 34.45\n",
      "epoch: 137, loss: 72.92185, loss1: 0.59238, loss2_3: 72.32946\n",
      "\ttrain_acc: 0.8837, test_acc: \u001b[31m0.8706460674157304\u001b[0m, time: 34.57\n",
      "epoch: 138, loss: 72.82247, loss1: 0.58705, loss2_3: 72.23542\n",
      "\ttrain_acc: 0.8859, test_acc: \u001b[31m0.8726404494382023\u001b[0m, time: 34.49\n",
      "epoch: 139, loss: 72.80615, loss1: 0.58849, loss2_3: 72.21766\n",
      "\ttrain_acc: 0.8857, test_acc: \u001b[31m0.8721629213483146\u001b[0m, time: 34.37\n",
      "epoch: 140, loss: 72.79452, loss1: 0.59211, loss2_3: 72.20241\n",
      "\ttrain_acc: 0.8854, test_acc: \u001b[31m0.8712921348314607\u001b[0m, time: 34.42\n",
      "epoch: 141, loss: 72.70303, loss1: 0.58931, loss2_3: 72.11371\n",
      "\ttrain_acc: 0.8850, test_acc: \u001b[31m0.8728932584269663\u001b[0m, time: 34.41\n",
      "epoch: 142, loss: 72.61008, loss1: 0.58695, loss2_3: 72.02313\n",
      "\ttrain_acc: 0.8843, test_acc: \u001b[31m0.8728932584269663\u001b[0m, time: 34.43\n",
      "epoch: 143, loss: 72.67710, loss1: 0.58767, loss2_3: 72.08943\n",
      "\ttrain_acc: 0.8831, test_acc: \u001b[31m0.8690168539325843\u001b[0m, time: 34.46\n",
      "epoch: 144, loss: 72.54012, loss1: 0.58465, loss2_3: 71.95548\n",
      "\ttrain_acc: 0.8857, test_acc: \u001b[31m0.8734269662921348\u001b[0m, time: 34.55\n",
      "epoch: 145, loss: 72.42550, loss1: 0.58645, loss2_3: 71.83906\n",
      "\ttrain_acc: 0.8836, test_acc: \u001b[31m0.8692696629213483\u001b[0m, time: 34.55\n",
      "epoch: 146, loss: 72.53520, loss1: 0.58497, loss2_3: 71.95023\n",
      "\ttrain_acc: 0.8857, test_acc: \u001b[31m0.8710674157303371\u001b[0m, time: 34.55\n",
      "epoch: 147, loss: 72.38940, loss1: 0.58546, loss2_3: 71.80394\n",
      "\ttrain_acc: 0.8862, test_acc: \u001b[31m0.8723595505617977\u001b[0m, time: 34.60\n",
      "epoch: 148, loss: 72.43797, loss1: 0.58659, loss2_3: 71.85138\n",
      "\ttrain_acc: 0.8863, test_acc: \u001b[31m0.873061797752809\u001b[0m, time: 34.50\n",
      "epoch: 149, loss: 72.37416, loss1: 0.58694, loss2_3: 71.78722\n",
      "\ttrain_acc: 0.8852, test_acc: \u001b[31m0.8705898876404494\u001b[0m, time: 34.48\n",
      "epoch: 150, loss: 72.08300, loss1: 0.58537, loss2_3: 71.49763\n",
      "\ttrain_acc: 0.8887, test_acc: \u001b[31m0.8728089887640449\u001b[0m, time: 34.42\n",
      "epoch: 151, loss: 71.94505, loss1: 0.58351, loss2_3: 71.36154\n",
      "\ttrain_acc: 0.8859, test_acc: \u001b[31m0.871629213483146\u001b[0m, time: 34.46\n",
      "epoch: 152, loss: 72.04353, loss1: 0.58351, loss2_3: 71.46002\n",
      "\ttrain_acc: 0.8865, test_acc: \u001b[31m0.8726123595505618\u001b[0m, time: 34.40\n",
      "epoch: 153, loss: 72.00978, loss1: 0.58485, loss2_3: 71.42493\n",
      "\ttrain_acc: 0.8867, test_acc: \u001b[31m0.8724438202247191\u001b[0m, time: 34.44\n",
      "epoch: 154, loss: 71.98307, loss1: 0.58197, loss2_3: 71.40111\n",
      "\ttrain_acc: 0.8880, test_acc: \u001b[31m0.8722471910112359\u001b[0m, time: 34.33\n",
      "epoch: 155, loss: 71.85496, loss1: 0.58481, loss2_3: 71.27015\n",
      "\ttrain_acc: 0.8858, test_acc: \u001b[31m0.8694943820224719\u001b[0m, time: 34.40\n",
      "epoch: 156, loss: 71.91148, loss1: 0.57996, loss2_3: 71.33152\n",
      "\ttrain_acc: 0.8879, test_acc: \u001b[31m0.871432584269663\u001b[0m, time: 34.40\n",
      "epoch: 157, loss: 71.88001, loss1: 0.58281, loss2_3: 71.29720\n",
      "\ttrain_acc: 0.8888, test_acc: \u001b[31m0.871685393258427\u001b[0m, time: 34.37\n",
      "epoch: 158, loss: 71.79739, loss1: 0.58153, loss2_3: 71.21586\n",
      "\ttrain_acc: 0.8876, test_acc: \u001b[31m0.8704213483146067\u001b[0m, time: 34.43\n",
      "epoch: 159, loss: 71.76072, loss1: 0.58044, loss2_3: 71.18028\n",
      "\ttrain_acc: 0.8879, test_acc: \u001b[31m0.8720224719101124\u001b[0m, time: 34.36\n",
      "epoch: 160, loss: 71.68089, loss1: 0.58135, loss2_3: 71.09954\n",
      "\ttrain_acc: 0.8822, test_acc: \u001b[31m0.8667134831460674\u001b[0m, time: 34.41\n",
      "epoch: 161, loss: 71.57552, loss1: 0.57923, loss2_3: 70.99629\n",
      "\ttrain_acc: 0.8879, test_acc: \u001b[31m0.8694101123595506\u001b[0m, time: 34.39\n",
      "epoch: 162, loss: 71.46184, loss1: 0.58072, loss2_3: 70.88112\n",
      "\ttrain_acc: 0.8884, test_acc: \u001b[31m0.8715449438202247\u001b[0m, time: 34.43\n",
      "epoch: 163, loss: 71.27738, loss1: 0.58000, loss2_3: 70.69738\n",
      "\ttrain_acc: 0.8894, test_acc: \u001b[31m0.8722471910112359\u001b[0m, time: 34.40\n",
      "epoch: 164, loss: 71.23948, loss1: 0.58038, loss2_3: 70.65909\n",
      "\ttrain_acc: 0.8887, test_acc: \u001b[31m0.8712078651685393\u001b[0m, time: 34.35\n",
      "epoch: 165, loss: 71.32640, loss1: 0.57714, loss2_3: 70.74926\n",
      "\ttrain_acc: 0.8895, test_acc: \u001b[31m0.8726685393258427\u001b[0m, time: 34.42\n",
      "epoch: 166, loss: 71.10213, loss1: 0.58005, loss2_3: 70.52207\n",
      "\ttrain_acc: 0.8903, test_acc: \u001b[31m0.8707865168539326\u001b[0m, time: 34.38\n",
      "epoch: 167, loss: 71.29230, loss1: 0.57738, loss2_3: 70.71492\n",
      "\ttrain_acc: 0.8863, test_acc: \u001b[31m0.8682022471910112\u001b[0m, time: 34.41\n",
      "epoch: 168, loss: 71.12711, loss1: 0.57630, loss2_3: 70.55082\n",
      "\ttrain_acc: 0.8898, test_acc: \u001b[31m0.8709550561797753\u001b[0m, time: 34.39\n",
      "epoch: 169, loss: 71.05437, loss1: 0.58147, loss2_3: 70.47290\n",
      "\ttrain_acc: 0.8841, test_acc: \u001b[31m0.8660955056179775\u001b[0m, time: 34.34\n",
      "epoch: 170, loss: 70.81111, loss1: 0.57491, loss2_3: 70.23620\n",
      "\ttrain_acc: 0.8874, test_acc: \u001b[31m0.8695786516853933\u001b[0m, time: 34.39\n",
      "epoch: 171, loss: 70.85609, loss1: 0.57865, loss2_3: 70.27744\n",
      "\ttrain_acc: 0.8881, test_acc: \u001b[31m0.8694101123595506\u001b[0m, time: 34.38\n",
      "epoch: 172, loss: 70.79832, loss1: 0.57624, loss2_3: 70.22208\n",
      "\ttrain_acc: 0.8874, test_acc: \u001b[31m0.8672191011235955\u001b[0m, time: 34.39\n",
      "epoch: 173, loss: 70.61325, loss1: 0.57572, loss2_3: 70.03753\n",
      "\ttrain_acc: 0.8902, test_acc: \u001b[31m0.8708426966292134\u001b[0m, time: 34.44\n",
      "epoch: 174, loss: 70.78401, loss1: 0.57628, loss2_3: 70.20773\n",
      "\ttrain_acc: 0.8921, test_acc: \u001b[31m0.8724157303370786\u001b[0m, time: 34.39\n",
      "epoch: 175, loss: 70.67026, loss1: 0.57738, loss2_3: 70.09288\n",
      "\ttrain_acc: 0.8910, test_acc: \u001b[31m0.8723033707865169\u001b[0m, time: 34.48\n",
      "epoch: 176, loss: 70.56458, loss1: 0.57595, loss2_3: 69.98863\n",
      "\ttrain_acc: 0.8907, test_acc: \u001b[31m0.870561797752809\u001b[0m, time: 34.46\n",
      "epoch: 177, loss: 70.61228, loss1: 0.57752, loss2_3: 70.03476\n",
      "\ttrain_acc: 0.8912, test_acc: \u001b[31m0.8712640449438203\u001b[0m, time: 34.38\n",
      "epoch: 178, loss: 70.39558, loss1: 0.57374, loss2_3: 69.82184\n",
      "\ttrain_acc: 0.8863, test_acc: \u001b[31m0.8664887640449438\u001b[0m, time: 34.41\n",
      "epoch: 179, loss: 70.58844, loss1: 0.57498, loss2_3: 70.01346\n",
      "\ttrain_acc: 0.8907, test_acc: \u001b[31m0.8691292134831461\u001b[0m, time: 34.37\n",
      "epoch: 180, loss: 70.33469, loss1: 0.57412, loss2_3: 69.76057\n",
      "\ttrain_acc: 0.8900, test_acc: \u001b[31m0.8704775280898877\u001b[0m, time: 34.42\n",
      "epoch: 181, loss: 70.31352, loss1: 0.57282, loss2_3: 69.74069\n",
      "\ttrain_acc: 0.8936, test_acc: \u001b[31m0.8726123595505618\u001b[0m, time: 34.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 182, loss: 70.10354, loss1: 0.57247, loss2_3: 69.53107\n",
      "\ttrain_acc: 0.8935, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 34.74\n",
      "epoch: 183, loss: 69.85791, loss1: 0.56840, loss2_3: 69.28951\n",
      "\ttrain_acc: 0.8930, test_acc: \u001b[31m0.8729775280898876\u001b[0m, time: 34.60\n",
      "epoch: 184, loss: 69.91896, loss1: 0.57257, loss2_3: 69.34638\n",
      "\ttrain_acc: 0.8889, test_acc: \u001b[31m0.8673876404494382\u001b[0m, time: 34.41\n",
      "epoch: 185, loss: 69.91865, loss1: 0.57192, loss2_3: 69.34673\n",
      "\ttrain_acc: 0.8935, test_acc: \u001b[31m0.871685393258427\u001b[0m, time: 34.49\n",
      "epoch: 186, loss: 69.86096, loss1: 0.57238, loss2_3: 69.28858\n",
      "\ttrain_acc: 0.8933, test_acc: \u001b[31m0.8701123595505618\u001b[0m, time: 34.54\n",
      "epoch: 187, loss: 69.70523, loss1: 0.57305, loss2_3: 69.13218\n",
      "\ttrain_acc: 0.8923, test_acc: \u001b[31m0.8686797752808989\u001b[0m, time: 34.48\n",
      "epoch: 188, loss: 69.46302, loss1: 0.56896, loss2_3: 68.89406\n",
      "\ttrain_acc: 0.8882, test_acc: \u001b[31m0.8666573033707865\u001b[0m, time: 34.42\n",
      "epoch: 189, loss: 69.62266, loss1: 0.57161, loss2_3: 69.05105\n",
      "\ttrain_acc: 0.8947, test_acc: \u001b[31m0.8717977528089887\u001b[0m, time: 34.39\n",
      "epoch: 190, loss: 69.46505, loss1: 0.56951, loss2_3: 68.89554\n",
      "\ttrain_acc: 0.8932, test_acc: \u001b[31m0.8696348314606741\u001b[0m, time: 34.47\n",
      "epoch: 191, loss: 69.44598, loss1: 0.57047, loss2_3: 68.87551\n",
      "\ttrain_acc: 0.8956, test_acc: \u001b[31m0.8709269662921348\u001b[0m, time: 34.48\n",
      "epoch: 192, loss: 69.35788, loss1: 0.56850, loss2_3: 68.78938\n",
      "\ttrain_acc: 0.8924, test_acc: \u001b[31m0.8684831460674157\u001b[0m, time: 34.43\n",
      "epoch: 193, loss: 69.02007, loss1: 0.56595, loss2_3: 68.45411\n",
      "\ttrain_acc: 0.8933, test_acc: \u001b[31m0.8687640449438202\u001b[0m, time: 34.39\n",
      "epoch: 194, loss: 69.05274, loss1: 0.56543, loss2_3: 68.48731\n",
      "\ttrain_acc: 0.8935, test_acc: \u001b[31m0.8708988764044944\u001b[0m, time: 34.34\n",
      "epoch: 195, loss: 69.00514, loss1: 0.56753, loss2_3: 68.43761\n",
      "\ttrain_acc: 0.8959, test_acc: \u001b[31m0.8722191011235955\u001b[0m, time: 34.42\n",
      "epoch: 196, loss: 69.00137, loss1: 0.56722, loss2_3: 68.43415\n",
      "\ttrain_acc: 0.8950, test_acc: \u001b[31m0.8693258426966292\u001b[0m, time: 34.42\n",
      "epoch: 197, loss: 68.81065, loss1: 0.56198, loss2_3: 68.24867\n",
      "\ttrain_acc: 0.8871, test_acc: \u001b[31m0.8625561797752809\u001b[0m, time: 34.68\n",
      "epoch: 198, loss: 68.85044, loss1: 0.56435, loss2_3: 68.28608\n",
      "\ttrain_acc: 0.8958, test_acc: \u001b[31m0.8692415730337079\u001b[0m, time: 34.74\n",
      "epoch: 199, loss: 68.59939, loss1: 0.56071, loss2_3: 68.03868\n",
      "\ttrain_acc: 0.8980, test_acc: \u001b[31m0.8697191011235955\u001b[0m, time: 34.73\n",
      "epoch: 200, loss: 68.47629, loss1: 0.56468, loss2_3: 67.91161\n",
      "\ttrain_acc: 0.8975, test_acc: \u001b[31m0.8700561797752809\u001b[0m, time: 34.71\n",
      "epoch: 201, loss: 68.58130, loss1: 0.56102, loss2_3: 68.02028\n",
      "\ttrain_acc: 0.8975, test_acc: \u001b[31m0.8707022471910112\u001b[0m, time: 34.74\n",
      "epoch: 202, loss: 68.40256, loss1: 0.56265, loss2_3: 67.83991\n",
      "\ttrain_acc: 0.8960, test_acc: \u001b[31m0.8698595505617978\u001b[0m, time: 34.82\n",
      "epoch: 203, loss: 68.28404, loss1: 0.56624, loss2_3: 67.71780\n",
      "\ttrain_acc: 0.8957, test_acc: \u001b[31m0.8699157303370787\u001b[0m, time: 34.57\n",
      "epoch: 204, loss: 68.28931, loss1: 0.56194, loss2_3: 67.72737\n",
      "\ttrain_acc: 0.8958, test_acc: \u001b[31m0.8685112359550562\u001b[0m, time: 34.53\n",
      "epoch: 205, loss: 68.25021, loss1: 0.56066, loss2_3: 67.68955\n",
      "\ttrain_acc: 0.8956, test_acc: \u001b[31m0.8687359550561797\u001b[0m, time: 34.84\n",
      "epoch: 206, loss: 68.05208, loss1: 0.56343, loss2_3: 67.48864\n",
      "\ttrain_acc: 0.8925, test_acc: \u001b[31m0.8653089887640449\u001b[0m, time: 34.62\n",
      "epoch: 207, loss: 67.98699, loss1: 0.56163, loss2_3: 67.42536\n",
      "\ttrain_acc: 0.8980, test_acc: \u001b[31m0.8707865168539326\u001b[0m, time: 34.48\n",
      "epoch: 208, loss: 67.95007, loss1: 0.56220, loss2_3: 67.38787\n",
      "\ttrain_acc: 0.8974, test_acc: \u001b[31m0.8657022471910112\u001b[0m, time: 34.46\n",
      "epoch: 209, loss: 67.73915, loss1: 0.56035, loss2_3: 67.17880\n",
      "\ttrain_acc: 0.8983, test_acc: \u001b[31m0.8691292134831461\u001b[0m, time: 34.45\n",
      "epoch: 210, loss: 67.74339, loss1: 0.55953, loss2_3: 67.18386\n",
      "\ttrain_acc: 0.8982, test_acc: \u001b[31m0.8701966292134832\u001b[0m, time: 34.40\n",
      "epoch: 211, loss: 67.68514, loss1: 0.55857, loss2_3: 67.12657\n",
      "\ttrain_acc: 0.8953, test_acc: \u001b[31m0.8658146067415731\u001b[0m, time: 34.41\n",
      "epoch: 212, loss: 67.48608, loss1: 0.55818, loss2_3: 66.92790\n",
      "\ttrain_acc: 0.8997, test_acc: \u001b[31m0.8703651685393259\u001b[0m, time: 34.57\n",
      "epoch: 213, loss: 67.26695, loss1: 0.55992, loss2_3: 66.70704\n",
      "\ttrain_acc: 0.8959, test_acc: \u001b[31m0.8676404494382023\u001b[0m, time: 34.47\n",
      "epoch: 214, loss: 67.33236, loss1: 0.55901, loss2_3: 66.77335\n",
      "\ttrain_acc: 0.8982, test_acc: \u001b[31m0.8698595505617978\u001b[0m, time: 34.39\n",
      "epoch: 215, loss: 67.24130, loss1: 0.55445, loss2_3: 66.68685\n",
      "\ttrain_acc: 0.8976, test_acc: \u001b[31m0.867808988764045\u001b[0m, time: 34.44\n",
      "epoch: 216, loss: 67.22174, loss1: 0.55493, loss2_3: 66.66681\n",
      "\ttrain_acc: 0.8992, test_acc: \u001b[31m0.8660955056179775\u001b[0m, time: 34.45\n",
      "epoch: 217, loss: 66.89090, loss1: 0.55613, loss2_3: 66.33477\n",
      "\ttrain_acc: 0.9010, test_acc: \u001b[31m0.868876404494382\u001b[0m, time: 34.40\n",
      "epoch: 218, loss: 66.83244, loss1: 0.55467, loss2_3: 66.27777\n",
      "\ttrain_acc: 0.8947, test_acc: \u001b[31m0.8657303370786517\u001b[0m, time: 34.40\n",
      "epoch: 219, loss: 66.86404, loss1: 0.55505, loss2_3: 66.30900\n",
      "\ttrain_acc: 0.8988, test_acc: \u001b[31m0.8680337078651685\u001b[0m, time: 34.35\n",
      "epoch: 220, loss: 66.91921, loss1: 0.55441, loss2_3: 66.36479\n",
      "\ttrain_acc: 0.9010, test_acc: \u001b[31m0.8682303370786517\u001b[0m, time: 34.38\n",
      "epoch: 221, loss: 66.62999, loss1: 0.55352, loss2_3: 66.07646\n",
      "\ttrain_acc: 0.8970, test_acc: \u001b[31m0.8623595505617978\u001b[0m, time: 34.41\n",
      "epoch: 222, loss: 66.38677, loss1: 0.55277, loss2_3: 65.83400\n",
      "\ttrain_acc: 0.9022, test_acc: \u001b[31m0.8669662921348315\u001b[0m, time: 34.63\n",
      "epoch: 223, loss: 66.33910, loss1: 0.55312, loss2_3: 65.78598\n",
      "\ttrain_acc: 0.8996, test_acc: \u001b[31m0.8669943820224719\u001b[0m, time: 34.44\n",
      "epoch: 224, loss: 66.18472, loss1: 0.55276, loss2_3: 65.63196\n",
      "\ttrain_acc: 0.8965, test_acc: \u001b[31m0.8661516853932584\u001b[0m, time: 34.41\n",
      "epoch: 225, loss: 66.41615, loss1: 0.55369, loss2_3: 65.86246\n",
      "\ttrain_acc: 0.9043, test_acc: \u001b[31m0.8682584269662922\u001b[0m, time: 34.44\n",
      "epoch: 226, loss: 66.29059, loss1: 0.55310, loss2_3: 65.73749\n",
      "\ttrain_acc: 0.9020, test_acc: \u001b[31m0.8676404494382023\u001b[0m, time: 34.42\n",
      "epoch: 227, loss: 65.94693, loss1: 0.54894, loss2_3: 65.39799\n",
      "\ttrain_acc: 0.9020, test_acc: \u001b[31m0.868876404494382\u001b[0m, time: 34.41\n",
      "epoch: 228, loss: 66.09473, loss1: 0.54783, loss2_3: 65.54690\n",
      "\ttrain_acc: 0.9031, test_acc: \u001b[31m0.8686516853932584\u001b[0m, time: 34.40\n",
      "epoch: 229, loss: 65.94696, loss1: 0.55125, loss2_3: 65.39571\n",
      "\ttrain_acc: 0.9042, test_acc: \u001b[31m0.8692696629213483\u001b[0m, time: 34.33\n",
      "epoch: 230, loss: 65.58450, loss1: 0.54782, loss2_3: 65.03668\n",
      "\ttrain_acc: 0.9021, test_acc: \u001b[31m0.8679494382022472\u001b[0m, time: 34.38\n",
      "epoch: 231, loss: 65.85727, loss1: 0.54627, loss2_3: 65.31100\n",
      "\ttrain_acc: 0.9046, test_acc: \u001b[31m0.8689325842696629\u001b[0m, time: 34.42\n",
      "epoch: 232, loss: 65.53076, loss1: 0.54650, loss2_3: 64.98426\n",
      "\ttrain_acc: 0.9012, test_acc: \u001b[31m0.8673033707865169\u001b[0m, time: 34.65\n",
      "epoch: 233, loss: 65.44876, loss1: 0.54778, loss2_3: 64.90098\n",
      "\ttrain_acc: 0.9013, test_acc: \u001b[31m0.8630898876404495\u001b[0m, time: 34.47\n",
      "epoch: 234, loss: 65.21169, loss1: 0.54484, loss2_3: 64.66684\n",
      "\ttrain_acc: 0.8983, test_acc: \u001b[31m0.8670786516853932\u001b[0m, time: 34.44\n",
      "epoch: 235, loss: 65.39848, loss1: 0.54508, loss2_3: 64.85341\n",
      "\ttrain_acc: 0.9052, test_acc: \u001b[31m0.8681179775280898\u001b[0m, time: 34.50\n",
      "epoch: 236, loss: 65.14434, loss1: 0.54373, loss2_3: 64.60061\n",
      "\ttrain_acc: 0.9051, test_acc: \u001b[31m0.8659269662921348\u001b[0m, time: 34.44\n",
      "epoch: 237, loss: 65.22570, loss1: 0.54585, loss2_3: 64.67985\n",
      "\ttrain_acc: 0.9005, test_acc: \u001b[31m0.8646629213483146\u001b[0m, time: 34.47\n",
      "epoch: 238, loss: 65.03185, loss1: 0.54720, loss2_3: 64.48464\n",
      "\ttrain_acc: 0.8916, test_acc: \u001b[31m0.8554775280898876\u001b[0m, time: 34.43\n",
      "epoch: 239, loss: 64.75739, loss1: 0.54395, loss2_3: 64.21345\n",
      "\ttrain_acc: 0.9051, test_acc: \u001b[31m0.8659550561797753\u001b[0m, time: 34.44\n",
      "epoch: 240, loss: 64.49296, loss1: 0.54183, loss2_3: 63.95113\n",
      "\ttrain_acc: 0.9073, test_acc: \u001b[31m0.8689325842696629\u001b[0m, time: 34.51\n",
      "epoch: 241, loss: 64.46731, loss1: 0.54159, loss2_3: 63.92573\n",
      "\ttrain_acc: 0.9084, test_acc: \u001b[31m0.8664606741573033\u001b[0m, time: 34.37\n",
      "epoch: 242, loss: 64.47245, loss1: 0.53995, loss2_3: 63.93250\n",
      "\ttrain_acc: 0.9038, test_acc: \u001b[31m0.8657584269662921\u001b[0m, time: 34.60\n",
      "epoch: 243, loss: 64.14911, loss1: 0.53875, loss2_3: 63.61036\n",
      "\ttrain_acc: 0.9082, test_acc: \u001b[31m0.8670224719101124\u001b[0m, time: 34.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 244, loss: 64.11658, loss1: 0.54010, loss2_3: 63.57648\n",
      "\ttrain_acc: 0.9032, test_acc: \u001b[31m0.8657865168539326\u001b[0m, time: 34.38\n",
      "epoch: 245, loss: 64.23264, loss1: 0.53951, loss2_3: 63.69312\n",
      "\ttrain_acc: 0.9038, test_acc: \u001b[31m0.8687359550561797\u001b[0m, time: 34.41\n",
      "epoch: 246, loss: 63.87667, loss1: 0.54117, loss2_3: 63.33550\n",
      "\ttrain_acc: 0.9075, test_acc: \u001b[31m0.862752808988764\u001b[0m, time: 34.44\n",
      "epoch: 247, loss: 63.96578, loss1: 0.53789, loss2_3: 63.42789\n",
      "\ttrain_acc: 0.8872, test_acc: \u001b[31m0.8489606741573034\u001b[0m, time: 34.40\n",
      "epoch: 248, loss: 63.67154, loss1: 0.53639, loss2_3: 63.13515\n",
      "\ttrain_acc: 0.9097, test_acc: \u001b[31m0.8654775280898876\u001b[0m, time: 34.42\n",
      "epoch: 249, loss: 63.67761, loss1: 0.53624, loss2_3: 63.14138\n",
      "\ttrain_acc: 0.8990, test_acc: \u001b[31m0.8617696629213483\u001b[0m, time: 34.38\n",
      "epoch: 250, loss: 63.73648, loss1: 0.53940, loss2_3: 63.19709\n",
      "\ttrain_acc: 0.9088, test_acc: \u001b[31m0.864747191011236\u001b[0m, time: 34.41\n"
     ]
    }
   ],
   "source": [
    "for num_model in range(1):  # just one train\n",
    "    net=newModel().to(device)\n",
    "    lr = 0.0001\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr,weight_decay=5e-4)\n",
    "    criterion = ContrastiveLoss()\n",
    "    criterion_model = nn.CrossEntropyLoss(reduction='sum')\n",
    "    \n",
    "    best_acc=0\n",
    "    EPOCH=250\n",
    "    for epoch in range(EPOCH):\n",
    "        loss_ls=[]\n",
    "        loss1_ls=[]\n",
    "        loss2_3_ls=[]\n",
    "        t0=time.time()\n",
    "        net.train()\n",
    "        for seq1,seq2,label,label1,label2 in train_iter_cont:\n",
    "                output1=net(seq1)\n",
    "                output2=net(seq2)\n",
    "                output3=net.trainModel(seq1)\n",
    "                output4=net.trainModel(seq2)\n",
    "                \n",
    "                loss1=criterion(output1, output2, label)\n",
    "                loss2=criterion_model(output3,label1)\n",
    "                loss3=criterion_model(output4,label2)\n",
    "                loss=loss1+loss2+loss3\n",
    "    #             print(loss)\n",
    "                optimizer.zero_grad() \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_ls.append(loss.item())\n",
    "                loss1_ls.append(loss1.item())\n",
    "                loss2_3_ls.append((loss2+loss3).item())\n",
    "\n",
    "\n",
    "        net.eval() \n",
    "        with torch.no_grad(): \n",
    "            train_acc=evaluate_accuracy(train_iter,net)\n",
    "            test_acc=evaluate_accuracy(val_iter,net)\n",
    "            \n",
    "        results=f\"epoch: {epoch+1}, loss: {np.mean(loss_ls):.5f}, loss1: {np.mean(loss1_ls):.5f}, loss2_3: {np.mean(loss2_3_ls):.5f}\\n\"\n",
    "        results+=f'\\ttrain_acc: {train_acc:.4f}, test_acc: {colored(test_acc,\"red\")}, time: {time.time()-t0:.2f}'\n",
    "        print(results)\n",
    "        if test_acc>best_acc:\n",
    "            best_acc=test_acc\n",
    "#             torch.save({\"best_acc\":best_acc,\"model\":net.state_dict()},f'compareModel/2021ACS_PepFormer/Model/{num_model}.pl')\n",
    "            print(f\"best_acc: {best_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T01:36:17.469265Z",
     "start_time": "2021-08-31T01:36:17.433429Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T02:00:14.432919Z",
     "start_time": "2021-08-31T02:00:14.429626Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs.argmax(dim=1):\n",
    "            y_pred.append(int(_))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T02:15:44.725526Z",
     "start_time": "2021-08-31T02:15:44.722214Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred_prob(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs:\n",
    "            y_pred.append(list(map(float, _)))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T06:49:10.807011Z",
     "start_time": "2021-09-02T06:49:02.742919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.832639900145621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83     33706\n",
      "           1       0.82      0.86      0.84     33592\n",
      "\n",
      "    accuracy                           0.83     67298\n",
      "   macro avg       0.83      0.83      0.83     67298\n",
      "weighted avg       0.83      0.83      0.83     67298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate_accuracy(test_iter,net)\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "# prediction\n",
    "y_pred = pred(test_iter, net)\n",
    "print(classification_report(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T06:49:35.584254Z",
     "start_time": "2021-09-02T06:49:29.066467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf auc : 0.9064775173821029\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAADCCAYAAADTjffnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWJUlEQVR4nO3deXgUVdbA4d/pNEIWNllUFpEtZBBBBRc2EYdVUUAWJSKIYHQQlBlUQBwUmW9cQOdD3GAcUBYDiARBFAVcEIEBHBBQdgLoIAYCYdEgWe780UnsJE1XJ10dqsN5feqBrqpTdQv75FbdqjoRYwxKqeC5zncDlCotNJmUsokmk1I20WRSyiaaTErZRJNJKZu4Q72DyPYTdOw9x8ElY853ExyjWoxb/C2PvGaY5fcmfdOrfrdR0kKeTEoViyvifLegyDSZlDNJ+F2BaDIpZ9KeSSmbiKMuhwKiyaScSXsmpWyi10xK2UR7JqVsEobJFH59qbowiMt6stqESBcR2Skie0RktJ/1rhORLBHpXdRYb5pMypkiIqwnP0QkAngN6Ao0BvqJSONzrPcC8ElRYwvSZFLOJGI9+Xc9sMcYs88YcxaYC3T3sd5w4H0gpRix+WgyKWdyRVhOIpIgIhu9pgSvLdQEfvD6/GPOvDwiUhPoCbxZYO+Wsb7oAIRypgCuiYwx04Bp59qCr5ACn/8fGGWMyZL8PV0gsYVoMilnCn4070egttfnWsChAuu0AObmJFJV4FYRyQwwthBNJuVMwT9OtAFoKCJ1gf8CdwPx3isYY+r+vjt5G/jQGLNIRNxWsb5oMilnCrJnMsZkisgwPKN0EcB0Y8x3IvJQzvKC10mWsVb71GRSzuQK/qtpjPkI+KjAPJ9JZIy5zyrWiiaTciZ9alwpm4Th40SaTMqZ9KlxpewhLk0mpWwhes2klD3EpcmklC1cepqnlD30NE8pm+hpnlI20Z5JKZvoNZNSdgm/jkmTSTmT9kxK2SQcByDCL/3VBUFELKcAtuG3XJeIdBeRLSKyOaeGRBuvZftFZGvuskDarD2TcqRgT/O8ynV1xPMa+gYRWWyM+d5rtZXAYmOMEZGmwHwgzmt5e2PM0YDbHFSLlQoRG3omy3JdxpjTxpjcQinRBFA0xR9NJuVI4hLrKchSXwAi0lNEdgBLgfu9FhngUxH5psB2zyksTvNcLuHrN4dw6OhJej05j8rlyzFrXC/qXFqRA4dP0H/8+6SdPlMobkficE79epas7Gwys7Jp89C/8i0f0fdGnvtTR2p1n0TqyXRaNqnF5BG3cjYjiwETFrLv0HEqRpdl1tO9uOOJd0vqcAMy/91ZLFm0AGMMd/TsTd/4AfmW/2fjesb8ZTiX1fR8f9q178CghKEA9O7WkaioaFwRLiIi3Pxr9nwAXn/lJf799WoaNIrjr88+B8CypYs5eeIEfePvLcGjC+ymrQ2lvjDGJAFJInITMAHokLOotTHmkIhUB5aLyA5jzCp/7QmLZBrW63p2HjxK+aiLAHgsvjVf/CeZSYlreKxfKx6Lb81T01b6jO3y55mknkwvNL9WtQrc0qIeBw+n5c17tE9L+j29gDqXViShe3NGv7GCMQPa8uKc1SE5ruLat2c3SxYt4J/vzMVdpgwjhz9IyzbtqH15nXzrNbumOS9Oft3nNl6ZOoNKlSvnfT596hTbvt3MO/OSGD/2Cfbu3kWt2pfz8ZJFvDRlakiPxxcbRvOKVK7LGLNKROqLSFVjzFFjzKGc+SkikoTntNFvMlme5olInIiMEpFXRGRyzt//ENDh2KBm1fJ0ubEhM5ZuypvXrVUjZn+yBYDZn2zh9taNirzdFx/uxNipK/P9qMrIyiKyrJuocmXIyMymbo3K1KhagdXfHgz2MGy1P3kfVzZpRrnISNxuN9dc24JVn68Iapsul4uMjAyMMfz222+43W7enTmd3nf3x12mjE0tL1p7rCYLeaW+ROQiPOW6FnuvICINJKcLFJFrgYuAVBGJFpHyOfOjgU7ANss2+1soIqPwXLgJsD6ngQIkBvqbAYI1cVhnxk5dQXb271/76hdHc/jYaQAOHztNtcpRPmONMSyZeA9fTx3C/d2uyZt/W6tYDh09yda9P+ff15yveW3kbQzrdQNvJm1g/OD2jJ/+hf0HFaR6DRqwedNGTqSlcSY9nbVff0XKz4cLrbdt62YG3t2TkcMfZN/ePXnzRYS/PPwA99/Thw8Wek7xoqKjufmPHRkU34vLatQkOqY827/fRtubbymx4/IW7ACEMSYTyC3XtR2Yn1vqK7fcF9AL2CYim/GM/N2VMyBxCbBaRL7F871faoxZZtVmq9O8wcCVxpiMAgf6MvAd8LyvoJwLtgQAd+wduGu0sGqHT11vbEhK2i9s2nWYts3qWAcUcMvwt/kp9TTVKkXx4aT+7DyYyn92HmJU/zZ0e3xOofW37P2Zdg/PAKB108v5KfUUIjBr3J1kZGYz+o3lpBz/pVjHYqcr6tan/8DB/HnoECKjomgQ24iIAr8VolFcYxZ8uJyoqGjWrl7FkyOHM3fRxwC8MX02VatV5/ixVEYMHUKdK+px9bUtuGfgYO4ZOBiA558dx5CHhrMkaQHr162hfsNY7hvyUKG2hIodN22tSn0ZY17A8xswCsbtA5oVdX9WfWU2UMPH/MtylvlkjJlmjGlhjGlR3EQCaNmkNt1axbIjcTgzx93JzdfUZfqTPUg59guXXhwDwKUXx3Dk+K8+439K9fReR9J+ZfFXO7gurgb1alxMnUsrsf6tBHYkDqdmtQqsnfYAl1SOzhc7un8bnpv5FWMH3sSEGV+SuHwrQ++8vtjHYrduPXox/d0FvPbWTCpUqEit2vl/2ETHxBAV5Tmmlm1uIjMzk7TjxwGoWq06AJUvrsJN7Tvw/bat+WJ37dgOQO06dVi2dDETXniZ5L17+OHggVAfVh47btqWNKtkGgGsFJGPRWRazrQMz82uR0PduHFvfUaDvpOJ6zeFAc8u5ItNydz/90UsXbOT/p2bAtC/c1M+XLOzUGxUuTLERF6U9/cOLerxXfIRvktOoc6dLxPXbwpx/abw3yMnaZnwT3726nH6d27Ksn/vIe30GaLKliHbGLKNIaqsc8Zrjh9LBeDwT4f48rMVdOhya77lqUePkHsL5fttW8jOzqZipUqkp//Kr794jjU9/Vc2rFtDvQYN8sW+9cYUhvxpGJmZmWRnZwGeL/eZM4UHckLF5RLLyWn8fjuMMctEJBbPSEZNPNdLPwIbjDFZJdA+nyYlrmH2070YeOvV/JByknueWQDAZVVieP2xbvQcM5fqlaOZN6EvAO4IF/NWbGP5hr2W244s66Z/52Z5p4GvvLeOxPF9OJuZxcAJC0N3UEU09vERnDyRRoTbzV9GP0WFChVZtGAeAD1638UXKz8lacE8IiIiKFu2HOOfm4SIcCw1lScfewSArKwsOna5jRtbtc3b7qrPVxJ3ZZO83uvKq65mQN8e1G8YS8PYuMINCREn9jxW5PcbwKER2X5CaHcQRg4uGXO+m+AY1WLcfrOl0ahPLL83O1/o7KiMc855i1JeIiIclScB0WRSjhSGZ3maTMqZnDjAYEWTSTlSOA5AaDIpR9KeSSmbaM+klE20Z1LKJppMStkkDM/yNJmUM4Vjz6Q1IJQjOaDUl99YX7RnUo4UbM8UTKmvAGMLtzmoFisVIiLWk4VgSn1ZxvqiyaQcKZAaECEs9RVQbEF6mqccKZDTvBCW+gootiBNJuVINgyNF7vUV1Fjc+lpnnIkG15bL3apr0BifdGeSTmSK8iuyRiTKSK5pb4igOm5pb5ylr+Jp9TXABHJANL5vdSXz1irfWoyKUey46ZtcUt9nSvWiiaTcqQwfABCk0k5Uzg+TqTJpBwpIgyfdNVkUo6kLwcqZZMIPc1Tyh5h2DFpMiln0gEIpWwS7E3b80GTSTmSJpNSNtEBCKVsEoYdkyaTcibtmZSyid60Vcom4fg4kb4cqBzJhoIqgZT6uien1NcWEVkjIs28lu0Xka25ZcACabP2TMqRSqjUVzLQzhhzXES64qkncYPX8vbGmKOB7lOTSTmSDQMQeeW6AEQkt1xXXjIZY9Z4rb8OT62HYgt5Mh1f/tdQ7yJsVL5u2PlugmOkb3rV7/IAK7YmAN7lvablVCwC3+W6vHudggYDH3t9NsCnImKAqV7bPSftmZQjBTIAYUepLwARaY8nmdp4zW5tjDkkItWB5SKywxizyl97dABCOZJLrCcLAZXryimL/BbQ3RiTmjvfGHMo588UIAnPaaP/Nls2SanzIMIllpOFQEp9XQ4sBO41xuzymh8tIuVz/w50ArZZ7VBP85QjBTv+EGCpr3FAFeD1nGu0TGNMC+ASPFVewZMj7xpjllntU5NJOZIdjxMFUOprCDDER9w+oFnB+VY0mZQjRYTfAxCaTMqZ9H0mpWwSEYZDY5pMypG0Z1LKJtozKWUT8fkAg7NpMilHcmvPpJQ99LV1pWwShuMPmkzKmdzaMyllD+2ZlLJJOBZU0WRSjhSGZ3n6PpNyJhveZwq2OpHfWF+0Z1KOFOzjRMFUJwowtnCbg2qxUiESIdaThbzqRMaYs0BudaI8xpg1xpjjOR+9qxNZxvqiyaQcySViOVnwVZ2opp/1vasTFTUW0NM85VCBnOZZlPoKpjpRwLHeNJmUIwUymmdR6quo1Ym6elUnCii2UJutm6xUyRMRy8lCsasTBRLri/ZMypGCvWkbTHWic8Va7VOTSTmSHfdsi1ud6FyxVjSZlCPp40RK2URrQChlkzDMJU0m5Ux6mqeUTbSgilI20Z5JKZuEYS5pMiln0tE8pWwSjqd5YfVs3v7kffS9s3ve1Or6a5k98+186yTv28u98XfR4uomvDPjX/mWzZn1Dnd270bPO27LF/ePlybSu+ftjB3zRN68JYsXMWfWO6E8nGJxuYS1iaN4f/JDAPx9RA82L3yK9fPGMO+lB6gYE1kopmGd6qybOzpv+vmriQyLv9lvfMtm9Vg/bwyrZz9OvdpVAagYE8ni1x4ukeMUsZ6cJqyS6Yq69Zi/8APmL/yAxPcWUq5cJLd06JhvnQoVKzFqzFgGDhqcb/7u3bt4f8F7zJn7Hu8t/IBVX37BgQP7OXXqFN9u3sSCpCVkZ2Wxe9dOzpw5w+JFSfS9O74kDy8gw+LbszP557zPK9ftoHmfv3P9Xc+x+0AKj9/fqVDM7gMp3Hj389x49/O0in+BX89ksPjzb/3GP3rvLfR7/C3GTVlCQp+2AIxJ6MKL0z8pgaP09ExWk9OEVTJ5+/e6tdSuXZsaNfK/s1WlShWaXNUUtzv/GWzyvr00bdaMyMhI3G43zVtcx2crluNyCRkZGRhjOPPbb7jdbt6e/hbx/e+lTJkyJXlIlmpWr0SXNlcyI2lN3ryV63aQlZUNwPqtydS8pJLfbbS/vhHJPx7h4E/H/cZnZGYRWbYMUZFlyMjMom6tqtSoXonV3+yx/8B8kAD+c5piJ5OIDLKzIUW17OOldLm1W8DrN2gQyzcbN5KWdpz09HRWf7WKw4cPEx0dQ4eOnbirVw9q1qxFTPnyfLdtG+1v6RDC1hfPxMd7MXbyIrKzfb+nNqB7Sz752m+ZAvp0bs78Zd9Yxk+c/imvPdWPYfHteXPuKsYPu53xr38Y3AEUgQ2/bb3EBTMAMR6Y4WuB9xuQr74+lcEPJPhardgyzp7ly88/49ERIwOOqVe/PoMGD+HBIfcTFRVFbKNGuCMiABg0+AEGDX4AgGfGjWXo8EdYuOA91q5ZTcPYRiQ8NNTW9hdH17ZNSDl2ik3bf6Bt84aFlj8xuDNZWdnM/WjDObdRxh3Bbe2uYtyUwq/mFIzfsuu/tBv4EgCtr63PT0dOIAiznh9ERmYWo19OIuXYKZuOrrBwHM3z2zN5lUEqOG3F8xupfTLGTMt5L6SF3YkEsHr1KuIaX0mVqlWLFHdnrz7MW5DEjJlzqFixEpfXqZNv+fbtnp/KdepcwZLFi5j48mT27NnNgQP77Wp6sbW8uh7d2l3FjqXjmfn8IG6+LpbpfxsAwD2338CtNzXhvrFv+91G5zaN2bzjh0JJYBU/ekgXnpv2MWMf7MqENz8i8aMNDO13sw1HdW52DEAEUOorTkTWishvIvJYgWX7RWSriGwWkY2BtNmqZ7oE6AwcLzBfgDWFVy8ZH3+0lK633lbkuNTUVKpUqcJPhw6xcsWnzJozL9/y16ZMZtwzz5KZmUl2VhYALnFxJv2MLe0Oxrgpi/N6lLbNGzJiwB+5/6mZdGz1B0be14FOQyaTfibD7zb6dmlR6BTPKr7/7Tew7KvvSDuVTlS5i8jONmRnG6LKhfZ6soRKfR0DHgF6nGMz7Y0xRwPdp1UyfQjEGGM2+2jsF4HuxE7p6emsW7OGvz79bN68+fMSAeh7Vz+OHjlCv7t68cvp07hcLmbPeoekxR8RExPDyBHDOZGWhtvt5smnnqZCxYp52/hs5QqaNLmK6tU9HW7Tq6+hV4/biY2NpVFcXMkeZBH8Y1Rfyl7k5sM3hgGwfut+Hvm/uVxWrSKvj4un5/A3AIgsV4Zbbohj2N8SA4rPjel/+w10G/oqAK/M/ozESUM4m5HJwDFvh/S4bDjJyyvXBSAiueW68pLJGJMCpIhI0X8y+yDGWBZdCcqZTOuqLheKytcNO99NcIz0Ta/6zZeNySctvzct6lY45zZEpDfQJedtWkTkXuAGY0yh/wki8gxw2hgzyWteMp4zMgNM9ap6dE76BIRypACviWwp9XUOrY0xh0SkOrBcRHYYY1b5C9BkUo4USDLZUerLz7YP5fyZIiJJeE4b/SZT2N60VaWbDTdti1WuC0BEokWkfO7fgU7ANqs47ZmUIwV7UzaQUl8icimwEagAZIvICKAxUBVIyin/5QbeNcYss9qnJpNypACKTFoKoNTXYX4v1u/tJNDMx3y/NJmUI4XhAxCaTMqZNJmUsokTnwq3osmkHMmJT4Vb0WRSzqTJpJQ9wvEVDE0m5UhhmEuaTMqZdABCKZvoAIRSdtFkUsoeOgChlE3CL5U0mZRD2fGga0nTZFKOFI4DEPpyoHIkB5T68hvri/ZMypGCPc0LptRXgLGFaM+kHEkCmCzklfoyxpwFckt95THGpBhjNgAFCwZaxvqiyaQcySViOVmoCfzg9fnHnHmBKFasJpNypgC6JhFJEJGNXlNCgS0UFGipr2LF6jWTcqRARvNCWOqrWLHaMylHEhHLyUKxS30VN1Z7JuVIwd5mCqbUlzHmpK9YyzZrrfGSo7XGf2dVa/zYL1mW35uLoyMcdWtXeyblSGH4NJEmk3ImTSalbKJv2iplk3B80FWTSTmSvoKhlE3CMJc0mZQzaTIpZZNwHIAI+U1bpxCRhEB+ye+FQP8tQuNCejYvwXqVC4b+W4TAhZRMSoWUJpNSNrmQkkmvEX6n/xYhcMEMQCgVahdSz6RUSJX6ZCpO/bPSSkSmi0iKiGw7320pjUp1MnnVP+sKNAb6iUjj89uq8+ptoMv5bkRpVaqTiWLWPyutjDGr8BReVCFQ2pMpmNppShVJaU+mYGqnKVUkpT2ZgqmdplSRlPZkCqZ2mlJFUqqTyRiTCeTWP9sOzA+k/llpJSKJwFqgkYj8KCKDz3ebShN9AkIpm5TqnkmpkqTJpJRNNJmUsokmk1I20WRSyiaaTErZRJNJKZtoMillk/8B4XsKOMQgqM0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AUC\n",
    "probs = np.array(pred_prob(test_iter, net))[:, 1]\n",
    "\n",
    "rf_auc = roc_auc_score(test_label, probs)\n",
    "print('rf auc : {}'.format(rf_auc))\n",
    "# plot the roc curve for the model81\n",
    "rf_fpr, rf_tpr, _ = roc_curve(test_label, probs)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='RF AUC = {:.4f}'.format(rf_auc), color='orange')\n",
    "plt.title('ROC curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "cf_matrix = confusion_matrix(test_label, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=',.0f')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
