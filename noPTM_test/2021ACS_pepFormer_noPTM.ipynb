{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:27:50.372342Z",
     "start_time": "2021-10-04T14:27:49.356309Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:27:51.311753Z",
     "start_time": "2021-10-04T14:27:50.374642Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import time\n",
    "import pickle\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:27:51.320959Z",
     "start_time": "2021-10-04T14:27:51.313684Z"
    }
   },
   "outputs": [],
   "source": [
    "def genData(file,max_len):\n",
    "    aa_dict={'A':1,'R':2,'N':3,'D':4,'C':5,'Q':6,'E':7,'G':8,'H':9,'I':10,\n",
    "             'L':11,'K':12,'M':13,'F':14,'P':15,'O':16,'S':17,'U':18,'T':19,\n",
    "             'W':20,'Y':21,'V':22,'X':23}\n",
    "    with open(file, 'r') as inf:\n",
    "        lines = inf.read().splitlines()\n",
    "        \n",
    "    long_pep_counter=0\n",
    "    pep_codes=[]\n",
    "    labels=[]\n",
    "    for pep in lines:\n",
    "        pep,label=pep.split(\",\")\n",
    "        labels.append(int(label))\n",
    "        if not len(pep) > max_len:\n",
    "            current_pep=[]\n",
    "            for aa in pep:\n",
    "                current_pep.append(aa_dict[aa])\n",
    "            pep_codes.append(torch.tensor(current_pep))\n",
    "        else:\n",
    "            long_pep_counter += 1\n",
    "    print(\"length > 81:\",long_pep_counter)\n",
    "    data = rnn_utils.pad_sequence(pep_codes,batch_first=True)\n",
    "    return data,torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:27:51.335181Z",
     "start_time": "2021-10-04T14:27:51.322059Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        acc_sum += (outputs.argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "def to_log(log):\n",
    "    with open(\"../compareModel/2021ACS_PepFormer/modelLog.log\",\"a+\") as f:\n",
    "        f.write(log+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:27:51.342718Z",
     "start_time": "2021-10-04T14:27:51.336692Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    seq1_ls=[]\n",
    "    seq2_ls=[]\n",
    "    label1_ls=[]\n",
    "    label2_ls=[]\n",
    "    label_ls=[]\n",
    "    batch_size=len(batch)\n",
    "    for i in range(int(batch_size/2)):\n",
    "        seq1,label1=batch[i][0],batch[i][1]\n",
    "        seq2,label2=batch[i+int(batch_size/2)][0],batch[i+int(batch_size/2)][1]\n",
    "        label1_ls.append(label1.unsqueeze(0))\n",
    "        label2_ls.append(label2.unsqueeze(0))\n",
    "        label=(label1^label2)\n",
    "        seq1_ls.append(seq1.unsqueeze(0))\n",
    "        seq2_ls.append(seq2.unsqueeze(0))\n",
    "        label_ls.append(label.unsqueeze(0))\n",
    "    seq1=torch.cat(seq1_ls).to(device)\n",
    "    seq2=torch.cat(seq2_ls).to(device)\n",
    "    label=torch.cat(label_ls).to(device)\n",
    "    label1=torch.cat(label1_ls).to(device)\n",
    "    label2=torch.cat(label2_ls).to(device)\n",
    "    return seq1,seq2,label,label1,label2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Data X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:28:02.807026Z",
     "start_time": "2021-10-04T14:28:01.705364Z"
    }
   },
   "outputs": [],
   "source": [
    "df_detect_peptide_train = pd.read_csv('../data/df_detect_peptide_train_noptm.csv')\n",
    "df_detect_peptide_test = pd.read_csv('../data/df_detect_peptide_test_noptm.csv')\n",
    "\n",
    "tra, val = train_test_split(df_detect_peptide_train[['PEP', 'ID']], test_size=0.2, random_state=7)\n",
    "tra.to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_train_noptm.csv', header=False, index=False)\n",
    "val.to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_val_noptm.csv', header=False, index=False)\n",
    "df_detect_peptide_test[['PEP', 'ID']].to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_test_noptm.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:42:01.365016Z",
     "start_time": "2021-10-04T14:41:56.840254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length > 81: 0\n",
      "torch.Size([142397, 30]) torch.Size([142397])\n",
      "length > 81: 0\n",
      "torch.Size([35600, 30]) torch.Size([35600])\n",
      "length > 81: 0\n",
      "torch.Size([44499, 30]) torch.Size([44499])\n"
     ]
    }
   ],
   "source": [
    "train_data,train_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_train_noptm.csv\",81)\n",
    "print(train_data.shape, train_label.shape)\n",
    "train_dataset = Data.TensorDataset(train_data, train_label)\n",
    "\n",
    "val_data,val_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_val_noptm.csv\",81)\n",
    "print(val_data.shape, val_label.shape)\n",
    "val_dataset = Data.TensorDataset(val_data, val_label)\n",
    "\n",
    "test_data,test_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_test_noptm.csv\",81)\n",
    "print(test_data.shape, test_label.shape)\n",
    "test_dataset = Data.TensorDataset(test_data, test_label)\n",
    "\n",
    "batch_size=256\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_iter_cont = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                                                  shuffle=True, collate_fn=collate)\n",
    "val_iter = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:40:18.695446Z",
     "start_time": "2021-10-04T14:40:18.692940Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T14:42:15.317278Z",
     "start_time": "2021-10-04T14:42:15.304938Z"
    }
   },
   "outputs": [],
   "source": [
    "class newModel(nn.Module):\n",
    "    def __init__(self, vocab_size=24):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 25\n",
    "        self.batch_size = 256\n",
    "        self.emb_dim = 512\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, self.emb_dim, padding_idx=0)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.gru = nn.GRU(self.emb_dim, self.hidden_dim, num_layers=2, \n",
    "                               bidirectional=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.block1=nn.Sequential(nn.Linear(1600,1024),\n",
    "                                            nn.BatchNorm1d(1024),\n",
    "                                            nn.LeakyReLU(),\n",
    "                                            nn.Linear(1024,256),\n",
    "                                 )\n",
    "\n",
    "        self.block2=nn.Sequential(\n",
    "                                               nn.BatchNorm1d(256),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(256,128),\n",
    "                                               nn.BatchNorm1d(128),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(128,64),\n",
    "                                               nn.BatchNorm1d(64),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(64,2)\n",
    "                                            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.embedding(x)\n",
    "        output=self.transformer_encoder(x).permute(1, 0, 2)\n",
    "        output,hn=self.gru(output)\n",
    "        output=output.permute(1,0,2)\n",
    "        hn=hn.permute(1,0,2)\n",
    "        output=output.reshape(output.shape[0],-1)\n",
    "        \n",
    "        hn=hn.reshape(output.shape[0],-1)\n",
    "        output=torch.cat([output,hn],1)\n",
    "#         print(output.shape, hn.shape)\n",
    "        return self.block1(output)\n",
    "\n",
    "    def trainModel(self, x):\n",
    "        with torch.no_grad():\n",
    "            output=self.forward(x)\n",
    "        return self.block2(output)\n",
    "\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # euclidean_distance: [128]\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +     # calmp夹断用法\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))     \n",
    "        \n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T09:04:10.102438Z",
     "start_time": "2021-10-04T23:04:37.381898Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 166.34050, loss1: 1.74163, loss2_3: 164.59887\n",
      "\ttrain_acc: 0.7271, test_acc: \u001b[31m0.7252528089887641\u001b[0m, time: 152.02\n",
      "best_acc: 0.7252528089887641\n",
      "epoch: 2, loss: 114.07835, loss1: 0.91585, loss2_3: 113.16250\n",
      "\ttrain_acc: 0.8104, test_acc: \u001b[31m0.8102247191011236\u001b[0m, time: 151.62\n",
      "best_acc: 0.8102247191011236\n",
      "epoch: 3, loss: 101.77880, loss1: 0.84985, loss2_3: 100.92894\n",
      "\ttrain_acc: 0.8338, test_acc: \u001b[31m0.8328370786516854\u001b[0m, time: 151.89\n",
      "best_acc: 0.8328370786516854\n",
      "epoch: 4, loss: 97.03369, loss1: 0.80558, loss2_3: 96.22811\n",
      "\ttrain_acc: 0.8270, test_acc: \u001b[31m0.827556179775281\u001b[0m, time: 152.10\n",
      "epoch: 5, loss: 94.41471, loss1: 0.78242, loss2_3: 93.63229\n",
      "\ttrain_acc: 0.8412, test_acc: \u001b[31m0.8415730337078652\u001b[0m, time: 151.30\n",
      "best_acc: 0.8415730337078652\n",
      "epoch: 6, loss: 92.93334, loss1: 0.77017, loss2_3: 92.16317\n",
      "\ttrain_acc: 0.8477, test_acc: \u001b[31m0.8491573033707865\u001b[0m, time: 152.78\n",
      "best_acc: 0.8491573033707865\n",
      "epoch: 7, loss: 92.04901, loss1: 0.75468, loss2_3: 91.29433\n",
      "\ttrain_acc: 0.8491, test_acc: \u001b[31m0.848623595505618\u001b[0m, time: 152.18\n",
      "epoch: 8, loss: 90.74863, loss1: 0.74715, loss2_3: 90.00148\n",
      "\ttrain_acc: 0.8505, test_acc: \u001b[31m0.8510955056179775\u001b[0m, time: 151.91\n",
      "best_acc: 0.8510955056179775\n",
      "epoch: 9, loss: 90.02922, loss1: 0.73838, loss2_3: 89.29084\n",
      "\ttrain_acc: 0.8551, test_acc: \u001b[31m0.8535393258426967\u001b[0m, time: 151.58\n",
      "best_acc: 0.8535393258426967\n",
      "epoch: 10, loss: 88.63394, loss1: 0.72377, loss2_3: 87.91017\n",
      "\ttrain_acc: 0.8546, test_acc: \u001b[31m0.8542134831460674\u001b[0m, time: 151.80\n",
      "best_acc: 0.8542134831460674\n",
      "epoch: 11, loss: 88.23800, loss1: 0.72592, loss2_3: 87.51208\n",
      "\ttrain_acc: 0.8565, test_acc: \u001b[31m0.8550842696629214\u001b[0m, time: 152.25\n",
      "best_acc: 0.8550842696629214\n",
      "epoch: 12, loss: 87.59726, loss1: 0.71440, loss2_3: 86.88286\n",
      "\ttrain_acc: 0.8569, test_acc: \u001b[31m0.854185393258427\u001b[0m, time: 150.97\n",
      "epoch: 13, loss: 86.98867, loss1: 0.71222, loss2_3: 86.27645\n",
      "\ttrain_acc: 0.8543, test_acc: \u001b[31m0.8537640449438202\u001b[0m, time: 152.26\n",
      "epoch: 14, loss: 86.91678, loss1: 0.70656, loss2_3: 86.21022\n",
      "\ttrain_acc: 0.8565, test_acc: \u001b[31m0.856376404494382\u001b[0m, time: 151.23\n",
      "best_acc: 0.856376404494382\n",
      "epoch: 15, loss: 86.38321, loss1: 0.70159, loss2_3: 85.68162\n",
      "\ttrain_acc: 0.8599, test_acc: \u001b[31m0.8582022471910112\u001b[0m, time: 153.16\n",
      "best_acc: 0.8582022471910112\n",
      "epoch: 16, loss: 85.92847, loss1: 0.69501, loss2_3: 85.23346\n",
      "\ttrain_acc: 0.8595, test_acc: \u001b[31m0.8589325842696629\u001b[0m, time: 151.75\n",
      "best_acc: 0.8589325842696629\n",
      "epoch: 17, loss: 85.55082, loss1: 0.69444, loss2_3: 84.85639\n",
      "\ttrain_acc: 0.8601, test_acc: \u001b[31m0.8581460674157303\u001b[0m, time: 151.66\n",
      "epoch: 18, loss: 85.26314, loss1: 0.69142, loss2_3: 84.57173\n",
      "\ttrain_acc: 0.8573, test_acc: \u001b[31m0.8558146067415731\u001b[0m, time: 152.09\n",
      "epoch: 19, loss: 85.04905, loss1: 0.68440, loss2_3: 84.36465\n",
      "\ttrain_acc: 0.8572, test_acc: \u001b[31m0.856938202247191\u001b[0m, time: 151.15\n",
      "epoch: 20, loss: 84.82160, loss1: 0.68579, loss2_3: 84.13581\n",
      "\ttrain_acc: 0.8621, test_acc: \u001b[31m0.8621348314606742\u001b[0m, time: 151.86\n",
      "best_acc: 0.8621348314606742\n",
      "epoch: 21, loss: 84.43071, loss1: 0.68148, loss2_3: 83.74923\n",
      "\ttrain_acc: 0.8614, test_acc: \u001b[31m0.8599157303370787\u001b[0m, time: 151.35\n",
      "epoch: 22, loss: 84.20294, loss1: 0.67692, loss2_3: 83.52602\n",
      "\ttrain_acc: 0.8558, test_acc: \u001b[31m0.8549438202247192\u001b[0m, time: 151.91\n",
      "epoch: 23, loss: 83.99371, loss1: 0.67732, loss2_3: 83.31639\n",
      "\ttrain_acc: 0.8637, test_acc: \u001b[31m0.8607022471910112\u001b[0m, time: 152.67\n",
      "epoch: 24, loss: 83.87788, loss1: 0.67732, loss2_3: 83.20056\n",
      "\ttrain_acc: 0.8643, test_acc: \u001b[31m0.8630337078651685\u001b[0m, time: 151.73\n",
      "best_acc: 0.8630337078651685\n",
      "epoch: 25, loss: 83.60640, loss1: 0.67385, loss2_3: 82.93255\n",
      "\ttrain_acc: 0.8621, test_acc: \u001b[31m0.8600842696629214\u001b[0m, time: 152.17\n",
      "epoch: 26, loss: 83.46067, loss1: 0.67094, loss2_3: 82.78973\n",
      "\ttrain_acc: 0.8652, test_acc: \u001b[31m0.8617415730337079\u001b[0m, time: 150.91\n",
      "epoch: 27, loss: 83.44307, loss1: 0.67325, loss2_3: 82.76982\n",
      "\ttrain_acc: 0.8613, test_acc: \u001b[31m0.8587640449438202\u001b[0m, time: 151.92\n",
      "epoch: 28, loss: 83.13007, loss1: 0.66903, loss2_3: 82.46104\n",
      "\ttrain_acc: 0.8614, test_acc: \u001b[31m0.8590168539325843\u001b[0m, time: 150.66\n",
      "epoch: 29, loss: 82.84261, loss1: 0.66447, loss2_3: 82.17815\n",
      "\ttrain_acc: 0.8659, test_acc: \u001b[31m0.8638483146067416\u001b[0m, time: 152.00\n",
      "best_acc: 0.8638483146067416\n",
      "epoch: 30, loss: 82.53488, loss1: 0.66495, loss2_3: 81.86993\n",
      "\ttrain_acc: 0.8656, test_acc: \u001b[31m0.8630056179775281\u001b[0m, time: 151.76\n",
      "epoch: 31, loss: 82.38636, loss1: 0.65946, loss2_3: 81.72690\n",
      "\ttrain_acc: 0.8660, test_acc: \u001b[31m0.8636797752808989\u001b[0m, time: 151.85\n",
      "epoch: 32, loss: 82.30813, loss1: 0.66122, loss2_3: 81.64692\n",
      "\ttrain_acc: 0.8663, test_acc: \u001b[31m0.8626404494382023\u001b[0m, time: 152.43\n",
      "epoch: 33, loss: 82.28591, loss1: 0.65971, loss2_3: 81.62620\n",
      "\ttrain_acc: 0.8674, test_acc: \u001b[31m0.865252808988764\u001b[0m, time: 150.53\n",
      "best_acc: 0.865252808988764\n",
      "epoch: 34, loss: 81.99167, loss1: 0.65879, loss2_3: 81.33288\n",
      "\ttrain_acc: 0.8671, test_acc: \u001b[31m0.8656179775280899\u001b[0m, time: 151.89\n",
      "best_acc: 0.8656179775280899\n",
      "epoch: 35, loss: 81.85768, loss1: 0.65666, loss2_3: 81.20102\n",
      "\ttrain_acc: 0.8673, test_acc: \u001b[31m0.864943820224719\u001b[0m, time: 150.91\n",
      "epoch: 36, loss: 81.42324, loss1: 0.65361, loss2_3: 80.76963\n",
      "\ttrain_acc: 0.8691, test_acc: \u001b[31m0.8651685393258427\u001b[0m, time: 151.52\n",
      "epoch: 37, loss: 81.57584, loss1: 0.65129, loss2_3: 80.92455\n",
      "\ttrain_acc: 0.8680, test_acc: \u001b[31m0.8645224719101123\u001b[0m, time: 151.80\n",
      "epoch: 38, loss: 81.28127, loss1: 0.65123, loss2_3: 80.63005\n",
      "\ttrain_acc: 0.8640, test_acc: \u001b[31m0.8609831460674158\u001b[0m, time: 150.89\n",
      "epoch: 39, loss: 81.30075, loss1: 0.64790, loss2_3: 80.65285\n",
      "\ttrain_acc: 0.8640, test_acc: \u001b[31m0.8613202247191011\u001b[0m, time: 152.93\n",
      "epoch: 40, loss: 80.86725, loss1: 0.64920, loss2_3: 80.21805\n",
      "\ttrain_acc: 0.8686, test_acc: \u001b[31m0.8637640449438202\u001b[0m, time: 151.09\n",
      "epoch: 41, loss: 80.84767, loss1: 0.64455, loss2_3: 80.20312\n",
      "\ttrain_acc: 0.8693, test_acc: \u001b[31m0.8652808988764045\u001b[0m, time: 151.99\n",
      "epoch: 42, loss: 80.77349, loss1: 0.64553, loss2_3: 80.12796\n",
      "\ttrain_acc: 0.8674, test_acc: \u001b[31m0.8632022471910112\u001b[0m, time: 151.66\n",
      "epoch: 43, loss: 80.39397, loss1: 0.64051, loss2_3: 79.75345\n",
      "\ttrain_acc: 0.8704, test_acc: \u001b[31m0.866685393258427\u001b[0m, time: 151.54\n",
      "best_acc: 0.866685393258427\n",
      "epoch: 44, loss: 80.55393, loss1: 0.64394, loss2_3: 79.90999\n",
      "\ttrain_acc: 0.8694, test_acc: \u001b[31m0.866685393258427\u001b[0m, time: 152.03\n",
      "epoch: 45, loss: 80.15113, loss1: 0.63899, loss2_3: 79.51214\n",
      "\ttrain_acc: 0.8704, test_acc: \u001b[31m0.866432584269663\u001b[0m, time: 150.59\n",
      "epoch: 46, loss: 79.87142, loss1: 0.63695, loss2_3: 79.23447\n",
      "\ttrain_acc: 0.8694, test_acc: \u001b[31m0.8653089887640449\u001b[0m, time: 151.65\n",
      "epoch: 47, loss: 79.87457, loss1: 0.63837, loss2_3: 79.23619\n",
      "\ttrain_acc: 0.8712, test_acc: \u001b[31m0.8692977528089888\u001b[0m, time: 151.32\n",
      "best_acc: 0.8692977528089888\n",
      "epoch: 48, loss: 79.43847, loss1: 0.63724, loss2_3: 78.80124\n",
      "\ttrain_acc: 0.8709, test_acc: \u001b[31m0.8685393258426967\u001b[0m, time: 152.51\n",
      "epoch: 49, loss: 79.43997, loss1: 0.63330, loss2_3: 78.80667\n",
      "\ttrain_acc: 0.8726, test_acc: \u001b[31m0.869747191011236\u001b[0m, time: 151.58\n",
      "best_acc: 0.869747191011236\n",
      "epoch: 50, loss: 79.23048, loss1: 0.63128, loss2_3: 78.59920\n",
      "\ttrain_acc: 0.8675, test_acc: \u001b[31m0.8626966292134831\u001b[0m, time: 150.71\n",
      "epoch: 51, loss: 79.14071, loss1: 0.63130, loss2_3: 78.50941\n",
      "\ttrain_acc: 0.8706, test_acc: \u001b[31m0.8648033707865168\u001b[0m, time: 152.01\n",
      "epoch: 52, loss: 78.94883, loss1: 0.62790, loss2_3: 78.32092\n",
      "\ttrain_acc: 0.8678, test_acc: \u001b[31m0.8622752808988764\u001b[0m, time: 150.79\n",
      "epoch: 53, loss: 78.79757, loss1: 0.63049, loss2_3: 78.16707\n",
      "\ttrain_acc: 0.8721, test_acc: \u001b[31m0.8696629213483146\u001b[0m, time: 151.86\n",
      "epoch: 54, loss: 78.64074, loss1: 0.62941, loss2_3: 78.01132\n",
      "\ttrain_acc: 0.8724, test_acc: \u001b[31m0.8702808988764045\u001b[0m, time: 150.91\n",
      "best_acc: 0.8702808988764045\n",
      "epoch: 55, loss: 78.51212, loss1: 0.62614, loss2_3: 77.88598\n",
      "\ttrain_acc: 0.8721, test_acc: \u001b[31m0.8677528089887641\u001b[0m, time: 152.48\n",
      "epoch: 56, loss: 78.45490, loss1: 0.62448, loss2_3: 77.83042\n",
      "\ttrain_acc: 0.8738, test_acc: \u001b[31m0.8704775280898877\u001b[0m, time: 152.79\n",
      "best_acc: 0.8704775280898877\n",
      "epoch: 57, loss: 78.30313, loss1: 0.62694, loss2_3: 77.67619\n",
      "\ttrain_acc: 0.8728, test_acc: \u001b[31m0.8679775280898876\u001b[0m, time: 151.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 58, loss: 78.14204, loss1: 0.62658, loss2_3: 77.51546\n",
      "\ttrain_acc: 0.8721, test_acc: \u001b[31m0.8681741573033708\u001b[0m, time: 151.73\n",
      "epoch: 59, loss: 77.92629, loss1: 0.62325, loss2_3: 77.30304\n",
      "\ttrain_acc: 0.8739, test_acc: \u001b[31m0.8701123595505618\u001b[0m, time: 150.57\n",
      "epoch: 60, loss: 78.12247, loss1: 0.62504, loss2_3: 77.49744\n",
      "\ttrain_acc: 0.8731, test_acc: \u001b[31m0.8692977528089888\u001b[0m, time: 152.08\n",
      "epoch: 61, loss: 77.96358, loss1: 0.62236, loss2_3: 77.34122\n",
      "\ttrain_acc: 0.8729, test_acc: \u001b[31m0.8671067415730337\u001b[0m, time: 151.38\n",
      "epoch: 62, loss: 77.95131, loss1: 0.62321, loss2_3: 77.32810\n",
      "\ttrain_acc: 0.8741, test_acc: \u001b[31m0.8704213483146067\u001b[0m, time: 151.66\n",
      "epoch: 63, loss: 77.88663, loss1: 0.62064, loss2_3: 77.26599\n",
      "\ttrain_acc: 0.8726, test_acc: \u001b[31m0.8665730337078652\u001b[0m, time: 151.52\n",
      "epoch: 64, loss: 77.60878, loss1: 0.61986, loss2_3: 76.98892\n",
      "\ttrain_acc: 0.8745, test_acc: \u001b[31m0.8689325842696629\u001b[0m, time: 151.80\n",
      "epoch: 65, loss: 77.62119, loss1: 0.62056, loss2_3: 77.00062\n",
      "\ttrain_acc: 0.8752, test_acc: \u001b[31m0.8695224719101123\u001b[0m, time: 151.98\n",
      "epoch: 66, loss: 77.53451, loss1: 0.61999, loss2_3: 76.91452\n",
      "\ttrain_acc: 0.8727, test_acc: \u001b[31m0.866938202247191\u001b[0m, time: 151.05\n",
      "epoch: 67, loss: 77.48858, loss1: 0.62198, loss2_3: 76.86660\n",
      "\ttrain_acc: 0.8746, test_acc: \u001b[31m0.8706179775280899\u001b[0m, time: 151.91\n",
      "best_acc: 0.8706179775280899\n",
      "epoch: 68, loss: 77.48372, loss1: 0.61890, loss2_3: 76.86482\n",
      "\ttrain_acc: 0.8721, test_acc: \u001b[31m0.8657865168539326\u001b[0m, time: 151.39\n",
      "epoch: 69, loss: 77.13305, loss1: 0.61483, loss2_3: 76.51822\n",
      "\ttrain_acc: 0.8761, test_acc: \u001b[31m0.870561797752809\u001b[0m, time: 151.08\n",
      "epoch: 70, loss: 77.20893, loss1: 0.61653, loss2_3: 76.59240\n",
      "\ttrain_acc: 0.8760, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 152.14\n",
      "best_acc: 0.8712359550561798\n",
      "epoch: 71, loss: 77.17574, loss1: 0.61685, loss2_3: 76.55889\n",
      "\ttrain_acc: 0.8760, test_acc: \u001b[31m0.871938202247191\u001b[0m, time: 151.27\n",
      "best_acc: 0.871938202247191\n",
      "epoch: 72, loss: 77.15844, loss1: 0.61722, loss2_3: 76.54122\n",
      "\ttrain_acc: 0.8748, test_acc: \u001b[31m0.8700280898876405\u001b[0m, time: 153.01\n",
      "epoch: 73, loss: 76.92584, loss1: 0.61399, loss2_3: 76.31186\n",
      "\ttrain_acc: 0.8760, test_acc: \u001b[31m0.8707303370786517\u001b[0m, time: 150.87\n",
      "epoch: 74, loss: 77.02253, loss1: 0.61514, loss2_3: 76.40739\n",
      "\ttrain_acc: 0.8763, test_acc: \u001b[31m0.8704494382022472\u001b[0m, time: 152.11\n",
      "epoch: 75, loss: 76.95144, loss1: 0.61169, loss2_3: 76.33975\n",
      "\ttrain_acc: 0.8749, test_acc: \u001b[31m0.8698595505617978\u001b[0m, time: 151.67\n",
      "epoch: 76, loss: 76.94779, loss1: 0.61683, loss2_3: 76.33096\n",
      "\ttrain_acc: 0.8770, test_acc: \u001b[31m0.8717977528089887\u001b[0m, time: 151.17\n",
      "epoch: 77, loss: 76.91779, loss1: 0.61289, loss2_3: 76.30491\n",
      "\ttrain_acc: 0.8760, test_acc: \u001b[31m0.8702808988764045\u001b[0m, time: 151.63\n",
      "epoch: 78, loss: 76.76435, loss1: 0.61215, loss2_3: 76.15220\n",
      "\ttrain_acc: 0.8752, test_acc: \u001b[31m0.8692977528089888\u001b[0m, time: 150.38\n",
      "epoch: 79, loss: 76.76890, loss1: 0.61561, loss2_3: 76.15328\n",
      "\ttrain_acc: 0.8761, test_acc: \u001b[31m0.8692977528089888\u001b[0m, time: 151.92\n",
      "epoch: 80, loss: 76.64673, loss1: 0.61592, loss2_3: 76.03080\n",
      "\ttrain_acc: 0.8782, test_acc: \u001b[31m0.871938202247191\u001b[0m, time: 151.96\n",
      "epoch: 81, loss: 76.60453, loss1: 0.61555, loss2_3: 75.98898\n",
      "\ttrain_acc: 0.8771, test_acc: \u001b[31m0.8709269662921348\u001b[0m, time: 152.43\n",
      "epoch: 82, loss: 76.52550, loss1: 0.61496, loss2_3: 75.91054\n",
      "\ttrain_acc: 0.8746, test_acc: \u001b[31m0.8665168539325843\u001b[0m, time: 151.89\n",
      "epoch: 83, loss: 76.41810, loss1: 0.61084, loss2_3: 75.80726\n",
      "\ttrain_acc: 0.8780, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 151.11\n",
      "epoch: 84, loss: 76.28815, loss1: 0.61478, loss2_3: 75.67337\n",
      "\ttrain_acc: 0.8773, test_acc: \u001b[31m0.8715168539325843\u001b[0m, time: 152.06\n",
      "epoch: 85, loss: 76.19207, loss1: 0.61246, loss2_3: 75.57961\n",
      "\ttrain_acc: 0.8773, test_acc: \u001b[31m0.8708426966292134\u001b[0m, time: 151.11\n",
      "epoch: 86, loss: 76.17183, loss1: 0.61041, loss2_3: 75.56143\n",
      "\ttrain_acc: 0.8764, test_acc: \u001b[31m0.8701123595505618\u001b[0m, time: 151.64\n",
      "epoch: 87, loss: 76.15097, loss1: 0.60784, loss2_3: 75.54313\n",
      "\ttrain_acc: 0.8776, test_acc: \u001b[31m0.87\u001b[0m, time: 151.22\n",
      "epoch: 88, loss: 76.10169, loss1: 0.60953, loss2_3: 75.49217\n",
      "\ttrain_acc: 0.8774, test_acc: \u001b[31m0.8706179775280899\u001b[0m, time: 152.40\n",
      "epoch: 89, loss: 75.96663, loss1: 0.60725, loss2_3: 75.35939\n",
      "\ttrain_acc: 0.8767, test_acc: \u001b[31m0.8698314606741573\u001b[0m, time: 152.59\n",
      "epoch: 90, loss: 76.21120, loss1: 0.60911, loss2_3: 75.60209\n",
      "\ttrain_acc: 0.8782, test_acc: \u001b[31m0.8721067415730337\u001b[0m, time: 150.41\n",
      "best_acc: 0.8721067415730337\n",
      "epoch: 91, loss: 75.94252, loss1: 0.61217, loss2_3: 75.33034\n",
      "\ttrain_acc: 0.8785, test_acc: \u001b[31m0.8702808988764045\u001b[0m, time: 151.38\n",
      "epoch: 92, loss: 75.90430, loss1: 0.60579, loss2_3: 75.29852\n",
      "\ttrain_acc: 0.8751, test_acc: \u001b[31m0.8673314606741573\u001b[0m, time: 150.27\n",
      "epoch: 93, loss: 75.74655, loss1: 0.60727, loss2_3: 75.13928\n",
      "\ttrain_acc: 0.8765, test_acc: \u001b[31m0.8694943820224719\u001b[0m, time: 152.16\n",
      "epoch: 94, loss: 75.91017, loss1: 0.60581, loss2_3: 75.30436\n",
      "\ttrain_acc: 0.8775, test_acc: \u001b[31m0.8702247191011236\u001b[0m, time: 151.63\n",
      "epoch: 95, loss: 75.75429, loss1: 0.60683, loss2_3: 75.14746\n",
      "\ttrain_acc: 0.8768, test_acc: \u001b[31m0.8696629213483146\u001b[0m, time: 152.00\n",
      "epoch: 96, loss: 75.57158, loss1: 0.60598, loss2_3: 74.96560\n",
      "\ttrain_acc: 0.8772, test_acc: \u001b[31m0.8693820224719101\u001b[0m, time: 152.14\n",
      "epoch: 97, loss: 75.77916, loss1: 0.60736, loss2_3: 75.17180\n",
      "\ttrain_acc: 0.8789, test_acc: \u001b[31m0.8719101123595505\u001b[0m, time: 151.72\n",
      "epoch: 98, loss: 75.60454, loss1: 0.60134, loss2_3: 75.00320\n",
      "\ttrain_acc: 0.8785, test_acc: \u001b[31m0.8721067415730337\u001b[0m, time: 152.29\n",
      "epoch: 99, loss: 75.68899, loss1: 0.60591, loss2_3: 75.08308\n",
      "\ttrain_acc: 0.8791, test_acc: \u001b[31m0.8717977528089887\u001b[0m, time: 151.21\n",
      "epoch: 100, loss: 75.50912, loss1: 0.60636, loss2_3: 74.90275\n",
      "\ttrain_acc: 0.8799, test_acc: \u001b[31m0.8722752808988764\u001b[0m, time: 151.85\n",
      "best_acc: 0.8722752808988764\n",
      "epoch: 101, loss: 75.53303, loss1: 0.60669, loss2_3: 74.92634\n",
      "\ttrain_acc: 0.8792, test_acc: \u001b[31m0.8712921348314607\u001b[0m, time: 151.49\n",
      "epoch: 102, loss: 75.50465, loss1: 0.60268, loss2_3: 74.90197\n",
      "\ttrain_acc: 0.8768, test_acc: \u001b[31m0.8692977528089888\u001b[0m, time: 151.77\n",
      "epoch: 103, loss: 75.32596, loss1: 0.60590, loss2_3: 74.72006\n",
      "\ttrain_acc: 0.8804, test_acc: \u001b[31m0.8710955056179776\u001b[0m, time: 152.04\n",
      "epoch: 104, loss: 75.64390, loss1: 0.60711, loss2_3: 75.03679\n",
      "\ttrain_acc: 0.8773, test_acc: \u001b[31m0.8698595505617978\u001b[0m, time: 150.80\n",
      "epoch: 105, loss: 75.36103, loss1: 0.60348, loss2_3: 74.75755\n",
      "\ttrain_acc: 0.8804, test_acc: \u001b[31m0.8714606741573033\u001b[0m, time: 152.89\n",
      "epoch: 106, loss: 75.42870, loss1: 0.60297, loss2_3: 74.82573\n",
      "\ttrain_acc: 0.8770, test_acc: \u001b[31m0.8689325842696629\u001b[0m, time: 150.91\n",
      "epoch: 107, loss: 75.23414, loss1: 0.60435, loss2_3: 74.62979\n",
      "\ttrain_acc: 0.8782, test_acc: \u001b[31m0.869943820224719\u001b[0m, time: 152.16\n",
      "epoch: 108, loss: 75.16042, loss1: 0.60577, loss2_3: 74.55466\n",
      "\ttrain_acc: 0.8812, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 151.79\n",
      "epoch: 109, loss: 75.22605, loss1: 0.60327, loss2_3: 74.62278\n",
      "\ttrain_acc: 0.8809, test_acc: \u001b[31m0.8717134831460674\u001b[0m, time: 151.46\n",
      "epoch: 110, loss: 74.87554, loss1: 0.60306, loss2_3: 74.27248\n",
      "\ttrain_acc: 0.8807, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 152.00\n",
      "epoch: 111, loss: 74.99521, loss1: 0.60250, loss2_3: 74.39271\n",
      "\ttrain_acc: 0.8811, test_acc: \u001b[31m0.8723033707865169\u001b[0m, time: 150.94\n",
      "best_acc: 0.8723033707865169\n",
      "epoch: 112, loss: 74.91611, loss1: 0.59713, loss2_3: 74.31897\n",
      "\ttrain_acc: 0.8787, test_acc: \u001b[31m0.8693539325842696\u001b[0m, time: 152.14\n",
      "epoch: 113, loss: 75.00376, loss1: 0.60209, loss2_3: 74.40166\n",
      "\ttrain_acc: 0.8797, test_acc: \u001b[31m0.8713483146067416\u001b[0m, time: 152.39\n",
      "epoch: 114, loss: 74.80388, loss1: 0.60011, loss2_3: 74.20377\n",
      "\ttrain_acc: 0.8811, test_acc: \u001b[31m0.8712640449438203\u001b[0m, time: 151.47\n",
      "epoch: 115, loss: 74.77550, loss1: 0.60030, loss2_3: 74.17520\n",
      "\ttrain_acc: 0.8811, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 151.74\n",
      "epoch: 116, loss: 74.73787, loss1: 0.60120, loss2_3: 74.13667\n",
      "\ttrain_acc: 0.8792, test_acc: \u001b[31m0.8692696629213483\u001b[0m, time: 151.17\n",
      "epoch: 117, loss: 74.68199, loss1: 0.59756, loss2_3: 74.08443\n",
      "\ttrain_acc: 0.8820, test_acc: \u001b[31m0.8732584269662922\u001b[0m, time: 151.42\n",
      "best_acc: 0.8732584269662922\n",
      "epoch: 118, loss: 74.54448, loss1: 0.60109, loss2_3: 73.94338\n",
      "\ttrain_acc: 0.8805, test_acc: \u001b[31m0.8696629213483146\u001b[0m, time: 150.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 119, loss: 74.57052, loss1: 0.59726, loss2_3: 73.97326\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.871629213483146\u001b[0m, time: 151.65\n",
      "epoch: 120, loss: 74.56740, loss1: 0.59821, loss2_3: 73.96919\n",
      "\ttrain_acc: 0.8824, test_acc: \u001b[31m0.8723314606741573\u001b[0m, time: 151.06\n",
      "epoch: 121, loss: 74.42412, loss1: 0.59917, loss2_3: 73.82494\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8706179775280899\u001b[0m, time: 152.65\n",
      "epoch: 122, loss: 74.58578, loss1: 0.59902, loss2_3: 73.98676\n",
      "\ttrain_acc: 0.8826, test_acc: \u001b[31m0.8726685393258427\u001b[0m, time: 151.99\n",
      "epoch: 123, loss: 74.58110, loss1: 0.60155, loss2_3: 73.97955\n",
      "\ttrain_acc: 0.8816, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 150.90\n",
      "epoch: 124, loss: 74.38289, loss1: 0.59557, loss2_3: 73.78732\n",
      "\ttrain_acc: 0.8817, test_acc: \u001b[31m0.870252808988764\u001b[0m, time: 151.83\n",
      "epoch: 125, loss: 74.56777, loss1: 0.59862, loss2_3: 73.96915\n",
      "\ttrain_acc: 0.8802, test_acc: \u001b[31m0.8686797752808989\u001b[0m, time: 150.98\n",
      "epoch: 126, loss: 74.42205, loss1: 0.59902, loss2_3: 73.82303\n",
      "\ttrain_acc: 0.8809, test_acc: \u001b[31m0.871938202247191\u001b[0m, time: 151.92\n",
      "epoch: 127, loss: 74.27612, loss1: 0.59514, loss2_3: 73.68097\n",
      "\ttrain_acc: 0.8819, test_acc: \u001b[31m0.8708146067415731\u001b[0m, time: 151.87\n",
      "epoch: 128, loss: 74.20605, loss1: 0.59656, loss2_3: 73.60949\n",
      "\ttrain_acc: 0.8826, test_acc: \u001b[31m0.8721629213483146\u001b[0m, time: 147.44\n",
      "epoch: 129, loss: 74.22968, loss1: 0.59770, loss2_3: 73.63198\n",
      "\ttrain_acc: 0.8826, test_acc: \u001b[31m0.8721348314606742\u001b[0m, time: 127.98\n",
      "epoch: 130, loss: 74.04249, loss1: 0.59266, loss2_3: 73.44983\n",
      "\ttrain_acc: 0.8835, test_acc: \u001b[31m0.8727528089887641\u001b[0m, time: 126.87\n",
      "epoch: 131, loss: 74.28682, loss1: 0.59366, loss2_3: 73.69316\n",
      "\ttrain_acc: 0.8831, test_acc: \u001b[31m0.8724719101123596\u001b[0m, time: 127.63\n",
      "epoch: 132, loss: 74.07592, loss1: 0.59631, loss2_3: 73.47961\n",
      "\ttrain_acc: 0.8829, test_acc: \u001b[31m0.8715449438202247\u001b[0m, time: 126.39\n",
      "epoch: 133, loss: 73.99987, loss1: 0.59652, loss2_3: 73.40335\n",
      "\ttrain_acc: 0.8819, test_acc: \u001b[31m0.8709831460674158\u001b[0m, time: 127.07\n",
      "epoch: 134, loss: 73.95767, loss1: 0.59560, loss2_3: 73.36207\n",
      "\ttrain_acc: 0.8826, test_acc: \u001b[31m0.8724157303370786\u001b[0m, time: 127.36\n",
      "epoch: 135, loss: 74.07935, loss1: 0.59608, loss2_3: 73.48328\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8695505617977528\u001b[0m, time: 127.44\n",
      "epoch: 136, loss: 73.96147, loss1: 0.59313, loss2_3: 73.36834\n",
      "\ttrain_acc: 0.8839, test_acc: \u001b[31m0.8723876404494382\u001b[0m, time: 127.69\n",
      "epoch: 137, loss: 73.86742, loss1: 0.59350, loss2_3: 73.27392\n",
      "\ttrain_acc: 0.8834, test_acc: \u001b[31m0.871629213483146\u001b[0m, time: 127.81\n",
      "epoch: 138, loss: 73.79410, loss1: 0.59434, loss2_3: 73.19976\n",
      "\ttrain_acc: 0.8734, test_acc: \u001b[31m0.8629775280898876\u001b[0m, time: 127.31\n",
      "epoch: 139, loss: 73.76503, loss1: 0.59435, loss2_3: 73.17068\n",
      "\ttrain_acc: 0.8834, test_acc: \u001b[31m0.8704213483146067\u001b[0m, time: 126.75\n",
      "epoch: 140, loss: 73.74245, loss1: 0.59022, loss2_3: 73.15224\n",
      "\ttrain_acc: 0.8839, test_acc: \u001b[31m0.8732865168539325\u001b[0m, time: 127.72\n",
      "best_acc: 0.8732865168539325\n",
      "epoch: 141, loss: 73.68391, loss1: 0.59617, loss2_3: 73.08774\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8684550561797753\u001b[0m, time: 127.47\n",
      "epoch: 142, loss: 73.76909, loss1: 0.59337, loss2_3: 73.17571\n",
      "\ttrain_acc: 0.8851, test_acc: \u001b[31m0.8725842696629214\u001b[0m, time: 127.17\n",
      "epoch: 143, loss: 73.45524, loss1: 0.59230, loss2_3: 72.86293\n",
      "\ttrain_acc: 0.8848, test_acc: \u001b[31m0.870561797752809\u001b[0m, time: 126.25\n",
      "epoch: 144, loss: 73.33099, loss1: 0.58898, loss2_3: 72.74201\n",
      "\ttrain_acc: 0.8839, test_acc: \u001b[31m0.8710393258426966\u001b[0m, time: 126.59\n",
      "epoch: 145, loss: 73.33306, loss1: 0.59357, loss2_3: 72.73949\n",
      "\ttrain_acc: 0.8851, test_acc: \u001b[31m0.8734269662921348\u001b[0m, time: 127.82\n",
      "best_acc: 0.8734269662921348\n",
      "epoch: 146, loss: 73.27548, loss1: 0.59202, loss2_3: 72.68346\n",
      "\ttrain_acc: 0.8839, test_acc: \u001b[31m0.869943820224719\u001b[0m, time: 127.46\n",
      "epoch: 147, loss: 73.26501, loss1: 0.59316, loss2_3: 72.67185\n",
      "\ttrain_acc: 0.8850, test_acc: \u001b[31m0.873314606741573\u001b[0m, time: 127.11\n",
      "epoch: 148, loss: 73.34935, loss1: 0.58957, loss2_3: 72.75978\n",
      "\ttrain_acc: 0.8847, test_acc: \u001b[31m0.8709831460674158\u001b[0m, time: 127.33\n",
      "epoch: 149, loss: 73.28315, loss1: 0.59052, loss2_3: 72.69263\n",
      "\ttrain_acc: 0.8824, test_acc: \u001b[31m0.8673876404494382\u001b[0m, time: 126.82\n",
      "epoch: 150, loss: 72.95461, loss1: 0.59095, loss2_3: 72.36366\n",
      "\ttrain_acc: 0.8784, test_acc: \u001b[31m0.8641292134831461\u001b[0m, time: 127.62\n",
      "epoch: 151, loss: 73.10044, loss1: 0.58982, loss2_3: 72.51063\n",
      "\ttrain_acc: 0.8861, test_acc: \u001b[31m0.8722752808988764\u001b[0m, time: 126.73\n",
      "epoch: 152, loss: 73.15411, loss1: 0.58743, loss2_3: 72.56668\n",
      "\ttrain_acc: 0.8849, test_acc: \u001b[31m0.871376404494382\u001b[0m, time: 128.55\n",
      "epoch: 153, loss: 72.88046, loss1: 0.59037, loss2_3: 72.29009\n",
      "\ttrain_acc: 0.8825, test_acc: \u001b[31m0.8678651685393258\u001b[0m, time: 127.62\n",
      "epoch: 154, loss: 73.07541, loss1: 0.59045, loss2_3: 72.48495\n",
      "\ttrain_acc: 0.8808, test_acc: \u001b[31m0.8671348314606742\u001b[0m, time: 127.27\n",
      "epoch: 155, loss: 72.91992, loss1: 0.58918, loss2_3: 72.33074\n",
      "\ttrain_acc: 0.8872, test_acc: \u001b[31m0.8738483146067416\u001b[0m, time: 127.58\n",
      "best_acc: 0.8738483146067416\n",
      "epoch: 156, loss: 72.93705, loss1: 0.58946, loss2_3: 72.34759\n",
      "\ttrain_acc: 0.8855, test_acc: \u001b[31m0.871376404494382\u001b[0m, time: 126.03\n",
      "epoch: 157, loss: 72.93616, loss1: 0.59269, loss2_3: 72.34347\n",
      "\ttrain_acc: 0.8858, test_acc: \u001b[31m0.871629213483146\u001b[0m, time: 127.61\n",
      "epoch: 158, loss: 72.67291, loss1: 0.58808, loss2_3: 72.08484\n",
      "\ttrain_acc: 0.8874, test_acc: \u001b[31m0.8717134831460674\u001b[0m, time: 126.62\n",
      "epoch: 159, loss: 72.61691, loss1: 0.58406, loss2_3: 72.03285\n",
      "\ttrain_acc: 0.8867, test_acc: \u001b[31m0.8719101123595505\u001b[0m, time: 128.55\n",
      "epoch: 160, loss: 72.66173, loss1: 0.58578, loss2_3: 72.07595\n",
      "\ttrain_acc: 0.8857, test_acc: \u001b[31m0.8712640449438203\u001b[0m, time: 127.41\n",
      "epoch: 161, loss: 72.69585, loss1: 0.58892, loss2_3: 72.10692\n",
      "\ttrain_acc: 0.8857, test_acc: \u001b[31m0.869943820224719\u001b[0m, time: 129.05\n",
      "epoch: 162, loss: 72.27598, loss1: 0.58673, loss2_3: 71.68924\n",
      "\ttrain_acc: 0.8831, test_acc: \u001b[31m0.8676123595505618\u001b[0m, time: 126.76\n",
      "epoch: 163, loss: 72.43094, loss1: 0.58550, loss2_3: 71.84544\n",
      "\ttrain_acc: 0.8868, test_acc: \u001b[31m0.8710112359550561\u001b[0m, time: 126.77\n",
      "epoch: 164, loss: 72.45176, loss1: 0.58453, loss2_3: 71.86723\n",
      "\ttrain_acc: 0.8879, test_acc: \u001b[31m0.8718258426966292\u001b[0m, time: 127.71\n",
      "epoch: 165, loss: 72.20081, loss1: 0.58614, loss2_3: 71.61467\n",
      "\ttrain_acc: 0.8807, test_acc: \u001b[31m0.8659550561797753\u001b[0m, time: 126.70\n",
      "epoch: 166, loss: 72.24723, loss1: 0.58150, loss2_3: 71.66573\n",
      "\ttrain_acc: 0.8871, test_acc: \u001b[31m0.8717134831460674\u001b[0m, time: 129.64\n",
      "epoch: 167, loss: 72.15915, loss1: 0.58177, loss2_3: 71.57738\n",
      "\ttrain_acc: 0.8866, test_acc: \u001b[31m0.8703370786516854\u001b[0m, time: 127.72\n",
      "epoch: 168, loss: 72.16879, loss1: 0.58564, loss2_3: 71.58314\n",
      "\ttrain_acc: 0.8871, test_acc: \u001b[31m0.8714044943820225\u001b[0m, time: 127.23\n",
      "epoch: 169, loss: 71.87199, loss1: 0.58242, loss2_3: 71.28957\n",
      "\ttrain_acc: 0.8852, test_acc: \u001b[31m0.8693820224719101\u001b[0m, time: 127.59\n",
      "epoch: 170, loss: 72.00026, loss1: 0.58251, loss2_3: 71.41775\n",
      "\ttrain_acc: 0.8890, test_acc: \u001b[31m0.8730898876404495\u001b[0m, time: 128.76\n",
      "epoch: 171, loss: 71.95029, loss1: 0.58598, loss2_3: 71.36432\n",
      "\ttrain_acc: 0.8866, test_acc: \u001b[31m0.8701685393258427\u001b[0m, time: 127.88\n",
      "epoch: 172, loss: 72.03021, loss1: 0.58166, loss2_3: 71.44855\n",
      "\ttrain_acc: 0.8878, test_acc: \u001b[31m0.8701123595505618\u001b[0m, time: 128.84\n",
      "epoch: 173, loss: 71.70508, loss1: 0.58238, loss2_3: 71.12269\n",
      "\ttrain_acc: 0.8894, test_acc: \u001b[31m0.8720786516853932\u001b[0m, time: 127.73\n",
      "epoch: 174, loss: 71.56406, loss1: 0.57899, loss2_3: 70.98507\n",
      "\ttrain_acc: 0.8897, test_acc: \u001b[31m0.8723314606741573\u001b[0m, time: 127.59\n",
      "epoch: 175, loss: 71.77595, loss1: 0.58231, loss2_3: 71.19364\n",
      "\ttrain_acc: 0.8846, test_acc: \u001b[31m0.8673033707865169\u001b[0m, time: 127.80\n",
      "epoch: 176, loss: 71.51246, loss1: 0.58361, loss2_3: 70.92885\n",
      "\ttrain_acc: 0.8898, test_acc: \u001b[31m0.8706179775280899\u001b[0m, time: 127.85\n",
      "epoch: 177, loss: 71.53016, loss1: 0.58078, loss2_3: 70.94938\n",
      "\ttrain_acc: 0.8877, test_acc: \u001b[31m0.8719101123595505\u001b[0m, time: 126.67\n",
      "epoch: 178, loss: 71.37269, loss1: 0.57767, loss2_3: 70.79502\n",
      "\ttrain_acc: 0.8902, test_acc: \u001b[31m0.8726123595505618\u001b[0m, time: 128.75\n",
      "epoch: 179, loss: 71.31129, loss1: 0.58063, loss2_3: 70.73066\n",
      "\ttrain_acc: 0.8901, test_acc: \u001b[31m0.8710112359550561\u001b[0m, time: 126.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 180, loss: 71.37382, loss1: 0.58100, loss2_3: 70.79281\n",
      "\ttrain_acc: 0.8895, test_acc: \u001b[31m0.8698595505617978\u001b[0m, time: 126.70\n",
      "epoch: 181, loss: 71.27949, loss1: 0.58144, loss2_3: 70.69805\n",
      "\ttrain_acc: 0.8879, test_acc: \u001b[31m0.8707584269662921\u001b[0m, time: 126.49\n",
      "epoch: 182, loss: 71.18733, loss1: 0.57732, loss2_3: 70.61001\n",
      "\ttrain_acc: 0.8851, test_acc: \u001b[31m0.8678932584269663\u001b[0m, time: 126.99\n",
      "epoch: 183, loss: 71.13735, loss1: 0.57687, loss2_3: 70.56048\n",
      "\ttrain_acc: 0.8906, test_acc: \u001b[31m0.871685393258427\u001b[0m, time: 128.50\n",
      "epoch: 184, loss: 71.14530, loss1: 0.57966, loss2_3: 70.56564\n",
      "\ttrain_acc: 0.8893, test_acc: \u001b[31m0.868314606741573\u001b[0m, time: 125.97\n",
      "epoch: 185, loss: 71.03333, loss1: 0.57964, loss2_3: 70.45369\n",
      "\ttrain_acc: 0.8893, test_acc: \u001b[31m0.8696348314606741\u001b[0m, time: 127.72\n",
      "epoch: 186, loss: 70.79782, loss1: 0.57526, loss2_3: 70.22256\n",
      "\ttrain_acc: 0.8912, test_acc: \u001b[31m0.8707303370786517\u001b[0m, time: 126.94\n",
      "epoch: 187, loss: 70.89135, loss1: 0.57950, loss2_3: 70.31185\n",
      "\ttrain_acc: 0.8909, test_acc: \u001b[31m0.8726123595505618\u001b[0m, time: 127.14\n",
      "epoch: 188, loss: 70.84009, loss1: 0.57936, loss2_3: 70.26073\n",
      "\ttrain_acc: 0.8910, test_acc: \u001b[31m0.8712640449438203\u001b[0m, time: 126.69\n",
      "epoch: 189, loss: 70.74344, loss1: 0.57420, loss2_3: 70.16924\n",
      "\ttrain_acc: 0.8902, test_acc: \u001b[31m0.8708988764044944\u001b[0m, time: 127.11\n",
      "epoch: 190, loss: 70.60605, loss1: 0.57750, loss2_3: 70.02855\n",
      "\ttrain_acc: 0.8916, test_acc: \u001b[31m0.871685393258427\u001b[0m, time: 128.64\n",
      "epoch: 191, loss: 70.73309, loss1: 0.57260, loss2_3: 70.16049\n",
      "\ttrain_acc: 0.8869, test_acc: \u001b[31m0.8670786516853932\u001b[0m, time: 126.91\n",
      "epoch: 192, loss: 70.80321, loss1: 0.57353, loss2_3: 70.22968\n",
      "\ttrain_acc: 0.8910, test_acc: \u001b[31m0.8712640449438203\u001b[0m, time: 127.13\n",
      "epoch: 193, loss: 70.51000, loss1: 0.57372, loss2_3: 69.93627\n",
      "\ttrain_acc: 0.8929, test_acc: \u001b[31m0.8722752808988764\u001b[0m, time: 126.70\n",
      "epoch: 194, loss: 70.47671, loss1: 0.57602, loss2_3: 69.90070\n",
      "\ttrain_acc: 0.8919, test_acc: \u001b[31m0.8715449438202247\u001b[0m, time: 126.81\n",
      "epoch: 195, loss: 70.34992, loss1: 0.57367, loss2_3: 69.77625\n",
      "\ttrain_acc: 0.8928, test_acc: \u001b[31m0.8723314606741573\u001b[0m, time: 128.76\n",
      "epoch: 196, loss: 70.29736, loss1: 0.57318, loss2_3: 69.72419\n",
      "\ttrain_acc: 0.8911, test_acc: \u001b[31m0.871685393258427\u001b[0m, time: 126.49\n",
      "epoch: 197, loss: 70.27370, loss1: 0.57382, loss2_3: 69.69988\n",
      "\ttrain_acc: 0.8929, test_acc: \u001b[31m0.8701404494382022\u001b[0m, time: 127.64\n",
      "epoch: 198, loss: 70.24639, loss1: 0.57012, loss2_3: 69.67627\n",
      "\ttrain_acc: 0.8933, test_acc: \u001b[31m0.871376404494382\u001b[0m, time: 126.57\n",
      "epoch: 199, loss: 70.07758, loss1: 0.57422, loss2_3: 69.50336\n",
      "\ttrain_acc: 0.8877, test_acc: \u001b[31m0.8669662921348315\u001b[0m, time: 127.64\n",
      "epoch: 200, loss: 70.11263, loss1: 0.57066, loss2_3: 69.54197\n",
      "\ttrain_acc: 0.8928, test_acc: \u001b[31m0.8678651685393258\u001b[0m, time: 126.95\n",
      "epoch: 201, loss: 69.97805, loss1: 0.56998, loss2_3: 69.40807\n",
      "\ttrain_acc: 0.8910, test_acc: \u001b[31m0.8679213483146068\u001b[0m, time: 126.72\n",
      "epoch: 202, loss: 69.81613, loss1: 0.57270, loss2_3: 69.24343\n",
      "\ttrain_acc: 0.8929, test_acc: \u001b[31m0.871938202247191\u001b[0m, time: 127.06\n",
      "epoch: 203, loss: 69.70637, loss1: 0.56899, loss2_3: 69.13738\n",
      "\ttrain_acc: 0.8792, test_acc: \u001b[31m0.8610393258426966\u001b[0m, time: 126.63\n",
      "epoch: 204, loss: 69.98922, loss1: 0.57018, loss2_3: 69.41905\n",
      "\ttrain_acc: 0.8942, test_acc: \u001b[31m0.8709550561797753\u001b[0m, time: 127.53\n",
      "epoch: 205, loss: 69.91641, loss1: 0.57299, loss2_3: 69.34342\n",
      "\ttrain_acc: 0.8925, test_acc: \u001b[31m0.8703651685393259\u001b[0m, time: 128.16\n",
      "epoch: 206, loss: 69.52689, loss1: 0.57192, loss2_3: 68.95497\n",
      "\ttrain_acc: 0.8949, test_acc: \u001b[31m0.871432584269663\u001b[0m, time: 127.00\n",
      "epoch: 207, loss: 69.55158, loss1: 0.56939, loss2_3: 68.98219\n",
      "\ttrain_acc: 0.8897, test_acc: \u001b[31m0.8670786516853932\u001b[0m, time: 126.88\n",
      "epoch: 208, loss: 69.53005, loss1: 0.56779, loss2_3: 68.96227\n",
      "\ttrain_acc: 0.8925, test_acc: \u001b[31m0.8695224719101123\u001b[0m, time: 126.20\n",
      "epoch: 209, loss: 69.45262, loss1: 0.56906, loss2_3: 68.88356\n",
      "\ttrain_acc: 0.8938, test_acc: \u001b[31m0.8714887640449438\u001b[0m, time: 127.31\n",
      "epoch: 210, loss: 69.46130, loss1: 0.56878, loss2_3: 68.89252\n",
      "\ttrain_acc: 0.8899, test_acc: \u001b[31m0.8664606741573033\u001b[0m, time: 126.48\n",
      "epoch: 211, loss: 69.41164, loss1: 0.56662, loss2_3: 68.84502\n",
      "\ttrain_acc: 0.8909, test_acc: \u001b[31m0.8673595505617977\u001b[0m, time: 127.03\n",
      "epoch: 212, loss: 69.37513, loss1: 0.56788, loss2_3: 68.80725\n",
      "\ttrain_acc: 0.8953, test_acc: \u001b[31m0.871376404494382\u001b[0m, time: 127.45\n",
      "epoch: 213, loss: 69.26038, loss1: 0.56587, loss2_3: 68.69451\n",
      "\ttrain_acc: 0.8966, test_acc: \u001b[31m0.8704494382022472\u001b[0m, time: 127.82\n",
      "epoch: 214, loss: 68.97854, loss1: 0.56905, loss2_3: 68.40949\n",
      "\ttrain_acc: 0.8915, test_acc: \u001b[31m0.8666573033707865\u001b[0m, time: 127.40\n",
      "epoch: 215, loss: 69.02037, loss1: 0.56707, loss2_3: 68.45330\n",
      "\ttrain_acc: 0.8942, test_acc: \u001b[31m0.8708146067415731\u001b[0m, time: 126.82\n",
      "epoch: 216, loss: 69.05519, loss1: 0.56508, loss2_3: 68.49011\n",
      "\ttrain_acc: 0.8939, test_acc: \u001b[31m0.8679775280898876\u001b[0m, time: 126.80\n",
      "epoch: 217, loss: 68.89596, loss1: 0.56623, loss2_3: 68.32972\n",
      "\ttrain_acc: 0.8959, test_acc: \u001b[31m0.870252808988764\u001b[0m, time: 128.45\n",
      "epoch: 218, loss: 68.83369, loss1: 0.56460, loss2_3: 68.26908\n",
      "\ttrain_acc: 0.8963, test_acc: \u001b[31m0.8704494382022472\u001b[0m, time: 127.13\n",
      "epoch: 219, loss: 68.77204, loss1: 0.56478, loss2_3: 68.20726\n",
      "\ttrain_acc: 0.8952, test_acc: \u001b[31m0.8697191011235955\u001b[0m, time: 127.13\n",
      "epoch: 220, loss: 68.52272, loss1: 0.56413, loss2_3: 67.95859\n",
      "\ttrain_acc: 0.8949, test_acc: \u001b[31m0.8707022471910112\u001b[0m, time: 128.17\n",
      "epoch: 221, loss: 68.50580, loss1: 0.56495, loss2_3: 67.94085\n",
      "\ttrain_acc: 0.8939, test_acc: \u001b[31m0.8665168539325843\u001b[0m, time: 126.81\n",
      "epoch: 222, loss: 68.62656, loss1: 0.56268, loss2_3: 68.06388\n",
      "\ttrain_acc: 0.8931, test_acc: \u001b[31m0.8679213483146068\u001b[0m, time: 126.85\n",
      "epoch: 223, loss: 68.64230, loss1: 0.56226, loss2_3: 68.08004\n",
      "\ttrain_acc: 0.8972, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 127.04\n",
      "epoch: 224, loss: 68.45261, loss1: 0.56338, loss2_3: 67.88923\n",
      "\ttrain_acc: 0.8955, test_acc: \u001b[31m0.8705337078651686\u001b[0m, time: 126.27\n",
      "epoch: 225, loss: 68.12023, loss1: 0.55881, loss2_3: 67.56142\n",
      "\ttrain_acc: 0.8965, test_acc: \u001b[31m0.8695505617977528\u001b[0m, time: 127.07\n",
      "epoch: 226, loss: 68.42617, loss1: 0.56237, loss2_3: 67.86380\n",
      "\ttrain_acc: 0.8975, test_acc: \u001b[31m0.8697752808988765\u001b[0m, time: 127.15\n",
      "epoch: 227, loss: 68.45459, loss1: 0.56255, loss2_3: 67.89203\n",
      "\ttrain_acc: 0.8943, test_acc: \u001b[31m0.8698595505617978\u001b[0m, time: 127.68\n",
      "epoch: 228, loss: 68.05805, loss1: 0.56045, loss2_3: 67.49761\n",
      "\ttrain_acc: 0.8945, test_acc: \u001b[31m0.8689887640449439\u001b[0m, time: 127.92\n",
      "epoch: 229, loss: 67.90115, loss1: 0.56119, loss2_3: 67.33996\n",
      "\ttrain_acc: 0.8957, test_acc: \u001b[31m0.8689606741573034\u001b[0m, time: 126.69\n",
      "epoch: 230, loss: 68.04440, loss1: 0.55907, loss2_3: 67.48533\n",
      "\ttrain_acc: 0.8968, test_acc: \u001b[31m0.8709550561797753\u001b[0m, time: 126.87\n",
      "epoch: 231, loss: 67.83328, loss1: 0.55595, loss2_3: 67.27733\n",
      "\ttrain_acc: 0.8981, test_acc: \u001b[31m0.8702247191011236\u001b[0m, time: 126.82\n",
      "epoch: 232, loss: 67.84398, loss1: 0.55988, loss2_3: 67.28410\n",
      "\ttrain_acc: 0.8981, test_acc: \u001b[31m0.8688483146067416\u001b[0m, time: 127.32\n",
      "epoch: 233, loss: 67.79845, loss1: 0.55482, loss2_3: 67.24363\n",
      "\ttrain_acc: 0.8958, test_acc: \u001b[31m0.8687078651685394\u001b[0m, time: 128.37\n",
      "epoch: 234, loss: 67.59514, loss1: 0.56103, loss2_3: 67.03411\n",
      "\ttrain_acc: 0.8989, test_acc: \u001b[31m0.8696348314606741\u001b[0m, time: 126.53\n",
      "epoch: 235, loss: 67.55994, loss1: 0.55870, loss2_3: 67.00125\n",
      "\ttrain_acc: 0.8999, test_acc: \u001b[31m0.8712078651685393\u001b[0m, time: 127.70\n",
      "epoch: 236, loss: 67.23925, loss1: 0.55682, loss2_3: 66.68243\n",
      "\ttrain_acc: 0.8993, test_acc: \u001b[31m0.8699719101123595\u001b[0m, time: 128.78\n",
      "epoch: 237, loss: 67.45673, loss1: 0.55800, loss2_3: 66.89873\n",
      "\ttrain_acc: 0.8929, test_acc: \u001b[31m0.8648033707865168\u001b[0m, time: 127.30\n",
      "epoch: 238, loss: 67.40760, loss1: 0.55524, loss2_3: 66.85236\n",
      "\ttrain_acc: 0.9001, test_acc: \u001b[31m0.8705337078651686\u001b[0m, time: 126.57\n",
      "epoch: 239, loss: 67.53054, loss1: 0.55720, loss2_3: 66.97335\n",
      "\ttrain_acc: 0.8997, test_acc: \u001b[31m0.8700280898876405\u001b[0m, time: 126.92\n",
      "epoch: 240, loss: 67.33103, loss1: 0.55527, loss2_3: 66.77575\n",
      "\ttrain_acc: 0.8996, test_acc: \u001b[31m0.8712921348314607\u001b[0m, time: 126.76\n",
      "epoch: 241, loss: 67.24136, loss1: 0.55550, loss2_3: 66.68586\n",
      "\ttrain_acc: 0.9007, test_acc: \u001b[31m0.868370786516854\u001b[0m, time: 126.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 242, loss: 67.12840, loss1: 0.55559, loss2_3: 66.57280\n",
      "\ttrain_acc: 0.9007, test_acc: \u001b[31m0.8692977528089888\u001b[0m, time: 128.23\n",
      "epoch: 243, loss: 67.04458, loss1: 0.55521, loss2_3: 66.48937\n",
      "\ttrain_acc: 0.8937, test_acc: \u001b[31m0.8656179775280899\u001b[0m, time: 126.31\n",
      "epoch: 244, loss: 66.89626, loss1: 0.55660, loss2_3: 66.33966\n",
      "\ttrain_acc: 0.9017, test_acc: \u001b[31m0.8690730337078652\u001b[0m, time: 126.95\n",
      "epoch: 245, loss: 66.79155, loss1: 0.55291, loss2_3: 66.23863\n",
      "\ttrain_acc: 0.9020, test_acc: \u001b[31m0.8702247191011236\u001b[0m, time: 126.79\n",
      "epoch: 246, loss: 66.89477, loss1: 0.55389, loss2_3: 66.34088\n",
      "\ttrain_acc: 0.9015, test_acc: \u001b[31m0.8709269662921348\u001b[0m, time: 126.93\n",
      "epoch: 247, loss: 66.70399, loss1: 0.55546, loss2_3: 66.14853\n",
      "\ttrain_acc: 0.8997, test_acc: \u001b[31m0.8681741573033708\u001b[0m, time: 127.23\n",
      "epoch: 248, loss: 66.41705, loss1: 0.55367, loss2_3: 65.86338\n",
      "\ttrain_acc: 0.9021, test_acc: \u001b[31m0.868623595505618\u001b[0m, time: 125.92\n",
      "epoch: 249, loss: 66.53418, loss1: 0.55201, loss2_3: 65.98216\n",
      "\ttrain_acc: 0.8996, test_acc: \u001b[31m0.8689325842696629\u001b[0m, time: 127.33\n",
      "epoch: 250, loss: 66.50203, loss1: 0.55478, loss2_3: 65.94725\n",
      "\ttrain_acc: 0.9012, test_acc: \u001b[31m0.8670505617977529\u001b[0m, time: 127.43\n",
      "epoch: 1, loss: 174.98935, loss1: 1.70195, loss2_3: 173.28740\n",
      "\ttrain_acc: 0.6355, test_acc: \u001b[31m0.6341292134831461\u001b[0m, time: 127.79\n",
      "best_acc: 0.6341292134831461\n",
      "epoch: 2, loss: 121.06567, loss1: 0.92659, loss2_3: 120.13908\n",
      "\ttrain_acc: 0.7958, test_acc: \u001b[31m0.7937921348314607\u001b[0m, time: 127.21\n",
      "best_acc: 0.7937921348314607\n",
      "epoch: 3, loss: 100.91502, loss1: 0.84115, loss2_3: 100.07387\n",
      "\ttrain_acc: 0.8204, test_acc: \u001b[31m0.820814606741573\u001b[0m, time: 126.58\n",
      "best_acc: 0.820814606741573\n",
      "epoch: 4, loss: 96.59116, loss1: 0.81068, loss2_3: 95.78047\n",
      "\ttrain_acc: 0.8368, test_acc: \u001b[31m0.8366573033707865\u001b[0m, time: 127.24\n",
      "best_acc: 0.8366573033707865\n",
      "epoch: 5, loss: 94.72722, loss1: 0.78108, loss2_3: 93.94614\n",
      "\ttrain_acc: 0.8448, test_acc: \u001b[31m0.8451685393258427\u001b[0m, time: 126.34\n",
      "best_acc: 0.8451685393258427\n",
      "epoch: 6, loss: 92.71268, loss1: 0.76742, loss2_3: 91.94525\n",
      "\ttrain_acc: 0.8492, test_acc: \u001b[31m0.8488483146067416\u001b[0m, time: 127.83\n",
      "best_acc: 0.8488483146067416\n",
      "epoch: 7, loss: 91.72595, loss1: 0.75371, loss2_3: 90.97224\n",
      "\ttrain_acc: 0.8502, test_acc: \u001b[31m0.8514887640449438\u001b[0m, time: 127.38\n",
      "best_acc: 0.8514887640449438\n",
      "epoch: 8, loss: 90.55735, loss1: 0.74209, loss2_3: 89.81526\n",
      "\ttrain_acc: 0.8514, test_acc: \u001b[31m0.8504494382022472\u001b[0m, time: 126.83\n",
      "epoch: 9, loss: 90.04341, loss1: 0.73810, loss2_3: 89.30531\n",
      "\ttrain_acc: 0.8480, test_acc: \u001b[31m0.8455898876404494\u001b[0m, time: 125.42\n",
      "epoch: 10, loss: 89.41613, loss1: 0.73276, loss2_3: 88.68336\n",
      "\ttrain_acc: 0.8491, test_acc: \u001b[31m0.8488202247191011\u001b[0m, time: 125.21\n",
      "epoch: 11, loss: 88.80748, loss1: 0.72304, loss2_3: 88.08443\n",
      "\ttrain_acc: 0.8545, test_acc: \u001b[31m0.8543258426966293\u001b[0m, time: 124.96\n",
      "best_acc: 0.8543258426966293\n",
      "epoch: 12, loss: 87.90589, loss1: 0.72002, loss2_3: 87.18587\n",
      "\ttrain_acc: 0.8572, test_acc: \u001b[31m0.8559269662921348\u001b[0m, time: 124.86\n",
      "best_acc: 0.8559269662921348\n",
      "epoch: 13, loss: 87.48764, loss1: 0.71434, loss2_3: 86.77330\n",
      "\ttrain_acc: 0.8539, test_acc: \u001b[31m0.8537640449438202\u001b[0m, time: 126.22\n",
      "epoch: 14, loss: 87.20497, loss1: 0.71263, loss2_3: 86.49233\n",
      "\ttrain_acc: 0.8576, test_acc: \u001b[31m0.8579213483146068\u001b[0m, time: 125.55\n",
      "best_acc: 0.8579213483146068\n",
      "epoch: 15, loss: 86.48685, loss1: 0.70470, loss2_3: 85.78215\n",
      "\ttrain_acc: 0.8596, test_acc: \u001b[31m0.8592415730337079\u001b[0m, time: 125.66\n",
      "best_acc: 0.8592415730337079\n",
      "epoch: 16, loss: 86.52797, loss1: 0.70793, loss2_3: 85.82004\n",
      "\ttrain_acc: 0.8586, test_acc: \u001b[31m0.8593539325842696\u001b[0m, time: 126.00\n",
      "best_acc: 0.8593539325842696\n",
      "epoch: 17, loss: 85.86301, loss1: 0.69935, loss2_3: 85.16366\n",
      "\ttrain_acc: 0.8603, test_acc: \u001b[31m0.8598314606741573\u001b[0m, time: 125.10\n",
      "best_acc: 0.8598314606741573\n",
      "epoch: 18, loss: 85.52039, loss1: 0.69721, loss2_3: 84.82318\n",
      "\ttrain_acc: 0.8608, test_acc: \u001b[31m0.8622191011235955\u001b[0m, time: 126.91\n",
      "best_acc: 0.8622191011235955\n",
      "epoch: 19, loss: 85.55032, loss1: 0.69806, loss2_3: 84.85226\n",
      "\ttrain_acc: 0.8606, test_acc: \u001b[31m0.8616011235955057\u001b[0m, time: 127.18\n",
      "epoch: 20, loss: 85.05125, loss1: 0.69230, loss2_3: 84.35894\n",
      "\ttrain_acc: 0.8630, test_acc: \u001b[31m0.8614887640449438\u001b[0m, time: 126.32\n",
      "epoch: 21, loss: 84.63844, loss1: 0.68699, loss2_3: 83.95145\n",
      "\ttrain_acc: 0.8598, test_acc: \u001b[31m0.8589887640449438\u001b[0m, time: 126.11\n",
      "epoch: 22, loss: 84.43091, loss1: 0.68817, loss2_3: 83.74274\n",
      "\ttrain_acc: 0.8630, test_acc: \u001b[31m0.8620786516853932\u001b[0m, time: 125.96\n",
      "epoch: 23, loss: 84.38787, loss1: 0.68686, loss2_3: 83.70101\n",
      "\ttrain_acc: 0.8632, test_acc: \u001b[31m0.8630898876404495\u001b[0m, time: 127.44\n",
      "best_acc: 0.8630898876404495\n",
      "epoch: 24, loss: 84.18121, loss1: 0.67998, loss2_3: 83.50123\n",
      "\ttrain_acc: 0.8615, test_acc: \u001b[31m0.8595505617977528\u001b[0m, time: 126.08\n",
      "epoch: 25, loss: 84.10346, loss1: 0.68202, loss2_3: 83.42144\n",
      "\ttrain_acc: 0.8615, test_acc: \u001b[31m0.8584831460674157\u001b[0m, time: 127.91\n",
      "epoch: 26, loss: 83.61813, loss1: 0.67518, loss2_3: 82.94294\n",
      "\ttrain_acc: 0.8643, test_acc: \u001b[31m0.8632022471910112\u001b[0m, time: 125.43\n",
      "best_acc: 0.8632022471910112\n",
      "epoch: 27, loss: 83.48371, loss1: 0.67375, loss2_3: 82.80995\n",
      "\ttrain_acc: 0.8637, test_acc: \u001b[31m0.8639887640449438\u001b[0m, time: 126.62\n",
      "best_acc: 0.8639887640449438\n",
      "epoch: 28, loss: 83.68564, loss1: 0.67383, loss2_3: 83.01182\n",
      "\ttrain_acc: 0.8629, test_acc: \u001b[31m0.8608426966292135\u001b[0m, time: 127.29\n",
      "epoch: 29, loss: 83.21690, loss1: 0.67121, loss2_3: 82.54569\n",
      "\ttrain_acc: 0.8647, test_acc: \u001b[31m0.8639606741573034\u001b[0m, time: 126.39\n",
      "epoch: 30, loss: 82.95108, loss1: 0.66800, loss2_3: 82.28308\n",
      "\ttrain_acc: 0.8645, test_acc: \u001b[31m0.862752808988764\u001b[0m, time: 127.04\n",
      "epoch: 31, loss: 83.02773, loss1: 0.66455, loss2_3: 82.36318\n",
      "\ttrain_acc: 0.8651, test_acc: \u001b[31m0.8641573033707866\u001b[0m, time: 125.54\n",
      "best_acc: 0.8641573033707866\n",
      "epoch: 32, loss: 82.59062, loss1: 0.66486, loss2_3: 81.92576\n",
      "\ttrain_acc: 0.8651, test_acc: \u001b[31m0.8631460674157303\u001b[0m, time: 126.98\n",
      "epoch: 33, loss: 82.55811, loss1: 0.66349, loss2_3: 81.89462\n",
      "\ttrain_acc: 0.8642, test_acc: \u001b[31m0.8648595505617978\u001b[0m, time: 126.09\n",
      "best_acc: 0.8648595505617978\n",
      "epoch: 34, loss: 82.40981, loss1: 0.66219, loss2_3: 81.74762\n",
      "\ttrain_acc: 0.8661, test_acc: \u001b[31m0.8645505617977528\u001b[0m, time: 125.78\n",
      "epoch: 35, loss: 82.47237, loss1: 0.66268, loss2_3: 81.80969\n",
      "\ttrain_acc: 0.8632, test_acc: \u001b[31m0.8624438202247191\u001b[0m, time: 125.65\n",
      "epoch: 36, loss: 82.29502, loss1: 0.65705, loss2_3: 81.63797\n",
      "\ttrain_acc: 0.8658, test_acc: \u001b[31m0.8635112359550562\u001b[0m, time: 125.35\n",
      "epoch: 37, loss: 82.26925, loss1: 0.65813, loss2_3: 81.61112\n",
      "\ttrain_acc: 0.8655, test_acc: \u001b[31m0.8634269662921348\u001b[0m, time: 126.53\n",
      "epoch: 38, loss: 81.88673, loss1: 0.65707, loss2_3: 81.22966\n",
      "\ttrain_acc: 0.8679, test_acc: \u001b[31m0.8656460674157304\u001b[0m, time: 125.45\n",
      "best_acc: 0.8656460674157304\n",
      "epoch: 39, loss: 81.51547, loss1: 0.65309, loss2_3: 80.86238\n",
      "\ttrain_acc: 0.8683, test_acc: \u001b[31m0.8664044943820225\u001b[0m, time: 124.92\n",
      "best_acc: 0.8664044943820225\n",
      "epoch: 40, loss: 81.71812, loss1: 0.65020, loss2_3: 81.06793\n",
      "\ttrain_acc: 0.8641, test_acc: \u001b[31m0.8617415730337079\u001b[0m, time: 125.35\n",
      "epoch: 41, loss: 81.36859, loss1: 0.64965, loss2_3: 80.71894\n",
      "\ttrain_acc: 0.8675, test_acc: \u001b[31m0.8649719101123595\u001b[0m, time: 125.96\n",
      "epoch: 42, loss: 80.96460, loss1: 0.64908, loss2_3: 80.31552\n",
      "\ttrain_acc: 0.8688, test_acc: \u001b[31m0.8664887640449438\u001b[0m, time: 125.76\n",
      "best_acc: 0.8664887640449438\n",
      "epoch: 43, loss: 80.86779, loss1: 0.64521, loss2_3: 80.22258\n",
      "\ttrain_acc: 0.8675, test_acc: \u001b[31m0.8653651685393259\u001b[0m, time: 126.08\n",
      "epoch: 44, loss: 80.81886, loss1: 0.64772, loss2_3: 80.17115\n",
      "\ttrain_acc: 0.8691, test_acc: \u001b[31m0.8666573033707865\u001b[0m, time: 135.81\n",
      "best_acc: 0.8666573033707865\n",
      "epoch: 45, loss: 80.57869, loss1: 0.64203, loss2_3: 79.93665\n",
      "\ttrain_acc: 0.8685, test_acc: \u001b[31m0.8671067415730337\u001b[0m, time: 142.53\n",
      "best_acc: 0.8671067415730337\n",
      "epoch: 46, loss: 80.41778, loss1: 0.64118, loss2_3: 79.77660\n",
      "\ttrain_acc: 0.8686, test_acc: \u001b[31m0.8673314606741573\u001b[0m, time: 141.43\n",
      "best_acc: 0.8673314606741573\n",
      "epoch: 47, loss: 80.36206, loss1: 0.64102, loss2_3: 79.72103\n",
      "\ttrain_acc: 0.8701, test_acc: \u001b[31m0.8682303370786517\u001b[0m, time: 148.41\n",
      "best_acc: 0.8682303370786517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48, loss: 79.90334, loss1: 0.64168, loss2_3: 79.26166\n",
      "\ttrain_acc: 0.8692, test_acc: \u001b[31m0.8678651685393258\u001b[0m, time: 155.31\n",
      "epoch: 49, loss: 79.78164, loss1: 0.63656, loss2_3: 79.14508\n",
      "\ttrain_acc: 0.8693, test_acc: \u001b[31m0.8685393258426967\u001b[0m, time: 151.82\n",
      "best_acc: 0.8685393258426967\n",
      "epoch: 50, loss: 79.84904, loss1: 0.63738, loss2_3: 79.21167\n",
      "\ttrain_acc: 0.8683, test_acc: \u001b[31m0.8661516853932584\u001b[0m, time: 151.43\n",
      "epoch: 51, loss: 79.67137, loss1: 0.63737, loss2_3: 79.03400\n",
      "\ttrain_acc: 0.8708, test_acc: \u001b[31m0.8702808988764045\u001b[0m, time: 291.47\n",
      "best_acc: 0.8702808988764045\n",
      "epoch: 52, loss: 79.44661, loss1: 0.63646, loss2_3: 78.81015\n",
      "\ttrain_acc: 0.8710, test_acc: \u001b[31m0.8685674157303371\u001b[0m, time: 385.88\n",
      "epoch: 53, loss: 79.47188, loss1: 0.63459, loss2_3: 78.83729\n",
      "\ttrain_acc: 0.8658, test_acc: \u001b[31m0.8614044943820225\u001b[0m, time: 243.41\n",
      "epoch: 54, loss: 79.32572, loss1: 0.63441, loss2_3: 78.69131\n",
      "\ttrain_acc: 0.8715, test_acc: \u001b[31m0.8693258426966292\u001b[0m, time: 268.33\n",
      "epoch: 55, loss: 79.08127, loss1: 0.63298, loss2_3: 78.44830\n",
      "\ttrain_acc: 0.8689, test_acc: \u001b[31m0.8664606741573033\u001b[0m, time: 610.82\n",
      "epoch: 56, loss: 78.78203, loss1: 0.63174, loss2_3: 78.15029\n",
      "\ttrain_acc: 0.8725, test_acc: \u001b[31m0.8710393258426966\u001b[0m, time: 661.43\n",
      "best_acc: 0.8710393258426966\n",
      "epoch: 57, loss: 78.50810, loss1: 0.63104, loss2_3: 77.87706\n",
      "\ttrain_acc: 0.8724, test_acc: \u001b[31m0.869747191011236\u001b[0m, time: 301.84\n",
      "epoch: 58, loss: 78.55430, loss1: 0.63145, loss2_3: 77.92284\n",
      "\ttrain_acc: 0.8714, test_acc: \u001b[31m0.8689606741573034\u001b[0m, time: 327.07\n",
      "epoch: 59, loss: 78.52220, loss1: 0.63179, loss2_3: 77.89041\n",
      "\ttrain_acc: 0.8674, test_acc: \u001b[31m0.862808988764045\u001b[0m, time: 635.91\n",
      "epoch: 60, loss: 78.52445, loss1: 0.62700, loss2_3: 77.89745\n",
      "\ttrain_acc: 0.8709, test_acc: \u001b[31m0.8682303370786517\u001b[0m, time: 562.79\n",
      "epoch: 61, loss: 78.32214, loss1: 0.62705, loss2_3: 77.69509\n",
      "\ttrain_acc: 0.8678, test_acc: \u001b[31m0.8646629213483146\u001b[0m, time: 456.95\n",
      "epoch: 62, loss: 78.41909, loss1: 0.62445, loss2_3: 77.79464\n",
      "\ttrain_acc: 0.8726, test_acc: \u001b[31m0.8710955056179776\u001b[0m, time: 630.74\n",
      "best_acc: 0.8710955056179776\n",
      "epoch: 63, loss: 78.29844, loss1: 0.62399, loss2_3: 77.67445\n",
      "\ttrain_acc: 0.8727, test_acc: \u001b[31m0.871376404494382\u001b[0m, time: 601.90\n",
      "best_acc: 0.871376404494382\n",
      "epoch: 64, loss: 78.25127, loss1: 0.62503, loss2_3: 77.62624\n",
      "\ttrain_acc: 0.8733, test_acc: \u001b[31m0.8708426966292134\u001b[0m, time: 580.51\n",
      "epoch: 65, loss: 78.12188, loss1: 0.62505, loss2_3: 77.49683\n",
      "\ttrain_acc: 0.8734, test_acc: \u001b[31m0.8730898876404495\u001b[0m, time: 617.68\n",
      "best_acc: 0.8730898876404495\n",
      "epoch: 66, loss: 78.09939, loss1: 0.62199, loss2_3: 77.47740\n",
      "\ttrain_acc: 0.8733, test_acc: \u001b[31m0.8713483146067416\u001b[0m, time: 475.68\n",
      "epoch: 67, loss: 77.83316, loss1: 0.62343, loss2_3: 77.20973\n",
      "\ttrain_acc: 0.8740, test_acc: \u001b[31m0.8701966292134832\u001b[0m, time: 322.51\n",
      "epoch: 68, loss: 77.94392, loss1: 0.62306, loss2_3: 77.32086\n",
      "\ttrain_acc: 0.8729, test_acc: \u001b[31m0.8691011235955056\u001b[0m, time: 358.83\n",
      "epoch: 69, loss: 77.72910, loss1: 0.62126, loss2_3: 77.10784\n",
      "\ttrain_acc: 0.8732, test_acc: \u001b[31m0.8701966292134832\u001b[0m, time: 253.68\n",
      "epoch: 70, loss: 77.79649, loss1: 0.62165, loss2_3: 77.17484\n",
      "\ttrain_acc: 0.8750, test_acc: \u001b[31m0.8726685393258427\u001b[0m, time: 120.97\n",
      "epoch: 71, loss: 77.64016, loss1: 0.62092, loss2_3: 77.01924\n",
      "\ttrain_acc: 0.8735, test_acc: \u001b[31m0.8717134831460674\u001b[0m, time: 126.49\n",
      "epoch: 72, loss: 77.64087, loss1: 0.62127, loss2_3: 77.01960\n",
      "\ttrain_acc: 0.8735, test_acc: \u001b[31m0.870252808988764\u001b[0m, time: 126.86\n",
      "epoch: 73, loss: 77.61564, loss1: 0.62245, loss2_3: 76.99319\n",
      "\ttrain_acc: 0.8747, test_acc: \u001b[31m0.8723033707865169\u001b[0m, time: 126.89\n",
      "epoch: 74, loss: 77.33024, loss1: 0.61646, loss2_3: 76.71378\n",
      "\ttrain_acc: 0.8740, test_acc: \u001b[31m0.8714044943820225\u001b[0m, time: 128.20\n",
      "epoch: 75, loss: 77.42030, loss1: 0.61649, loss2_3: 76.80381\n",
      "\ttrain_acc: 0.8712, test_acc: \u001b[31m0.8675280898876404\u001b[0m, time: 127.71\n",
      "epoch: 76, loss: 77.27336, loss1: 0.61689, loss2_3: 76.65648\n",
      "\ttrain_acc: 0.8750, test_acc: \u001b[31m0.8717415730337079\u001b[0m, time: 127.07\n",
      "epoch: 77, loss: 77.29967, loss1: 0.61962, loss2_3: 76.68005\n",
      "\ttrain_acc: 0.8753, test_acc: \u001b[31m0.8718820224719102\u001b[0m, time: 126.95\n",
      "epoch: 78, loss: 77.20345, loss1: 0.61869, loss2_3: 76.58476\n",
      "\ttrain_acc: 0.8742, test_acc: \u001b[31m0.870561797752809\u001b[0m, time: 126.60\n",
      "epoch: 79, loss: 77.10165, loss1: 0.61857, loss2_3: 76.48308\n",
      "\ttrain_acc: 0.8751, test_acc: \u001b[31m0.8723314606741573\u001b[0m, time: 127.63\n",
      "epoch: 80, loss: 77.23268, loss1: 0.61861, loss2_3: 76.61408\n",
      "\ttrain_acc: 0.8756, test_acc: \u001b[31m0.8718258426966292\u001b[0m, time: 126.86\n",
      "epoch: 81, loss: 76.98335, loss1: 0.61706, loss2_3: 76.36629\n",
      "\ttrain_acc: 0.8758, test_acc: \u001b[31m0.8726404494382023\u001b[0m, time: 127.20\n",
      "epoch: 82, loss: 76.92843, loss1: 0.61714, loss2_3: 76.31129\n",
      "\ttrain_acc: 0.8753, test_acc: \u001b[31m0.8714044943820225\u001b[0m, time: 128.15\n",
      "epoch: 83, loss: 77.02123, loss1: 0.61761, loss2_3: 76.40362\n",
      "\ttrain_acc: 0.8762, test_acc: \u001b[31m0.8723314606741573\u001b[0m, time: 126.35\n",
      "epoch: 84, loss: 77.01284, loss1: 0.61541, loss2_3: 76.39744\n",
      "\ttrain_acc: 0.8754, test_acc: \u001b[31m0.8723033707865169\u001b[0m, time: 127.38\n",
      "epoch: 85, loss: 76.67838, loss1: 0.61373, loss2_3: 76.06465\n",
      "\ttrain_acc: 0.8753, test_acc: \u001b[31m0.8713202247191011\u001b[0m, time: 126.46\n",
      "epoch: 86, loss: 76.88664, loss1: 0.61507, loss2_3: 76.27156\n",
      "\ttrain_acc: 0.8763, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 127.17\n",
      "epoch: 87, loss: 76.55393, loss1: 0.61240, loss2_3: 75.94153\n",
      "\ttrain_acc: 0.8764, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 126.96\n",
      "epoch: 88, loss: 76.74087, loss1: 0.61728, loss2_3: 76.12359\n",
      "\ttrain_acc: 0.8746, test_acc: \u001b[31m0.8709831460674158\u001b[0m, time: 126.97\n",
      "epoch: 89, loss: 76.67357, loss1: 0.61621, loss2_3: 76.05735\n",
      "\ttrain_acc: 0.8758, test_acc: \u001b[31m0.8704213483146067\u001b[0m, time: 128.29\n",
      "epoch: 90, loss: 76.66174, loss1: 0.61330, loss2_3: 76.04844\n",
      "\ttrain_acc: 0.8723, test_acc: \u001b[31m0.8667134831460674\u001b[0m, time: 126.36\n",
      "epoch: 91, loss: 76.48291, loss1: 0.61184, loss2_3: 75.87107\n",
      "\ttrain_acc: 0.8757, test_acc: \u001b[31m0.8706460674157304\u001b[0m, time: 126.87\n",
      "epoch: 92, loss: 76.49864, loss1: 0.60926, loss2_3: 75.88938\n",
      "\ttrain_acc: 0.8769, test_acc: \u001b[31m0.8728932584269663\u001b[0m, time: 126.54\n",
      "epoch: 93, loss: 76.47894, loss1: 0.61280, loss2_3: 75.86613\n",
      "\ttrain_acc: 0.8772, test_acc: \u001b[31m0.8728089887640449\u001b[0m, time: 124.08\n",
      "epoch: 94, loss: 76.37547, loss1: 0.60968, loss2_3: 75.76579\n",
      "\ttrain_acc: 0.8772, test_acc: \u001b[31m0.8735112359550562\u001b[0m, time: 126.58\n",
      "best_acc: 0.8735112359550562\n",
      "epoch: 95, loss: 76.49348, loss1: 0.61323, loss2_3: 75.88025\n",
      "\ttrain_acc: 0.8768, test_acc: \u001b[31m0.8726123595505618\u001b[0m, time: 103.59\n",
      "epoch: 96, loss: 76.45427, loss1: 0.61191, loss2_3: 75.84236\n",
      "\ttrain_acc: 0.8750, test_acc: \u001b[31m0.8681460674157303\u001b[0m, time: 103.79\n",
      "epoch: 97, loss: 76.20846, loss1: 0.60888, loss2_3: 75.59959\n",
      "\ttrain_acc: 0.8744, test_acc: \u001b[31m0.8695224719101123\u001b[0m, time: 104.78\n",
      "epoch: 98, loss: 76.23031, loss1: 0.60971, loss2_3: 75.62060\n",
      "\ttrain_acc: 0.8777, test_acc: \u001b[31m0.8731179775280898\u001b[0m, time: 104.28\n",
      "epoch: 99, loss: 76.22426, loss1: 0.61002, loss2_3: 75.61424\n",
      "\ttrain_acc: 0.8750, test_acc: \u001b[31m0.870561797752809\u001b[0m, time: 103.42\n",
      "epoch: 100, loss: 76.18989, loss1: 0.60944, loss2_3: 75.58045\n",
      "\ttrain_acc: 0.8785, test_acc: \u001b[31m0.8728089887640449\u001b[0m, time: 103.74\n",
      "epoch: 101, loss: 76.07006, loss1: 0.61074, loss2_3: 75.45932\n",
      "\ttrain_acc: 0.8760, test_acc: \u001b[31m0.8690449438202247\u001b[0m, time: 103.83\n",
      "epoch: 102, loss: 75.98647, loss1: 0.61159, loss2_3: 75.37489\n",
      "\ttrain_acc: 0.8729, test_acc: \u001b[31m0.866376404494382\u001b[0m, time: 104.40\n",
      "epoch: 103, loss: 75.89440, loss1: 0.60684, loss2_3: 75.28756\n",
      "\ttrain_acc: 0.8762, test_acc: \u001b[31m0.8699719101123595\u001b[0m, time: 104.03\n",
      "epoch: 104, loss: 76.04199, loss1: 0.61010, loss2_3: 75.43189\n",
      "\ttrain_acc: 0.8760, test_acc: \u001b[31m0.8706460674157304\u001b[0m, time: 103.62\n",
      "epoch: 105, loss: 76.00553, loss1: 0.61146, loss2_3: 75.39407\n",
      "\ttrain_acc: 0.8732, test_acc: \u001b[31m0.8660112359550561\u001b[0m, time: 103.52\n",
      "epoch: 106, loss: 75.92382, loss1: 0.60831, loss2_3: 75.31551\n",
      "\ttrain_acc: 0.8781, test_acc: \u001b[31m0.8717977528089887\u001b[0m, time: 103.55\n",
      "epoch: 107, loss: 75.87577, loss1: 0.60580, loss2_3: 75.26997\n",
      "\ttrain_acc: 0.8780, test_acc: \u001b[31m0.8710393258426966\u001b[0m, time: 103.96\n",
      "epoch: 108, loss: 75.72840, loss1: 0.60529, loss2_3: 75.12311\n",
      "\ttrain_acc: 0.8788, test_acc: \u001b[31m0.8735112359550562\u001b[0m, time: 104.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 109, loss: 75.93355, loss1: 0.60555, loss2_3: 75.32800\n",
      "\ttrain_acc: 0.8783, test_acc: \u001b[31m0.8731741573033708\u001b[0m, time: 103.30\n",
      "epoch: 110, loss: 75.68937, loss1: 0.60364, loss2_3: 75.08574\n",
      "\ttrain_acc: 0.8792, test_acc: \u001b[31m0.8727528089887641\u001b[0m, time: 103.86\n",
      "epoch: 111, loss: 75.69480, loss1: 0.60501, loss2_3: 75.08980\n",
      "\ttrain_acc: 0.8788, test_acc: \u001b[31m0.8731460674157303\u001b[0m, time: 104.00\n",
      "epoch: 112, loss: 75.58095, loss1: 0.60257, loss2_3: 74.97837\n",
      "\ttrain_acc: 0.8775, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 104.02\n",
      "epoch: 113, loss: 75.61919, loss1: 0.60623, loss2_3: 75.01296\n",
      "\ttrain_acc: 0.8781, test_acc: \u001b[31m0.8729494382022472\u001b[0m, time: 103.71\n",
      "epoch: 114, loss: 75.44820, loss1: 0.60576, loss2_3: 74.84243\n",
      "\ttrain_acc: 0.8779, test_acc: \u001b[31m0.8720786516853932\u001b[0m, time: 103.76\n",
      "epoch: 115, loss: 75.59705, loss1: 0.61042, loss2_3: 74.98663\n",
      "\ttrain_acc: 0.8774, test_acc: \u001b[31m0.8706460674157304\u001b[0m, time: 104.15\n",
      "epoch: 116, loss: 75.45195, loss1: 0.60444, loss2_3: 74.84750\n",
      "\ttrain_acc: 0.8738, test_acc: \u001b[31m0.8680056179775281\u001b[0m, time: 103.72\n",
      "epoch: 117, loss: 75.41873, loss1: 0.60243, loss2_3: 74.81631\n",
      "\ttrain_acc: 0.8792, test_acc: \u001b[31m0.873314606741573\u001b[0m, time: 103.98\n",
      "epoch: 118, loss: 75.43745, loss1: 0.60653, loss2_3: 74.83092\n",
      "\ttrain_acc: 0.8801, test_acc: \u001b[31m0.873061797752809\u001b[0m, time: 103.33\n",
      "epoch: 119, loss: 75.47797, loss1: 0.60317, loss2_3: 74.87481\n",
      "\ttrain_acc: 0.8785, test_acc: \u001b[31m0.8714044943820225\u001b[0m, time: 103.82\n",
      "epoch: 120, loss: 75.39864, loss1: 0.60349, loss2_3: 74.79516\n",
      "\ttrain_acc: 0.8779, test_acc: \u001b[31m0.8712640449438203\u001b[0m, time: 103.70\n",
      "epoch: 121, loss: 75.57865, loss1: 0.60576, loss2_3: 74.97290\n",
      "\ttrain_acc: 0.8790, test_acc: \u001b[31m0.8723033707865169\u001b[0m, time: 103.77\n",
      "epoch: 122, loss: 75.27628, loss1: 0.60550, loss2_3: 74.67078\n",
      "\ttrain_acc: 0.8788, test_acc: \u001b[31m0.8712078651685393\u001b[0m, time: 104.25\n",
      "epoch: 123, loss: 75.25301, loss1: 0.60292, loss2_3: 74.65010\n",
      "\ttrain_acc: 0.8805, test_acc: \u001b[31m0.8729775280898876\u001b[0m, time: 103.29\n",
      "epoch: 124, loss: 75.10149, loss1: 0.60270, loss2_3: 74.49879\n",
      "\ttrain_acc: 0.8810, test_acc: \u001b[31m0.8733426966292135\u001b[0m, time: 104.08\n",
      "epoch: 125, loss: 75.05974, loss1: 0.60165, loss2_3: 74.45809\n",
      "\ttrain_acc: 0.8807, test_acc: \u001b[31m0.8737921348314607\u001b[0m, time: 103.42\n",
      "best_acc: 0.8737921348314607\n",
      "epoch: 126, loss: 75.38267, loss1: 0.60530, loss2_3: 74.77737\n",
      "\ttrain_acc: 0.8796, test_acc: \u001b[31m0.8732584269662922\u001b[0m, time: 104.31\n",
      "epoch: 127, loss: 75.21109, loss1: 0.60415, loss2_3: 74.60695\n",
      "\ttrain_acc: 0.8788, test_acc: \u001b[31m0.8720786516853932\u001b[0m, time: 103.74\n",
      "epoch: 128, loss: 75.05541, loss1: 0.60507, loss2_3: 74.45034\n",
      "\ttrain_acc: 0.8795, test_acc: \u001b[31m0.8741853932584269\u001b[0m, time: 103.73\n",
      "best_acc: 0.8741853932584269\n",
      "epoch: 129, loss: 75.09438, loss1: 0.60170, loss2_3: 74.49268\n",
      "\ttrain_acc: 0.8801, test_acc: \u001b[31m0.8735955056179775\u001b[0m, time: 104.17\n",
      "epoch: 130, loss: 74.96614, loss1: 0.59947, loss2_3: 74.36666\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8741292134831461\u001b[0m, time: 107.00\n",
      "epoch: 131, loss: 75.07389, loss1: 0.59930, loss2_3: 74.47459\n",
      "\ttrain_acc: 0.8812, test_acc: \u001b[31m0.8740449438202247\u001b[0m, time: 106.60\n",
      "epoch: 132, loss: 75.12153, loss1: 0.60516, loss2_3: 74.51637\n",
      "\ttrain_acc: 0.8799, test_acc: \u001b[31m0.871376404494382\u001b[0m, time: 102.66\n",
      "epoch: 133, loss: 74.97466, loss1: 0.60251, loss2_3: 74.37214\n",
      "\ttrain_acc: 0.8792, test_acc: \u001b[31m0.8715730337078652\u001b[0m, time: 104.10\n",
      "epoch: 134, loss: 74.89919, loss1: 0.60055, loss2_3: 74.29864\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8744662921348315\u001b[0m, time: 104.01\n",
      "best_acc: 0.8744662921348315\n",
      "epoch: 135, loss: 74.79040, loss1: 0.60001, loss2_3: 74.19039\n",
      "\ttrain_acc: 0.8775, test_acc: \u001b[31m0.8700280898876405\u001b[0m, time: 103.65\n",
      "epoch: 136, loss: 74.86006, loss1: 0.60119, loss2_3: 74.25887\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8732584269662922\u001b[0m, time: 103.89\n",
      "epoch: 137, loss: 74.89900, loss1: 0.60388, loss2_3: 74.29511\n",
      "\ttrain_acc: 0.8801, test_acc: \u001b[31m0.8716011235955056\u001b[0m, time: 103.17\n",
      "epoch: 138, loss: 74.60408, loss1: 0.59901, loss2_3: 74.00507\n",
      "\ttrain_acc: 0.8805, test_acc: \u001b[31m0.8725280898876404\u001b[0m, time: 105.17\n",
      "epoch: 139, loss: 74.61614, loss1: 0.60169, loss2_3: 74.01446\n",
      "\ttrain_acc: 0.8806, test_acc: \u001b[31m0.8731741573033708\u001b[0m, time: 103.40\n",
      "epoch: 140, loss: 74.66976, loss1: 0.60173, loss2_3: 74.06803\n",
      "\ttrain_acc: 0.8816, test_acc: \u001b[31m0.8731741573033708\u001b[0m, time: 103.93\n",
      "epoch: 141, loss: 74.69774, loss1: 0.60041, loss2_3: 74.09733\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8744101123595506\u001b[0m, time: 103.71\n",
      "epoch: 142, loss: 74.50994, loss1: 0.59784, loss2_3: 73.91210\n",
      "\ttrain_acc: 0.8811, test_acc: \u001b[31m0.8741011235955056\u001b[0m, time: 103.57\n",
      "epoch: 143, loss: 74.76960, loss1: 0.59748, loss2_3: 74.17212\n",
      "\ttrain_acc: 0.8824, test_acc: \u001b[31m0.8744943820224719\u001b[0m, time: 104.01\n",
      "best_acc: 0.8744943820224719\n",
      "epoch: 144, loss: 74.52304, loss1: 0.59831, loss2_3: 73.92472\n",
      "\ttrain_acc: 0.8802, test_acc: \u001b[31m0.8705898876404494\u001b[0m, time: 103.52\n",
      "epoch: 145, loss: 74.61877, loss1: 0.59895, loss2_3: 74.01982\n",
      "\ttrain_acc: 0.8814, test_acc: \u001b[31m0.8732303370786517\u001b[0m, time: 103.74\n",
      "epoch: 146, loss: 74.44487, loss1: 0.60081, loss2_3: 73.84406\n",
      "\ttrain_acc: 0.8819, test_acc: \u001b[31m0.873876404494382\u001b[0m, time: 103.31\n",
      "epoch: 147, loss: 74.62780, loss1: 0.59821, loss2_3: 74.02959\n",
      "\ttrain_acc: 0.8810, test_acc: \u001b[31m0.8707584269662921\u001b[0m, time: 103.67\n",
      "epoch: 148, loss: 74.41864, loss1: 0.59616, loss2_3: 73.82248\n",
      "\ttrain_acc: 0.8826, test_acc: \u001b[31m0.8739325842696629\u001b[0m, time: 103.78\n",
      "epoch: 149, loss: 74.27056, loss1: 0.59901, loss2_3: 73.67155\n",
      "\ttrain_acc: 0.8807, test_acc: \u001b[31m0.8711516853932584\u001b[0m, time: 98.76\n",
      "epoch: 150, loss: 74.17210, loss1: 0.59543, loss2_3: 73.57667\n",
      "\ttrain_acc: 0.8812, test_acc: \u001b[31m0.8721629213483146\u001b[0m, time: 73.55\n",
      "epoch: 151, loss: 74.40370, loss1: 0.59747, loss2_3: 73.80623\n",
      "\ttrain_acc: 0.8819, test_acc: \u001b[31m0.8733426966292135\u001b[0m, time: 74.02\n",
      "epoch: 152, loss: 74.35012, loss1: 0.59524, loss2_3: 73.75488\n",
      "\ttrain_acc: 0.8830, test_acc: \u001b[31m0.873623595505618\u001b[0m, time: 74.80\n",
      "epoch: 153, loss: 74.32042, loss1: 0.59618, loss2_3: 73.72425\n",
      "\ttrain_acc: 0.8807, test_acc: \u001b[31m0.8731741573033708\u001b[0m, time: 74.87\n",
      "epoch: 154, loss: 74.38945, loss1: 0.59549, loss2_3: 73.79396\n",
      "\ttrain_acc: 0.8830, test_acc: \u001b[31m0.8733426966292135\u001b[0m, time: 74.68\n",
      "epoch: 155, loss: 74.15705, loss1: 0.59554, loss2_3: 73.56151\n",
      "\ttrain_acc: 0.8807, test_acc: \u001b[31m0.8725\u001b[0m, time: 72.92\n",
      "epoch: 156, loss: 74.20890, loss1: 0.59547, loss2_3: 73.61343\n",
      "\ttrain_acc: 0.8834, test_acc: \u001b[31m0.8737078651685394\u001b[0m, time: 74.45\n",
      "epoch: 157, loss: 73.91720, loss1: 0.59533, loss2_3: 73.32186\n",
      "\ttrain_acc: 0.8833, test_acc: \u001b[31m0.8740168539325842\u001b[0m, time: 74.56\n",
      "epoch: 158, loss: 73.98384, loss1: 0.60064, loss2_3: 73.38321\n",
      "\ttrain_acc: 0.8816, test_acc: \u001b[31m0.8710674157303371\u001b[0m, time: 74.74\n",
      "epoch: 159, loss: 74.11384, loss1: 0.59622, loss2_3: 73.51762\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8724719101123596\u001b[0m, time: 74.12\n",
      "epoch: 160, loss: 74.14758, loss1: 0.60095, loss2_3: 73.54663\n",
      "\ttrain_acc: 0.8821, test_acc: \u001b[31m0.8714887640449438\u001b[0m, time: 73.21\n",
      "epoch: 161, loss: 74.02215, loss1: 0.59979, loss2_3: 73.42236\n",
      "\ttrain_acc: 0.8824, test_acc: \u001b[31m0.8733988764044944\u001b[0m, time: 74.68\n",
      "epoch: 162, loss: 74.06743, loss1: 0.59865, loss2_3: 73.46878\n",
      "\ttrain_acc: 0.8796, test_acc: \u001b[31m0.8711516853932584\u001b[0m, time: 74.73\n",
      "epoch: 163, loss: 73.97288, loss1: 0.59606, loss2_3: 73.37683\n",
      "\ttrain_acc: 0.8833, test_acc: \u001b[31m0.8734269662921348\u001b[0m, time: 74.67\n",
      "epoch: 164, loss: 73.87992, loss1: 0.59488, loss2_3: 73.28504\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8703370786516854\u001b[0m, time: 73.52\n",
      "epoch: 165, loss: 73.96142, loss1: 0.59392, loss2_3: 73.36751\n",
      "\ttrain_acc: 0.8841, test_acc: \u001b[31m0.8726966292134831\u001b[0m, time: 73.85\n",
      "epoch: 166, loss: 73.95362, loss1: 0.59626, loss2_3: 73.35737\n",
      "\ttrain_acc: 0.8841, test_acc: \u001b[31m0.873314606741573\u001b[0m, time: 74.77\n",
      "epoch: 167, loss: 73.81854, loss1: 0.59323, loss2_3: 73.22532\n",
      "\ttrain_acc: 0.8814, test_acc: \u001b[31m0.8705337078651686\u001b[0m, time: 74.87\n",
      "epoch: 168, loss: 73.72955, loss1: 0.59220, loss2_3: 73.13735\n",
      "\ttrain_acc: 0.8833, test_acc: \u001b[31m0.8732865168539325\u001b[0m, time: 74.43\n",
      "epoch: 169, loss: 73.64259, loss1: 0.59313, loss2_3: 73.04946\n",
      "\ttrain_acc: 0.8797, test_acc: \u001b[31m0.8687921348314607\u001b[0m, time: 73.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 170, loss: 73.65372, loss1: 0.59040, loss2_3: 73.06332\n",
      "\ttrain_acc: 0.8823, test_acc: \u001b[31m0.8704494382022472\u001b[0m, time: 74.26\n",
      "epoch: 171, loss: 73.74445, loss1: 0.59128, loss2_3: 73.15317\n",
      "\ttrain_acc: 0.8833, test_acc: \u001b[31m0.8749157303370787\u001b[0m, time: 74.88\n",
      "best_acc: 0.8749157303370787\n",
      "epoch: 172, loss: 73.76639, loss1: 0.59035, loss2_3: 73.17604\n",
      "\ttrain_acc: 0.8811, test_acc: \u001b[31m0.8694662921348315\u001b[0m, time: 74.86\n",
      "epoch: 173, loss: 73.51931, loss1: 0.59095, loss2_3: 72.92836\n",
      "\ttrain_acc: 0.8832, test_acc: \u001b[31m0.8727808988764045\u001b[0m, time: 74.06\n",
      "epoch: 174, loss: 73.62758, loss1: 0.59375, loss2_3: 73.03383\n",
      "\ttrain_acc: 0.8842, test_acc: \u001b[31m0.8731460674157303\u001b[0m, time: 73.32\n",
      "epoch: 175, loss: 73.43793, loss1: 0.59120, loss2_3: 72.84673\n",
      "\ttrain_acc: 0.8845, test_acc: \u001b[31m0.8734550561797753\u001b[0m, time: 74.76\n",
      "epoch: 176, loss: 73.41499, loss1: 0.59348, loss2_3: 72.82151\n",
      "\ttrain_acc: 0.8843, test_acc: \u001b[31m0.8741292134831461\u001b[0m, time: 74.88\n",
      "epoch: 177, loss: 73.34189, loss1: 0.58928, loss2_3: 72.75260\n",
      "\ttrain_acc: 0.8836, test_acc: \u001b[31m0.8732584269662922\u001b[0m, time: 77.65\n",
      "epoch: 178, loss: 73.46862, loss1: 0.59512, loss2_3: 72.87350\n",
      "\ttrain_acc: 0.8857, test_acc: \u001b[31m0.873623595505618\u001b[0m, time: 78.45\n",
      "epoch: 179, loss: 73.51298, loss1: 0.59034, loss2_3: 72.92264\n",
      "\ttrain_acc: 0.8855, test_acc: \u001b[31m0.8744101123595506\u001b[0m, time: 75.40\n",
      "epoch: 180, loss: 73.21776, loss1: 0.59344, loss2_3: 72.62432\n",
      "\ttrain_acc: 0.8845, test_acc: \u001b[31m0.8725\u001b[0m, time: 74.99\n",
      "epoch: 181, loss: 73.38400, loss1: 0.59201, loss2_3: 72.79200\n",
      "\ttrain_acc: 0.8841, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 74.43\n",
      "epoch: 182, loss: 73.34027, loss1: 0.58986, loss2_3: 72.75041\n",
      "\ttrain_acc: 0.8853, test_acc: \u001b[31m0.8741011235955056\u001b[0m, time: 73.08\n",
      "epoch: 183, loss: 73.46162, loss1: 0.58875, loss2_3: 72.87286\n",
      "\ttrain_acc: 0.8854, test_acc: \u001b[31m0.8723033707865169\u001b[0m, time: 74.84\n",
      "epoch: 184, loss: 73.12772, loss1: 0.58978, loss2_3: 72.53794\n",
      "\ttrain_acc: 0.8826, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 74.74\n",
      "epoch: 185, loss: 73.28055, loss1: 0.59604, loss2_3: 72.68451\n",
      "\ttrain_acc: 0.8838, test_acc: \u001b[31m0.8724157303370786\u001b[0m, time: 74.70\n",
      "epoch: 186, loss: 73.37667, loss1: 0.59125, loss2_3: 72.78542\n",
      "\ttrain_acc: 0.8801, test_acc: \u001b[31m0.8678932584269663\u001b[0m, time: 73.71\n",
      "epoch: 187, loss: 73.12265, loss1: 0.59228, loss2_3: 72.53037\n",
      "\ttrain_acc: 0.8860, test_acc: \u001b[31m0.8726404494382023\u001b[0m, time: 73.79\n",
      "epoch: 188, loss: 73.39463, loss1: 0.59070, loss2_3: 72.80393\n",
      "\ttrain_acc: 0.8861, test_acc: \u001b[31m0.8746629213483146\u001b[0m, time: 74.78\n",
      "epoch: 189, loss: 73.13083, loss1: 0.59186, loss2_3: 72.53897\n",
      "\ttrain_acc: 0.8832, test_acc: \u001b[31m0.8707584269662921\u001b[0m, time: 74.95\n",
      "epoch: 190, loss: 73.25552, loss1: 0.58732, loss2_3: 72.66820\n",
      "\ttrain_acc: 0.8851, test_acc: \u001b[31m0.8730337078651685\u001b[0m, time: 78.51\n",
      "epoch: 191, loss: 73.01029, loss1: 0.59024, loss2_3: 72.42006\n",
      "\ttrain_acc: 0.8855, test_acc: \u001b[31m0.8722191011235955\u001b[0m, time: 73.57\n",
      "epoch: 192, loss: 73.07182, loss1: 0.58635, loss2_3: 72.48547\n",
      "\ttrain_acc: 0.8850, test_acc: \u001b[31m0.8723033707865169\u001b[0m, time: 74.80\n",
      "epoch: 193, loss: 72.91056, loss1: 0.59000, loss2_3: 72.32056\n",
      "\ttrain_acc: 0.8856, test_acc: \u001b[31m0.8737359550561797\u001b[0m, time: 74.77\n",
      "epoch: 194, loss: 72.98535, loss1: 0.59063, loss2_3: 72.39472\n",
      "\ttrain_acc: 0.8843, test_acc: \u001b[31m0.8715168539325843\u001b[0m, time: 74.84\n",
      "epoch: 195, loss: 72.94915, loss1: 0.58874, loss2_3: 72.36041\n",
      "\ttrain_acc: 0.8829, test_acc: \u001b[31m0.8712078651685393\u001b[0m, time: 73.31\n",
      "epoch: 196, loss: 72.96764, loss1: 0.58958, loss2_3: 72.37806\n",
      "\ttrain_acc: 0.8848, test_acc: \u001b[31m0.8728932584269663\u001b[0m, time: 74.26\n",
      "epoch: 197, loss: 72.73551, loss1: 0.58516, loss2_3: 72.15035\n",
      "\ttrain_acc: 0.8849, test_acc: \u001b[31m0.8730056179775281\u001b[0m, time: 74.86\n",
      "epoch: 198, loss: 72.83783, loss1: 0.58710, loss2_3: 72.25073\n",
      "\ttrain_acc: 0.8865, test_acc: \u001b[31m0.8726966292134831\u001b[0m, time: 74.88\n",
      "epoch: 199, loss: 72.80124, loss1: 0.58537, loss2_3: 72.21587\n",
      "\ttrain_acc: 0.8859, test_acc: \u001b[31m0.8734269662921348\u001b[0m, time: 74.33\n",
      "epoch: 200, loss: 72.77868, loss1: 0.58784, loss2_3: 72.19083\n",
      "\ttrain_acc: 0.8862, test_acc: \u001b[31m0.8730337078651685\u001b[0m, time: 73.22\n",
      "epoch: 201, loss: 72.71769, loss1: 0.58466, loss2_3: 72.13303\n",
      "\ttrain_acc: 0.8862, test_acc: \u001b[31m0.8726123595505618\u001b[0m, time: 74.83\n",
      "epoch: 202, loss: 72.79347, loss1: 0.58709, loss2_3: 72.20638\n",
      "\ttrain_acc: 0.8865, test_acc: \u001b[31m0.8735112359550562\u001b[0m, time: 74.84\n",
      "epoch: 203, loss: 72.72396, loss1: 0.58642, loss2_3: 72.13754\n",
      "\ttrain_acc: 0.8845, test_acc: \u001b[31m0.8698595505617978\u001b[0m, time: 74.84\n",
      "epoch: 204, loss: 72.70891, loss1: 0.58746, loss2_3: 72.12145\n",
      "\ttrain_acc: 0.8858, test_acc: \u001b[31m0.8728651685393258\u001b[0m, time: 73.73\n",
      "epoch: 205, loss: 72.60389, loss1: 0.58722, loss2_3: 72.01667\n",
      "\ttrain_acc: 0.8861, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 73.70\n",
      "epoch: 206, loss: 72.61357, loss1: 0.58573, loss2_3: 72.02784\n",
      "\ttrain_acc: 0.8845, test_acc: \u001b[31m0.8679775280898876\u001b[0m, time: 74.81\n",
      "epoch: 207, loss: 72.55469, loss1: 0.58534, loss2_3: 71.96934\n",
      "\ttrain_acc: 0.8868, test_acc: \u001b[31m0.8729775280898876\u001b[0m, time: 74.83\n",
      "epoch: 208, loss: 72.62419, loss1: 0.58799, loss2_3: 72.03619\n",
      "\ttrain_acc: 0.8873, test_acc: \u001b[31m0.8734831460674157\u001b[0m, time: 74.72\n",
      "epoch: 209, loss: 72.55344, loss1: 0.58548, loss2_3: 71.96796\n",
      "\ttrain_acc: 0.8862, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 73.24\n",
      "epoch: 210, loss: 72.52122, loss1: 0.58509, loss2_3: 71.93613\n",
      "\ttrain_acc: 0.8872, test_acc: \u001b[31m0.8732865168539325\u001b[0m, time: 74.31\n",
      "epoch: 211, loss: 72.45675, loss1: 0.58724, loss2_3: 71.86951\n",
      "\ttrain_acc: 0.8871, test_acc: \u001b[31m0.8733426966292135\u001b[0m, time: 74.67\n",
      "epoch: 212, loss: 72.60787, loss1: 0.58691, loss2_3: 72.02096\n",
      "\ttrain_acc: 0.8874, test_acc: \u001b[31m0.8724438202247191\u001b[0m, time: 74.88\n",
      "epoch: 213, loss: 72.28453, loss1: 0.58178, loss2_3: 71.70275\n",
      "\ttrain_acc: 0.8834, test_acc: \u001b[31m0.8694943820224719\u001b[0m, time: 74.25\n",
      "epoch: 214, loss: 72.52875, loss1: 0.58794, loss2_3: 71.94081\n",
      "\ttrain_acc: 0.8879, test_acc: \u001b[31m0.873567415730337\u001b[0m, time: 73.28\n",
      "epoch: 215, loss: 72.44954, loss1: 0.58236, loss2_3: 71.86718\n",
      "\ttrain_acc: 0.8886, test_acc: \u001b[31m0.8739887640449439\u001b[0m, time: 74.75\n",
      "epoch: 216, loss: 72.30759, loss1: 0.58357, loss2_3: 71.72403\n",
      "\ttrain_acc: 0.8872, test_acc: \u001b[31m0.8714044943820225\u001b[0m, time: 74.76\n",
      "epoch: 217, loss: 72.26850, loss1: 0.58591, loss2_3: 71.68259\n",
      "\ttrain_acc: 0.8878, test_acc: \u001b[31m0.8737640449438202\u001b[0m, time: 74.88\n",
      "epoch: 218, loss: 72.42666, loss1: 0.58340, loss2_3: 71.84326\n",
      "\ttrain_acc: 0.8878, test_acc: \u001b[31m0.8727808988764045\u001b[0m, time: 73.62\n",
      "epoch: 219, loss: 72.43098, loss1: 0.58157, loss2_3: 71.84941\n",
      "\ttrain_acc: 0.8878, test_acc: \u001b[31m0.873061797752809\u001b[0m, time: 73.82\n",
      "epoch: 220, loss: 72.10802, loss1: 0.58423, loss2_3: 71.52379\n",
      "\ttrain_acc: 0.8886, test_acc: \u001b[31m0.874438202247191\u001b[0m, time: 75.01\n",
      "epoch: 221, loss: 72.21964, loss1: 0.58403, loss2_3: 71.63562\n",
      "\ttrain_acc: 0.8890, test_acc: \u001b[31m0.8739887640449439\u001b[0m, time: 75.07\n",
      "epoch: 222, loss: 72.03642, loss1: 0.58441, loss2_3: 71.45201\n",
      "\ttrain_acc: 0.8887, test_acc: \u001b[31m0.8727808988764045\u001b[0m, time: 75.18\n",
      "epoch: 223, loss: 72.11361, loss1: 0.58379, loss2_3: 71.52982\n",
      "\ttrain_acc: 0.8886, test_acc: \u001b[31m0.8727808988764045\u001b[0m, time: 73.36\n",
      "epoch: 224, loss: 71.97385, loss1: 0.58252, loss2_3: 71.39133\n",
      "\ttrain_acc: 0.8882, test_acc: \u001b[31m0.871685393258427\u001b[0m, time: 74.37\n",
      "epoch: 225, loss: 72.00577, loss1: 0.58128, loss2_3: 71.42449\n",
      "\ttrain_acc: 0.8887, test_acc: \u001b[31m0.8739044943820224\u001b[0m, time: 75.21\n",
      "epoch: 226, loss: 71.82422, loss1: 0.58260, loss2_3: 71.24162\n",
      "\ttrain_acc: 0.8880, test_acc: \u001b[31m0.8719101123595505\u001b[0m, time: 75.19\n",
      "epoch: 227, loss: 71.87180, loss1: 0.57966, loss2_3: 71.29214\n",
      "\ttrain_acc: 0.8875, test_acc: \u001b[31m0.8727808988764045\u001b[0m, time: 74.64\n",
      "epoch: 228, loss: 71.96929, loss1: 0.57940, loss2_3: 71.38989\n",
      "\ttrain_acc: 0.8890, test_acc: \u001b[31m0.873623595505618\u001b[0m, time: 73.31\n",
      "epoch: 229, loss: 71.76612, loss1: 0.58209, loss2_3: 71.18402\n",
      "\ttrain_acc: 0.8882, test_acc: \u001b[31m0.8717415730337079\u001b[0m, time: 75.03\n",
      "epoch: 230, loss: 71.71452, loss1: 0.58238, loss2_3: 71.13215\n",
      "\ttrain_acc: 0.8882, test_acc: \u001b[31m0.871938202247191\u001b[0m, time: 75.01\n",
      "epoch: 231, loss: 71.85135, loss1: 0.58326, loss2_3: 71.26809\n",
      "\ttrain_acc: 0.8885, test_acc: \u001b[31m0.8731741573033708\u001b[0m, time: 75.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 232, loss: 71.66729, loss1: 0.57887, loss2_3: 71.08842\n",
      "\ttrain_acc: 0.8851, test_acc: \u001b[31m0.87\u001b[0m, time: 74.04\n",
      "epoch: 233, loss: 71.71643, loss1: 0.57939, loss2_3: 71.13704\n",
      "\ttrain_acc: 0.8857, test_acc: \u001b[31m0.8693258426966292\u001b[0m, time: 73.79\n",
      "epoch: 234, loss: 71.84243, loss1: 0.58122, loss2_3: 71.26121\n",
      "\ttrain_acc: 0.8876, test_acc: \u001b[31m0.8707584269662921\u001b[0m, time: 75.20\n",
      "epoch: 235, loss: 71.68099, loss1: 0.58089, loss2_3: 71.10010\n",
      "\ttrain_acc: 0.8882, test_acc: \u001b[31m0.8733426966292135\u001b[0m, time: 74.96\n",
      "epoch: 236, loss: 71.65054, loss1: 0.58244, loss2_3: 71.06809\n",
      "\ttrain_acc: 0.8899, test_acc: \u001b[31m0.8719662921348315\u001b[0m, time: 75.07\n",
      "epoch: 237, loss: 71.56415, loss1: 0.58103, loss2_3: 70.98313\n",
      "\ttrain_acc: 0.8890, test_acc: \u001b[31m0.8726966292134831\u001b[0m, time: 73.67\n",
      "epoch: 238, loss: 71.58699, loss1: 0.58113, loss2_3: 71.00586\n",
      "\ttrain_acc: 0.8886, test_acc: \u001b[31m0.8709550561797753\u001b[0m, time: 74.34\n",
      "epoch: 239, loss: 71.46080, loss1: 0.58226, loss2_3: 70.87854\n",
      "\ttrain_acc: 0.8899, test_acc: \u001b[31m0.8711516853932584\u001b[0m, time: 75.14\n",
      "epoch: 240, loss: 71.45743, loss1: 0.57917, loss2_3: 70.87826\n",
      "\ttrain_acc: 0.8889, test_acc: \u001b[31m0.871123595505618\u001b[0m, time: 75.03\n",
      "epoch: 241, loss: 71.51746, loss1: 0.57879, loss2_3: 70.93867\n",
      "\ttrain_acc: 0.8892, test_acc: \u001b[31m0.8711797752808988\u001b[0m, time: 74.71\n",
      "epoch: 242, loss: 71.45520, loss1: 0.58044, loss2_3: 70.87476\n",
      "\ttrain_acc: 0.8872, test_acc: \u001b[31m0.8692415730337079\u001b[0m, time: 73.32\n",
      "epoch: 243, loss: 71.35264, loss1: 0.57798, loss2_3: 70.77466\n",
      "\ttrain_acc: 0.8888, test_acc: \u001b[31m0.8722752808988764\u001b[0m, time: 74.87\n",
      "epoch: 244, loss: 71.30777, loss1: 0.57929, loss2_3: 70.72848\n",
      "\ttrain_acc: 0.8902, test_acc: \u001b[31m0.8703651685393259\u001b[0m, time: 75.13\n",
      "epoch: 245, loss: 71.68080, loss1: 0.57910, loss2_3: 71.10170\n",
      "\ttrain_acc: 0.8902, test_acc: \u001b[31m0.8715168539325843\u001b[0m, time: 75.12\n",
      "epoch: 246, loss: 71.29542, loss1: 0.57804, loss2_3: 70.71738\n",
      "\ttrain_acc: 0.8902, test_acc: \u001b[31m0.8731460674157303\u001b[0m, time: 74.38\n",
      "epoch: 247, loss: 71.40299, loss1: 0.57918, loss2_3: 70.82381\n",
      "\ttrain_acc: 0.8896, test_acc: \u001b[31m0.8726123595505618\u001b[0m, time: 73.91\n",
      "epoch: 248, loss: 71.23855, loss1: 0.57680, loss2_3: 70.66174\n",
      "\ttrain_acc: 0.8902, test_acc: \u001b[31m0.8719943820224719\u001b[0m, time: 74.98\n",
      "epoch: 249, loss: 71.46814, loss1: 0.57863, loss2_3: 70.88951\n",
      "\ttrain_acc: 0.8886, test_acc: \u001b[31m0.8704213483146067\u001b[0m, time: 74.95\n",
      "epoch: 250, loss: 71.25382, loss1: 0.57814, loss2_3: 70.67568\n",
      "\ttrain_acc: 0.8911, test_acc: \u001b[31m0.8735112359550562\u001b[0m, time: 75.03\n",
      "epoch: 1, loss: 154.14843, loss1: 1.76069, loss2_3: 152.38774\n",
      "\ttrain_acc: 0.7915, test_acc: \u001b[31m0.7907303370786517\u001b[0m, time: 73.81\n",
      "best_acc: 0.7907303370786517\n",
      "epoch: 2, loss: 106.21485, loss1: 0.87791, loss2_3: 105.33695\n",
      "\ttrain_acc: 0.8254, test_acc: \u001b[31m0.8226966292134832\u001b[0m, time: 74.56\n",
      "best_acc: 0.8226966292134832\n",
      "epoch: 3, loss: 99.60941, loss1: 0.82651, loss2_3: 98.78290\n",
      "\ttrain_acc: 0.8259, test_acc: \u001b[31m0.8249719101123596\u001b[0m, time: 75.12\n",
      "best_acc: 0.8249719101123596\n",
      "epoch: 4, loss: 96.40159, loss1: 0.80399, loss2_3: 95.59761\n",
      "\ttrain_acc: 0.8281, test_acc: \u001b[31m0.8275280898876405\u001b[0m, time: 75.27\n",
      "best_acc: 0.8275280898876405\n",
      "epoch: 5, loss: 94.98770, loss1: 0.78887, loss2_3: 94.19882\n",
      "\ttrain_acc: 0.8367, test_acc: \u001b[31m0.8355337078651686\u001b[0m, time: 75.11\n",
      "best_acc: 0.8355337078651686\n",
      "epoch: 6, loss: 93.01512, loss1: 0.76348, loss2_3: 92.25163\n",
      "\ttrain_acc: 0.8463, test_acc: \u001b[31m0.8465730337078652\u001b[0m, time: 73.60\n",
      "best_acc: 0.8465730337078652\n",
      "epoch: 7, loss: 91.94592, loss1: 0.75550, loss2_3: 91.19043\n",
      "\ttrain_acc: 0.8501, test_acc: \u001b[31m0.8523033707865169\u001b[0m, time: 74.99\n",
      "best_acc: 0.8523033707865169\n",
      "epoch: 8, loss: 90.99500, loss1: 0.74709, loss2_3: 90.24791\n",
      "\ttrain_acc: 0.8462, test_acc: \u001b[31m0.8450280898876404\u001b[0m, time: 75.00\n",
      "epoch: 9, loss: 89.85481, loss1: 0.73902, loss2_3: 89.11579\n",
      "\ttrain_acc: 0.8487, test_acc: \u001b[31m0.848005617977528\u001b[0m, time: 75.20\n",
      "epoch: 10, loss: 88.45854, loss1: 0.72434, loss2_3: 87.73419\n",
      "\ttrain_acc: 0.8521, test_acc: \u001b[31m0.8501404494382022\u001b[0m, time: 74.08\n",
      "epoch: 11, loss: 88.29782, loss1: 0.72416, loss2_3: 87.57367\n",
      "\ttrain_acc: 0.8484, test_acc: \u001b[31m0.8471629213483146\u001b[0m, time: 73.89\n",
      "epoch: 12, loss: 87.32554, loss1: 0.71347, loss2_3: 86.61207\n",
      "\ttrain_acc: 0.8553, test_acc: \u001b[31m0.8562640449438202\u001b[0m, time: 75.30\n",
      "best_acc: 0.8562640449438202\n",
      "epoch: 13, loss: 86.79366, loss1: 0.70458, loss2_3: 86.08908\n",
      "\ttrain_acc: 0.8584, test_acc: \u001b[31m0.8581460674157303\u001b[0m, time: 75.14\n",
      "best_acc: 0.8581460674157303\n",
      "epoch: 14, loss: 86.24273, loss1: 0.70806, loss2_3: 85.53467\n",
      "\ttrain_acc: 0.8592, test_acc: \u001b[31m0.8604213483146067\u001b[0m, time: 75.82\n",
      "best_acc: 0.8604213483146067\n",
      "epoch: 15, loss: 86.31815, loss1: 0.69844, loss2_3: 85.61971\n",
      "\ttrain_acc: 0.8569, test_acc: \u001b[31m0.854691011235955\u001b[0m, time: 73.32\n",
      "epoch: 16, loss: 86.24684, loss1: 0.70027, loss2_3: 85.54657\n",
      "\ttrain_acc: 0.8588, test_acc: \u001b[31m0.8575\u001b[0m, time: 74.65\n",
      "epoch: 17, loss: 85.49768, loss1: 0.70330, loss2_3: 84.79439\n",
      "\ttrain_acc: 0.8598, test_acc: \u001b[31m0.8584550561797752\u001b[0m, time: 75.03\n",
      "epoch: 18, loss: 85.06638, loss1: 0.69240, loss2_3: 84.37398\n",
      "\ttrain_acc: 0.8575, test_acc: \u001b[31m0.8571629213483146\u001b[0m, time: 74.92\n",
      "epoch: 19, loss: 84.68627, loss1: 0.68694, loss2_3: 83.99933\n",
      "\ttrain_acc: 0.8602, test_acc: \u001b[31m0.8579494382022472\u001b[0m, time: 74.34\n",
      "epoch: 20, loss: 84.77317, loss1: 0.68640, loss2_3: 84.08677\n",
      "\ttrain_acc: 0.8584, test_acc: \u001b[31m0.8554213483146067\u001b[0m, time: 73.46\n",
      "epoch: 21, loss: 84.06201, loss1: 0.68266, loss2_3: 83.37935\n",
      "\ttrain_acc: 0.8624, test_acc: \u001b[31m0.8607022471910112\u001b[0m, time: 74.96\n",
      "best_acc: 0.8607022471910112\n",
      "epoch: 22, loss: 83.64699, loss1: 0.67489, loss2_3: 82.97210\n",
      "\ttrain_acc: 0.8619, test_acc: \u001b[31m0.8581460674157303\u001b[0m, time: 75.06\n",
      "epoch: 23, loss: 83.77389, loss1: 0.67841, loss2_3: 83.09548\n",
      "\ttrain_acc: 0.8620, test_acc: \u001b[31m0.8615168539325843\u001b[0m, time: 74.97\n",
      "best_acc: 0.8615168539325843\n",
      "epoch: 24, loss: 83.56807, loss1: 0.67814, loss2_3: 82.88993\n",
      "\ttrain_acc: 0.8634, test_acc: \u001b[31m0.8628651685393258\u001b[0m, time: 73.75\n",
      "best_acc: 0.8628651685393258\n",
      "epoch: 25, loss: 83.22306, loss1: 0.67207, loss2_3: 82.55098\n",
      "\ttrain_acc: 0.8653, test_acc: \u001b[31m0.8640730337078651\u001b[0m, time: 73.88\n",
      "best_acc: 0.8640730337078651\n",
      "epoch: 26, loss: 82.95112, loss1: 0.66687, loss2_3: 82.28425\n",
      "\ttrain_acc: 0.8639, test_acc: \u001b[31m0.8634269662921348\u001b[0m, time: 75.00\n",
      "epoch: 27, loss: 83.08258, loss1: 0.66955, loss2_3: 82.41303\n",
      "\ttrain_acc: 0.8649, test_acc: \u001b[31m0.8629494382022472\u001b[0m, time: 74.96\n",
      "epoch: 28, loss: 82.30761, loss1: 0.66512, loss2_3: 81.64250\n",
      "\ttrain_acc: 0.8636, test_acc: \u001b[31m0.8617696629213483\u001b[0m, time: 74.95\n",
      "epoch: 29, loss: 82.38579, loss1: 0.66211, loss2_3: 81.72368\n",
      "\ttrain_acc: 0.8645, test_acc: \u001b[31m0.8627808988764045\u001b[0m, time: 73.12\n",
      "epoch: 30, loss: 82.36568, loss1: 0.66004, loss2_3: 81.70564\n",
      "\ttrain_acc: 0.8623, test_acc: \u001b[31m0.8601685393258427\u001b[0m, time: 74.34\n",
      "epoch: 31, loss: 82.18178, loss1: 0.65652, loss2_3: 81.52526\n",
      "\ttrain_acc: 0.8657, test_acc: \u001b[31m0.864691011235955\u001b[0m, time: 74.93\n",
      "best_acc: 0.864691011235955\n",
      "epoch: 32, loss: 82.14942, loss1: 0.65629, loss2_3: 81.49313\n",
      "\ttrain_acc: 0.8666, test_acc: \u001b[31m0.8641573033707866\u001b[0m, time: 74.92\n",
      "epoch: 33, loss: 81.41739, loss1: 0.65049, loss2_3: 80.76690\n",
      "\ttrain_acc: 0.8676, test_acc: \u001b[31m0.866938202247191\u001b[0m, time: 74.31\n",
      "best_acc: 0.866938202247191\n",
      "epoch: 34, loss: 81.09382, loss1: 0.65097, loss2_3: 80.44286\n",
      "\ttrain_acc: 0.8690, test_acc: \u001b[31m0.8677247191011236\u001b[0m, time: 73.49\n",
      "best_acc: 0.8677247191011236\n",
      "epoch: 35, loss: 80.99574, loss1: 0.65120, loss2_3: 80.34453\n",
      "\ttrain_acc: 0.8692, test_acc: \u001b[31m0.8670224719101124\u001b[0m, time: 74.89\n",
      "epoch: 36, loss: 80.87478, loss1: 0.64862, loss2_3: 80.22616\n",
      "\ttrain_acc: 0.8698, test_acc: \u001b[31m0.8680056179775281\u001b[0m, time: 74.87\n",
      "best_acc: 0.8680056179775281\n",
      "epoch: 37, loss: 80.81898, loss1: 0.64510, loss2_3: 80.17388\n",
      "\ttrain_acc: 0.8689, test_acc: \u001b[31m0.8667134831460674\u001b[0m, time: 74.89\n",
      "epoch: 38, loss: 80.59264, loss1: 0.64545, loss2_3: 79.94719\n",
      "\ttrain_acc: 0.8694, test_acc: \u001b[31m0.8672752808988764\u001b[0m, time: 73.70\n",
      "epoch: 39, loss: 80.40935, loss1: 0.64137, loss2_3: 79.76797\n",
      "\ttrain_acc: 0.8704, test_acc: \u001b[31m0.868370786516854\u001b[0m, time: 73.92\n",
      "best_acc: 0.868370786516854\n",
      "epoch: 40, loss: 80.13738, loss1: 0.64296, loss2_3: 79.49442\n",
      "\ttrain_acc: 0.8705, test_acc: \u001b[31m0.8693820224719101\u001b[0m, time: 74.93\n",
      "best_acc: 0.8693820224719101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41, loss: 80.24643, loss1: 0.64008, loss2_3: 79.60635\n",
      "\ttrain_acc: 0.8715, test_acc: \u001b[31m0.8703932584269662\u001b[0m, time: 75.05\n",
      "best_acc: 0.8703932584269662\n",
      "epoch: 42, loss: 79.83617, loss1: 0.63856, loss2_3: 79.19761\n",
      "\ttrain_acc: 0.8711, test_acc: \u001b[31m0.8696348314606741\u001b[0m, time: 74.83\n",
      "epoch: 43, loss: 79.61544, loss1: 0.64005, loss2_3: 78.97539\n",
      "\ttrain_acc: 0.8715, test_acc: \u001b[31m0.8705898876404494\u001b[0m, time: 73.18\n",
      "best_acc: 0.8705898876404494\n",
      "epoch: 44, loss: 79.63897, loss1: 0.63771, loss2_3: 79.00126\n",
      "\ttrain_acc: 0.8719, test_acc: \u001b[31m0.8699719101123595\u001b[0m, time: 74.72\n",
      "epoch: 45, loss: 79.57081, loss1: 0.63570, loss2_3: 78.93511\n",
      "\ttrain_acc: 0.8721, test_acc: \u001b[31m0.8693539325842696\u001b[0m, time: 74.82\n",
      "epoch: 46, loss: 79.51684, loss1: 0.63490, loss2_3: 78.88194\n",
      "\ttrain_acc: 0.8711, test_acc: \u001b[31m0.8700842696629213\u001b[0m, time: 75.01\n",
      "epoch: 47, loss: 79.23487, loss1: 0.63593, loss2_3: 78.59894\n",
      "\ttrain_acc: 0.8733, test_acc: \u001b[31m0.8715168539325843\u001b[0m, time: 74.17\n",
      "best_acc: 0.8715168539325843\n",
      "epoch: 48, loss: 79.31307, loss1: 0.63398, loss2_3: 78.67909\n",
      "\ttrain_acc: 0.8732, test_acc: \u001b[31m0.8721348314606742\u001b[0m, time: 73.23\n",
      "best_acc: 0.8721348314606742\n",
      "epoch: 49, loss: 78.92119, loss1: 0.62787, loss2_3: 78.29332\n",
      "\ttrain_acc: 0.8694, test_acc: \u001b[31m0.8658146067415731\u001b[0m, time: 74.78\n",
      "epoch: 50, loss: 78.58408, loss1: 0.63239, loss2_3: 77.95169\n",
      "\ttrain_acc: 0.8735, test_acc: \u001b[31m0.871123595505618\u001b[0m, time: 74.78\n",
      "epoch: 51, loss: 78.71948, loss1: 0.62673, loss2_3: 78.09275\n",
      "\ttrain_acc: 0.8698, test_acc: \u001b[31m0.8665449438202247\u001b[0m, time: 74.87\n",
      "epoch: 52, loss: 78.48710, loss1: 0.62875, loss2_3: 77.85835\n",
      "\ttrain_acc: 0.8733, test_acc: \u001b[31m0.8714606741573033\u001b[0m, time: 73.49\n",
      "epoch: 53, loss: 78.55370, loss1: 0.62787, loss2_3: 77.92583\n",
      "\ttrain_acc: 0.8730, test_acc: \u001b[31m0.8699157303370787\u001b[0m, time: 73.78\n",
      "epoch: 54, loss: 78.34549, loss1: 0.62563, loss2_3: 77.71986\n",
      "\ttrain_acc: 0.8673, test_acc: \u001b[31m0.8636797752808989\u001b[0m, time: 74.73\n",
      "epoch: 55, loss: 78.33761, loss1: 0.62513, loss2_3: 77.71248\n",
      "\ttrain_acc: 0.8746, test_acc: \u001b[31m0.8725842696629214\u001b[0m, time: 75.54\n",
      "best_acc: 0.8725842696629214\n",
      "epoch: 56, loss: 78.09486, loss1: 0.62450, loss2_3: 77.47036\n",
      "\ttrain_acc: 0.8747, test_acc: \u001b[31m0.871938202247191\u001b[0m, time: 74.74\n",
      "epoch: 57, loss: 78.11686, loss1: 0.62211, loss2_3: 77.49474\n",
      "\ttrain_acc: 0.8747, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 73.04\n",
      "epoch: 58, loss: 78.07364, loss1: 0.62291, loss2_3: 77.45073\n",
      "\ttrain_acc: 0.8731, test_acc: \u001b[31m0.8688483146067416\u001b[0m, time: 74.48\n",
      "epoch: 59, loss: 77.90532, loss1: 0.62455, loss2_3: 77.28077\n",
      "\ttrain_acc: 0.8752, test_acc: \u001b[31m0.8714044943820225\u001b[0m, time: 74.82\n",
      "epoch: 60, loss: 77.68054, loss1: 0.62013, loss2_3: 77.06042\n",
      "\ttrain_acc: 0.8744, test_acc: \u001b[31m0.8711797752808988\u001b[0m, time: 74.76\n",
      "epoch: 61, loss: 77.54783, loss1: 0.62200, loss2_3: 76.92583\n",
      "\ttrain_acc: 0.8755, test_acc: \u001b[31m0.8705898876404494\u001b[0m, time: 74.02\n",
      "epoch: 62, loss: 77.63585, loss1: 0.62188, loss2_3: 77.01397\n",
      "\ttrain_acc: 0.8739, test_acc: \u001b[31m0.8708426966292134\u001b[0m, time: 73.45\n",
      "epoch: 63, loss: 77.68207, loss1: 0.61935, loss2_3: 77.06272\n",
      "\ttrain_acc: 0.8754, test_acc: \u001b[31m0.8711516853932584\u001b[0m, time: 74.81\n",
      "epoch: 64, loss: 77.49167, loss1: 0.61887, loss2_3: 76.87280\n",
      "\ttrain_acc: 0.8731, test_acc: \u001b[31m0.8667415730337079\u001b[0m, time: 74.78\n",
      "epoch: 65, loss: 77.27088, loss1: 0.61572, loss2_3: 76.65516\n",
      "\ttrain_acc: 0.8737, test_acc: \u001b[31m0.8692415730337079\u001b[0m, time: 74.91\n",
      "epoch: 66, loss: 77.31694, loss1: 0.61961, loss2_3: 76.69733\n",
      "\ttrain_acc: 0.8764, test_acc: \u001b[31m0.8708707865168539\u001b[0m, time: 73.58\n",
      "epoch: 67, loss: 77.29325, loss1: 0.61961, loss2_3: 76.67363\n",
      "\ttrain_acc: 0.8739, test_acc: \u001b[31m0.8680056179775281\u001b[0m, time: 74.09\n",
      "epoch: 68, loss: 77.23042, loss1: 0.61799, loss2_3: 76.61243\n",
      "\ttrain_acc: 0.8759, test_acc: \u001b[31m0.8706179775280899\u001b[0m, time: 74.94\n",
      "epoch: 69, loss: 77.08556, loss1: 0.61628, loss2_3: 76.46929\n",
      "\ttrain_acc: 0.8744, test_acc: \u001b[31m0.8704494382022472\u001b[0m, time: 74.91\n",
      "epoch: 70, loss: 76.85393, loss1: 0.61570, loss2_3: 76.23824\n",
      "\ttrain_acc: 0.8761, test_acc: \u001b[31m0.871685393258427\u001b[0m, time: 74.71\n",
      "epoch: 71, loss: 76.93020, loss1: 0.61696, loss2_3: 76.31325\n",
      "\ttrain_acc: 0.8768, test_acc: \u001b[31m0.8716573033707865\u001b[0m, time: 73.02\n",
      "epoch: 72, loss: 76.98291, loss1: 0.61365, loss2_3: 76.36925\n",
      "\ttrain_acc: 0.8750, test_acc: \u001b[31m0.868876404494382\u001b[0m, time: 74.54\n",
      "epoch: 73, loss: 76.94641, loss1: 0.61533, loss2_3: 76.33108\n",
      "\ttrain_acc: 0.8771, test_acc: \u001b[31m0.8714606741573033\u001b[0m, time: 74.90\n",
      "epoch: 74, loss: 76.62175, loss1: 0.61663, loss2_3: 76.00512\n",
      "\ttrain_acc: 0.8768, test_acc: \u001b[31m0.8725280898876404\u001b[0m, time: 74.75\n",
      "epoch: 75, loss: 76.53180, loss1: 0.61393, loss2_3: 75.91786\n",
      "\ttrain_acc: 0.8763, test_acc: \u001b[31m0.8706460674157304\u001b[0m, time: 74.15\n",
      "epoch: 76, loss: 76.61386, loss1: 0.61200, loss2_3: 76.00185\n",
      "\ttrain_acc: 0.8765, test_acc: \u001b[31m0.871432584269663\u001b[0m, time: 73.27\n",
      "epoch: 77, loss: 76.50925, loss1: 0.61449, loss2_3: 75.89476\n",
      "\ttrain_acc: 0.8749, test_acc: \u001b[31m0.8679213483146068\u001b[0m, time: 74.78\n",
      "epoch: 78, loss: 76.48240, loss1: 0.61249, loss2_3: 75.86991\n",
      "\ttrain_acc: 0.8753, test_acc: \u001b[31m0.8694662921348315\u001b[0m, time: 74.86\n",
      "epoch: 79, loss: 76.46079, loss1: 0.60986, loss2_3: 75.85093\n",
      "\ttrain_acc: 0.8774, test_acc: \u001b[31m0.8721629213483146\u001b[0m, time: 74.82\n",
      "epoch: 80, loss: 76.42003, loss1: 0.61250, loss2_3: 75.80753\n",
      "\ttrain_acc: 0.8770, test_acc: \u001b[31m0.8717134831460674\u001b[0m, time: 73.60\n",
      "epoch: 81, loss: 76.25797, loss1: 0.61017, loss2_3: 75.64780\n",
      "\ttrain_acc: 0.8763, test_acc: \u001b[31m0.871376404494382\u001b[0m, time: 73.95\n",
      "epoch: 82, loss: 76.12730, loss1: 0.61391, loss2_3: 75.51339\n",
      "\ttrain_acc: 0.8786, test_acc: \u001b[31m0.8737921348314607\u001b[0m, time: 74.82\n",
      "best_acc: 0.8737921348314607\n",
      "epoch: 83, loss: 76.29397, loss1: 0.61198, loss2_3: 75.68199\n",
      "\ttrain_acc: 0.8778, test_acc: \u001b[31m0.871938202247191\u001b[0m, time: 74.86\n",
      "epoch: 84, loss: 75.99706, loss1: 0.60913, loss2_3: 75.38792\n",
      "\ttrain_acc: 0.8785, test_acc: \u001b[31m0.8723314606741573\u001b[0m, time: 74.74\n",
      "epoch: 85, loss: 76.05878, loss1: 0.60789, loss2_3: 75.45089\n",
      "\ttrain_acc: 0.8762, test_acc: \u001b[31m0.8684269662921348\u001b[0m, time: 73.06\n",
      "epoch: 86, loss: 75.98697, loss1: 0.60635, loss2_3: 75.38062\n",
      "\ttrain_acc: 0.8778, test_acc: \u001b[31m0.8725280898876404\u001b[0m, time: 74.35\n",
      "epoch: 87, loss: 75.92250, loss1: 0.61061, loss2_3: 75.31189\n",
      "\ttrain_acc: 0.8785, test_acc: \u001b[31m0.8725280898876404\u001b[0m, time: 74.79\n",
      "epoch: 88, loss: 75.68047, loss1: 0.60893, loss2_3: 75.07154\n",
      "\ttrain_acc: 0.8789, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 74.67\n",
      "epoch: 89, loss: 75.65860, loss1: 0.60659, loss2_3: 75.05202\n",
      "\ttrain_acc: 0.8795, test_acc: \u001b[31m0.8727528089887641\u001b[0m, time: 74.10\n",
      "epoch: 90, loss: 75.62752, loss1: 0.60563, loss2_3: 75.02189\n",
      "\ttrain_acc: 0.8782, test_acc: \u001b[31m0.8706179775280899\u001b[0m, time: 73.18\n",
      "epoch: 91, loss: 75.67147, loss1: 0.60270, loss2_3: 75.06877\n",
      "\ttrain_acc: 0.8750, test_acc: \u001b[31m0.8665168539325843\u001b[0m, time: 74.83\n",
      "epoch: 92, loss: 75.51538, loss1: 0.60302, loss2_3: 74.91236\n",
      "\ttrain_acc: 0.8781, test_acc: \u001b[31m0.8717977528089887\u001b[0m, time: 76.48\n",
      "epoch: 93, loss: 75.67962, loss1: 0.60784, loss2_3: 75.07179\n",
      "\ttrain_acc: 0.8801, test_acc: \u001b[31m0.8723314606741573\u001b[0m, time: 78.62\n",
      "epoch: 94, loss: 75.46952, loss1: 0.60127, loss2_3: 74.86825\n",
      "\ttrain_acc: 0.8796, test_acc: \u001b[31m0.8732584269662922\u001b[0m, time: 78.54\n",
      "epoch: 95, loss: 75.48737, loss1: 0.60556, loss2_3: 74.88181\n",
      "\ttrain_acc: 0.8790, test_acc: \u001b[31m0.8708426966292134\u001b[0m, time: 76.79\n",
      "epoch: 96, loss: 75.45368, loss1: 0.60303, loss2_3: 74.85066\n",
      "\ttrain_acc: 0.8795, test_acc: \u001b[31m0.8732865168539325\u001b[0m, time: 74.79\n",
      "epoch: 97, loss: 75.55451, loss1: 0.60427, loss2_3: 74.95024\n",
      "\ttrain_acc: 0.8781, test_acc: \u001b[31m0.8695786516853933\u001b[0m, time: 73.57\n",
      "epoch: 98, loss: 75.54533, loss1: 0.60268, loss2_3: 74.94264\n",
      "\ttrain_acc: 0.8793, test_acc: \u001b[31m0.8716573033707865\u001b[0m, time: 73.98\n",
      "epoch: 99, loss: 75.44421, loss1: 0.60712, loss2_3: 74.83709\n",
      "\ttrain_acc: 0.8786, test_acc: \u001b[31m0.8715730337078652\u001b[0m, time: 74.75\n",
      "epoch: 100, loss: 75.11419, loss1: 0.60294, loss2_3: 74.51126\n",
      "\ttrain_acc: 0.8798, test_acc: \u001b[31m0.8715730337078652\u001b[0m, time: 74.83\n",
      "epoch: 101, loss: 75.16496, loss1: 0.60407, loss2_3: 74.56089\n",
      "\ttrain_acc: 0.8797, test_acc: \u001b[31m0.8738483146067416\u001b[0m, time: 74.76\n",
      "best_acc: 0.8738483146067416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 102, loss: 75.13001, loss1: 0.60675, loss2_3: 74.52326\n",
      "\ttrain_acc: 0.8801, test_acc: \u001b[31m0.8711516853932584\u001b[0m, time: 73.12\n",
      "epoch: 103, loss: 75.26444, loss1: 0.60077, loss2_3: 74.66367\n",
      "\ttrain_acc: 0.8809, test_acc: \u001b[31m0.8736797752808989\u001b[0m, time: 74.49\n",
      "epoch: 104, loss: 74.93713, loss1: 0.59834, loss2_3: 74.33879\n",
      "\ttrain_acc: 0.8779, test_acc: \u001b[31m0.8688483146067416\u001b[0m, time: 74.74\n",
      "epoch: 105, loss: 74.98938, loss1: 0.60270, loss2_3: 74.38669\n",
      "\ttrain_acc: 0.8808, test_acc: \u001b[31m0.8719943820224719\u001b[0m, time: 74.77\n",
      "epoch: 106, loss: 74.98649, loss1: 0.60012, loss2_3: 74.38637\n",
      "\ttrain_acc: 0.8815, test_acc: \u001b[31m0.8729775280898876\u001b[0m, time: 74.39\n",
      "epoch: 107, loss: 74.72262, loss1: 0.59866, loss2_3: 74.12396\n",
      "\ttrain_acc: 0.8807, test_acc: \u001b[31m0.8708426966292134\u001b[0m, time: 73.22\n",
      "epoch: 108, loss: 74.96792, loss1: 0.60113, loss2_3: 74.36679\n",
      "\ttrain_acc: 0.8812, test_acc: \u001b[31m0.8723033707865169\u001b[0m, time: 74.71\n",
      "epoch: 109, loss: 74.64582, loss1: 0.59963, loss2_3: 74.04619\n",
      "\ttrain_acc: 0.8802, test_acc: \u001b[31m0.8709269662921348\u001b[0m, time: 74.92\n",
      "epoch: 110, loss: 74.73956, loss1: 0.59541, loss2_3: 74.14414\n",
      "\ttrain_acc: 0.8819, test_acc: \u001b[31m0.8724438202247191\u001b[0m, time: 74.87\n",
      "epoch: 111, loss: 74.66104, loss1: 0.60101, loss2_3: 74.06003\n",
      "\ttrain_acc: 0.8820, test_acc: \u001b[31m0.8731741573033708\u001b[0m, time: 73.74\n",
      "epoch: 112, loss: 74.55881, loss1: 0.59543, loss2_3: 73.96338\n",
      "\ttrain_acc: 0.8799, test_acc: \u001b[31m0.8698595505617978\u001b[0m, time: 73.72\n",
      "epoch: 113, loss: 74.65437, loss1: 0.60072, loss2_3: 74.05365\n",
      "\ttrain_acc: 0.8814, test_acc: \u001b[31m0.8725561797752809\u001b[0m, time: 74.92\n",
      "epoch: 114, loss: 74.43148, loss1: 0.59732, loss2_3: 73.83416\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 74.76\n",
      "epoch: 115, loss: 74.50365, loss1: 0.59903, loss2_3: 73.90462\n",
      "\ttrain_acc: 0.8799, test_acc: \u001b[31m0.8695786516853933\u001b[0m, time: 74.93\n",
      "epoch: 116, loss: 74.29504, loss1: 0.59369, loss2_3: 73.70135\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8714887640449438\u001b[0m, time: 73.25\n",
      "epoch: 117, loss: 74.48934, loss1: 0.59867, loss2_3: 73.89067\n",
      "\ttrain_acc: 0.8778, test_acc: \u001b[31m0.8676685393258426\u001b[0m, time: 74.27\n",
      "epoch: 118, loss: 74.21011, loss1: 0.59519, loss2_3: 73.61491\n",
      "\ttrain_acc: 0.8819, test_acc: \u001b[31m0.8715168539325843\u001b[0m, time: 74.86\n",
      "epoch: 119, loss: 74.36495, loss1: 0.59558, loss2_3: 73.76937\n",
      "\ttrain_acc: 0.8820, test_acc: \u001b[31m0.8718820224719102\u001b[0m, time: 74.75\n",
      "epoch: 120, loss: 74.17834, loss1: 0.59464, loss2_3: 73.58369\n",
      "\ttrain_acc: 0.8821, test_acc: \u001b[31m0.8731741573033708\u001b[0m, time: 74.36\n",
      "epoch: 121, loss: 74.24758, loss1: 0.59707, loss2_3: 73.65051\n",
      "\ttrain_acc: 0.8829, test_acc: \u001b[31m0.8728370786516854\u001b[0m, time: 73.01\n",
      "epoch: 122, loss: 74.13267, loss1: 0.59445, loss2_3: 73.53822\n",
      "\ttrain_acc: 0.8789, test_acc: \u001b[31m0.8682584269662922\u001b[0m, time: 74.71\n",
      "epoch: 123, loss: 73.89762, loss1: 0.59397, loss2_3: 73.30365\n",
      "\ttrain_acc: 0.8836, test_acc: \u001b[31m0.8733988764044944\u001b[0m, time: 74.83\n",
      "epoch: 124, loss: 74.20856, loss1: 0.59063, loss2_3: 73.61793\n",
      "\ttrain_acc: 0.8816, test_acc: \u001b[31m0.8717977528089887\u001b[0m, time: 74.69\n",
      "epoch: 125, loss: 74.06524, loss1: 0.59540, loss2_3: 73.46984\n",
      "\ttrain_acc: 0.8837, test_acc: \u001b[31m0.8723876404494382\u001b[0m, time: 73.82\n",
      "epoch: 126, loss: 73.92747, loss1: 0.59780, loss2_3: 73.32966\n",
      "\ttrain_acc: 0.8832, test_acc: \u001b[31m0.8722191011235955\u001b[0m, time: 73.74\n",
      "epoch: 127, loss: 73.76151, loss1: 0.59764, loss2_3: 73.16387\n",
      "\ttrain_acc: 0.8834, test_acc: \u001b[31m0.8726123595505618\u001b[0m, time: 74.84\n",
      "epoch: 128, loss: 73.83452, loss1: 0.59506, loss2_3: 73.23945\n",
      "\ttrain_acc: 0.8825, test_acc: \u001b[31m0.8723595505617977\u001b[0m, time: 74.85\n",
      "epoch: 129, loss: 73.67950, loss1: 0.59405, loss2_3: 73.08546\n",
      "\ttrain_acc: 0.8845, test_acc: \u001b[31m0.8740730337078652\u001b[0m, time: 74.79\n",
      "best_acc: 0.8740730337078652\n",
      "epoch: 130, loss: 73.68626, loss1: 0.59158, loss2_3: 73.09468\n",
      "\ttrain_acc: 0.8830, test_acc: \u001b[31m0.871685393258427\u001b[0m, time: 73.13\n",
      "epoch: 131, loss: 73.78091, loss1: 0.59405, loss2_3: 73.18686\n",
      "\ttrain_acc: 0.8836, test_acc: \u001b[31m0.8724719101123596\u001b[0m, time: 74.27\n",
      "epoch: 132, loss: 73.67726, loss1: 0.58945, loss2_3: 73.08781\n",
      "\ttrain_acc: 0.8837, test_acc: \u001b[31m0.8729213483146068\u001b[0m, time: 76.27\n",
      "epoch: 133, loss: 73.63689, loss1: 0.59577, loss2_3: 73.04111\n",
      "\ttrain_acc: 0.8837, test_acc: \u001b[31m0.871938202247191\u001b[0m, time: 75.79\n",
      "epoch: 134, loss: 73.43258, loss1: 0.59176, loss2_3: 72.84083\n",
      "\ttrain_acc: 0.8831, test_acc: \u001b[31m0.8715730337078652\u001b[0m, time: 73.78\n",
      "epoch: 135, loss: 73.64904, loss1: 0.59421, loss2_3: 73.05482\n",
      "\ttrain_acc: 0.8837, test_acc: \u001b[31m0.871123595505618\u001b[0m, time: 73.72\n",
      "epoch: 136, loss: 73.28721, loss1: 0.59028, loss2_3: 72.69693\n",
      "\ttrain_acc: 0.8858, test_acc: \u001b[31m0.8737078651685394\u001b[0m, time: 74.77\n",
      "epoch: 137, loss: 73.42912, loss1: 0.58990, loss2_3: 72.83922\n",
      "\ttrain_acc: 0.8838, test_acc: \u001b[31m0.8729775280898876\u001b[0m, time: 74.84\n",
      "epoch: 138, loss: 73.45791, loss1: 0.59031, loss2_3: 72.86760\n",
      "\ttrain_acc: 0.8828, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 74.87\n",
      "epoch: 139, loss: 73.22530, loss1: 0.58983, loss2_3: 72.63548\n",
      "\ttrain_acc: 0.8850, test_acc: \u001b[31m0.873314606741573\u001b[0m, time: 73.13\n",
      "epoch: 140, loss: 73.42828, loss1: 0.59209, loss2_3: 72.83620\n",
      "\ttrain_acc: 0.8846, test_acc: \u001b[31m0.8725842696629214\u001b[0m, time: 74.36\n",
      "epoch: 141, loss: 73.26783, loss1: 0.59043, loss2_3: 72.67740\n",
      "\ttrain_acc: 0.8843, test_acc: \u001b[31m0.8714044943820225\u001b[0m, time: 74.87\n",
      "epoch: 142, loss: 73.34777, loss1: 0.59165, loss2_3: 72.75612\n",
      "\ttrain_acc: 0.8837, test_acc: \u001b[31m0.8701685393258427\u001b[0m, time: 74.85\n",
      "epoch: 143, loss: 73.18932, loss1: 0.58886, loss2_3: 72.60046\n",
      "\ttrain_acc: 0.8849, test_acc: \u001b[31m0.8710112359550561\u001b[0m, time: 74.40\n",
      "epoch: 144, loss: 72.97100, loss1: 0.58962, loss2_3: 72.38138\n",
      "\ttrain_acc: 0.8864, test_acc: \u001b[31m0.8716573033707865\u001b[0m, time: 73.24\n",
      "epoch: 145, loss: 73.02009, loss1: 0.58761, loss2_3: 72.43248\n",
      "\ttrain_acc: 0.8858, test_acc: \u001b[31m0.8725\u001b[0m, time: 74.95\n",
      "epoch: 146, loss: 72.91209, loss1: 0.58872, loss2_3: 72.32338\n",
      "\ttrain_acc: 0.8851, test_acc: \u001b[31m0.8707303370786517\u001b[0m, time: 74.88\n",
      "epoch: 147, loss: 72.93015, loss1: 0.58815, loss2_3: 72.34200\n",
      "\ttrain_acc: 0.8868, test_acc: \u001b[31m0.871376404494382\u001b[0m, time: 74.75\n",
      "epoch: 148, loss: 72.63924, loss1: 0.58771, loss2_3: 72.05153\n",
      "\ttrain_acc: 0.8776, test_acc: \u001b[31m0.8645786516853933\u001b[0m, time: 73.74\n",
      "epoch: 149, loss: 72.74855, loss1: 0.58997, loss2_3: 72.15858\n",
      "\ttrain_acc: 0.8866, test_acc: \u001b[31m0.8721629213483146\u001b[0m, time: 73.75\n",
      "epoch: 150, loss: 72.82212, loss1: 0.58560, loss2_3: 72.23652\n",
      "\ttrain_acc: 0.8832, test_acc: \u001b[31m0.870561797752809\u001b[0m, time: 74.68\n",
      "epoch: 151, loss: 72.62559, loss1: 0.58720, loss2_3: 72.03839\n",
      "\ttrain_acc: 0.8860, test_acc: \u001b[31m0.873314606741573\u001b[0m, time: 74.79\n",
      "epoch: 152, loss: 72.46212, loss1: 0.58439, loss2_3: 71.87773\n",
      "\ttrain_acc: 0.8860, test_acc: \u001b[31m0.871432584269663\u001b[0m, time: 74.74\n",
      "epoch: 153, loss: 72.42132, loss1: 0.58708, loss2_3: 71.83424\n",
      "\ttrain_acc: 0.8855, test_acc: \u001b[31m0.8708146067415731\u001b[0m, time: 73.21\n",
      "epoch: 154, loss: 72.16210, loss1: 0.58584, loss2_3: 71.57625\n",
      "\ttrain_acc: 0.8837, test_acc: \u001b[31m0.8689325842696629\u001b[0m, time: 74.29\n",
      "epoch: 155, loss: 72.31724, loss1: 0.58473, loss2_3: 71.73251\n",
      "\ttrain_acc: 0.8882, test_acc: \u001b[31m0.8726966292134831\u001b[0m, time: 74.65\n",
      "epoch: 156, loss: 72.33632, loss1: 0.58766, loss2_3: 71.74866\n",
      "\ttrain_acc: 0.8867, test_acc: \u001b[31m0.8725\u001b[0m, time: 74.82\n",
      "epoch: 157, loss: 72.29359, loss1: 0.58833, loss2_3: 71.70525\n",
      "\ttrain_acc: 0.8878, test_acc: \u001b[31m0.8733426966292135\u001b[0m, time: 74.25\n",
      "epoch: 158, loss: 72.15300, loss1: 0.58386, loss2_3: 71.56914\n",
      "\ttrain_acc: 0.8878, test_acc: \u001b[31m0.8717977528089887\u001b[0m, time: 73.24\n",
      "epoch: 159, loss: 71.97528, loss1: 0.58464, loss2_3: 71.39064\n",
      "\ttrain_acc: 0.8879, test_acc: \u001b[31m0.873061797752809\u001b[0m, time: 74.89\n",
      "epoch: 160, loss: 72.00327, loss1: 0.58425, loss2_3: 71.41902\n",
      "\ttrain_acc: 0.8869, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 74.77\n",
      "epoch: 161, loss: 72.24280, loss1: 0.58397, loss2_3: 71.65884\n",
      "\ttrain_acc: 0.8890, test_acc: \u001b[31m0.8729775280898876\u001b[0m, time: 74.84\n",
      "epoch: 162, loss: 71.87078, loss1: 0.58380, loss2_3: 71.28698\n",
      "\ttrain_acc: 0.8878, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 73.66\n",
      "epoch: 163, loss: 71.83664, loss1: 0.58279, loss2_3: 71.25385\n",
      "\ttrain_acc: 0.8882, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 73.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 164, loss: 71.69501, loss1: 0.58752, loss2_3: 71.10749\n",
      "\ttrain_acc: 0.8884, test_acc: \u001b[31m0.8735112359550562\u001b[0m, time: 74.80\n",
      "epoch: 165, loss: 71.62356, loss1: 0.58114, loss2_3: 71.04242\n",
      "\ttrain_acc: 0.8891, test_acc: \u001b[31m0.8726685393258427\u001b[0m, time: 74.88\n",
      "epoch: 166, loss: 71.61938, loss1: 0.57866, loss2_3: 71.04072\n",
      "\ttrain_acc: 0.8884, test_acc: \u001b[31m0.8734550561797753\u001b[0m, time: 74.57\n",
      "epoch: 167, loss: 71.66165, loss1: 0.58023, loss2_3: 71.08142\n",
      "\ttrain_acc: 0.8876, test_acc: \u001b[31m0.8715168539325843\u001b[0m, time: 73.04\n",
      "epoch: 168, loss: 71.60818, loss1: 0.57714, loss2_3: 71.03104\n",
      "\ttrain_acc: 0.8908, test_acc: \u001b[31m0.8741011235955056\u001b[0m, time: 74.57\n",
      "best_acc: 0.8741011235955056\n",
      "epoch: 169, loss: 71.57462, loss1: 0.57908, loss2_3: 70.99554\n",
      "\ttrain_acc: 0.8891, test_acc: \u001b[31m0.8716011235955056\u001b[0m, time: 74.64\n",
      "epoch: 170, loss: 71.45853, loss1: 0.57784, loss2_3: 70.88069\n",
      "\ttrain_acc: 0.8870, test_acc: \u001b[31m0.8696629213483146\u001b[0m, time: 74.90\n",
      "epoch: 171, loss: 71.46158, loss1: 0.57803, loss2_3: 70.88354\n",
      "\ttrain_acc: 0.8894, test_acc: \u001b[31m0.8733426966292135\u001b[0m, time: 74.18\n",
      "epoch: 172, loss: 71.28521, loss1: 0.57912, loss2_3: 70.70608\n",
      "\ttrain_acc: 0.8882, test_acc: \u001b[31m0.8716011235955056\u001b[0m, time: 73.08\n",
      "epoch: 173, loss: 70.96710, loss1: 0.57923, loss2_3: 70.38787\n",
      "\ttrain_acc: 0.8898, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 74.81\n",
      "epoch: 174, loss: 71.10452, loss1: 0.57717, loss2_3: 70.52735\n",
      "\ttrain_acc: 0.8899, test_acc: \u001b[31m0.8726966292134831\u001b[0m, time: 74.85\n",
      "epoch: 175, loss: 71.02824, loss1: 0.57998, loss2_3: 70.44826\n",
      "\ttrain_acc: 0.8891, test_acc: \u001b[31m0.8715730337078652\u001b[0m, time: 75.01\n",
      "epoch: 176, loss: 70.99160, loss1: 0.57612, loss2_3: 70.41549\n",
      "\ttrain_acc: 0.8879, test_acc: \u001b[31m0.8685112359550562\u001b[0m, time: 74.00\n",
      "epoch: 177, loss: 71.00861, loss1: 0.57422, loss2_3: 70.43439\n",
      "\ttrain_acc: 0.8914, test_acc: \u001b[31m0.871629213483146\u001b[0m, time: 73.80\n",
      "epoch: 178, loss: 70.96470, loss1: 0.57668, loss2_3: 70.38801\n",
      "\ttrain_acc: 0.8876, test_acc: \u001b[31m0.8694943820224719\u001b[0m, time: 75.06\n",
      "epoch: 179, loss: 71.00457, loss1: 0.57718, loss2_3: 70.42738\n",
      "\ttrain_acc: 0.8873, test_acc: \u001b[31m0.8686516853932584\u001b[0m, time: 74.83\n",
      "epoch: 180, loss: 70.90476, loss1: 0.57206, loss2_3: 70.33270\n",
      "\ttrain_acc: 0.8924, test_acc: \u001b[31m0.8728089887640449\u001b[0m, time: 75.11\n",
      "epoch: 181, loss: 70.76062, loss1: 0.57510, loss2_3: 70.18552\n",
      "\ttrain_acc: 0.8897, test_acc: \u001b[31m0.8705337078651686\u001b[0m, time: 77.47\n",
      "epoch: 182, loss: 70.56711, loss1: 0.57044, loss2_3: 69.99667\n",
      "\ttrain_acc: 0.8917, test_acc: \u001b[31m0.8728651685393258\u001b[0m, time: 77.90\n",
      "epoch: 183, loss: 70.58398, loss1: 0.57399, loss2_3: 70.00999\n",
      "\ttrain_acc: 0.8915, test_acc: \u001b[31m0.8708988764044944\u001b[0m, time: 76.51\n",
      "epoch: 184, loss: 70.50395, loss1: 0.57218, loss2_3: 69.93177\n",
      "\ttrain_acc: 0.8919, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 75.46\n",
      "epoch: 185, loss: 70.23815, loss1: 0.57319, loss2_3: 69.66495\n",
      "\ttrain_acc: 0.8889, test_acc: \u001b[31m0.8686797752808989\u001b[0m, time: 73.34\n",
      "epoch: 186, loss: 70.35519, loss1: 0.57456, loss2_3: 69.78063\n",
      "\ttrain_acc: 0.8908, test_acc: \u001b[31m0.8704213483146067\u001b[0m, time: 75.12\n",
      "epoch: 187, loss: 70.13208, loss1: 0.57215, loss2_3: 69.55993\n",
      "\ttrain_acc: 0.8926, test_acc: \u001b[31m0.8715449438202247\u001b[0m, time: 75.32\n",
      "epoch: 188, loss: 70.21049, loss1: 0.57108, loss2_3: 69.63940\n",
      "\ttrain_acc: 0.8923, test_acc: \u001b[31m0.871685393258427\u001b[0m, time: 75.23\n",
      "epoch: 189, loss: 70.08700, loss1: 0.57174, loss2_3: 69.51526\n",
      "\ttrain_acc: 0.8935, test_acc: \u001b[31m0.8724438202247191\u001b[0m, time: 74.14\n",
      "epoch: 190, loss: 69.92383, loss1: 0.57115, loss2_3: 69.35268\n",
      "\ttrain_acc: 0.8925, test_acc: \u001b[31m0.8708426966292134\u001b[0m, time: 73.86\n",
      "epoch: 191, loss: 69.87348, loss1: 0.57130, loss2_3: 69.30218\n",
      "\ttrain_acc: 0.8931, test_acc: \u001b[31m0.8710112359550561\u001b[0m, time: 75.14\n",
      "epoch: 192, loss: 70.06946, loss1: 0.56873, loss2_3: 69.50074\n",
      "\ttrain_acc: 0.8936, test_acc: \u001b[31m0.8721348314606742\u001b[0m, time: 75.20\n",
      "epoch: 193, loss: 69.68212, loss1: 0.57078, loss2_3: 69.11134\n",
      "\ttrain_acc: 0.8903, test_acc: \u001b[31m0.8681460674157303\u001b[0m, time: 75.10\n",
      "epoch: 194, loss: 69.89709, loss1: 0.57394, loss2_3: 69.32314\n",
      "\ttrain_acc: 0.8934, test_acc: \u001b[31m0.8723314606741573\u001b[0m, time: 73.60\n",
      "epoch: 195, loss: 69.72843, loss1: 0.57009, loss2_3: 69.15834\n",
      "\ttrain_acc: 0.8930, test_acc: \u001b[31m0.8701404494382022\u001b[0m, time: 74.16\n",
      "epoch: 196, loss: 69.56837, loss1: 0.56953, loss2_3: 68.99884\n",
      "\ttrain_acc: 0.8936, test_acc: \u001b[31m0.8692696629213483\u001b[0m, time: 75.25\n",
      "epoch: 197, loss: 69.47586, loss1: 0.56738, loss2_3: 68.90847\n",
      "\ttrain_acc: 0.8931, test_acc: \u001b[31m0.8696067415730337\u001b[0m, time: 75.10\n",
      "epoch: 198, loss: 69.57522, loss1: 0.57087, loss2_3: 69.00434\n",
      "\ttrain_acc: 0.8939, test_acc: \u001b[31m0.8727528089887641\u001b[0m, time: 74.88\n",
      "epoch: 199, loss: 69.47255, loss1: 0.56578, loss2_3: 68.90677\n",
      "\ttrain_acc: 0.8943, test_acc: \u001b[31m0.869438202247191\u001b[0m, time: 73.02\n",
      "epoch: 200, loss: 69.50314, loss1: 0.56606, loss2_3: 68.93708\n",
      "\ttrain_acc: 0.8829, test_acc: \u001b[31m0.8603370786516854\u001b[0m, time: 74.52\n",
      "epoch: 201, loss: 69.23823, loss1: 0.56999, loss2_3: 68.66825\n",
      "\ttrain_acc: 0.8931, test_acc: \u001b[31m0.8699157303370787\u001b[0m, time: 75.05\n",
      "epoch: 202, loss: 69.14134, loss1: 0.56816, loss2_3: 68.57317\n",
      "\ttrain_acc: 0.8960, test_acc: \u001b[31m0.873314606741573\u001b[0m, time: 75.16\n",
      "epoch: 203, loss: 68.97802, loss1: 0.56777, loss2_3: 68.41024\n",
      "\ttrain_acc: 0.8965, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 74.43\n",
      "epoch: 204, loss: 68.98675, loss1: 0.56690, loss2_3: 68.41985\n",
      "\ttrain_acc: 0.8964, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 73.48\n",
      "epoch: 205, loss: 69.02234, loss1: 0.56684, loss2_3: 68.45550\n",
      "\ttrain_acc: 0.8935, test_acc: \u001b[31m0.8684269662921348\u001b[0m, time: 75.01\n",
      "epoch: 206, loss: 68.95008, loss1: 0.56418, loss2_3: 68.38590\n",
      "\ttrain_acc: 0.8960, test_acc: \u001b[31m0.8718258426966292\u001b[0m, time: 75.12\n",
      "epoch: 207, loss: 68.76578, loss1: 0.56383, loss2_3: 68.20195\n",
      "\ttrain_acc: 0.8952, test_acc: \u001b[31m0.8718820224719102\u001b[0m, time: 75.04\n",
      "epoch: 208, loss: 68.58083, loss1: 0.56666, loss2_3: 68.01416\n",
      "\ttrain_acc: 0.8950, test_acc: \u001b[31m0.8689325842696629\u001b[0m, time: 73.74\n",
      "epoch: 209, loss: 68.58337, loss1: 0.56439, loss2_3: 68.01898\n",
      "\ttrain_acc: 0.8984, test_acc: \u001b[31m0.8717415730337079\u001b[0m, time: 74.04\n",
      "epoch: 210, loss: 68.48047, loss1: 0.56401, loss2_3: 67.91646\n",
      "\ttrain_acc: 0.8935, test_acc: \u001b[31m0.8658426966292135\u001b[0m, time: 75.00\n",
      "epoch: 211, loss: 68.48440, loss1: 0.56059, loss2_3: 67.92381\n",
      "\ttrain_acc: 0.8980, test_acc: \u001b[31m0.8727528089887641\u001b[0m, time: 74.98\n",
      "epoch: 212, loss: 68.51920, loss1: 0.56516, loss2_3: 67.95404\n",
      "\ttrain_acc: 0.8964, test_acc: \u001b[31m0.8724719101123596\u001b[0m, time: 75.13\n",
      "epoch: 213, loss: 68.14218, loss1: 0.56282, loss2_3: 67.57936\n",
      "\ttrain_acc: 0.8964, test_acc: \u001b[31m0.8731179775280898\u001b[0m, time: 73.26\n",
      "epoch: 214, loss: 68.29613, loss1: 0.56339, loss2_3: 67.73273\n",
      "\ttrain_acc: 0.8972, test_acc: \u001b[31m0.8704494382022472\u001b[0m, time: 74.52\n",
      "epoch: 215, loss: 68.02338, loss1: 0.56209, loss2_3: 67.46129\n",
      "\ttrain_acc: 0.8980, test_acc: \u001b[31m0.8720224719101124\u001b[0m, time: 75.06\n",
      "epoch: 216, loss: 68.25167, loss1: 0.56294, loss2_3: 67.68872\n",
      "\ttrain_acc: 0.8986, test_acc: \u001b[31m0.8707865168539326\u001b[0m, time: 74.90\n",
      "epoch: 217, loss: 68.13892, loss1: 0.56065, loss2_3: 67.57827\n",
      "\ttrain_acc: 0.8949, test_acc: \u001b[31m0.8677247191011236\u001b[0m, time: 74.42\n",
      "epoch: 218, loss: 67.87413, loss1: 0.56014, loss2_3: 67.31398\n",
      "\ttrain_acc: 0.8973, test_acc: \u001b[31m0.8703651685393259\u001b[0m, time: 73.11\n",
      "epoch: 219, loss: 67.79784, loss1: 0.56242, loss2_3: 67.23542\n",
      "\ttrain_acc: 0.8993, test_acc: \u001b[31m0.8705898876404494\u001b[0m, time: 74.74\n",
      "epoch: 220, loss: 67.71259, loss1: 0.56075, loss2_3: 67.15183\n",
      "\ttrain_acc: 0.8937, test_acc: \u001b[31m0.8678932584269663\u001b[0m, time: 74.86\n",
      "epoch: 221, loss: 67.83026, loss1: 0.56054, loss2_3: 67.26971\n",
      "\ttrain_acc: 0.8955, test_acc: \u001b[31m0.8690449438202247\u001b[0m, time: 74.96\n",
      "epoch: 222, loss: 67.80089, loss1: 0.55857, loss2_3: 67.24231\n",
      "\ttrain_acc: 0.8998, test_acc: \u001b[31m0.871123595505618\u001b[0m, time: 73.64\n",
      "epoch: 223, loss: 67.30868, loss1: 0.55717, loss2_3: 66.75150\n",
      "\ttrain_acc: 0.9003, test_acc: \u001b[31m0.8719101123595505\u001b[0m, time: 73.61\n",
      "epoch: 224, loss: 67.39018, loss1: 0.55537, loss2_3: 66.83481\n",
      "\ttrain_acc: 0.9002, test_acc: \u001b[31m0.8693258426966292\u001b[0m, time: 74.58\n",
      "epoch: 225, loss: 67.28685, loss1: 0.55794, loss2_3: 66.72891\n",
      "\ttrain_acc: 0.8932, test_acc: \u001b[31m0.8666011235955056\u001b[0m, time: 74.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 226, loss: 67.07374, loss1: 0.55495, loss2_3: 66.51879\n",
      "\ttrain_acc: 0.9008, test_acc: \u001b[31m0.8711516853932584\u001b[0m, time: 74.80\n",
      "epoch: 227, loss: 66.97578, loss1: 0.55754, loss2_3: 66.41824\n",
      "\ttrain_acc: 0.9005, test_acc: \u001b[31m0.8698876404494382\u001b[0m, time: 73.28\n",
      "epoch: 228, loss: 66.92131, loss1: 0.55878, loss2_3: 66.36253\n",
      "\ttrain_acc: 0.8980, test_acc: \u001b[31m0.8683426966292135\u001b[0m, time: 74.14\n",
      "epoch: 229, loss: 66.76412, loss1: 0.55253, loss2_3: 66.21159\n",
      "\ttrain_acc: 0.9002, test_acc: \u001b[31m0.8713202247191011\u001b[0m, time: 74.82\n",
      "epoch: 230, loss: 66.92851, loss1: 0.55497, loss2_3: 66.37354\n",
      "\ttrain_acc: 0.8979, test_acc: \u001b[31m0.8701404494382022\u001b[0m, time: 74.82\n",
      "epoch: 231, loss: 66.96542, loss1: 0.55663, loss2_3: 66.40878\n",
      "\ttrain_acc: 0.8977, test_acc: \u001b[31m0.8677247191011236\u001b[0m, time: 74.58\n",
      "epoch: 232, loss: 66.71306, loss1: 0.55370, loss2_3: 66.15935\n",
      "\ttrain_acc: 0.9014, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 72.79\n",
      "epoch: 233, loss: 66.65567, loss1: 0.55563, loss2_3: 66.10003\n",
      "\ttrain_acc: 0.9001, test_acc: \u001b[31m0.8716011235955056\u001b[0m, time: 74.58\n",
      "epoch: 234, loss: 66.85515, loss1: 0.55321, loss2_3: 66.30193\n",
      "\ttrain_acc: 0.9020, test_acc: \u001b[31m0.8728089887640449\u001b[0m, time: 74.95\n",
      "epoch: 235, loss: 66.40868, loss1: 0.55284, loss2_3: 65.85584\n",
      "\ttrain_acc: 0.9004, test_acc: \u001b[31m0.8700561797752809\u001b[0m, time: 74.92\n",
      "epoch: 236, loss: 66.51398, loss1: 0.55362, loss2_3: 65.96036\n",
      "\ttrain_acc: 0.8981, test_acc: \u001b[31m0.8672471910112359\u001b[0m, time: 73.95\n",
      "epoch: 237, loss: 66.39790, loss1: 0.55119, loss2_3: 65.84671\n",
      "\ttrain_acc: 0.9008, test_acc: \u001b[31m0.8707303370786517\u001b[0m, time: 73.68\n",
      "epoch: 238, loss: 66.33801, loss1: 0.55007, loss2_3: 65.78793\n",
      "\ttrain_acc: 0.9005, test_acc: \u001b[31m0.8691573033707866\u001b[0m, time: 74.81\n",
      "epoch: 239, loss: 66.10899, loss1: 0.55050, loss2_3: 65.55850\n",
      "\ttrain_acc: 0.9015, test_acc: \u001b[31m0.8691853932584269\u001b[0m, time: 74.77\n",
      "epoch: 240, loss: 66.19193, loss1: 0.54909, loss2_3: 65.64284\n",
      "\ttrain_acc: 0.9004, test_acc: \u001b[31m0.8680898876404495\u001b[0m, time: 74.91\n",
      "epoch: 241, loss: 66.23229, loss1: 0.55490, loss2_3: 65.67738\n",
      "\ttrain_acc: 0.8991, test_acc: \u001b[31m0.8658988764044944\u001b[0m, time: 73.38\n",
      "epoch: 242, loss: 65.94301, loss1: 0.55008, loss2_3: 65.39293\n",
      "\ttrain_acc: 0.8989, test_acc: \u001b[31m0.8653932584269662\u001b[0m, time: 73.87\n",
      "epoch: 243, loss: 66.09420, loss1: 0.55282, loss2_3: 65.54138\n",
      "\ttrain_acc: 0.8972, test_acc: \u001b[31m0.8658146067415731\u001b[0m, time: 74.97\n",
      "epoch: 244, loss: 65.87746, loss1: 0.54796, loss2_3: 65.32951\n",
      "\ttrain_acc: 0.9036, test_acc: \u001b[31m0.8698876404494382\u001b[0m, time: 74.81\n",
      "epoch: 245, loss: 65.66063, loss1: 0.54857, loss2_3: 65.11207\n",
      "\ttrain_acc: 0.9034, test_acc: \u001b[31m0.8699157303370787\u001b[0m, time: 74.53\n",
      "epoch: 246, loss: 65.81994, loss1: 0.54642, loss2_3: 65.27352\n",
      "\ttrain_acc: 0.9051, test_acc: \u001b[31m0.8690730337078652\u001b[0m, time: 72.97\n",
      "epoch: 247, loss: 65.58058, loss1: 0.54504, loss2_3: 65.03554\n",
      "\ttrain_acc: 0.9041, test_acc: \u001b[31m0.8704494382022472\u001b[0m, time: 74.64\n",
      "epoch: 248, loss: 65.58693, loss1: 0.54964, loss2_3: 65.03729\n",
      "\ttrain_acc: 0.9036, test_acc: \u001b[31m0.8711516853932584\u001b[0m, time: 74.98\n",
      "epoch: 249, loss: 65.68775, loss1: 0.54654, loss2_3: 65.14121\n",
      "\ttrain_acc: 0.9049, test_acc: \u001b[31m0.8685393258426967\u001b[0m, time: 74.82\n",
      "epoch: 250, loss: 65.51697, loss1: 0.54717, loss2_3: 64.96980\n",
      "\ttrain_acc: 0.9052, test_acc: \u001b[31m0.8695505617977528\u001b[0m, time: 73.80\n",
      "epoch: 1, loss: 159.59089, loss1: 1.80762, loss2_3: 157.78327\n",
      "\ttrain_acc: 0.7811, test_acc: \u001b[31m0.7816011235955056\u001b[0m, time: 73.87\n",
      "best_acc: 0.7816011235955056\n",
      "epoch: 2, loss: 110.74212, loss1: 0.89820, loss2_3: 109.84392\n",
      "\ttrain_acc: 0.8101, test_acc: \u001b[31m0.8120224719101123\u001b[0m, time: 75.06\n",
      "best_acc: 0.8120224719101123\n",
      "epoch: 3, loss: 102.33206, loss1: 0.85204, loss2_3: 101.48002\n",
      "\ttrain_acc: 0.8322, test_acc: \u001b[31m0.8314606741573034\u001b[0m, time: 75.13\n",
      "best_acc: 0.8314606741573034\n",
      "epoch: 4, loss: 97.27814, loss1: 0.81347, loss2_3: 96.46467\n",
      "\ttrain_acc: 0.8436, test_acc: \u001b[31m0.8431741573033708\u001b[0m, time: 75.08\n",
      "best_acc: 0.8431741573033708\n",
      "epoch: 5, loss: 94.27961, loss1: 0.78356, loss2_3: 93.49604\n",
      "\ttrain_acc: 0.8475, test_acc: \u001b[31m0.8484269662921349\u001b[0m, time: 73.40\n",
      "best_acc: 0.8484269662921349\n",
      "epoch: 6, loss: 92.28674, loss1: 0.76090, loss2_3: 91.52585\n",
      "\ttrain_acc: 0.8450, test_acc: \u001b[31m0.8457865168539326\u001b[0m, time: 74.67\n",
      "epoch: 7, loss: 91.21009, loss1: 0.75223, loss2_3: 90.45787\n",
      "\ttrain_acc: 0.8368, test_acc: \u001b[31m0.8353932584269663\u001b[0m, time: 75.03\n",
      "epoch: 8, loss: 89.85664, loss1: 0.73483, loss2_3: 89.12182\n",
      "\ttrain_acc: 0.8537, test_acc: \u001b[31m0.8533988764044944\u001b[0m, time: 75.07\n",
      "best_acc: 0.8533988764044944\n",
      "epoch: 9, loss: 89.03242, loss1: 0.73192, loss2_3: 88.30049\n",
      "\ttrain_acc: 0.8530, test_acc: \u001b[31m0.8520505617977528\u001b[0m, time: 74.57\n",
      "epoch: 10, loss: 88.39693, loss1: 0.72128, loss2_3: 87.67565\n",
      "\ttrain_acc: 0.8555, test_acc: \u001b[31m0.8560674157303371\u001b[0m, time: 73.31\n",
      "best_acc: 0.8560674157303371\n",
      "epoch: 11, loss: 87.84132, loss1: 0.71614, loss2_3: 87.12518\n",
      "\ttrain_acc: 0.8544, test_acc: \u001b[31m0.8523033707865169\u001b[0m, time: 74.96\n",
      "epoch: 12, loss: 87.35730, loss1: 0.71340, loss2_3: 86.64391\n",
      "\ttrain_acc: 0.8557, test_acc: \u001b[31m0.8553651685393259\u001b[0m, time: 75.01\n",
      "epoch: 13, loss: 87.08847, loss1: 0.71351, loss2_3: 86.37496\n",
      "\ttrain_acc: 0.8592, test_acc: \u001b[31m0.8581741573033708\u001b[0m, time: 74.92\n",
      "best_acc: 0.8581741573033708\n",
      "epoch: 14, loss: 86.33729, loss1: 0.70078, loss2_3: 85.63651\n",
      "\ttrain_acc: 0.8595, test_acc: \u001b[31m0.8568820224719101\u001b[0m, time: 73.87\n",
      "epoch: 15, loss: 86.39472, loss1: 0.70488, loss2_3: 85.68985\n",
      "\ttrain_acc: 0.8580, test_acc: \u001b[31m0.8571067415730337\u001b[0m, time: 73.86\n",
      "epoch: 16, loss: 85.82653, loss1: 0.69498, loss2_3: 85.13155\n",
      "\ttrain_acc: 0.8475, test_acc: \u001b[31m0.846432584269663\u001b[0m, time: 75.03\n",
      "epoch: 17, loss: 85.90380, loss1: 0.69731, loss2_3: 85.20648\n",
      "\ttrain_acc: 0.8611, test_acc: \u001b[31m0.8586516853932584\u001b[0m, time: 75.08\n",
      "best_acc: 0.8586516853932584\n",
      "epoch: 18, loss: 85.70893, loss1: 0.68884, loss2_3: 85.02010\n",
      "\ttrain_acc: 0.8599, test_acc: \u001b[31m0.859438202247191\u001b[0m, time: 75.10\n",
      "best_acc: 0.859438202247191\n",
      "epoch: 19, loss: 85.05386, loss1: 0.69100, loss2_3: 84.36286\n",
      "\ttrain_acc: 0.8612, test_acc: \u001b[31m0.8605056179775281\u001b[0m, time: 73.20\n",
      "best_acc: 0.8605056179775281\n",
      "epoch: 20, loss: 84.90097, loss1: 0.68980, loss2_3: 84.21118\n",
      "\ttrain_acc: 0.8613, test_acc: \u001b[31m0.8604213483146067\u001b[0m, time: 74.50\n",
      "epoch: 21, loss: 84.66899, loss1: 0.68387, loss2_3: 83.98512\n",
      "\ttrain_acc: 0.8620, test_acc: \u001b[31m0.8612640449438203\u001b[0m, time: 75.02\n",
      "best_acc: 0.8612640449438203\n",
      "epoch: 22, loss: 84.43974, loss1: 0.68271, loss2_3: 83.75703\n",
      "\ttrain_acc: 0.8632, test_acc: \u001b[31m0.8637359550561797\u001b[0m, time: 74.94\n",
      "best_acc: 0.8637359550561797\n",
      "epoch: 23, loss: 84.70810, loss1: 0.68459, loss2_3: 84.02351\n",
      "\ttrain_acc: 0.8627, test_acc: \u001b[31m0.8618820224719101\u001b[0m, time: 74.43\n",
      "epoch: 24, loss: 84.10042, loss1: 0.68260, loss2_3: 83.41782\n",
      "\ttrain_acc: 0.8630, test_acc: \u001b[31m0.8602247191011236\u001b[0m, time: 73.37\n",
      "epoch: 25, loss: 83.91982, loss1: 0.67307, loss2_3: 83.24676\n",
      "\ttrain_acc: 0.8629, test_acc: \u001b[31m0.8624438202247191\u001b[0m, time: 74.88\n",
      "epoch: 26, loss: 83.66085, loss1: 0.67658, loss2_3: 82.98427\n",
      "\ttrain_acc: 0.8621, test_acc: \u001b[31m0.8597752808988764\u001b[0m, time: 74.92\n",
      "epoch: 27, loss: 83.49147, loss1: 0.66966, loss2_3: 82.82180\n",
      "\ttrain_acc: 0.8652, test_acc: \u001b[31m0.8638483146067416\u001b[0m, time: 74.85\n",
      "best_acc: 0.8638483146067416\n",
      "epoch: 28, loss: 83.30058, loss1: 0.67217, loss2_3: 82.62841\n",
      "\ttrain_acc: 0.8648, test_acc: \u001b[31m0.8634831460674157\u001b[0m, time: 73.81\n",
      "epoch: 29, loss: 83.13925, loss1: 0.66462, loss2_3: 82.47463\n",
      "\ttrain_acc: 0.8572, test_acc: \u001b[31m0.8558988764044944\u001b[0m, time: 73.91\n",
      "epoch: 30, loss: 83.20159, loss1: 0.66813, loss2_3: 82.53346\n",
      "\ttrain_acc: 0.8644, test_acc: \u001b[31m0.8639325842696629\u001b[0m, time: 74.75\n",
      "best_acc: 0.8639325842696629\n",
      "epoch: 31, loss: 82.61409, loss1: 0.66353, loss2_3: 81.95056\n",
      "\ttrain_acc: 0.8655, test_acc: \u001b[31m0.8640168539325843\u001b[0m, time: 74.92\n",
      "best_acc: 0.8640168539325843\n",
      "epoch: 32, loss: 82.63067, loss1: 0.66216, loss2_3: 81.96851\n",
      "\ttrain_acc: 0.8639, test_acc: \u001b[31m0.8626123595505618\u001b[0m, time: 74.92\n",
      "epoch: 33, loss: 82.68225, loss1: 0.66369, loss2_3: 82.01857\n",
      "\ttrain_acc: 0.8661, test_acc: \u001b[31m0.8642696629213483\u001b[0m, time: 73.07\n",
      "best_acc: 0.8642696629213483\n",
      "epoch: 34, loss: 82.36577, loss1: 0.65926, loss2_3: 81.70651\n",
      "\ttrain_acc: 0.8668, test_acc: \u001b[31m0.8645786516853933\u001b[0m, time: 74.56\n",
      "best_acc: 0.8645786516853933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35, loss: 81.92733, loss1: 0.65582, loss2_3: 81.27151\n",
      "\ttrain_acc: 0.8680, test_acc: \u001b[31m0.8665168539325843\u001b[0m, time: 74.94\n",
      "best_acc: 0.8665168539325843\n",
      "epoch: 36, loss: 82.13264, loss1: 0.65417, loss2_3: 81.47848\n",
      "\ttrain_acc: 0.8657, test_acc: \u001b[31m0.864691011235955\u001b[0m, time: 74.82\n",
      "epoch: 37, loss: 81.55462, loss1: 0.65316, loss2_3: 80.90146\n",
      "\ttrain_acc: 0.8658, test_acc: \u001b[31m0.8629775280898876\u001b[0m, time: 74.25\n",
      "epoch: 38, loss: 81.48491, loss1: 0.65112, loss2_3: 80.83379\n",
      "\ttrain_acc: 0.8680, test_acc: \u001b[31m0.8658146067415731\u001b[0m, time: 73.44\n",
      "epoch: 39, loss: 81.46216, loss1: 0.64872, loss2_3: 80.81343\n",
      "\ttrain_acc: 0.8615, test_acc: \u001b[31m0.8582865168539325\u001b[0m, time: 74.92\n",
      "epoch: 40, loss: 81.27865, loss1: 0.65095, loss2_3: 80.62770\n",
      "\ttrain_acc: 0.8673, test_acc: \u001b[31m0.866376404494382\u001b[0m, time: 74.93\n",
      "epoch: 41, loss: 81.35147, loss1: 0.64821, loss2_3: 80.70326\n",
      "\ttrain_acc: 0.8705, test_acc: \u001b[31m0.868061797752809\u001b[0m, time: 74.88\n",
      "best_acc: 0.868061797752809\n",
      "epoch: 42, loss: 80.90702, loss1: 0.64467, loss2_3: 80.26235\n",
      "\ttrain_acc: 0.8680, test_acc: \u001b[31m0.8660674157303371\u001b[0m, time: 73.63\n",
      "epoch: 43, loss: 80.88482, loss1: 0.64757, loss2_3: 80.23726\n",
      "\ttrain_acc: 0.8696, test_acc: \u001b[31m0.8673314606741573\u001b[0m, time: 74.02\n",
      "epoch: 44, loss: 80.61918, loss1: 0.64200, loss2_3: 79.97718\n",
      "\ttrain_acc: 0.8689, test_acc: \u001b[31m0.866432584269663\u001b[0m, time: 74.93\n",
      "epoch: 45, loss: 80.51521, loss1: 0.64438, loss2_3: 79.87084\n",
      "\ttrain_acc: 0.8701, test_acc: \u001b[31m0.8682022471910112\u001b[0m, time: 74.87\n",
      "best_acc: 0.8682022471910112\n",
      "epoch: 46, loss: 80.33655, loss1: 0.64141, loss2_3: 79.69515\n",
      "\ttrain_acc: 0.8706, test_acc: \u001b[31m0.8681460674157303\u001b[0m, time: 74.86\n",
      "epoch: 47, loss: 79.95901, loss1: 0.63940, loss2_3: 79.31961\n",
      "\ttrain_acc: 0.8695, test_acc: \u001b[31m0.865252808988764\u001b[0m, time: 73.18\n",
      "epoch: 48, loss: 79.94920, loss1: 0.63759, loss2_3: 79.31161\n",
      "\ttrain_acc: 0.8711, test_acc: \u001b[31m0.8680056179775281\u001b[0m, time: 74.43\n",
      "epoch: 49, loss: 80.00730, loss1: 0.63717, loss2_3: 79.37013\n",
      "\ttrain_acc: 0.8709, test_acc: \u001b[31m0.8685674157303371\u001b[0m, time: 74.80\n",
      "best_acc: 0.8685674157303371\n",
      "epoch: 50, loss: 79.57836, loss1: 0.63486, loss2_3: 78.94349\n",
      "\ttrain_acc: 0.8714, test_acc: \u001b[31m0.868314606741573\u001b[0m, time: 74.81\n",
      "epoch: 51, loss: 79.55199, loss1: 0.63132, loss2_3: 78.92067\n",
      "\ttrain_acc: 0.8712, test_acc: \u001b[31m0.8675842696629213\u001b[0m, time: 74.52\n",
      "epoch: 52, loss: 79.48550, loss1: 0.63512, loss2_3: 78.85038\n",
      "\ttrain_acc: 0.8716, test_acc: \u001b[31m0.8694662921348315\u001b[0m, time: 73.98\n",
      "best_acc: 0.8694662921348315\n",
      "epoch: 53, loss: 79.38676, loss1: 0.63338, loss2_3: 78.75338\n",
      "\ttrain_acc: 0.8694, test_acc: \u001b[31m0.8664887640449438\u001b[0m, time: 75.30\n",
      "epoch: 54, loss: 79.06875, loss1: 0.63455, loss2_3: 78.43419\n",
      "\ttrain_acc: 0.8717, test_acc: \u001b[31m0.8698314606741573\u001b[0m, time: 74.78\n",
      "best_acc: 0.8698314606741573\n",
      "epoch: 55, loss: 78.89330, loss1: 0.62845, loss2_3: 78.26485\n",
      "\ttrain_acc: 0.8712, test_acc: \u001b[31m0.8685674157303371\u001b[0m, time: 74.88\n",
      "epoch: 56, loss: 78.94589, loss1: 0.63093, loss2_3: 78.31496\n",
      "\ttrain_acc: 0.8733, test_acc: \u001b[31m0.871685393258427\u001b[0m, time: 73.32\n",
      "best_acc: 0.871685393258427\n",
      "epoch: 57, loss: 78.82130, loss1: 0.63076, loss2_3: 78.19054\n",
      "\ttrain_acc: 0.8714, test_acc: \u001b[31m0.8677808988764045\u001b[0m, time: 74.33\n",
      "epoch: 58, loss: 78.51617, loss1: 0.62780, loss2_3: 77.88837\n",
      "\ttrain_acc: 0.8718, test_acc: \u001b[31m0.8691011235955056\u001b[0m, time: 74.95\n",
      "epoch: 59, loss: 78.46970, loss1: 0.62567, loss2_3: 77.84403\n",
      "\ttrain_acc: 0.8740, test_acc: \u001b[31m0.869943820224719\u001b[0m, time: 74.97\n",
      "epoch: 60, loss: 78.37714, loss1: 0.62739, loss2_3: 77.74975\n",
      "\ttrain_acc: 0.8734, test_acc: \u001b[31m0.8708707865168539\u001b[0m, time: 74.28\n",
      "epoch: 61, loss: 78.47672, loss1: 0.62624, loss2_3: 77.85048\n",
      "\ttrain_acc: 0.8735, test_acc: \u001b[31m0.8704494382022472\u001b[0m, time: 73.21\n",
      "epoch: 62, loss: 78.22934, loss1: 0.62270, loss2_3: 77.60664\n",
      "\ttrain_acc: 0.8743, test_acc: \u001b[31m0.8717415730337079\u001b[0m, time: 74.95\n",
      "best_acc: 0.8717415730337079\n",
      "epoch: 63, loss: 77.83635, loss1: 0.62149, loss2_3: 77.21487\n",
      "\ttrain_acc: 0.8742, test_acc: \u001b[31m0.871432584269663\u001b[0m, time: 74.89\n",
      "epoch: 64, loss: 78.17949, loss1: 0.62691, loss2_3: 77.55258\n",
      "\ttrain_acc: 0.8746, test_acc: \u001b[31m0.8714606741573033\u001b[0m, time: 74.97\n",
      "epoch: 65, loss: 77.68931, loss1: 0.62568, loss2_3: 77.06364\n",
      "\ttrain_acc: 0.8745, test_acc: \u001b[31m0.8705337078651686\u001b[0m, time: 73.90\n",
      "epoch: 66, loss: 77.65350, loss1: 0.62414, loss2_3: 77.02936\n",
      "\ttrain_acc: 0.8748, test_acc: \u001b[31m0.869943820224719\u001b[0m, time: 73.98\n",
      "epoch: 67, loss: 77.69185, loss1: 0.62229, loss2_3: 77.06956\n",
      "\ttrain_acc: 0.8753, test_acc: \u001b[31m0.8707584269662921\u001b[0m, time: 74.96\n",
      "epoch: 68, loss: 77.54291, loss1: 0.61969, loss2_3: 76.92322\n",
      "\ttrain_acc: 0.8752, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 75.06\n",
      "best_acc: 0.8720505617977528\n",
      "epoch: 69, loss: 77.60179, loss1: 0.61823, loss2_3: 76.98356\n",
      "\ttrain_acc: 0.8742, test_acc: \u001b[31m0.8718258426966292\u001b[0m, time: 74.73\n",
      "epoch: 70, loss: 77.50918, loss1: 0.61991, loss2_3: 76.88927\n",
      "\ttrain_acc: 0.8742, test_acc: \u001b[31m0.8701404494382022\u001b[0m, time: 73.09\n",
      "epoch: 71, loss: 77.42590, loss1: 0.61717, loss2_3: 76.80873\n",
      "\ttrain_acc: 0.8760, test_acc: \u001b[31m0.8721629213483146\u001b[0m, time: 74.57\n",
      "best_acc: 0.8721629213483146\n",
      "epoch: 72, loss: 77.48265, loss1: 0.62017, loss2_3: 76.86248\n",
      "\ttrain_acc: 0.8754, test_acc: \u001b[31m0.8708707865168539\u001b[0m, time: 74.84\n",
      "epoch: 73, loss: 77.21005, loss1: 0.61437, loss2_3: 76.59569\n",
      "\ttrain_acc: 0.8761, test_acc: \u001b[31m0.8714887640449438\u001b[0m, time: 74.86\n",
      "epoch: 74, loss: 77.23993, loss1: 0.62097, loss2_3: 76.61895\n",
      "\ttrain_acc: 0.8755, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 74.09\n",
      "epoch: 75, loss: 77.24451, loss1: 0.61683, loss2_3: 76.62768\n",
      "\ttrain_acc: 0.8759, test_acc: \u001b[31m0.8714044943820225\u001b[0m, time: 73.54\n",
      "epoch: 76, loss: 77.01873, loss1: 0.61576, loss2_3: 76.40297\n",
      "\ttrain_acc: 0.8763, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 74.97\n",
      "epoch: 77, loss: 76.84431, loss1: 0.61547, loss2_3: 76.22883\n",
      "\ttrain_acc: 0.8748, test_acc: \u001b[31m0.8703651685393259\u001b[0m, time: 74.91\n",
      "epoch: 78, loss: 76.82409, loss1: 0.61177, loss2_3: 76.21232\n",
      "\ttrain_acc: 0.8761, test_acc: \u001b[31m0.8721348314606742\u001b[0m, time: 74.96\n",
      "epoch: 79, loss: 76.61419, loss1: 0.61180, loss2_3: 76.00239\n",
      "\ttrain_acc: 0.8762, test_acc: \u001b[31m0.8710393258426966\u001b[0m, time: 73.61\n",
      "epoch: 80, loss: 76.73929, loss1: 0.61169, loss2_3: 76.12759\n",
      "\ttrain_acc: 0.8763, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 74.07\n",
      "epoch: 81, loss: 76.73170, loss1: 0.61590, loss2_3: 76.11579\n",
      "\ttrain_acc: 0.8775, test_acc: \u001b[31m0.8732303370786517\u001b[0m, time: 75.04\n",
      "best_acc: 0.8732303370786517\n",
      "epoch: 82, loss: 76.55051, loss1: 0.61240, loss2_3: 75.93811\n",
      "\ttrain_acc: 0.8753, test_acc: \u001b[31m0.8704494382022472\u001b[0m, time: 74.85\n",
      "epoch: 83, loss: 76.54600, loss1: 0.61093, loss2_3: 75.93507\n",
      "\ttrain_acc: 0.8777, test_acc: \u001b[31m0.8728932584269663\u001b[0m, time: 74.62\n",
      "epoch: 84, loss: 76.51706, loss1: 0.61150, loss2_3: 75.90556\n",
      "\ttrain_acc: 0.8778, test_acc: \u001b[31m0.8731179775280898\u001b[0m, time: 73.12\n",
      "epoch: 85, loss: 76.51932, loss1: 0.61418, loss2_3: 75.90513\n",
      "\ttrain_acc: 0.8766, test_acc: \u001b[31m0.8715449438202247\u001b[0m, time: 74.75\n",
      "epoch: 86, loss: 76.26584, loss1: 0.61101, loss2_3: 75.65483\n",
      "\ttrain_acc: 0.8756, test_acc: \u001b[31m0.8700561797752809\u001b[0m, time: 75.02\n",
      "epoch: 87, loss: 76.36083, loss1: 0.61073, loss2_3: 75.75010\n",
      "\ttrain_acc: 0.8774, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 75.03\n",
      "epoch: 88, loss: 76.32577, loss1: 0.61152, loss2_3: 75.71425\n",
      "\ttrain_acc: 0.8750, test_acc: \u001b[31m0.8687359550561797\u001b[0m, time: 74.05\n",
      "epoch: 89, loss: 76.25636, loss1: 0.61055, loss2_3: 75.64582\n",
      "\ttrain_acc: 0.8786, test_acc: \u001b[31m0.8731460674157303\u001b[0m, time: 73.57\n",
      "epoch: 90, loss: 76.11638, loss1: 0.60934, loss2_3: 75.50704\n",
      "\ttrain_acc: 0.8781, test_acc: \u001b[31m0.8730898876404495\u001b[0m, time: 74.98\n",
      "epoch: 91, loss: 76.07024, loss1: 0.60705, loss2_3: 75.46319\n",
      "\ttrain_acc: 0.8765, test_acc: \u001b[31m0.8701685393258427\u001b[0m, time: 74.90\n",
      "epoch: 92, loss: 76.26480, loss1: 0.60963, loss2_3: 75.65517\n",
      "\ttrain_acc: 0.8788, test_acc: \u001b[31m0.8732584269662922\u001b[0m, time: 74.95\n",
      "best_acc: 0.8732584269662922\n",
      "epoch: 93, loss: 75.94128, loss1: 0.61188, loss2_3: 75.32941\n",
      "\ttrain_acc: 0.8784, test_acc: \u001b[31m0.8729494382022472\u001b[0m, time: 73.56\n",
      "epoch: 94, loss: 76.05278, loss1: 0.61093, loss2_3: 75.44185\n",
      "\ttrain_acc: 0.8762, test_acc: \u001b[31m0.868623595505618\u001b[0m, time: 74.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 95, loss: 75.96024, loss1: 0.60390, loss2_3: 75.35635\n",
      "\ttrain_acc: 0.8788, test_acc: \u001b[31m0.8731460674157303\u001b[0m, time: 75.01\n",
      "epoch: 96, loss: 75.78150, loss1: 0.60791, loss2_3: 75.17358\n",
      "\ttrain_acc: 0.8795, test_acc: \u001b[31m0.8729494382022472\u001b[0m, time: 74.94\n",
      "epoch: 97, loss: 75.94135, loss1: 0.60708, loss2_3: 75.33427\n",
      "\ttrain_acc: 0.8796, test_acc: \u001b[31m0.8732022471910112\u001b[0m, time: 74.64\n",
      "epoch: 98, loss: 75.67301, loss1: 0.60566, loss2_3: 75.06735\n",
      "\ttrain_acc: 0.8794, test_acc: \u001b[31m0.871376404494382\u001b[0m, time: 73.08\n",
      "epoch: 99, loss: 75.60429, loss1: 0.60513, loss2_3: 74.99916\n",
      "\ttrain_acc: 0.8788, test_acc: \u001b[31m0.8724438202247191\u001b[0m, time: 74.84\n",
      "epoch: 100, loss: 75.49202, loss1: 0.60654, loss2_3: 74.88547\n",
      "\ttrain_acc: 0.8782, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 75.02\n",
      "epoch: 101, loss: 75.60382, loss1: 0.60471, loss2_3: 74.99911\n",
      "\ttrain_acc: 0.8793, test_acc: \u001b[31m0.8731179775280898\u001b[0m, time: 74.99\n",
      "epoch: 102, loss: 75.58287, loss1: 0.60924, loss2_3: 74.97363\n",
      "\ttrain_acc: 0.8793, test_acc: \u001b[31m0.8728370786516854\u001b[0m, time: 73.99\n",
      "epoch: 103, loss: 75.46063, loss1: 0.60393, loss2_3: 74.85669\n",
      "\ttrain_acc: 0.8797, test_acc: \u001b[31m0.8722191011235955\u001b[0m, time: 73.62\n",
      "epoch: 104, loss: 75.69799, loss1: 0.60532, loss2_3: 75.09266\n",
      "\ttrain_acc: 0.8790, test_acc: \u001b[31m0.8735955056179775\u001b[0m, time: 74.91\n",
      "best_acc: 0.8735955056179775\n",
      "epoch: 105, loss: 75.34871, loss1: 0.60621, loss2_3: 74.74250\n",
      "\ttrain_acc: 0.8800, test_acc: \u001b[31m0.8721910112359551\u001b[0m, time: 75.16\n",
      "epoch: 106, loss: 75.58153, loss1: 0.60368, loss2_3: 74.97784\n",
      "\ttrain_acc: 0.8789, test_acc: \u001b[31m0.8719662921348315\u001b[0m, time: 74.92\n",
      "epoch: 107, loss: 75.38925, loss1: 0.60560, loss2_3: 74.78364\n",
      "\ttrain_acc: 0.8792, test_acc: \u001b[31m0.8727247191011236\u001b[0m, time: 73.60\n",
      "epoch: 108, loss: 75.35277, loss1: 0.60444, loss2_3: 74.74833\n",
      "\ttrain_acc: 0.8807, test_acc: \u001b[31m0.8714606741573033\u001b[0m, time: 74.68\n",
      "epoch: 109, loss: 75.28438, loss1: 0.60371, loss2_3: 74.68066\n",
      "\ttrain_acc: 0.8785, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 74.99\n",
      "epoch: 110, loss: 75.13781, loss1: 0.60557, loss2_3: 74.53224\n",
      "\ttrain_acc: 0.8805, test_acc: \u001b[31m0.8729775280898876\u001b[0m, time: 74.94\n",
      "epoch: 111, loss: 75.23223, loss1: 0.59932, loss2_3: 74.63291\n",
      "\ttrain_acc: 0.8799, test_acc: \u001b[31m0.8722191011235955\u001b[0m, time: 74.29\n",
      "epoch: 112, loss: 75.23536, loss1: 0.60457, loss2_3: 74.63079\n",
      "\ttrain_acc: 0.8800, test_acc: \u001b[31m0.8721067415730337\u001b[0m, time: 73.41\n",
      "epoch: 113, loss: 75.12038, loss1: 0.60250, loss2_3: 74.51788\n",
      "\ttrain_acc: 0.8809, test_acc: \u001b[31m0.8733988764044944\u001b[0m, time: 74.83\n",
      "epoch: 114, loss: 75.02149, loss1: 0.60076, loss2_3: 74.42072\n",
      "\ttrain_acc: 0.8809, test_acc: \u001b[31m0.871685393258427\u001b[0m, time: 74.95\n",
      "epoch: 115, loss: 74.95109, loss1: 0.60212, loss2_3: 74.34897\n",
      "\ttrain_acc: 0.8776, test_acc: \u001b[31m0.8702808988764045\u001b[0m, time: 74.91\n",
      "epoch: 116, loss: 74.97319, loss1: 0.60341, loss2_3: 74.36978\n",
      "\ttrain_acc: 0.8802, test_acc: \u001b[31m0.8728651685393258\u001b[0m, time: 73.71\n",
      "epoch: 117, loss: 75.05218, loss1: 0.59927, loss2_3: 74.45291\n",
      "\ttrain_acc: 0.8794, test_acc: \u001b[31m0.8720224719101124\u001b[0m, time: 73.96\n",
      "epoch: 118, loss: 74.89942, loss1: 0.59699, loss2_3: 74.30243\n",
      "\ttrain_acc: 0.8817, test_acc: \u001b[31m0.875308988764045\u001b[0m, time: 74.96\n",
      "best_acc: 0.875308988764045\n",
      "epoch: 119, loss: 74.82997, loss1: 0.59897, loss2_3: 74.23100\n",
      "\ttrain_acc: 0.8812, test_acc: \u001b[31m0.8725\u001b[0m, time: 74.87\n",
      "epoch: 120, loss: 74.65971, loss1: 0.59673, loss2_3: 74.06298\n",
      "\ttrain_acc: 0.8818, test_acc: \u001b[31m0.8729213483146068\u001b[0m, time: 74.85\n",
      "epoch: 121, loss: 74.69475, loss1: 0.59773, loss2_3: 74.09701\n",
      "\ttrain_acc: 0.8814, test_acc: \u001b[31m0.8731741573033708\u001b[0m, time: 73.20\n",
      "epoch: 122, loss: 74.52122, loss1: 0.60181, loss2_3: 73.91941\n",
      "\ttrain_acc: 0.8809, test_acc: \u001b[31m0.8732865168539325\u001b[0m, time: 74.46\n",
      "epoch: 123, loss: 74.75121, loss1: 0.60084, loss2_3: 74.15037\n",
      "\ttrain_acc: 0.8816, test_acc: \u001b[31m0.873061797752809\u001b[0m, time: 74.90\n",
      "epoch: 124, loss: 74.54121, loss1: 0.59788, loss2_3: 73.94334\n",
      "\ttrain_acc: 0.8821, test_acc: \u001b[31m0.8734550561797753\u001b[0m, time: 74.87\n",
      "epoch: 125, loss: 74.59138, loss1: 0.60329, loss2_3: 73.98808\n",
      "\ttrain_acc: 0.8799, test_acc: \u001b[31m0.8692415730337079\u001b[0m, time: 74.21\n",
      "epoch: 126, loss: 74.41542, loss1: 0.59896, loss2_3: 73.81646\n",
      "\ttrain_acc: 0.8820, test_acc: \u001b[31m0.8729775280898876\u001b[0m, time: 73.48\n",
      "epoch: 127, loss: 74.58442, loss1: 0.59547, loss2_3: 73.98895\n",
      "\ttrain_acc: 0.8820, test_acc: \u001b[31m0.8725842696629214\u001b[0m, time: 74.80\n",
      "epoch: 128, loss: 74.34321, loss1: 0.59608, loss2_3: 73.74713\n",
      "\ttrain_acc: 0.8824, test_acc: \u001b[31m0.8719943820224719\u001b[0m, time: 74.83\n",
      "epoch: 129, loss: 74.19580, loss1: 0.59534, loss2_3: 73.60045\n",
      "\ttrain_acc: 0.8771, test_acc: \u001b[31m0.8669101123595505\u001b[0m, time: 74.92\n",
      "epoch: 130, loss: 74.36994, loss1: 0.59756, loss2_3: 73.77239\n",
      "\ttrain_acc: 0.8823, test_acc: \u001b[31m0.8721067415730337\u001b[0m, time: 73.47\n",
      "epoch: 131, loss: 74.09586, loss1: 0.59562, loss2_3: 73.50024\n",
      "\ttrain_acc: 0.8789, test_acc: \u001b[31m0.8693539325842696\u001b[0m, time: 74.03\n",
      "epoch: 132, loss: 74.12031, loss1: 0.59738, loss2_3: 73.52293\n",
      "\ttrain_acc: 0.8816, test_acc: \u001b[31m0.8713483146067416\u001b[0m, time: 75.10\n",
      "epoch: 133, loss: 74.20094, loss1: 0.59960, loss2_3: 73.60134\n",
      "\ttrain_acc: 0.8823, test_acc: \u001b[31m0.8720224719101124\u001b[0m, time: 75.04\n",
      "epoch: 134, loss: 74.03910, loss1: 0.59592, loss2_3: 73.44318\n",
      "\ttrain_acc: 0.8818, test_acc: \u001b[31m0.8706179775280899\u001b[0m, time: 74.93\n",
      "epoch: 135, loss: 73.86788, loss1: 0.59546, loss2_3: 73.27242\n",
      "\ttrain_acc: 0.8827, test_acc: \u001b[31m0.8724438202247191\u001b[0m, time: 73.30\n",
      "epoch: 136, loss: 74.12402, loss1: 0.59393, loss2_3: 73.53009\n",
      "\ttrain_acc: 0.8825, test_acc: \u001b[31m0.8710112359550561\u001b[0m, time: 74.56\n",
      "epoch: 137, loss: 73.69256, loss1: 0.59470, loss2_3: 73.09786\n",
      "\ttrain_acc: 0.8843, test_acc: \u001b[31m0.8735393258426967\u001b[0m, time: 75.27\n",
      "epoch: 138, loss: 73.81914, loss1: 0.59396, loss2_3: 73.22517\n",
      "\ttrain_acc: 0.8815, test_acc: \u001b[31m0.8698033707865168\u001b[0m, time: 75.15\n",
      "epoch: 139, loss: 73.75111, loss1: 0.59389, loss2_3: 73.15722\n",
      "\ttrain_acc: 0.8835, test_acc: \u001b[31m0.873876404494382\u001b[0m, time: 74.36\n",
      "epoch: 140, loss: 73.66540, loss1: 0.59270, loss2_3: 73.07270\n",
      "\ttrain_acc: 0.8828, test_acc: \u001b[31m0.8715168539325843\u001b[0m, time: 73.56\n",
      "epoch: 141, loss: 73.58824, loss1: 0.59520, loss2_3: 72.99304\n",
      "\ttrain_acc: 0.8833, test_acc: \u001b[31m0.8724719101123596\u001b[0m, time: 75.11\n",
      "epoch: 142, loss: 73.63512, loss1: 0.59335, loss2_3: 73.04177\n",
      "\ttrain_acc: 0.8838, test_acc: \u001b[31m0.8744662921348315\u001b[0m, time: 75.02\n",
      "epoch: 143, loss: 73.64206, loss1: 0.59160, loss2_3: 73.05046\n",
      "\ttrain_acc: 0.8823, test_acc: \u001b[31m0.8718258426966292\u001b[0m, time: 75.23\n",
      "epoch: 144, loss: 73.63231, loss1: 0.59094, loss2_3: 73.04136\n",
      "\ttrain_acc: 0.8834, test_acc: \u001b[31m0.8710674157303371\u001b[0m, time: 73.98\n",
      "epoch: 145, loss: 73.46700, loss1: 0.59035, loss2_3: 72.87665\n",
      "\ttrain_acc: 0.8839, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 73.78\n",
      "epoch: 146, loss: 73.42106, loss1: 0.59043, loss2_3: 72.83063\n",
      "\ttrain_acc: 0.8844, test_acc: \u001b[31m0.8739606741573034\u001b[0m, time: 75.21\n",
      "epoch: 147, loss: 73.32226, loss1: 0.59430, loss2_3: 72.72796\n",
      "\ttrain_acc: 0.8849, test_acc: \u001b[31m0.8722471910112359\u001b[0m, time: 75.17\n",
      "epoch: 148, loss: 73.16444, loss1: 0.59051, loss2_3: 72.57393\n",
      "\ttrain_acc: 0.8849, test_acc: \u001b[31m0.8743820224719101\u001b[0m, time: 75.14\n",
      "epoch: 149, loss: 73.19254, loss1: 0.58893, loss2_3: 72.60361\n",
      "\ttrain_acc: 0.8854, test_acc: \u001b[31m0.8727247191011236\u001b[0m, time: 73.57\n",
      "epoch: 150, loss: 73.11194, loss1: 0.58901, loss2_3: 72.52293\n",
      "\ttrain_acc: 0.8846, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 77.56\n",
      "epoch: 151, loss: 73.21729, loss1: 0.58904, loss2_3: 72.62825\n",
      "\ttrain_acc: 0.8837, test_acc: \u001b[31m0.8705337078651686\u001b[0m, time: 78.99\n",
      "epoch: 152, loss: 72.94861, loss1: 0.59072, loss2_3: 72.35789\n",
      "\ttrain_acc: 0.8855, test_acc: \u001b[31m0.8733426966292135\u001b[0m, time: 78.80\n",
      "epoch: 153, loss: 73.10427, loss1: 0.59001, loss2_3: 72.51426\n",
      "\ttrain_acc: 0.8844, test_acc: \u001b[31m0.8724438202247191\u001b[0m, time: 78.43\n",
      "epoch: 154, loss: 73.02295, loss1: 0.58731, loss2_3: 72.43564\n",
      "\ttrain_acc: 0.8849, test_acc: \u001b[31m0.8718258426966292\u001b[0m, time: 78.63\n",
      "epoch: 155, loss: 73.10277, loss1: 0.58967, loss2_3: 72.51310\n",
      "\ttrain_acc: 0.8859, test_acc: \u001b[31m0.8735112359550562\u001b[0m, time: 74.99\n",
      "epoch: 156, loss: 72.84404, loss1: 0.59059, loss2_3: 72.25345\n",
      "\ttrain_acc: 0.8855, test_acc: \u001b[31m0.871432584269663\u001b[0m, time: 73.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 157, loss: 72.91923, loss1: 0.58940, loss2_3: 72.32983\n",
      "\ttrain_acc: 0.8860, test_acc: \u001b[31m0.8730056179775281\u001b[0m, time: 74.62\n",
      "epoch: 158, loss: 72.85222, loss1: 0.58683, loss2_3: 72.26539\n",
      "\ttrain_acc: 0.8860, test_acc: \u001b[31m0.8731741573033708\u001b[0m, time: 75.08\n",
      "epoch: 159, loss: 72.81719, loss1: 0.58849, loss2_3: 72.22870\n",
      "\ttrain_acc: 0.8867, test_acc: \u001b[31m0.8732865168539325\u001b[0m, time: 75.17\n",
      "epoch: 160, loss: 72.74823, loss1: 0.58626, loss2_3: 72.16197\n",
      "\ttrain_acc: 0.8843, test_acc: \u001b[31m0.8723876404494382\u001b[0m, time: 74.41\n",
      "epoch: 161, loss: 72.59940, loss1: 0.58684, loss2_3: 72.01256\n",
      "\ttrain_acc: 0.8855, test_acc: \u001b[31m0.8714887640449438\u001b[0m, time: 73.28\n",
      "epoch: 162, loss: 72.60635, loss1: 0.58504, loss2_3: 72.02132\n",
      "\ttrain_acc: 0.8846, test_acc: \u001b[31m0.8698876404494382\u001b[0m, time: 75.09\n",
      "epoch: 163, loss: 72.53385, loss1: 0.58764, loss2_3: 71.94621\n",
      "\ttrain_acc: 0.8866, test_acc: \u001b[31m0.873061797752809\u001b[0m, time: 75.05\n",
      "epoch: 164, loss: 72.43418, loss1: 0.58682, loss2_3: 71.84735\n",
      "\ttrain_acc: 0.8869, test_acc: \u001b[31m0.8733426966292135\u001b[0m, time: 75.12\n",
      "epoch: 165, loss: 72.71455, loss1: 0.58672, loss2_3: 72.12783\n",
      "\ttrain_acc: 0.8877, test_acc: \u001b[31m0.8723033707865169\u001b[0m, time: 74.14\n",
      "epoch: 166, loss: 72.55029, loss1: 0.58673, loss2_3: 71.96356\n",
      "\ttrain_acc: 0.8861, test_acc: \u001b[31m0.8728370786516854\u001b[0m, time: 73.90\n",
      "epoch: 167, loss: 72.63932, loss1: 0.58634, loss2_3: 72.05298\n",
      "\ttrain_acc: 0.8863, test_acc: \u001b[31m0.8722191011235955\u001b[0m, time: 75.22\n",
      "epoch: 168, loss: 72.31057, loss1: 0.58479, loss2_3: 71.72578\n",
      "\ttrain_acc: 0.8878, test_acc: \u001b[31m0.873314606741573\u001b[0m, time: 75.22\n",
      "epoch: 169, loss: 72.09729, loss1: 0.58474, loss2_3: 71.51255\n",
      "\ttrain_acc: 0.8873, test_acc: \u001b[31m0.8738483146067416\u001b[0m, time: 75.09\n",
      "epoch: 170, loss: 72.18520, loss1: 0.58417, loss2_3: 71.60103\n",
      "\ttrain_acc: 0.8860, test_acc: \u001b[31m0.8715449438202247\u001b[0m, time: 73.47\n",
      "epoch: 171, loss: 72.10651, loss1: 0.58385, loss2_3: 71.52266\n",
      "\ttrain_acc: 0.8873, test_acc: \u001b[31m0.8739325842696629\u001b[0m, time: 74.55\n",
      "epoch: 172, loss: 72.21002, loss1: 0.58292, loss2_3: 71.62710\n",
      "\ttrain_acc: 0.8870, test_acc: \u001b[31m0.8721910112359551\u001b[0m, time: 75.09\n",
      "epoch: 173, loss: 72.38236, loss1: 0.58304, loss2_3: 71.79932\n",
      "\ttrain_acc: 0.8864, test_acc: \u001b[31m0.8722191011235955\u001b[0m, time: 75.14\n",
      "epoch: 174, loss: 71.76497, loss1: 0.58113, loss2_3: 71.18384\n",
      "\ttrain_acc: 0.8855, test_acc: \u001b[31m0.8706460674157304\u001b[0m, time: 74.57\n",
      "epoch: 175, loss: 71.85286, loss1: 0.58471, loss2_3: 71.26815\n",
      "\ttrain_acc: 0.8882, test_acc: \u001b[31m0.8730898876404495\u001b[0m, time: 73.16\n",
      "epoch: 176, loss: 71.85873, loss1: 0.58144, loss2_3: 71.27730\n",
      "\ttrain_acc: 0.8867, test_acc: \u001b[31m0.8698314606741573\u001b[0m, time: 75.08\n",
      "epoch: 177, loss: 71.62629, loss1: 0.58149, loss2_3: 71.04480\n",
      "\ttrain_acc: 0.8876, test_acc: \u001b[31m0.8714606741573033\u001b[0m, time: 75.02\n",
      "epoch: 178, loss: 71.90843, loss1: 0.58005, loss2_3: 71.32837\n",
      "\ttrain_acc: 0.8878, test_acc: \u001b[31m0.871685393258427\u001b[0m, time: 74.96\n",
      "epoch: 179, loss: 71.69850, loss1: 0.58151, loss2_3: 71.11699\n",
      "\ttrain_acc: 0.8896, test_acc: \u001b[31m0.8729213483146068\u001b[0m, time: 73.88\n",
      "epoch: 180, loss: 71.74579, loss1: 0.58244, loss2_3: 71.16335\n",
      "\ttrain_acc: 0.8871, test_acc: \u001b[31m0.8698314606741573\u001b[0m, time: 73.84\n",
      "epoch: 181, loss: 71.48089, loss1: 0.58078, loss2_3: 70.90010\n",
      "\ttrain_acc: 0.8895, test_acc: \u001b[31m0.8727528089887641\u001b[0m, time: 74.96\n",
      "epoch: 182, loss: 71.52893, loss1: 0.58329, loss2_3: 70.94564\n",
      "\ttrain_acc: 0.8903, test_acc: \u001b[31m0.8726404494382023\u001b[0m, time: 74.96\n",
      "epoch: 183, loss: 71.46094, loss1: 0.57717, loss2_3: 70.88378\n",
      "\ttrain_acc: 0.8892, test_acc: \u001b[31m0.871629213483146\u001b[0m, time: 75.33\n",
      "epoch: 184, loss: 71.37911, loss1: 0.58237, loss2_3: 70.79674\n",
      "\ttrain_acc: 0.8899, test_acc: \u001b[31m0.8740449438202247\u001b[0m, time: 73.28\n",
      "epoch: 185, loss: 71.17434, loss1: 0.57951, loss2_3: 70.59483\n",
      "\ttrain_acc: 0.8874, test_acc: \u001b[31m0.8691292134831461\u001b[0m, time: 74.55\n",
      "epoch: 186, loss: 71.29030, loss1: 0.57932, loss2_3: 70.71098\n",
      "\ttrain_acc: 0.8873, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 75.11\n",
      "epoch: 187, loss: 71.13971, loss1: 0.57665, loss2_3: 70.56305\n",
      "\ttrain_acc: 0.8889, test_acc: \u001b[31m0.8694662921348315\u001b[0m, time: 75.07\n",
      "epoch: 188, loss: 71.14182, loss1: 0.57773, loss2_3: 70.56410\n",
      "\ttrain_acc: 0.8905, test_acc: \u001b[31m0.8721629213483146\u001b[0m, time: 74.32\n",
      "epoch: 189, loss: 70.90762, loss1: 0.57788, loss2_3: 70.32974\n",
      "\ttrain_acc: 0.8902, test_acc: \u001b[31m0.8711516853932584\u001b[0m, time: 73.47\n",
      "epoch: 190, loss: 70.82967, loss1: 0.57559, loss2_3: 70.25408\n",
      "\ttrain_acc: 0.8892, test_acc: \u001b[31m0.8703651685393259\u001b[0m, time: 74.79\n",
      "epoch: 191, loss: 70.94776, loss1: 0.57342, loss2_3: 70.37434\n",
      "\ttrain_acc: 0.8921, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 78.71\n",
      "epoch: 192, loss: 70.82577, loss1: 0.57648, loss2_3: 70.24929\n",
      "\ttrain_acc: 0.8911, test_acc: \u001b[31m0.8723314606741573\u001b[0m, time: 78.70\n",
      "epoch: 193, loss: 70.86268, loss1: 0.57464, loss2_3: 70.28803\n",
      "\ttrain_acc: 0.8919, test_acc: \u001b[31m0.8721067415730337\u001b[0m, time: 73.96\n",
      "epoch: 194, loss: 70.74137, loss1: 0.57846, loss2_3: 70.16291\n",
      "\ttrain_acc: 0.8912, test_acc: \u001b[31m0.8730056179775281\u001b[0m, time: 75.21\n",
      "epoch: 195, loss: 70.63807, loss1: 0.57278, loss2_3: 70.06529\n",
      "\ttrain_acc: 0.8914, test_acc: \u001b[31m0.8716573033707865\u001b[0m, time: 75.01\n",
      "epoch: 196, loss: 70.67955, loss1: 0.57834, loss2_3: 70.10122\n",
      "\ttrain_acc: 0.8917, test_acc: \u001b[31m0.8724719101123596\u001b[0m, time: 74.67\n",
      "epoch: 197, loss: 70.59243, loss1: 0.57200, loss2_3: 70.02043\n",
      "\ttrain_acc: 0.8911, test_acc: \u001b[31m0.8703370786516854\u001b[0m, time: 73.28\n",
      "epoch: 198, loss: 70.48364, loss1: 0.57472, loss2_3: 69.90893\n",
      "\ttrain_acc: 0.8914, test_acc: \u001b[31m0.8703089887640449\u001b[0m, time: 74.91\n",
      "epoch: 199, loss: 70.43412, loss1: 0.57458, loss2_3: 69.85954\n",
      "\ttrain_acc: 0.8918, test_acc: \u001b[31m0.8708707865168539\u001b[0m, time: 74.97\n",
      "epoch: 200, loss: 70.17595, loss1: 0.57393, loss2_3: 69.60202\n",
      "\ttrain_acc: 0.8910, test_acc: \u001b[31m0.8682584269662922\u001b[0m, time: 74.86\n",
      "epoch: 201, loss: 70.16040, loss1: 0.57300, loss2_3: 69.58739\n",
      "\ttrain_acc: 0.8927, test_acc: \u001b[31m0.8719101123595505\u001b[0m, time: 73.95\n",
      "epoch: 202, loss: 70.24568, loss1: 0.57572, loss2_3: 69.66996\n",
      "\ttrain_acc: 0.8934, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 73.75\n",
      "epoch: 203, loss: 70.09943, loss1: 0.57272, loss2_3: 69.52670\n",
      "\ttrain_acc: 0.8926, test_acc: \u001b[31m0.8720786516853932\u001b[0m, time: 74.95\n",
      "epoch: 204, loss: 69.99936, loss1: 0.57163, loss2_3: 69.42773\n",
      "\ttrain_acc: 0.8934, test_acc: \u001b[31m0.8716573033707865\u001b[0m, time: 75.02\n",
      "epoch: 205, loss: 69.93118, loss1: 0.57044, loss2_3: 69.36074\n",
      "\ttrain_acc: 0.8933, test_acc: \u001b[31m0.8706741573033708\u001b[0m, time: 74.94\n",
      "epoch: 206, loss: 69.76567, loss1: 0.56704, loss2_3: 69.19863\n",
      "\ttrain_acc: 0.8924, test_acc: \u001b[31m0.8691292134831461\u001b[0m, time: 73.38\n",
      "epoch: 207, loss: 69.77686, loss1: 0.57178, loss2_3: 69.20508\n",
      "\ttrain_acc: 0.8920, test_acc: \u001b[31m0.8709269662921348\u001b[0m, time: 74.10\n",
      "epoch: 208, loss: 69.82823, loss1: 0.56942, loss2_3: 69.25881\n",
      "\ttrain_acc: 0.8912, test_acc: \u001b[31m0.8688483146067416\u001b[0m, time: 74.87\n",
      "epoch: 209, loss: 69.76071, loss1: 0.56716, loss2_3: 69.19355\n",
      "\ttrain_acc: 0.8900, test_acc: \u001b[31m0.8681741573033708\u001b[0m, time: 74.99\n",
      "epoch: 210, loss: 69.33967, loss1: 0.56819, loss2_3: 68.77148\n",
      "\ttrain_acc: 0.8931, test_acc: \u001b[31m0.8704494382022472\u001b[0m, time: 74.61\n",
      "epoch: 211, loss: 69.36759, loss1: 0.56932, loss2_3: 68.79827\n",
      "\ttrain_acc: 0.8915, test_acc: \u001b[31m0.8715168539325843\u001b[0m, time: 73.00\n",
      "epoch: 212, loss: 69.33210, loss1: 0.57037, loss2_3: 68.76173\n",
      "\ttrain_acc: 0.8957, test_acc: \u001b[31m0.871376404494382\u001b[0m, time: 74.51\n",
      "epoch: 213, loss: 69.26300, loss1: 0.56962, loss2_3: 68.69339\n",
      "\ttrain_acc: 0.8936, test_acc: \u001b[31m0.8712078651685393\u001b[0m, time: 74.78\n",
      "epoch: 214, loss: 69.31773, loss1: 0.56423, loss2_3: 68.75350\n",
      "\ttrain_acc: 0.8928, test_acc: \u001b[31m0.8698314606741573\u001b[0m, time: 74.90\n",
      "epoch: 215, loss: 69.21224, loss1: 0.56709, loss2_3: 68.64515\n",
      "\ttrain_acc: 0.8919, test_acc: \u001b[31m0.868623595505618\u001b[0m, time: 74.11\n",
      "epoch: 216, loss: 69.05615, loss1: 0.56544, loss2_3: 68.49071\n",
      "\ttrain_acc: 0.8909, test_acc: \u001b[31m0.8647191011235955\u001b[0m, time: 73.45\n",
      "epoch: 217, loss: 68.92505, loss1: 0.56433, loss2_3: 68.36072\n",
      "\ttrain_acc: 0.8933, test_acc: \u001b[31m0.8693539325842696\u001b[0m, time: 74.86\n",
      "epoch: 218, loss: 69.02993, loss1: 0.56787, loss2_3: 68.46206\n",
      "\ttrain_acc: 0.8958, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 75.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 219, loss: 68.74286, loss1: 0.56574, loss2_3: 68.17712\n",
      "\ttrain_acc: 0.8960, test_acc: \u001b[31m0.8702808988764045\u001b[0m, time: 74.89\n",
      "epoch: 220, loss: 68.92646, loss1: 0.56812, loss2_3: 68.35834\n",
      "\ttrain_acc: 0.8974, test_acc: \u001b[31m0.8703370786516854\u001b[0m, time: 73.46\n",
      "epoch: 221, loss: 68.81938, loss1: 0.56765, loss2_3: 68.25173\n",
      "\ttrain_acc: 0.8957, test_acc: \u001b[31m0.8697752808988765\u001b[0m, time: 74.01\n",
      "epoch: 222, loss: 68.61715, loss1: 0.56581, loss2_3: 68.05134\n",
      "\ttrain_acc: 0.8979, test_acc: \u001b[31m0.8712921348314607\u001b[0m, time: 74.91\n",
      "epoch: 223, loss: 68.66962, loss1: 0.56193, loss2_3: 68.10769\n",
      "\ttrain_acc: 0.8959, test_acc: \u001b[31m0.8697191011235955\u001b[0m, time: 74.78\n",
      "epoch: 224, loss: 68.43855, loss1: 0.56151, loss2_3: 67.87705\n",
      "\ttrain_acc: 0.8964, test_acc: \u001b[31m0.8705898876404494\u001b[0m, time: 74.78\n",
      "epoch: 225, loss: 68.36566, loss1: 0.55860, loss2_3: 67.80706\n",
      "\ttrain_acc: 0.8898, test_acc: \u001b[31m0.8662640449438203\u001b[0m, time: 73.15\n",
      "epoch: 226, loss: 68.52762, loss1: 0.56277, loss2_3: 67.96485\n",
      "\ttrain_acc: 0.8964, test_acc: \u001b[31m0.8712078651685393\u001b[0m, time: 74.67\n",
      "epoch: 227, loss: 68.09155, loss1: 0.56169, loss2_3: 67.52985\n",
      "\ttrain_acc: 0.8983, test_acc: \u001b[31m0.869691011235955\u001b[0m, time: 75.03\n",
      "epoch: 228, loss: 68.29123, loss1: 0.56293, loss2_3: 67.72830\n",
      "\ttrain_acc: 0.8865, test_acc: \u001b[31m0.8615168539325843\u001b[0m, time: 74.89\n",
      "epoch: 229, loss: 68.16091, loss1: 0.56335, loss2_3: 67.59756\n",
      "\ttrain_acc: 0.8988, test_acc: \u001b[31m0.8700842696629213\u001b[0m, time: 74.27\n",
      "epoch: 230, loss: 67.94003, loss1: 0.55901, loss2_3: 67.38101\n",
      "\ttrain_acc: 0.8971, test_acc: \u001b[31m0.8692415730337079\u001b[0m, time: 73.48\n",
      "epoch: 231, loss: 67.86167, loss1: 0.55876, loss2_3: 67.30291\n",
      "\ttrain_acc: 0.8959, test_acc: \u001b[31m0.8680898876404495\u001b[0m, time: 74.89\n",
      "epoch: 232, loss: 67.99537, loss1: 0.55871, loss2_3: 67.43666\n",
      "\ttrain_acc: 0.8980, test_acc: \u001b[31m0.8714044943820225\u001b[0m, time: 75.00\n",
      "epoch: 233, loss: 67.53952, loss1: 0.55521, loss2_3: 66.98431\n",
      "\ttrain_acc: 0.8927, test_acc: \u001b[31m0.8626685393258426\u001b[0m, time: 74.81\n",
      "epoch: 234, loss: 67.63834, loss1: 0.55693, loss2_3: 67.08141\n",
      "\ttrain_acc: 0.8932, test_acc: \u001b[31m0.8670224719101124\u001b[0m, time: 73.58\n",
      "epoch: 235, loss: 67.42553, loss1: 0.55947, loss2_3: 66.86606\n",
      "\ttrain_acc: 0.8996, test_acc: \u001b[31m0.8692134831460674\u001b[0m, time: 74.06\n",
      "epoch: 236, loss: 67.41195, loss1: 0.55991, loss2_3: 66.85203\n",
      "\ttrain_acc: 0.8994, test_acc: \u001b[31m0.8710393258426966\u001b[0m, time: 74.86\n",
      "epoch: 237, loss: 67.27930, loss1: 0.55647, loss2_3: 66.72283\n",
      "\ttrain_acc: 0.8994, test_acc: \u001b[31m0.8703932584269662\u001b[0m, time: 74.86\n",
      "epoch: 238, loss: 67.26098, loss1: 0.55409, loss2_3: 66.70689\n",
      "\ttrain_acc: 0.9015, test_acc: \u001b[31m0.8687921348314607\u001b[0m, time: 74.53\n",
      "epoch: 239, loss: 67.28803, loss1: 0.55777, loss2_3: 66.73026\n",
      "\ttrain_acc: 0.9001, test_acc: \u001b[31m0.8713202247191011\u001b[0m, time: 72.95\n",
      "epoch: 240, loss: 66.92176, loss1: 0.55552, loss2_3: 66.36624\n",
      "\ttrain_acc: 0.9014, test_acc: \u001b[31m0.8700280898876405\u001b[0m, time: 74.72\n",
      "epoch: 241, loss: 66.85611, loss1: 0.55507, loss2_3: 66.30104\n",
      "\ttrain_acc: 0.8970, test_acc: \u001b[31m0.8682865168539325\u001b[0m, time: 74.86\n",
      "epoch: 242, loss: 66.88630, loss1: 0.55359, loss2_3: 66.33271\n",
      "\ttrain_acc: 0.9020, test_acc: \u001b[31m0.8692134831460674\u001b[0m, time: 74.87\n",
      "epoch: 243, loss: 66.93004, loss1: 0.55204, loss2_3: 66.37801\n",
      "\ttrain_acc: 0.8973, test_acc: \u001b[31m0.8668258426966292\u001b[0m, time: 74.18\n",
      "epoch: 244, loss: 66.61949, loss1: 0.55512, loss2_3: 66.06437\n",
      "\ttrain_acc: 0.9030, test_acc: \u001b[31m0.868876404494382\u001b[0m, time: 73.43\n",
      "epoch: 245, loss: 66.62959, loss1: 0.55175, loss2_3: 66.07784\n",
      "\ttrain_acc: 0.8989, test_acc: \u001b[31m0.8674157303370786\u001b[0m, time: 74.90\n",
      "epoch: 246, loss: 66.78399, loss1: 0.55238, loss2_3: 66.23162\n",
      "\ttrain_acc: 0.8997, test_acc: \u001b[31m0.8673033707865169\u001b[0m, time: 74.95\n",
      "epoch: 247, loss: 66.59780, loss1: 0.55199, loss2_3: 66.04580\n",
      "\ttrain_acc: 0.9023, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 74.81\n",
      "epoch: 248, loss: 66.48228, loss1: 0.55242, loss2_3: 65.92986\n",
      "\ttrain_acc: 0.9023, test_acc: \u001b[31m0.8693539325842696\u001b[0m, time: 73.29\n",
      "epoch: 249, loss: 66.28756, loss1: 0.55272, loss2_3: 65.73484\n",
      "\ttrain_acc: 0.9045, test_acc: \u001b[31m0.8673876404494382\u001b[0m, time: 73.92\n",
      "epoch: 250, loss: 66.48587, loss1: 0.54909, loss2_3: 65.93678\n",
      "\ttrain_acc: 0.9039, test_acc: \u001b[31m0.8698595505617978\u001b[0m, time: 74.78\n",
      "epoch: 1, loss: 158.19058, loss1: 1.69059, loss2_3: 156.49998\n",
      "\ttrain_acc: 0.7827, test_acc: \u001b[31m0.7856460674157303\u001b[0m, time: 76.28\n",
      "best_acc: 0.7856460674157303\n",
      "epoch: 2, loss: 109.87429, loss1: 0.89850, loss2_3: 108.97579\n",
      "\ttrain_acc: 0.8243, test_acc: \u001b[31m0.8262078651685393\u001b[0m, time: 74.92\n",
      "best_acc: 0.8262078651685393\n",
      "epoch: 3, loss: 101.22614, loss1: 0.84803, loss2_3: 100.37810\n",
      "\ttrain_acc: 0.8204, test_acc: \u001b[31m0.8213202247191012\u001b[0m, time: 73.65\n",
      "epoch: 4, loss: 97.66147, loss1: 0.81769, loss2_3: 96.84378\n",
      "\ttrain_acc: 0.8380, test_acc: \u001b[31m0.8385674157303371\u001b[0m, time: 75.07\n",
      "best_acc: 0.8385674157303371\n",
      "epoch: 5, loss: 95.16665, loss1: 0.78804, loss2_3: 94.37860\n",
      "\ttrain_acc: 0.8454, test_acc: \u001b[31m0.8468820224719101\u001b[0m, time: 74.94\n",
      "best_acc: 0.8468820224719101\n",
      "epoch: 6, loss: 94.05684, loss1: 0.78241, loss2_3: 93.27443\n",
      "\ttrain_acc: 0.8222, test_acc: \u001b[31m0.8217134831460674\u001b[0m, time: 75.00\n",
      "epoch: 7, loss: 92.02879, loss1: 0.76393, loss2_3: 91.26485\n",
      "\ttrain_acc: 0.8468, test_acc: \u001b[31m0.8454213483146067\u001b[0m, time: 73.72\n",
      "epoch: 8, loss: 91.12734, loss1: 0.75714, loss2_3: 90.37021\n",
      "\ttrain_acc: 0.8520, test_acc: \u001b[31m0.8524157303370786\u001b[0m, time: 74.16\n",
      "best_acc: 0.8524157303370786\n",
      "epoch: 9, loss: 90.52013, loss1: 0.74710, loss2_3: 89.77303\n",
      "\ttrain_acc: 0.8501, test_acc: \u001b[31m0.8502528089887641\u001b[0m, time: 75.17\n",
      "epoch: 10, loss: 89.81725, loss1: 0.73646, loss2_3: 89.08079\n",
      "\ttrain_acc: 0.8526, test_acc: \u001b[31m0.8541573033707865\u001b[0m, time: 75.02\n",
      "best_acc: 0.8541573033707865\n",
      "epoch: 11, loss: 88.82137, loss1: 0.72828, loss2_3: 88.09308\n",
      "\ttrain_acc: 0.8532, test_acc: \u001b[31m0.8531741573033708\u001b[0m, time: 74.71\n",
      "epoch: 12, loss: 88.01254, loss1: 0.71996, loss2_3: 87.29258\n",
      "\ttrain_acc: 0.8550, test_acc: \u001b[31m0.8549719101123595\u001b[0m, time: 73.24\n",
      "best_acc: 0.8549719101123595\n",
      "epoch: 13, loss: 87.63790, loss1: 0.71999, loss2_3: 86.91791\n",
      "\ttrain_acc: 0.8531, test_acc: \u001b[31m0.8539044943820224\u001b[0m, time: 74.74\n",
      "epoch: 14, loss: 87.24557, loss1: 0.71549, loss2_3: 86.53008\n",
      "\ttrain_acc: 0.8557, test_acc: \u001b[31m0.8543820224719101\u001b[0m, time: 75.02\n",
      "epoch: 15, loss: 86.51568, loss1: 0.70684, loss2_3: 85.80885\n",
      "\ttrain_acc: 0.8532, test_acc: \u001b[31m0.8524719101123596\u001b[0m, time: 75.06\n",
      "epoch: 16, loss: 86.37329, loss1: 0.71044, loss2_3: 85.66285\n",
      "\ttrain_acc: 0.8608, test_acc: \u001b[31m0.8606460674157304\u001b[0m, time: 74.16\n",
      "best_acc: 0.8606460674157304\n",
      "epoch: 17, loss: 86.10529, loss1: 0.70011, loss2_3: 85.40518\n",
      "\ttrain_acc: 0.8594, test_acc: \u001b[31m0.8590730337078651\u001b[0m, time: 73.63\n",
      "epoch: 18, loss: 85.56439, loss1: 0.69442, loss2_3: 84.86997\n",
      "\ttrain_acc: 0.8625, test_acc: \u001b[31m0.8614044943820225\u001b[0m, time: 75.15\n",
      "best_acc: 0.8614044943820225\n",
      "epoch: 19, loss: 85.27049, loss1: 0.69154, loss2_3: 84.57895\n",
      "\ttrain_acc: 0.8616, test_acc: \u001b[31m0.8618258426966292\u001b[0m, time: 75.04\n",
      "best_acc: 0.8618258426966292\n",
      "epoch: 20, loss: 84.84252, loss1: 0.68366, loss2_3: 84.15886\n",
      "\ttrain_acc: 0.8626, test_acc: \u001b[31m0.8607865168539326\u001b[0m, time: 75.08\n",
      "epoch: 21, loss: 84.62475, loss1: 0.68295, loss2_3: 83.94180\n",
      "\ttrain_acc: 0.8619, test_acc: \u001b[31m0.8616573033707865\u001b[0m, time: 73.63\n",
      "epoch: 22, loss: 84.68940, loss1: 0.68665, loss2_3: 84.00274\n",
      "\ttrain_acc: 0.8639, test_acc: \u001b[31m0.8635393258426967\u001b[0m, time: 74.28\n",
      "best_acc: 0.8635393258426967\n",
      "epoch: 23, loss: 84.54522, loss1: 0.67994, loss2_3: 83.86528\n",
      "\ttrain_acc: 0.8639, test_acc: \u001b[31m0.863314606741573\u001b[0m, time: 74.99\n",
      "epoch: 24, loss: 84.18614, loss1: 0.67818, loss2_3: 83.50796\n",
      "\ttrain_acc: 0.8650, test_acc: \u001b[31m0.8640168539325843\u001b[0m, time: 75.09\n",
      "best_acc: 0.8640168539325843\n",
      "epoch: 25, loss: 83.95802, loss1: 0.67690, loss2_3: 83.28112\n",
      "\ttrain_acc: 0.8635, test_acc: \u001b[31m0.8645786516853933\u001b[0m, time: 74.74\n",
      "best_acc: 0.8645786516853933\n",
      "epoch: 26, loss: 83.61308, loss1: 0.67582, loss2_3: 82.93726\n",
      "\ttrain_acc: 0.8656, test_acc: \u001b[31m0.8648595505617978\u001b[0m, time: 73.15\n",
      "best_acc: 0.8648595505617978\n",
      "epoch: 27, loss: 83.42581, loss1: 0.67474, loss2_3: 82.75107\n",
      "\ttrain_acc: 0.8633, test_acc: \u001b[31m0.8603932584269663\u001b[0m, time: 74.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28, loss: 83.29667, loss1: 0.66735, loss2_3: 82.62932\n",
      "\ttrain_acc: 0.8652, test_acc: \u001b[31m0.8638764044943821\u001b[0m, time: 75.02\n",
      "epoch: 29, loss: 83.09768, loss1: 0.66681, loss2_3: 82.43088\n",
      "\ttrain_acc: 0.8649, test_acc: \u001b[31m0.8639044943820224\u001b[0m, time: 74.98\n",
      "epoch: 30, loss: 82.81535, loss1: 0.66549, loss2_3: 82.14986\n",
      "\ttrain_acc: 0.8655, test_acc: \u001b[31m0.8640168539325843\u001b[0m, time: 74.02\n",
      "epoch: 31, loss: 82.65809, loss1: 0.66361, loss2_3: 81.99449\n",
      "\ttrain_acc: 0.8667, test_acc: \u001b[31m0.8658146067415731\u001b[0m, time: 73.62\n",
      "best_acc: 0.8658146067415731\n",
      "epoch: 32, loss: 83.05391, loss1: 0.66291, loss2_3: 82.39100\n",
      "\ttrain_acc: 0.8643, test_acc: \u001b[31m0.8626404494382023\u001b[0m, time: 75.06\n",
      "epoch: 33, loss: 82.46041, loss1: 0.65905, loss2_3: 81.80136\n",
      "\ttrain_acc: 0.8666, test_acc: \u001b[31m0.8642696629213483\u001b[0m, time: 75.00\n",
      "epoch: 34, loss: 82.22346, loss1: 0.66034, loss2_3: 81.56313\n",
      "\ttrain_acc: 0.8673, test_acc: \u001b[31m0.8649719101123595\u001b[0m, time: 74.93\n",
      "epoch: 35, loss: 81.98361, loss1: 0.65627, loss2_3: 81.32734\n",
      "\ttrain_acc: 0.8661, test_acc: \u001b[31m0.8633426966292135\u001b[0m, time: 73.63\n",
      "epoch: 36, loss: 81.90581, loss1: 0.65088, loss2_3: 81.25493\n",
      "\ttrain_acc: 0.8655, test_acc: \u001b[31m0.861629213483146\u001b[0m, time: 74.24\n",
      "epoch: 37, loss: 81.73860, loss1: 0.65452, loss2_3: 81.08408\n",
      "\ttrain_acc: 0.8660, test_acc: \u001b[31m0.8646629213483146\u001b[0m, time: 75.07\n",
      "epoch: 38, loss: 81.58724, loss1: 0.65246, loss2_3: 80.93478\n",
      "\ttrain_acc: 0.8677, test_acc: \u001b[31m0.8663483146067416\u001b[0m, time: 75.08\n",
      "best_acc: 0.8663483146067416\n",
      "epoch: 39, loss: 81.31406, loss1: 0.64877, loss2_3: 80.66530\n",
      "\ttrain_acc: 0.8649, test_acc: \u001b[31m0.8640730337078651\u001b[0m, time: 74.99\n",
      "epoch: 40, loss: 81.25930, loss1: 0.64767, loss2_3: 80.61162\n",
      "\ttrain_acc: 0.8689, test_acc: \u001b[31m0.8667696629213483\u001b[0m, time: 73.90\n",
      "best_acc: 0.8667696629213483\n",
      "epoch: 41, loss: 81.25326, loss1: 0.64873, loss2_3: 80.60454\n",
      "\ttrain_acc: 0.8703, test_acc: \u001b[31m0.8665449438202247\u001b[0m, time: 74.84\n",
      "epoch: 42, loss: 81.10868, loss1: 0.64412, loss2_3: 80.46455\n",
      "\ttrain_acc: 0.8694, test_acc: \u001b[31m0.866685393258427\u001b[0m, time: 74.98\n",
      "epoch: 43, loss: 80.76775, loss1: 0.64367, loss2_3: 80.12408\n",
      "\ttrain_acc: 0.8679, test_acc: \u001b[31m0.8647191011235955\u001b[0m, time: 74.90\n",
      "epoch: 44, loss: 80.53219, loss1: 0.64316, loss2_3: 79.88903\n",
      "\ttrain_acc: 0.8703, test_acc: \u001b[31m0.8665730337078652\u001b[0m, time: 73.73\n",
      "epoch: 45, loss: 80.24253, loss1: 0.63968, loss2_3: 79.60285\n",
      "\ttrain_acc: 0.8704, test_acc: \u001b[31m0.8677808988764045\u001b[0m, time: 73.74\n",
      "best_acc: 0.8677808988764045\n",
      "epoch: 46, loss: 80.15644, loss1: 0.64131, loss2_3: 79.51514\n",
      "\ttrain_acc: 0.8694, test_acc: \u001b[31m0.8648595505617978\u001b[0m, time: 74.91\n",
      "epoch: 47, loss: 79.88047, loss1: 0.64117, loss2_3: 79.23930\n",
      "\ttrain_acc: 0.8721, test_acc: \u001b[31m0.8682303370786517\u001b[0m, time: 74.95\n",
      "best_acc: 0.8682303370786517\n",
      "epoch: 48, loss: 79.92726, loss1: 0.63582, loss2_3: 79.29144\n",
      "\ttrain_acc: 0.8716, test_acc: \u001b[31m0.8671910112359551\u001b[0m, time: 74.97\n",
      "epoch: 49, loss: 79.49490, loss1: 0.63230, loss2_3: 78.86261\n",
      "\ttrain_acc: 0.8702, test_acc: \u001b[31m0.8672471910112359\u001b[0m, time: 73.36\n",
      "epoch: 50, loss: 79.43175, loss1: 0.63339, loss2_3: 78.79836\n",
      "\ttrain_acc: 0.8703, test_acc: \u001b[31m0.8669101123595505\u001b[0m, time: 74.36\n",
      "epoch: 51, loss: 79.45566, loss1: 0.63198, loss2_3: 78.82368\n",
      "\ttrain_acc: 0.8720, test_acc: \u001b[31m0.8699719101123595\u001b[0m, time: 74.87\n",
      "best_acc: 0.8699719101123595\n",
      "epoch: 52, loss: 79.17589, loss1: 0.62881, loss2_3: 78.54708\n",
      "\ttrain_acc: 0.8729, test_acc: \u001b[31m0.8707584269662921\u001b[0m, time: 74.87\n",
      "best_acc: 0.8707584269662921\n",
      "epoch: 53, loss: 79.03800, loss1: 0.63207, loss2_3: 78.40593\n",
      "\ttrain_acc: 0.8707, test_acc: \u001b[31m0.8676404494382023\u001b[0m, time: 74.42\n",
      "epoch: 54, loss: 78.96952, loss1: 0.62982, loss2_3: 78.33969\n",
      "\ttrain_acc: 0.8722, test_acc: \u001b[31m0.8689606741573034\u001b[0m, time: 73.43\n",
      "epoch: 55, loss: 78.73881, loss1: 0.63413, loss2_3: 78.10468\n",
      "\ttrain_acc: 0.8733, test_acc: \u001b[31m0.8689887640449439\u001b[0m, time: 75.03\n",
      "epoch: 56, loss: 78.93229, loss1: 0.62896, loss2_3: 78.30332\n",
      "\ttrain_acc: 0.8736, test_acc: \u001b[31m0.8692134831460674\u001b[0m, time: 74.84\n",
      "epoch: 57, loss: 78.62895, loss1: 0.62774, loss2_3: 78.00121\n",
      "\ttrain_acc: 0.8738, test_acc: \u001b[31m0.8698595505617978\u001b[0m, time: 74.98\n",
      "epoch: 58, loss: 78.46879, loss1: 0.62443, loss2_3: 77.84436\n",
      "\ttrain_acc: 0.8728, test_acc: \u001b[31m0.8687359550561797\u001b[0m, time: 73.63\n",
      "epoch: 59, loss: 78.25570, loss1: 0.62398, loss2_3: 77.63172\n",
      "\ttrain_acc: 0.8742, test_acc: \u001b[31m0.8707303370786517\u001b[0m, time: 73.92\n",
      "epoch: 60, loss: 78.21087, loss1: 0.62322, loss2_3: 77.58765\n",
      "\ttrain_acc: 0.8742, test_acc: \u001b[31m0.8703651685393259\u001b[0m, time: 74.94\n",
      "epoch: 61, loss: 78.33452, loss1: 0.62321, loss2_3: 77.71132\n",
      "\ttrain_acc: 0.8743, test_acc: \u001b[31m0.869438202247191\u001b[0m, time: 77.47\n",
      "epoch: 62, loss: 78.06197, loss1: 0.62213, loss2_3: 77.43983\n",
      "\ttrain_acc: 0.8736, test_acc: \u001b[31m0.8700842696629213\u001b[0m, time: 78.61\n",
      "epoch: 63, loss: 78.08500, loss1: 0.62140, loss2_3: 77.46360\n",
      "\ttrain_acc: 0.8755, test_acc: \u001b[31m0.8706741573033708\u001b[0m, time: 78.67\n",
      "epoch: 64, loss: 77.84745, loss1: 0.62080, loss2_3: 77.22666\n",
      "\ttrain_acc: 0.8742, test_acc: \u001b[31m0.8695786516853933\u001b[0m, time: 75.08\n",
      "epoch: 65, loss: 77.76379, loss1: 0.62315, loss2_3: 77.14064\n",
      "\ttrain_acc: 0.8747, test_acc: \u001b[31m0.8695224719101123\u001b[0m, time: 75.08\n",
      "epoch: 66, loss: 77.79916, loss1: 0.62168, loss2_3: 77.17748\n",
      "\ttrain_acc: 0.8738, test_acc: \u001b[31m0.8696348314606741\u001b[0m, time: 73.26\n",
      "epoch: 67, loss: 77.56882, loss1: 0.61942, loss2_3: 76.94940\n",
      "\ttrain_acc: 0.8742, test_acc: \u001b[31m0.8693820224719101\u001b[0m, time: 74.19\n",
      "epoch: 68, loss: 77.61819, loss1: 0.61977, loss2_3: 76.99842\n",
      "\ttrain_acc: 0.8727, test_acc: \u001b[31m0.8675561797752809\u001b[0m, time: 74.93\n",
      "epoch: 69, loss: 77.59802, loss1: 0.62076, loss2_3: 76.97726\n",
      "\ttrain_acc: 0.8755, test_acc: \u001b[31m0.8709269662921348\u001b[0m, time: 74.89\n",
      "best_acc: 0.8709269662921348\n",
      "epoch: 70, loss: 77.51807, loss1: 0.61912, loss2_3: 76.89896\n",
      "\ttrain_acc: 0.8755, test_acc: \u001b[31m0.8714887640449438\u001b[0m, time: 74.42\n",
      "best_acc: 0.8714887640449438\n",
      "epoch: 71, loss: 77.31561, loss1: 0.61850, loss2_3: 76.69711\n",
      "\ttrain_acc: 0.8763, test_acc: \u001b[31m0.8700280898876405\u001b[0m, time: 73.36\n",
      "epoch: 72, loss: 77.31710, loss1: 0.61911, loss2_3: 76.69799\n",
      "\ttrain_acc: 0.8748, test_acc: \u001b[31m0.8689887640449439\u001b[0m, time: 74.92\n",
      "epoch: 73, loss: 77.10393, loss1: 0.61805, loss2_3: 76.48588\n",
      "\ttrain_acc: 0.8766, test_acc: \u001b[31m0.8719943820224719\u001b[0m, time: 74.99\n",
      "best_acc: 0.8719943820224719\n",
      "epoch: 74, loss: 77.13983, loss1: 0.61898, loss2_3: 76.52085\n",
      "\ttrain_acc: 0.8761, test_acc: \u001b[31m0.8717415730337079\u001b[0m, time: 74.95\n",
      "epoch: 75, loss: 76.97658, loss1: 0.61415, loss2_3: 76.36243\n",
      "\ttrain_acc: 0.8767, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 73.84\n",
      "epoch: 76, loss: 77.19943, loss1: 0.61859, loss2_3: 76.58084\n",
      "\ttrain_acc: 0.8756, test_acc: \u001b[31m0.8703089887640449\u001b[0m, time: 73.88\n",
      "epoch: 77, loss: 77.05014, loss1: 0.61739, loss2_3: 76.43275\n",
      "\ttrain_acc: 0.8756, test_acc: \u001b[31m0.8701404494382022\u001b[0m, time: 75.13\n",
      "epoch: 78, loss: 76.90310, loss1: 0.61293, loss2_3: 76.29017\n",
      "\ttrain_acc: 0.8754, test_acc: \u001b[31m0.869943820224719\u001b[0m, time: 74.88\n",
      "epoch: 79, loss: 76.89802, loss1: 0.61471, loss2_3: 76.28331\n",
      "\ttrain_acc: 0.8766, test_acc: \u001b[31m0.87\u001b[0m, time: 74.96\n",
      "epoch: 80, loss: 76.73719, loss1: 0.61391, loss2_3: 76.12327\n",
      "\ttrain_acc: 0.8763, test_acc: \u001b[31m0.8694101123595506\u001b[0m, time: 73.31\n",
      "epoch: 81, loss: 76.71959, loss1: 0.61255, loss2_3: 76.10703\n",
      "\ttrain_acc: 0.8773, test_acc: \u001b[31m0.8717134831460674\u001b[0m, time: 74.34\n",
      "epoch: 82, loss: 76.50021, loss1: 0.61211, loss2_3: 75.88810\n",
      "\ttrain_acc: 0.8747, test_acc: \u001b[31m0.8679494382022472\u001b[0m, time: 74.95\n",
      "epoch: 83, loss: 76.67654, loss1: 0.61295, loss2_3: 76.06359\n",
      "\ttrain_acc: 0.8776, test_acc: \u001b[31m0.8700280898876405\u001b[0m, time: 74.80\n",
      "epoch: 84, loss: 76.88110, loss1: 0.61354, loss2_3: 76.26756\n",
      "\ttrain_acc: 0.8761, test_acc: \u001b[31m0.8685393258426967\u001b[0m, time: 74.21\n",
      "epoch: 85, loss: 76.57681, loss1: 0.61121, loss2_3: 75.96560\n",
      "\ttrain_acc: 0.8765, test_acc: \u001b[31m0.8700561797752809\u001b[0m, time: 73.34\n",
      "epoch: 86, loss: 76.36473, loss1: 0.61121, loss2_3: 75.75351\n",
      "\ttrain_acc: 0.8743, test_acc: \u001b[31m0.8668539325842697\u001b[0m, time: 75.16\n",
      "epoch: 87, loss: 76.60686, loss1: 0.61148, loss2_3: 75.99539\n",
      "\ttrain_acc: 0.8755, test_acc: \u001b[31m0.8682584269662922\u001b[0m, time: 75.15\n",
      "epoch: 88, loss: 76.32163, loss1: 0.61118, loss2_3: 75.71045\n",
      "\ttrain_acc: 0.8780, test_acc: \u001b[31m0.8707303370786517\u001b[0m, time: 75.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 89, loss: 76.42891, loss1: 0.61075, loss2_3: 75.81817\n",
      "\ttrain_acc: 0.8764, test_acc: \u001b[31m0.8709550561797753\u001b[0m, time: 73.97\n",
      "epoch: 90, loss: 76.35208, loss1: 0.61101, loss2_3: 75.74107\n",
      "\ttrain_acc: 0.8765, test_acc: \u001b[31m0.8697752808988765\u001b[0m, time: 73.79\n",
      "epoch: 91, loss: 76.15389, loss1: 0.60974, loss2_3: 75.54415\n",
      "\ttrain_acc: 0.8777, test_acc: \u001b[31m0.8693539325842696\u001b[0m, time: 75.11\n",
      "epoch: 92, loss: 75.99060, loss1: 0.60596, loss2_3: 75.38464\n",
      "\ttrain_acc: 0.8788, test_acc: \u001b[31m0.8721629213483146\u001b[0m, time: 75.04\n",
      "best_acc: 0.8721629213483146\n",
      "epoch: 93, loss: 76.07101, loss1: 0.61280, loss2_3: 75.45820\n",
      "\ttrain_acc: 0.8789, test_acc: \u001b[31m0.871123595505618\u001b[0m, time: 75.33\n",
      "epoch: 94, loss: 76.00815, loss1: 0.60707, loss2_3: 75.40107\n",
      "\ttrain_acc: 0.8779, test_acc: \u001b[31m0.8713202247191011\u001b[0m, time: 73.56\n",
      "epoch: 95, loss: 76.20362, loss1: 0.60848, loss2_3: 75.59514\n",
      "\ttrain_acc: 0.8762, test_acc: \u001b[31m0.867808988764045\u001b[0m, time: 74.57\n",
      "epoch: 96, loss: 75.94701, loss1: 0.60598, loss2_3: 75.34103\n",
      "\ttrain_acc: 0.8800, test_acc: \u001b[31m0.8722752808988764\u001b[0m, time: 75.00\n",
      "best_acc: 0.8722752808988764\n",
      "epoch: 97, loss: 75.86881, loss1: 0.60764, loss2_3: 75.26117\n",
      "\ttrain_acc: 0.8781, test_acc: \u001b[31m0.8697191011235955\u001b[0m, time: 75.10\n",
      "epoch: 98, loss: 75.95284, loss1: 0.60503, loss2_3: 75.34781\n",
      "\ttrain_acc: 0.8788, test_acc: \u001b[31m0.8700842696629213\u001b[0m, time: 74.61\n",
      "epoch: 99, loss: 75.73742, loss1: 0.60603, loss2_3: 75.13139\n",
      "\ttrain_acc: 0.8789, test_acc: \u001b[31m0.870561797752809\u001b[0m, time: 73.66\n",
      "epoch: 100, loss: 75.64327, loss1: 0.60698, loss2_3: 75.03629\n",
      "\ttrain_acc: 0.8786, test_acc: \u001b[31m0.8713483146067416\u001b[0m, time: 75.50\n",
      "epoch: 101, loss: 75.48333, loss1: 0.60695, loss2_3: 74.87638\n",
      "\ttrain_acc: 0.8784, test_acc: \u001b[31m0.8723595505617977\u001b[0m, time: 75.44\n",
      "best_acc: 0.8723595505617977\n",
      "epoch: 102, loss: 75.63227, loss1: 0.60431, loss2_3: 75.02796\n",
      "\ttrain_acc: 0.8792, test_acc: \u001b[31m0.8721067415730337\u001b[0m, time: 75.36\n",
      "epoch: 103, loss: 75.61340, loss1: 0.60731, loss2_3: 75.00610\n",
      "\ttrain_acc: 0.8780, test_acc: \u001b[31m0.8674157303370786\u001b[0m, time: 74.08\n",
      "epoch: 104, loss: 75.57346, loss1: 0.60620, loss2_3: 74.96726\n",
      "\ttrain_acc: 0.8802, test_acc: \u001b[31m0.8713202247191011\u001b[0m, time: 74.43\n",
      "epoch: 105, loss: 75.62647, loss1: 0.60139, loss2_3: 75.02507\n",
      "\ttrain_acc: 0.8794, test_acc: \u001b[31m0.8722471910112359\u001b[0m, time: 75.49\n",
      "epoch: 106, loss: 75.62928, loss1: 0.60411, loss2_3: 75.02517\n",
      "\ttrain_acc: 0.8798, test_acc: \u001b[31m0.8717415730337079\u001b[0m, time: 74.97\n",
      "epoch: 107, loss: 75.29249, loss1: 0.60574, loss2_3: 74.68675\n",
      "\ttrain_acc: 0.8777, test_acc: \u001b[31m0.8687640449438202\u001b[0m, time: 74.93\n",
      "epoch: 108, loss: 75.34018, loss1: 0.60402, loss2_3: 74.73616\n",
      "\ttrain_acc: 0.8793, test_acc: \u001b[31m0.8702247191011236\u001b[0m, time: 73.20\n",
      "epoch: 109, loss: 75.13102, loss1: 0.60415, loss2_3: 74.52687\n",
      "\ttrain_acc: 0.8798, test_acc: \u001b[31m0.8713202247191011\u001b[0m, time: 74.70\n",
      "epoch: 110, loss: 75.11934, loss1: 0.60148, loss2_3: 74.51787\n",
      "\ttrain_acc: 0.8805, test_acc: \u001b[31m0.8719943820224719\u001b[0m, time: 75.26\n",
      "epoch: 111, loss: 75.28034, loss1: 0.60114, loss2_3: 74.67919\n",
      "\ttrain_acc: 0.8798, test_acc: \u001b[31m0.8710112359550561\u001b[0m, time: 75.12\n",
      "epoch: 112, loss: 75.03773, loss1: 0.60363, loss2_3: 74.43410\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8722471910112359\u001b[0m, time: 74.23\n",
      "epoch: 113, loss: 75.14016, loss1: 0.60442, loss2_3: 74.53574\n",
      "\ttrain_acc: 0.8802, test_acc: \u001b[31m0.8706741573033708\u001b[0m, time: 78.43\n",
      "epoch: 114, loss: 74.83937, loss1: 0.59950, loss2_3: 74.23988\n",
      "\ttrain_acc: 0.8810, test_acc: \u001b[31m0.8707865168539326\u001b[0m, time: 76.59\n",
      "epoch: 115, loss: 74.84302, loss1: 0.59769, loss2_3: 74.24533\n",
      "\ttrain_acc: 0.8787, test_acc: \u001b[31m0.8688202247191011\u001b[0m, time: 75.06\n",
      "epoch: 116, loss: 74.95034, loss1: 0.60172, loss2_3: 74.34862\n",
      "\ttrain_acc: 0.8798, test_acc: \u001b[31m0.8699157303370787\u001b[0m, time: 74.16\n",
      "epoch: 117, loss: 74.93208, loss1: 0.60054, loss2_3: 74.33155\n",
      "\ttrain_acc: 0.8812, test_acc: \u001b[31m0.8728651685393258\u001b[0m, time: 73.63\n",
      "best_acc: 0.8728651685393258\n",
      "epoch: 118, loss: 74.66854, loss1: 0.60198, loss2_3: 74.06655\n",
      "\ttrain_acc: 0.8812, test_acc: \u001b[31m0.8729213483146068\u001b[0m, time: 75.12\n",
      "best_acc: 0.8729213483146068\n",
      "epoch: 119, loss: 74.75651, loss1: 0.60108, loss2_3: 74.15543\n",
      "\ttrain_acc: 0.8808, test_acc: \u001b[31m0.8722752808988764\u001b[0m, time: 75.08\n",
      "epoch: 120, loss: 74.66569, loss1: 0.59829, loss2_3: 74.06740\n",
      "\ttrain_acc: 0.8815, test_acc: \u001b[31m0.8740730337078652\u001b[0m, time: 75.11\n",
      "best_acc: 0.8740730337078652\n",
      "epoch: 121, loss: 74.67961, loss1: 0.60237, loss2_3: 74.07724\n",
      "\ttrain_acc: 0.8792, test_acc: \u001b[31m0.8686516853932584\u001b[0m, time: 73.57\n",
      "epoch: 122, loss: 74.63814, loss1: 0.60024, loss2_3: 74.03790\n",
      "\ttrain_acc: 0.8823, test_acc: \u001b[31m0.8731179775280898\u001b[0m, time: 74.15\n",
      "epoch: 123, loss: 74.34731, loss1: 0.59773, loss2_3: 73.74958\n",
      "\ttrain_acc: 0.8822, test_acc: \u001b[31m0.8728932584269663\u001b[0m, time: 75.04\n",
      "epoch: 124, loss: 74.47881, loss1: 0.59791, loss2_3: 73.88091\n",
      "\ttrain_acc: 0.8796, test_acc: \u001b[31m0.8692415730337079\u001b[0m, time: 74.97\n",
      "epoch: 125, loss: 74.47167, loss1: 0.59475, loss2_3: 73.87693\n",
      "\ttrain_acc: 0.8822, test_acc: \u001b[31m0.8715449438202247\u001b[0m, time: 74.82\n",
      "epoch: 126, loss: 74.58273, loss1: 0.59588, loss2_3: 73.98685\n",
      "\ttrain_acc: 0.8830, test_acc: \u001b[31m0.8709831460674158\u001b[0m, time: 73.03\n",
      "epoch: 127, loss: 74.39329, loss1: 0.59698, loss2_3: 73.79631\n",
      "\ttrain_acc: 0.8793, test_acc: \u001b[31m0.8690730337078652\u001b[0m, time: 74.68\n",
      "epoch: 128, loss: 74.45184, loss1: 0.59832, loss2_3: 73.85352\n",
      "\ttrain_acc: 0.8794, test_acc: \u001b[31m0.8681179775280898\u001b[0m, time: 75.01\n",
      "epoch: 129, loss: 74.09535, loss1: 0.59446, loss2_3: 73.50089\n",
      "\ttrain_acc: 0.8827, test_acc: \u001b[31m0.8714044943820225\u001b[0m, time: 74.93\n",
      "epoch: 130, loss: 74.33244, loss1: 0.59570, loss2_3: 73.73674\n",
      "\ttrain_acc: 0.8803, test_acc: \u001b[31m0.8701966292134832\u001b[0m, time: 74.38\n",
      "epoch: 131, loss: 74.19665, loss1: 0.60009, loss2_3: 73.59656\n",
      "\ttrain_acc: 0.8818, test_acc: \u001b[31m0.8712078651685393\u001b[0m, time: 73.57\n",
      "epoch: 132, loss: 74.15721, loss1: 0.59636, loss2_3: 73.56085\n",
      "\ttrain_acc: 0.8833, test_acc: \u001b[31m0.8734269662921348\u001b[0m, time: 74.75\n",
      "epoch: 133, loss: 74.38965, loss1: 0.59850, loss2_3: 73.79115\n",
      "\ttrain_acc: 0.8836, test_acc: \u001b[31m0.8738202247191011\u001b[0m, time: 74.88\n",
      "epoch: 134, loss: 74.12329, loss1: 0.59560, loss2_3: 73.52769\n",
      "\ttrain_acc: 0.8835, test_acc: \u001b[31m0.8707022471910112\u001b[0m, time: 74.94\n",
      "epoch: 135, loss: 73.80594, loss1: 0.59630, loss2_3: 73.20964\n",
      "\ttrain_acc: 0.8834, test_acc: \u001b[31m0.8710955056179776\u001b[0m, time: 73.74\n",
      "epoch: 136, loss: 73.83254, loss1: 0.59414, loss2_3: 73.23840\n",
      "\ttrain_acc: 0.8831, test_acc: \u001b[31m0.8715449438202247\u001b[0m, time: 73.92\n",
      "epoch: 137, loss: 73.94916, loss1: 0.59333, loss2_3: 73.35584\n",
      "\ttrain_acc: 0.8835, test_acc: \u001b[31m0.87\u001b[0m, time: 74.98\n",
      "epoch: 138, loss: 73.83645, loss1: 0.59485, loss2_3: 73.24160\n",
      "\ttrain_acc: 0.8839, test_acc: \u001b[31m0.8724719101123596\u001b[0m, time: 75.15\n",
      "epoch: 139, loss: 73.81107, loss1: 0.59329, loss2_3: 73.21778\n",
      "\ttrain_acc: 0.8843, test_acc: \u001b[31m0.873370786516854\u001b[0m, time: 74.70\n",
      "epoch: 140, loss: 73.83161, loss1: 0.59469, loss2_3: 73.23692\n",
      "\ttrain_acc: 0.8820, test_acc: \u001b[31m0.8711797752808988\u001b[0m, time: 73.21\n",
      "epoch: 141, loss: 73.58641, loss1: 0.58998, loss2_3: 72.99642\n",
      "\ttrain_acc: 0.8853, test_acc: \u001b[31m0.8731460674157303\u001b[0m, time: 74.56\n",
      "epoch: 142, loss: 73.75247, loss1: 0.59399, loss2_3: 73.15848\n",
      "\ttrain_acc: 0.8843, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 74.84\n",
      "epoch: 143, loss: 73.37449, loss1: 0.59343, loss2_3: 72.78106\n",
      "\ttrain_acc: 0.8851, test_acc: \u001b[31m0.8718820224719102\u001b[0m, time: 74.89\n",
      "epoch: 144, loss: 73.35708, loss1: 0.59149, loss2_3: 72.76559\n",
      "\ttrain_acc: 0.8795, test_acc: \u001b[31m0.8673595505617977\u001b[0m, time: 74.13\n",
      "epoch: 145, loss: 73.42832, loss1: 0.59288, loss2_3: 72.83544\n",
      "\ttrain_acc: 0.8714, test_acc: \u001b[31m0.859747191011236\u001b[0m, time: 73.47\n",
      "epoch: 146, loss: 73.20338, loss1: 0.59185, loss2_3: 72.61152\n",
      "\ttrain_acc: 0.8852, test_acc: \u001b[31m0.8710393258426966\u001b[0m, time: 75.01\n",
      "epoch: 147, loss: 73.11755, loss1: 0.59052, loss2_3: 72.52703\n",
      "\ttrain_acc: 0.8844, test_acc: \u001b[31m0.8717415730337079\u001b[0m, time: 74.94\n",
      "epoch: 148, loss: 73.23770, loss1: 0.59098, loss2_3: 72.64673\n",
      "\ttrain_acc: 0.8862, test_acc: \u001b[31m0.873314606741573\u001b[0m, time: 74.90\n",
      "epoch: 149, loss: 73.16387, loss1: 0.59184, loss2_3: 72.57204\n",
      "\ttrain_acc: 0.8854, test_acc: \u001b[31m0.8710674157303371\u001b[0m, time: 73.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 150, loss: 73.05570, loss1: 0.58857, loss2_3: 72.46713\n",
      "\ttrain_acc: 0.8857, test_acc: \u001b[31m0.8725842696629214\u001b[0m, time: 73.99\n",
      "epoch: 151, loss: 72.92210, loss1: 0.59029, loss2_3: 72.33181\n",
      "\ttrain_acc: 0.8857, test_acc: \u001b[31m0.8725\u001b[0m, time: 74.98\n",
      "epoch: 152, loss: 72.95904, loss1: 0.58955, loss2_3: 72.36949\n",
      "\ttrain_acc: 0.8856, test_acc: \u001b[31m0.8714606741573033\u001b[0m, time: 74.90\n",
      "epoch: 153, loss: 72.90264, loss1: 0.59217, loss2_3: 72.31047\n",
      "\ttrain_acc: 0.8845, test_acc: \u001b[31m0.8690168539325843\u001b[0m, time: 74.71\n",
      "epoch: 154, loss: 73.01715, loss1: 0.58762, loss2_3: 72.42952\n",
      "\ttrain_acc: 0.8868, test_acc: \u001b[31m0.8728932584269663\u001b[0m, time: 72.98\n",
      "epoch: 155, loss: 73.05304, loss1: 0.58642, loss2_3: 72.46662\n",
      "\ttrain_acc: 0.8844, test_acc: \u001b[31m0.8691011235955056\u001b[0m, time: 74.46\n",
      "epoch: 156, loss: 73.07864, loss1: 0.58914, loss2_3: 72.48950\n",
      "\ttrain_acc: 0.8846, test_acc: \u001b[31m0.871629213483146\u001b[0m, time: 74.82\n",
      "epoch: 157, loss: 72.91700, loss1: 0.58959, loss2_3: 72.32742\n",
      "\ttrain_acc: 0.8866, test_acc: \u001b[31m0.8727528089887641\u001b[0m, time: 74.82\n",
      "epoch: 158, loss: 72.68719, loss1: 0.58471, loss2_3: 72.10248\n",
      "\ttrain_acc: 0.8864, test_acc: \u001b[31m0.8730898876404495\u001b[0m, time: 74.27\n",
      "epoch: 159, loss: 72.72535, loss1: 0.58773, loss2_3: 72.13762\n",
      "\ttrain_acc: 0.8858, test_acc: \u001b[31m0.8699157303370787\u001b[0m, time: 73.26\n",
      "epoch: 160, loss: 72.74450, loss1: 0.58739, loss2_3: 72.15711\n",
      "\ttrain_acc: 0.8855, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 75.03\n",
      "epoch: 161, loss: 72.53968, loss1: 0.58706, loss2_3: 71.95262\n",
      "\ttrain_acc: 0.8873, test_acc: \u001b[31m0.8724157303370786\u001b[0m, time: 74.91\n",
      "epoch: 162, loss: 72.44165, loss1: 0.58558, loss2_3: 71.85607\n",
      "\ttrain_acc: 0.8859, test_acc: \u001b[31m0.8702247191011236\u001b[0m, time: 74.88\n",
      "epoch: 163, loss: 72.45975, loss1: 0.58420, loss2_3: 71.87555\n",
      "\ttrain_acc: 0.8824, test_acc: \u001b[31m0.8682303370786517\u001b[0m, time: 73.89\n",
      "epoch: 164, loss: 72.69788, loss1: 0.58838, loss2_3: 72.10950\n",
      "\ttrain_acc: 0.8845, test_acc: \u001b[31m0.8699719101123595\u001b[0m, time: 73.83\n",
      "epoch: 165, loss: 72.55337, loss1: 0.58766, loss2_3: 71.96571\n",
      "\ttrain_acc: 0.8872, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 74.97\n",
      "epoch: 166, loss: 72.35762, loss1: 0.58736, loss2_3: 71.77026\n",
      "\ttrain_acc: 0.8882, test_acc: \u001b[31m0.8719662921348315\u001b[0m, time: 74.86\n",
      "epoch: 167, loss: 72.42562, loss1: 0.58455, loss2_3: 71.84107\n",
      "\ttrain_acc: 0.8851, test_acc: \u001b[31m0.869691011235955\u001b[0m, time: 74.84\n",
      "epoch: 168, loss: 72.11222, loss1: 0.58490, loss2_3: 71.52732\n",
      "\ttrain_acc: 0.8878, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 73.27\n",
      "epoch: 169, loss: 72.13931, loss1: 0.58466, loss2_3: 71.55465\n",
      "\ttrain_acc: 0.8884, test_acc: \u001b[31m0.8725\u001b[0m, time: 74.36\n",
      "epoch: 170, loss: 72.21118, loss1: 0.58259, loss2_3: 71.62859\n",
      "\ttrain_acc: 0.8875, test_acc: \u001b[31m0.8714606741573033\u001b[0m, time: 74.79\n",
      "epoch: 171, loss: 71.92543, loss1: 0.58605, loss2_3: 71.33938\n",
      "\ttrain_acc: 0.8889, test_acc: \u001b[31m0.8732865168539325\u001b[0m, time: 74.69\n",
      "epoch: 172, loss: 72.02491, loss1: 0.58441, loss2_3: 71.44050\n",
      "\ttrain_acc: 0.8868, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 74.27\n",
      "epoch: 173, loss: 71.88953, loss1: 0.58267, loss2_3: 71.30686\n",
      "\ttrain_acc: 0.8872, test_acc: \u001b[31m0.8719662921348315\u001b[0m, time: 73.16\n",
      "epoch: 174, loss: 71.89684, loss1: 0.58604, loss2_3: 71.31080\n",
      "\ttrain_acc: 0.8884, test_acc: \u001b[31m0.8721348314606742\u001b[0m, time: 74.59\n",
      "epoch: 175, loss: 71.90127, loss1: 0.58231, loss2_3: 71.31897\n",
      "\ttrain_acc: 0.8884, test_acc: \u001b[31m0.870252808988764\u001b[0m, time: 76.83\n",
      "epoch: 176, loss: 71.81706, loss1: 0.57961, loss2_3: 71.23745\n",
      "\ttrain_acc: 0.8897, test_acc: \u001b[31m0.8727528089887641\u001b[0m, time: 75.43\n",
      "epoch: 177, loss: 71.75178, loss1: 0.57935, loss2_3: 71.17244\n",
      "\ttrain_acc: 0.8887, test_acc: \u001b[31m0.8734831460674157\u001b[0m, time: 73.21\n",
      "epoch: 178, loss: 71.81958, loss1: 0.58276, loss2_3: 71.23682\n",
      "\ttrain_acc: 0.8873, test_acc: \u001b[31m0.8693539325842696\u001b[0m, time: 74.33\n",
      "epoch: 179, loss: 71.61898, loss1: 0.57951, loss2_3: 71.03947\n",
      "\ttrain_acc: 0.8896, test_acc: \u001b[31m0.8724719101123596\u001b[0m, time: 74.80\n",
      "epoch: 180, loss: 71.51442, loss1: 0.58078, loss2_3: 70.93363\n",
      "\ttrain_acc: 0.8870, test_acc: \u001b[31m0.8689606741573034\u001b[0m, time: 74.64\n",
      "epoch: 181, loss: 71.61812, loss1: 0.58422, loss2_3: 71.03389\n",
      "\ttrain_acc: 0.8891, test_acc: \u001b[31m0.8717977528089887\u001b[0m, time: 74.24\n",
      "epoch: 182, loss: 71.55229, loss1: 0.58000, loss2_3: 70.97228\n",
      "\ttrain_acc: 0.8890, test_acc: \u001b[31m0.8718820224719102\u001b[0m, time: 73.50\n",
      "epoch: 183, loss: 71.43232, loss1: 0.58094, loss2_3: 70.85138\n",
      "\ttrain_acc: 0.8907, test_acc: \u001b[31m0.8725\u001b[0m, time: 74.95\n",
      "epoch: 184, loss: 71.37450, loss1: 0.58242, loss2_3: 70.79207\n",
      "\ttrain_acc: 0.8803, test_acc: \u001b[31m0.8631741573033708\u001b[0m, time: 74.79\n",
      "epoch: 185, loss: 71.40614, loss1: 0.57919, loss2_3: 70.82695\n",
      "\ttrain_acc: 0.8913, test_acc: \u001b[31m0.8725842696629214\u001b[0m, time: 75.32\n",
      "epoch: 186, loss: 71.26129, loss1: 0.57778, loss2_3: 70.68351\n",
      "\ttrain_acc: 0.8900, test_acc: \u001b[31m0.8721067415730337\u001b[0m, time: 73.44\n",
      "epoch: 187, loss: 71.18272, loss1: 0.57948, loss2_3: 70.60324\n",
      "\ttrain_acc: 0.8909, test_acc: \u001b[31m0.8707022471910112\u001b[0m, time: 73.92\n",
      "epoch: 188, loss: 71.29070, loss1: 0.57757, loss2_3: 70.71313\n",
      "\ttrain_acc: 0.8899, test_acc: \u001b[31m0.8692696629213483\u001b[0m, time: 74.68\n",
      "epoch: 189, loss: 71.02174, loss1: 0.57660, loss2_3: 70.44514\n",
      "\ttrain_acc: 0.8863, test_acc: \u001b[31m0.8681179775280898\u001b[0m, time: 74.89\n",
      "epoch: 190, loss: 71.21792, loss1: 0.57946, loss2_3: 70.63846\n",
      "\ttrain_acc: 0.8903, test_acc: \u001b[31m0.8710112359550561\u001b[0m, time: 74.69\n",
      "epoch: 191, loss: 70.94727, loss1: 0.58000, loss2_3: 70.36728\n",
      "\ttrain_acc: 0.8851, test_acc: \u001b[31m0.8653651685393259\u001b[0m, time: 72.92\n",
      "epoch: 192, loss: 70.91583, loss1: 0.57590, loss2_3: 70.33993\n",
      "\ttrain_acc: 0.8919, test_acc: \u001b[31m0.8726404494382023\u001b[0m, time: 74.45\n",
      "epoch: 193, loss: 71.02537, loss1: 0.57572, loss2_3: 70.44965\n",
      "\ttrain_acc: 0.8916, test_acc: \u001b[31m0.8717977528089887\u001b[0m, time: 74.78\n",
      "epoch: 194, loss: 70.92844, loss1: 0.57619, loss2_3: 70.35225\n",
      "\ttrain_acc: 0.8920, test_acc: \u001b[31m0.8719662921348315\u001b[0m, time: 74.86\n",
      "epoch: 195, loss: 70.72867, loss1: 0.57615, loss2_3: 70.15252\n",
      "\ttrain_acc: 0.8910, test_acc: \u001b[31m0.8707022471910112\u001b[0m, time: 73.98\n",
      "epoch: 196, loss: 70.68607, loss1: 0.57578, loss2_3: 70.11030\n",
      "\ttrain_acc: 0.8915, test_acc: \u001b[31m0.8703089887640449\u001b[0m, time: 73.39\n",
      "epoch: 197, loss: 70.45737, loss1: 0.57779, loss2_3: 69.87959\n",
      "\ttrain_acc: 0.8924, test_acc: \u001b[31m0.8715168539325843\u001b[0m, time: 74.82\n",
      "epoch: 198, loss: 70.56182, loss1: 0.57275, loss2_3: 69.98907\n",
      "\ttrain_acc: 0.8883, test_acc: \u001b[31m0.8689044943820224\u001b[0m, time: 74.73\n",
      "epoch: 199, loss: 70.72915, loss1: 0.57594, loss2_3: 70.15321\n",
      "\ttrain_acc: 0.8918, test_acc: \u001b[31m0.8703370786516854\u001b[0m, time: 74.93\n",
      "epoch: 200, loss: 70.55496, loss1: 0.57219, loss2_3: 69.98277\n",
      "\ttrain_acc: 0.8918, test_acc: \u001b[31m0.870252808988764\u001b[0m, time: 73.46\n",
      "epoch: 201, loss: 70.48881, loss1: 0.57372, loss2_3: 69.91510\n",
      "\ttrain_acc: 0.8906, test_acc: \u001b[31m0.8701123595505618\u001b[0m, time: 73.92\n",
      "epoch: 202, loss: 70.57379, loss1: 0.57188, loss2_3: 70.00191\n",
      "\ttrain_acc: 0.8926, test_acc: \u001b[31m0.871938202247191\u001b[0m, time: 74.75\n",
      "epoch: 203, loss: 70.43163, loss1: 0.57380, loss2_3: 69.85782\n",
      "\ttrain_acc: 0.8911, test_acc: \u001b[31m0.8700842696629213\u001b[0m, time: 74.81\n",
      "epoch: 204, loss: 70.30793, loss1: 0.57048, loss2_3: 69.73744\n",
      "\ttrain_acc: 0.8915, test_acc: \u001b[31m0.871629213483146\u001b[0m, time: 74.75\n",
      "epoch: 205, loss: 70.34383, loss1: 0.57222, loss2_3: 69.77161\n",
      "\ttrain_acc: 0.8897, test_acc: \u001b[31m0.8676685393258426\u001b[0m, time: 73.06\n",
      "epoch: 206, loss: 70.40060, loss1: 0.57220, loss2_3: 69.82840\n",
      "\ttrain_acc: 0.8925, test_acc: \u001b[31m0.871123595505618\u001b[0m, time: 74.39\n",
      "epoch: 207, loss: 70.17430, loss1: 0.57022, loss2_3: 69.60408\n",
      "\ttrain_acc: 0.8885, test_acc: \u001b[31m0.866629213483146\u001b[0m, time: 74.88\n",
      "epoch: 208, loss: 70.18262, loss1: 0.57065, loss2_3: 69.61197\n",
      "\ttrain_acc: 0.8917, test_acc: \u001b[31m0.8710393258426966\u001b[0m, time: 74.86\n",
      "epoch: 209, loss: 70.20382, loss1: 0.57194, loss2_3: 69.63188\n",
      "\ttrain_acc: 0.8912, test_acc: \u001b[31m0.8685674157303371\u001b[0m, time: 74.18\n",
      "epoch: 210, loss: 70.13557, loss1: 0.57287, loss2_3: 69.56270\n",
      "\ttrain_acc: 0.8932, test_acc: \u001b[31m0.8712078651685393\u001b[0m, time: 73.44\n",
      "epoch: 211, loss: 69.91821, loss1: 0.57351, loss2_3: 69.34471\n",
      "\ttrain_acc: 0.8878, test_acc: \u001b[31m0.8675842696629213\u001b[0m, time: 75.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 212, loss: 69.87587, loss1: 0.56799, loss2_3: 69.30788\n",
      "\ttrain_acc: 0.8912, test_acc: \u001b[31m0.868061797752809\u001b[0m, time: 74.89\n",
      "epoch: 213, loss: 69.97193, loss1: 0.57168, loss2_3: 69.40026\n",
      "\ttrain_acc: 0.8923, test_acc: \u001b[31m0.8692977528089888\u001b[0m, time: 75.13\n",
      "epoch: 214, loss: 69.83677, loss1: 0.57040, loss2_3: 69.26638\n",
      "\ttrain_acc: 0.8882, test_acc: \u001b[31m0.8646629213483146\u001b[0m, time: 73.60\n",
      "epoch: 215, loss: 69.73704, loss1: 0.56973, loss2_3: 69.16732\n",
      "\ttrain_acc: 0.8949, test_acc: \u001b[31m0.871123595505618\u001b[0m, time: 73.93\n",
      "epoch: 216, loss: 69.55449, loss1: 0.56734, loss2_3: 68.98715\n",
      "\ttrain_acc: 0.8949, test_acc: \u001b[31m0.8707022471910112\u001b[0m, time: 75.01\n",
      "epoch: 217, loss: 69.48110, loss1: 0.57165, loss2_3: 68.90944\n",
      "\ttrain_acc: 0.8952, test_acc: \u001b[31m0.8714606741573033\u001b[0m, time: 74.87\n",
      "epoch: 218, loss: 69.84137, loss1: 0.56866, loss2_3: 69.27271\n",
      "\ttrain_acc: 0.8950, test_acc: \u001b[31m0.8698314606741573\u001b[0m, time: 74.87\n",
      "epoch: 219, loss: 69.76466, loss1: 0.56995, loss2_3: 69.19471\n",
      "\ttrain_acc: 0.8943, test_acc: \u001b[31m0.8703370786516854\u001b[0m, time: 73.12\n",
      "epoch: 220, loss: 69.57489, loss1: 0.56969, loss2_3: 69.00520\n",
      "\ttrain_acc: 0.8949, test_acc: \u001b[31m0.8708426966292134\u001b[0m, time: 74.41\n",
      "epoch: 221, loss: 69.51349, loss1: 0.56382, loss2_3: 68.94967\n",
      "\ttrain_acc: 0.8955, test_acc: \u001b[31m0.8722191011235955\u001b[0m, time: 74.98\n",
      "epoch: 222, loss: 69.61815, loss1: 0.56762, loss2_3: 69.05053\n",
      "\ttrain_acc: 0.8941, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 74.95\n",
      "epoch: 223, loss: 69.59899, loss1: 0.56915, loss2_3: 69.02984\n",
      "\ttrain_acc: 0.8945, test_acc: \u001b[31m0.8710112359550561\u001b[0m, time: 74.26\n",
      "epoch: 224, loss: 69.31554, loss1: 0.56802, loss2_3: 68.74752\n",
      "\ttrain_acc: 0.8951, test_acc: \u001b[31m0.8699157303370787\u001b[0m, time: 73.42\n",
      "epoch: 225, loss: 69.27962, loss1: 0.56536, loss2_3: 68.71426\n",
      "\ttrain_acc: 0.8956, test_acc: \u001b[31m0.8688202247191011\u001b[0m, time: 74.88\n",
      "epoch: 226, loss: 69.23826, loss1: 0.56681, loss2_3: 68.67145\n",
      "\ttrain_acc: 0.8931, test_acc: \u001b[31m0.8672471910112359\u001b[0m, time: 74.80\n",
      "epoch: 227, loss: 69.13268, loss1: 0.56529, loss2_3: 68.56739\n",
      "\ttrain_acc: 0.8947, test_acc: \u001b[31m0.8671067415730337\u001b[0m, time: 74.82\n",
      "epoch: 228, loss: 69.07385, loss1: 0.56460, loss2_3: 68.50925\n",
      "\ttrain_acc: 0.8886, test_acc: \u001b[31m0.865\u001b[0m, time: 73.71\n",
      "epoch: 229, loss: 69.27132, loss1: 0.56686, loss2_3: 68.70445\n",
      "\ttrain_acc: 0.8956, test_acc: \u001b[31m0.8706741573033708\u001b[0m, time: 73.93\n",
      "epoch: 230, loss: 68.96234, loss1: 0.56133, loss2_3: 68.40101\n",
      "\ttrain_acc: 0.8952, test_acc: \u001b[31m0.8680056179775281\u001b[0m, time: 74.94\n",
      "epoch: 231, loss: 68.80211, loss1: 0.56575, loss2_3: 68.23636\n",
      "\ttrain_acc: 0.8968, test_acc: \u001b[31m0.8687921348314607\u001b[0m, time: 74.77\n",
      "epoch: 232, loss: 68.96707, loss1: 0.56478, loss2_3: 68.40229\n",
      "\ttrain_acc: 0.8955, test_acc: \u001b[31m0.8697191011235955\u001b[0m, time: 74.70\n",
      "epoch: 233, loss: 68.77002, loss1: 0.56491, loss2_3: 68.20511\n",
      "\ttrain_acc: 0.8969, test_acc: \u001b[31m0.8696629213483146\u001b[0m, time: 73.09\n",
      "epoch: 234, loss: 68.83514, loss1: 0.56413, loss2_3: 68.27101\n",
      "\ttrain_acc: 0.8971, test_acc: \u001b[31m0.869691011235955\u001b[0m, time: 74.50\n",
      "epoch: 235, loss: 68.70345, loss1: 0.56301, loss2_3: 68.14044\n",
      "\ttrain_acc: 0.8877, test_acc: \u001b[31m0.8621910112359551\u001b[0m, time: 74.86\n",
      "epoch: 236, loss: 68.64242, loss1: 0.56504, loss2_3: 68.07738\n",
      "\ttrain_acc: 0.8973, test_acc: \u001b[31m0.8689887640449439\u001b[0m, time: 75.98\n",
      "epoch: 237, loss: 68.57951, loss1: 0.56364, loss2_3: 68.01587\n",
      "\ttrain_acc: 0.8909, test_acc: \u001b[31m0.864747191011236\u001b[0m, time: 78.38\n",
      "epoch: 238, loss: 68.40191, loss1: 0.56511, loss2_3: 67.83680\n",
      "\ttrain_acc: 0.8977, test_acc: \u001b[31m0.8704494382022472\u001b[0m, time: 79.14\n",
      "epoch: 239, loss: 68.45188, loss1: 0.56055, loss2_3: 67.89132\n",
      "\ttrain_acc: 0.8969, test_acc: \u001b[31m0.868061797752809\u001b[0m, time: 78.23\n",
      "epoch: 240, loss: 68.31948, loss1: 0.56383, loss2_3: 67.75565\n",
      "\ttrain_acc: 0.8960, test_acc: \u001b[31m0.8691292134831461\u001b[0m, time: 77.32\n",
      "epoch: 241, loss: 68.43040, loss1: 0.56167, loss2_3: 67.86873\n",
      "\ttrain_acc: 0.8956, test_acc: \u001b[31m0.8685955056179775\u001b[0m, time: 79.28\n",
      "epoch: 242, loss: 68.05323, loss1: 0.55877, loss2_3: 67.49445\n",
      "\ttrain_acc: 0.8962, test_acc: \u001b[31m0.8682022471910112\u001b[0m, time: 79.25\n",
      "epoch: 243, loss: 68.39008, loss1: 0.55919, loss2_3: 67.83089\n",
      "\ttrain_acc: 0.8950, test_acc: \u001b[31m0.866432584269663\u001b[0m, time: 79.86\n",
      "epoch: 244, loss: 68.03747, loss1: 0.56352, loss2_3: 67.47394\n",
      "\ttrain_acc: 0.8990, test_acc: \u001b[31m0.8687921348314607\u001b[0m, time: 79.45\n",
      "epoch: 245, loss: 68.26791, loss1: 0.56093, loss2_3: 67.70698\n",
      "\ttrain_acc: 0.8978, test_acc: \u001b[31m0.869691011235955\u001b[0m, time: 79.16\n",
      "epoch: 246, loss: 67.93060, loss1: 0.56213, loss2_3: 67.36848\n",
      "\ttrain_acc: 0.8992, test_acc: \u001b[31m0.8690730337078652\u001b[0m, time: 78.35\n",
      "epoch: 247, loss: 67.79328, loss1: 0.55779, loss2_3: 67.23549\n",
      "\ttrain_acc: 0.8969, test_acc: \u001b[31m0.8670505617977529\u001b[0m, time: 77.60\n",
      "epoch: 248, loss: 68.06926, loss1: 0.55876, loss2_3: 67.51049\n",
      "\ttrain_acc: 0.8971, test_acc: \u001b[31m0.8696067415730337\u001b[0m, time: 77.77\n",
      "epoch: 249, loss: 68.08350, loss1: 0.56011, loss2_3: 67.52340\n",
      "\ttrain_acc: 0.8934, test_acc: \u001b[31m0.8641853932584269\u001b[0m, time: 77.17\n",
      "epoch: 250, loss: 67.99806, loss1: 0.55835, loss2_3: 67.43971\n",
      "\ttrain_acc: 0.8996, test_acc: \u001b[31m0.8693820224719101\u001b[0m, time: 78.06\n"
     ]
    }
   ],
   "source": [
    "for num_model in range(5):\n",
    "    net=newModel().to(device)\n",
    "    lr = 0.0001\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr,weight_decay=5e-4)\n",
    "    criterion = ContrastiveLoss()\n",
    "    criterion_model = nn.CrossEntropyLoss(reduction='sum')\n",
    "    best_acc=0\n",
    "    EPOCH=250\n",
    "    for epoch in range(EPOCH):\n",
    "        loss_ls=[]\n",
    "        loss1_ls=[]\n",
    "        loss2_3_ls=[]\n",
    "        t0=time.time()\n",
    "        net.train()\n",
    "        for seq1,seq2,label,label1,label2 in train_iter_cont:\n",
    "                output1=net(seq1)\n",
    "                output2=net(seq2)\n",
    "                output3=net.trainModel(seq1)\n",
    "                output4=net.trainModel(seq2)\n",
    "                loss1=criterion(output1, output2, label)\n",
    "                loss2=criterion_model(output3,label1)\n",
    "                loss3=criterion_model(output4,label2)\n",
    "                loss=loss1+loss2+loss3\n",
    "    #             print(loss)\n",
    "                optimizer.zero_grad() \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_ls.append(loss.item())\n",
    "                loss1_ls.append(loss1.item())\n",
    "                loss2_3_ls.append((loss2+loss3).item())\n",
    "\n",
    "\n",
    "        net.eval() \n",
    "        with torch.no_grad(): \n",
    "            train_acc=evaluate_accuracy(train_iter,net)\n",
    "            test_acc=evaluate_accuracy(val_iter,net)\n",
    "        results=f\"epoch: {epoch+1}, loss: {np.mean(loss_ls):.5f}, loss1: {np.mean(loss1_ls):.5f}, loss2_3: {np.mean(loss2_3_ls):.5f}\\n\"\n",
    "        results+=f'\\ttrain_acc: {train_acc:.4f}, test_acc: {colored(test_acc,\"red\")}, time: {time.time()-t0:.2f}'\n",
    "        print(results)\n",
    "#         to_log(results)\n",
    "        if test_acc>best_acc:\n",
    "            best_acc=test_acc\n",
    "#             torch.save({\"best_acc\":best_acc,\"model\":net.state_dict()},f'./Model/{num_model}.pl')\n",
    "            print(f\"best_acc: {best_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T21:22:02.434965Z",
     "start_time": "2021-10-04T21:22:02.410718Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T21:22:02.439656Z",
     "start_time": "2021-10-04T21:22:02.436313Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs.argmax(dim=1):\n",
    "            y_pred.append(int(_))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T21:22:02.445110Z",
     "start_time": "2021-10-04T21:22:02.440723Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred_prob(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs:\n",
    "            y_pred.append(list(map(float, _)))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T09:04:25.557066Z",
     "start_time": "2021-10-06T09:04:10.104412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8678172543203218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86     22330\n",
      "           1       0.85      0.90      0.87     22169\n",
      "\n",
      "    accuracy                           0.87     44499\n",
      "   macro avg       0.87      0.87      0.87     44499\n",
      "weighted avg       0.87      0.87      0.87     44499\n",
      "\n",
      "rf auc : 0.9391573548608613\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_acc = evaluate_accuracy(test_iter,net)\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "# prediction\n",
    "y_pred = pred(test_iter, net)\n",
    "print(classification_report(test_label, y_pred))\n",
    "\n",
    "# AUC\n",
    "probs = np.array(pred_prob(test_iter, net))[:, 1]\n",
    "\n",
    "rf_auc = roc_auc_score(test_label, probs)\n",
    "print('rf auc : {}'.format(rf_auc))\n",
    "# plot the roc curve for the model81\n",
    "rf_fpr, rf_tpr, _ = roc_curve(test_label, probs)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='RF AUC = {:.4f}'.format(rf_auc), color='orange')\n",
    "plt.title('ROC curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "cf_matrix = confusion_matrix(test_label, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=',.0f')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
