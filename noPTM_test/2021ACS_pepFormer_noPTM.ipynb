{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:59:28.812657Z",
     "start_time": "2021-09-30T16:59:27.841497Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import time\n",
    "import pickle\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:59:28.824185Z",
     "start_time": "2021-09-30T16:59:28.815725Z"
    }
   },
   "outputs": [],
   "source": [
    "def genData(file,max_len):\n",
    "    aa_dict={'A':1,'R':2,'N':3,'D':4,'C':5,'Q':6,'E':7,'G':8,'H':9,'I':10,\n",
    "             'L':11,'K':12,'M':13,'F':14,'P':15,'O':16,'S':17,'U':18,'T':19,\n",
    "             'W':20,'Y':21,'V':22,'X':23}\n",
    "    with open(file, 'r') as inf:\n",
    "        lines = inf.read().splitlines()\n",
    "        \n",
    "    long_pep_counter=0\n",
    "    pep_codes=[]\n",
    "    labels=[]\n",
    "    for pep in lines:\n",
    "        pep,label=pep.split(\",\")\n",
    "        labels.append(int(label))\n",
    "        if not len(pep) > max_len:\n",
    "            current_pep=[]\n",
    "            for aa in pep:\n",
    "                current_pep.append(aa_dict[aa])\n",
    "            pep_codes.append(torch.tensor(current_pep))\n",
    "        else:\n",
    "            long_pep_counter += 1\n",
    "    print(\"length > {}:\".format(max_len),long_pep_counter)\n",
    "    data = rnn_utils.pad_sequence(pep_codes, batch_first=True)  # padding\n",
    "    return data,torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:59:28.838834Z",
     "start_time": "2021-09-30T16:59:28.828121Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        acc_sum += (outputs.argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "def to_log(log):\n",
    "    with open(\"../compareModel/2021ACS_PepFormer/modelLog.log\",\"a+\") as f:\n",
    "        f.write(log+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:59:28.849291Z",
     "start_time": "2021-09-30T16:59:28.840775Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    seq1_ls=[]\n",
    "    seq2_ls=[]\n",
    "    label1_ls=[]\n",
    "    label2_ls=[]\n",
    "    label_ls=[]\n",
    "    batch_size=len(batch)\n",
    "    for i in range(int(batch_size/2)):\n",
    "        seq1,label1=batch[i][0],batch[i][1]\n",
    "        seq2,label2=batch[i+int(batch_size/2)][0],batch[i+int(batch_size/2)][1]\n",
    "        label1_ls.append(label1.unsqueeze(0))\n",
    "        label2_ls.append(label2.unsqueeze(0))\n",
    "        label=(label1^label2)\n",
    "        seq1_ls.append(seq1.unsqueeze(0))\n",
    "        seq2_ls.append(seq2.unsqueeze(0))\n",
    "        label_ls.append(label.unsqueeze(0))\n",
    "    seq1=torch.cat(seq1_ls).to(device)\n",
    "    seq2=torch.cat(seq2_ls).to(device)\n",
    "    label=torch.cat(label_ls).to(device)\n",
    "    label1=torch.cat(label1_ls).to(device)\n",
    "    label2=torch.cat(label2_ls).to(device)\n",
    "    return seq1,seq2,label,label1,label2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Data X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:59:29.817260Z",
     "start_time": "2021-09-30T16:59:28.850875Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:59:35.620963Z",
     "start_time": "2021-09-30T16:59:29.819414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length > 30: 0\n",
      "torch.Size([142397, 30]) torch.Size([142397])\n",
      "length > 30: 0\n",
      "torch.Size([35600, 30]) torch.Size([35600])\n",
      "length > 30: 0\n",
      "torch.Size([44499, 30]) torch.Size([44499])\n"
     ]
    }
   ],
   "source": [
    "df_detect_peptide_train = pd.read_csv('../data/df_detect_peptide_train_noptm.csv')\n",
    "df_detect_peptide_test = pd.read_csv('../data/df_detect_peptide_test_noptm.csv')\n",
    "\n",
    "tra, val = train_test_split(df_detect_peptide_train[['PEP', 'ID']], test_size=0.2, random_state=7)\n",
    "tra.to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_train_noptm.csv', header=False, index=False)\n",
    "val.to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_val_noptm.csv', header=False, index=False)\n",
    "df_detect_peptide_test[['PEP', 'ID']].to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_test_noptm.csv', header=False, index=False)\n",
    "\n",
    "train_data,train_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_train_noptm.csv\",30)\n",
    "print(train_data.shape, train_label.shape)\n",
    "train_dataset = Data.TensorDataset(train_data, train_label)\n",
    "\n",
    "val_data,val_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_val_noptm.csv\",30)\n",
    "print(val_data.shape, val_label.shape)\n",
    "val_dataset = Data.TensorDataset(val_data, val_label)\n",
    "\n",
    "test_data,test_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_test_noptm.csv\",30)\n",
    "print(test_data.shape, test_label.shape)\n",
    "test_dataset = Data.TensorDataset(test_data, test_label)\n",
    "\n",
    "batch_size=256\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_iter_cont = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                                                  shuffle=True, collate_fn=collate)\n",
    "val_iter = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:59:35.637798Z",
     "start_time": "2021-09-30T16:59:35.623247Z"
    }
   },
   "outputs": [],
   "source": [
    "class newModel(nn.Module):\n",
    "    def __init__(self, vocab_size=24):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 25\n",
    "        self.batch_size = 256\n",
    "        self.emb_dim = 512\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, self.emb_dim, padding_idx=0)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.gru = nn.GRU(self.emb_dim, self.hidden_dim, num_layers=2, \n",
    "                               bidirectional=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.block1=nn.Sequential(nn.Linear(1600,1024),\n",
    "                                            nn.BatchNorm1d(1024),\n",
    "                                            nn.LeakyReLU(),\n",
    "                                            nn.Linear(1024,256),\n",
    "                                 )\n",
    "\n",
    "        self.block2=nn.Sequential(\n",
    "                                               nn.BatchNorm1d(256),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(256,128),\n",
    "                                               nn.BatchNorm1d(128),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(128,64),\n",
    "                                               nn.BatchNorm1d(64),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(64,2)\n",
    "                                            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.embedding(x)\n",
    "        output=self.transformer_encoder(x).permute(1, 0, 2)\n",
    "        output,hn=self.gru(output)\n",
    "        output=output.permute(1,0,2)\n",
    "        hn=hn.permute(1,0,2)\n",
    "        output=output.reshape(output.shape[0],-1)\n",
    "        hn=hn.reshape(output.shape[0],-1)\n",
    "        output=torch.cat([output,hn],1)\n",
    "        return self.block1(output)\n",
    "\n",
    "    def trainModel(self, x):\n",
    "        with torch.no_grad():\n",
    "            output=self.forward(x)\n",
    "        return self.block2(output)\n",
    "\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # euclidean_distance: [128]\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +     # calmp夹断用法\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))     \n",
    "        \n",
    "        return loss_contrastive\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:59:35.656034Z",
     "start_time": "2021-09-30T16:59:35.639624Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T22:26:37.193781Z",
     "start_time": "2021-09-30T16:59:45.776401Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 159.61594, loss1: 1.71799, loss2_3: 157.89795\n",
      "\ttrain_acc: 0.7756, test_acc: \u001b[31m0.7767696629213483\u001b[0m, time: 45.33\n",
      "best_acc: 0.7767696629213483\n",
      "epoch: 2, loss: 107.92861, loss1: 0.88568, loss2_3: 107.04293\n",
      "\ttrain_acc: 0.8166, test_acc: \u001b[31m0.8153089887640449\u001b[0m, time: 65.78\n",
      "best_acc: 0.8153089887640449\n",
      "epoch: 3, loss: 100.87598, loss1: 0.83497, loss2_3: 100.04101\n",
      "\ttrain_acc: 0.8308, test_acc: \u001b[31m0.8301685393258427\u001b[0m, time: 89.49\n",
      "best_acc: 0.8301685393258427\n",
      "epoch: 4, loss: 97.84169, loss1: 0.81168, loss2_3: 97.03000\n",
      "\ttrain_acc: 0.8419, test_acc: \u001b[31m0.8426123595505618\u001b[0m, time: 89.31\n",
      "best_acc: 0.8426123595505618\n",
      "epoch: 5, loss: 95.25465, loss1: 0.78985, loss2_3: 94.46480\n",
      "\ttrain_acc: 0.8393, test_acc: \u001b[31m0.838061797752809\u001b[0m, time: 63.73\n",
      "epoch: 6, loss: 93.31366, loss1: 0.77655, loss2_3: 92.53711\n",
      "\ttrain_acc: 0.8308, test_acc: \u001b[31m0.8311516853932585\u001b[0m, time: 64.26\n",
      "epoch: 7, loss: 91.61994, loss1: 0.75463, loss2_3: 90.86531\n",
      "\ttrain_acc: 0.8476, test_acc: \u001b[31m0.8472471910112359\u001b[0m, time: 62.33\n",
      "best_acc: 0.8472471910112359\n",
      "epoch: 8, loss: 91.22447, loss1: 0.75466, loss2_3: 90.46981\n",
      "\ttrain_acc: 0.8529, test_acc: \u001b[31m0.8539606741573034\u001b[0m, time: 63.38\n",
      "best_acc: 0.8539606741573034\n",
      "epoch: 9, loss: 89.55383, loss1: 0.73944, loss2_3: 88.81439\n",
      "\ttrain_acc: 0.8494, test_acc: \u001b[31m0.8505056179775281\u001b[0m, time: 62.70\n",
      "epoch: 10, loss: 89.01354, loss1: 0.73136, loss2_3: 88.28218\n",
      "\ttrain_acc: 0.8549, test_acc: \u001b[31m0.8558988764044944\u001b[0m, time: 62.67\n",
      "best_acc: 0.8558988764044944\n",
      "epoch: 11, loss: 88.14790, loss1: 0.72603, loss2_3: 87.42187\n",
      "\ttrain_acc: 0.8561, test_acc: \u001b[31m0.8561797752808988\u001b[0m, time: 63.14\n",
      "best_acc: 0.8561797752808988\n",
      "epoch: 12, loss: 87.38993, loss1: 0.71574, loss2_3: 86.67419\n",
      "\ttrain_acc: 0.8569, test_acc: \u001b[31m0.856629213483146\u001b[0m, time: 62.51\n",
      "best_acc: 0.856629213483146\n",
      "epoch: 13, loss: 87.17224, loss1: 0.71387, loss2_3: 86.45837\n",
      "\ttrain_acc: 0.8573, test_acc: \u001b[31m0.8574157303370786\u001b[0m, time: 63.38\n",
      "best_acc: 0.8574157303370786\n",
      "epoch: 14, loss: 86.28631, loss1: 0.70902, loss2_3: 85.57729\n",
      "\ttrain_acc: 0.8601, test_acc: \u001b[31m0.8599157303370787\u001b[0m, time: 65.36\n",
      "best_acc: 0.8599157303370787\n",
      "epoch: 15, loss: 86.33587, loss1: 0.70230, loss2_3: 85.63357\n",
      "\ttrain_acc: 0.8607, test_acc: \u001b[31m0.859943820224719\u001b[0m, time: 68.91\n",
      "best_acc: 0.859943820224719\n",
      "epoch: 16, loss: 85.75614, loss1: 0.69870, loss2_3: 85.05744\n",
      "\ttrain_acc: 0.8599, test_acc: \u001b[31m0.8598033707865168\u001b[0m, time: 68.86\n",
      "epoch: 17, loss: 85.63692, loss1: 0.69974, loss2_3: 84.93719\n",
      "\ttrain_acc: 0.8582, test_acc: \u001b[31m0.8576966292134831\u001b[0m, time: 68.61\n",
      "epoch: 18, loss: 85.12520, loss1: 0.69669, loss2_3: 84.42851\n",
      "\ttrain_acc: 0.8557, test_acc: \u001b[31m0.8546067415730337\u001b[0m, time: 68.74\n",
      "epoch: 19, loss: 84.83846, loss1: 0.69018, loss2_3: 84.14828\n",
      "\ttrain_acc: 0.8557, test_acc: \u001b[31m0.8532865168539325\u001b[0m, time: 69.45\n",
      "epoch: 20, loss: 84.65085, loss1: 0.68400, loss2_3: 83.96686\n",
      "\ttrain_acc: 0.8605, test_acc: \u001b[31m0.8576123595505618\u001b[0m, time: 68.39\n",
      "epoch: 21, loss: 84.15714, loss1: 0.68404, loss2_3: 83.47309\n",
      "\ttrain_acc: 0.8632, test_acc: \u001b[31m0.8620505617977529\u001b[0m, time: 69.08\n",
      "best_acc: 0.8620505617977529\n",
      "epoch: 22, loss: 84.20540, loss1: 0.68123, loss2_3: 83.52417\n",
      "\ttrain_acc: 0.8640, test_acc: \u001b[31m0.8638483146067416\u001b[0m, time: 68.95\n",
      "best_acc: 0.8638483146067416\n",
      "epoch: 23, loss: 83.90007, loss1: 0.67875, loss2_3: 83.22133\n",
      "\ttrain_acc: 0.8647, test_acc: \u001b[31m0.8644662921348315\u001b[0m, time: 68.98\n",
      "best_acc: 0.8644662921348315\n",
      "epoch: 24, loss: 83.95711, loss1: 0.67536, loss2_3: 83.28175\n",
      "\ttrain_acc: 0.8636, test_acc: \u001b[31m0.8634831460674157\u001b[0m, time: 68.95\n",
      "epoch: 25, loss: 83.63195, loss1: 0.67712, loss2_3: 82.95483\n",
      "\ttrain_acc: 0.8641, test_acc: \u001b[31m0.8628932584269663\u001b[0m, time: 68.13\n",
      "epoch: 26, loss: 83.31297, loss1: 0.67255, loss2_3: 82.64042\n",
      "\ttrain_acc: 0.8659, test_acc: \u001b[31m0.8650280898876405\u001b[0m, time: 69.49\n",
      "best_acc: 0.8650280898876405\n",
      "epoch: 27, loss: 83.07766, loss1: 0.67022, loss2_3: 82.40743\n",
      "\ttrain_acc: 0.8657, test_acc: \u001b[31m0.8640449438202247\u001b[0m, time: 68.97\n",
      "epoch: 28, loss: 83.09850, loss1: 0.66990, loss2_3: 82.42859\n",
      "\ttrain_acc: 0.8645, test_acc: \u001b[31m0.8638202247191011\u001b[0m, time: 69.50\n",
      "epoch: 29, loss: 82.67818, loss1: 0.66708, loss2_3: 82.01110\n",
      "\ttrain_acc: 0.8653, test_acc: \u001b[31m0.8644101123595506\u001b[0m, time: 69.12\n",
      "epoch: 30, loss: 82.60693, loss1: 0.66509, loss2_3: 81.94184\n",
      "\ttrain_acc: 0.8646, test_acc: \u001b[31m0.861938202247191\u001b[0m, time: 68.88\n",
      "epoch: 31, loss: 82.33166, loss1: 0.66438, loss2_3: 81.66728\n",
      "\ttrain_acc: 0.8670, test_acc: \u001b[31m0.866123595505618\u001b[0m, time: 68.73\n",
      "best_acc: 0.866123595505618\n",
      "epoch: 32, loss: 82.27199, loss1: 0.66219, loss2_3: 81.60980\n",
      "\ttrain_acc: 0.8673, test_acc: \u001b[31m0.8653370786516854\u001b[0m, time: 68.86\n",
      "epoch: 33, loss: 81.92780, loss1: 0.65906, loss2_3: 81.26874\n",
      "\ttrain_acc: 0.8646, test_acc: \u001b[31m0.8635393258426967\u001b[0m, time: 68.94\n",
      "epoch: 34, loss: 81.81506, loss1: 0.65463, loss2_3: 81.16042\n",
      "\ttrain_acc: 0.8662, test_acc: \u001b[31m0.8632303370786517\u001b[0m, time: 69.06\n",
      "epoch: 35, loss: 81.63980, loss1: 0.65547, loss2_3: 80.98432\n",
      "\ttrain_acc: 0.8666, test_acc: \u001b[31m0.8635393258426967\u001b[0m, time: 68.74\n",
      "epoch: 36, loss: 81.47795, loss1: 0.65425, loss2_3: 80.82370\n",
      "\ttrain_acc: 0.8696, test_acc: \u001b[31m0.8669943820224719\u001b[0m, time: 68.68\n",
      "best_acc: 0.8669943820224719\n",
      "epoch: 37, loss: 81.16389, loss1: 0.64912, loss2_3: 80.51477\n",
      "\ttrain_acc: 0.8690, test_acc: \u001b[31m0.8656460674157304\u001b[0m, time: 68.56\n",
      "epoch: 38, loss: 80.94520, loss1: 0.65295, loss2_3: 80.29225\n",
      "\ttrain_acc: 0.8635, test_acc: \u001b[31m0.8596067415730337\u001b[0m, time: 69.25\n",
      "epoch: 39, loss: 81.02358, loss1: 0.64820, loss2_3: 80.37539\n",
      "\ttrain_acc: 0.8689, test_acc: \u001b[31m0.8670505617977529\u001b[0m, time: 68.69\n",
      "best_acc: 0.8670505617977529\n",
      "epoch: 40, loss: 80.71074, loss1: 0.64251, loss2_3: 80.06823\n",
      "\ttrain_acc: 0.8695, test_acc: \u001b[31m0.8672191011235955\u001b[0m, time: 68.53\n",
      "best_acc: 0.8672191011235955\n",
      "epoch: 41, loss: 80.60459, loss1: 0.64786, loss2_3: 79.95673\n",
      "\ttrain_acc: 0.8704, test_acc: \u001b[31m0.8689325842696629\u001b[0m, time: 68.59\n",
      "best_acc: 0.8689325842696629\n",
      "epoch: 42, loss: 80.33851, loss1: 0.64428, loss2_3: 79.69423\n",
      "\ttrain_acc: 0.8696, test_acc: \u001b[31m0.8677247191011236\u001b[0m, time: 69.08\n",
      "epoch: 43, loss: 79.99847, loss1: 0.64122, loss2_3: 79.35725\n",
      "\ttrain_acc: 0.8719, test_acc: \u001b[31m0.8694943820224719\u001b[0m, time: 69.21\n",
      "best_acc: 0.8694943820224719\n",
      "epoch: 44, loss: 79.67454, loss1: 0.63667, loss2_3: 79.03787\n",
      "\ttrain_acc: 0.8708, test_acc: \u001b[31m0.867808988764045\u001b[0m, time: 68.99\n",
      "epoch: 45, loss: 79.64913, loss1: 0.64195, loss2_3: 79.00718\n",
      "\ttrain_acc: 0.8687, test_acc: \u001b[31m0.8653089887640449\u001b[0m, time: 68.83\n",
      "epoch: 46, loss: 79.68601, loss1: 0.63847, loss2_3: 79.04754\n",
      "\ttrain_acc: 0.8648, test_acc: \u001b[31m0.8633426966292135\u001b[0m, time: 68.47\n",
      "epoch: 47, loss: 79.44934, loss1: 0.63518, loss2_3: 78.81416\n",
      "\ttrain_acc: 0.8715, test_acc: \u001b[31m0.868370786516854\u001b[0m, time: 68.50\n",
      "epoch: 48, loss: 79.43002, loss1: 0.63890, loss2_3: 78.79112\n",
      "\ttrain_acc: 0.8705, test_acc: \u001b[31m0.8655898876404494\u001b[0m, time: 69.14\n",
      "epoch: 49, loss: 79.23754, loss1: 0.63499, loss2_3: 78.60255\n",
      "\ttrain_acc: 0.8723, test_acc: \u001b[31m0.8684831460674157\u001b[0m, time: 69.24\n",
      "epoch: 50, loss: 78.95582, loss1: 0.63350, loss2_3: 78.32233\n",
      "\ttrain_acc: 0.8712, test_acc: \u001b[31m0.8691292134831461\u001b[0m, time: 69.03\n",
      "epoch: 51, loss: 78.91480, loss1: 0.63364, loss2_3: 78.28116\n",
      "\ttrain_acc: 0.8730, test_acc: \u001b[31m0.8707865168539326\u001b[0m, time: 86.73\n",
      "best_acc: 0.8707865168539326\n",
      "epoch: 52, loss: 79.01207, loss1: 0.63345, loss2_3: 78.37861\n",
      "\ttrain_acc: 0.8723, test_acc: \u001b[31m0.8693539325842696\u001b[0m, time: 86.42\n",
      "epoch: 53, loss: 78.69311, loss1: 0.62784, loss2_3: 78.06527\n",
      "\ttrain_acc: 0.8663, test_acc: \u001b[31m0.8623595505617978\u001b[0m, time: 86.60\n",
      "epoch: 54, loss: 78.75216, loss1: 0.63074, loss2_3: 78.12142\n",
      "\ttrain_acc: 0.8730, test_acc: \u001b[31m0.8685674157303371\u001b[0m, time: 88.12\n",
      "epoch: 55, loss: 78.61608, loss1: 0.62664, loss2_3: 77.98944\n",
      "\ttrain_acc: 0.8734, test_acc: \u001b[31m0.8698595505617978\u001b[0m, time: 87.62\n",
      "epoch: 56, loss: 78.32293, loss1: 0.62624, loss2_3: 77.69669\n",
      "\ttrain_acc: 0.8734, test_acc: \u001b[31m0.8714044943820225\u001b[0m, time: 86.11\n",
      "best_acc: 0.8714044943820225\n",
      "epoch: 57, loss: 78.18526, loss1: 0.62742, loss2_3: 77.55784\n",
      "\ttrain_acc: 0.8728, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 86.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 58, loss: 78.27410, loss1: 0.62901, loss2_3: 77.64509\n",
      "\ttrain_acc: 0.8741, test_acc: \u001b[31m0.8705898876404494\u001b[0m, time: 85.99\n",
      "epoch: 59, loss: 78.21847, loss1: 0.62532, loss2_3: 77.59315\n",
      "\ttrain_acc: 0.8722, test_acc: \u001b[31m0.8660955056179775\u001b[0m, time: 87.59\n",
      "epoch: 60, loss: 78.19763, loss1: 0.62728, loss2_3: 77.57035\n",
      "\ttrain_acc: 0.8739, test_acc: \u001b[31m0.8700561797752809\u001b[0m, time: 87.12\n",
      "epoch: 61, loss: 77.94862, loss1: 0.62177, loss2_3: 77.32685\n",
      "\ttrain_acc: 0.8749, test_acc: \u001b[31m0.8715168539325843\u001b[0m, time: 87.22\n",
      "best_acc: 0.8715168539325843\n",
      "epoch: 62, loss: 77.93366, loss1: 0.62381, loss2_3: 77.30984\n",
      "\ttrain_acc: 0.8744, test_acc: \u001b[31m0.871685393258427\u001b[0m, time: 87.15\n",
      "best_acc: 0.871685393258427\n",
      "epoch: 63, loss: 77.71453, loss1: 0.62602, loss2_3: 77.08852\n",
      "\ttrain_acc: 0.8736, test_acc: \u001b[31m0.8717134831460674\u001b[0m, time: 85.98\n",
      "best_acc: 0.8717134831460674\n",
      "epoch: 64, loss: 77.69325, loss1: 0.62081, loss2_3: 77.07244\n",
      "\ttrain_acc: 0.8754, test_acc: \u001b[31m0.8713483146067416\u001b[0m, time: 86.93\n",
      "epoch: 65, loss: 77.69057, loss1: 0.62001, loss2_3: 77.07056\n",
      "\ttrain_acc: 0.8758, test_acc: \u001b[31m0.873370786516854\u001b[0m, time: 85.72\n",
      "best_acc: 0.873370786516854\n",
      "epoch: 66, loss: 77.47943, loss1: 0.61855, loss2_3: 76.86088\n",
      "\ttrain_acc: 0.8726, test_acc: \u001b[31m0.8693539325842696\u001b[0m, time: 87.84\n",
      "epoch: 67, loss: 77.45292, loss1: 0.62226, loss2_3: 76.83066\n",
      "\ttrain_acc: 0.8758, test_acc: \u001b[31m0.8719662921348315\u001b[0m, time: 86.98\n",
      "epoch: 68, loss: 77.52871, loss1: 0.61853, loss2_3: 76.91018\n",
      "\ttrain_acc: 0.8750, test_acc: \u001b[31m0.8708146067415731\u001b[0m, time: 86.90\n",
      "epoch: 69, loss: 77.22697, loss1: 0.61958, loss2_3: 76.60739\n",
      "\ttrain_acc: 0.8732, test_acc: \u001b[31m0.8686797752808989\u001b[0m, time: 86.96\n",
      "epoch: 70, loss: 77.28597, loss1: 0.62309, loss2_3: 76.66288\n",
      "\ttrain_acc: 0.8752, test_acc: \u001b[31m0.8725280898876404\u001b[0m, time: 86.77\n",
      "epoch: 71, loss: 77.32455, loss1: 0.61824, loss2_3: 76.70631\n",
      "\ttrain_acc: 0.8743, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 87.45\n",
      "epoch: 72, loss: 77.22204, loss1: 0.61763, loss2_3: 76.60441\n",
      "\ttrain_acc: 0.8764, test_acc: \u001b[31m0.8722191011235955\u001b[0m, time: 86.74\n",
      "epoch: 73, loss: 77.07441, loss1: 0.62056, loss2_3: 76.45384\n",
      "\ttrain_acc: 0.8737, test_acc: \u001b[31m0.8684831460674157\u001b[0m, time: 87.58\n",
      "epoch: 74, loss: 77.07518, loss1: 0.61661, loss2_3: 76.45857\n",
      "\ttrain_acc: 0.8737, test_acc: \u001b[31m0.8692415730337079\u001b[0m, time: 87.83\n",
      "epoch: 75, loss: 77.09910, loss1: 0.61750, loss2_3: 76.48160\n",
      "\ttrain_acc: 0.8770, test_acc: \u001b[31m0.8715730337078652\u001b[0m, time: 86.69\n",
      "epoch: 76, loss: 76.89844, loss1: 0.61402, loss2_3: 76.28441\n",
      "\ttrain_acc: 0.8762, test_acc: \u001b[31m0.8701123595505618\u001b[0m, time: 87.03\n",
      "epoch: 77, loss: 76.83727, loss1: 0.61509, loss2_3: 76.22218\n",
      "\ttrain_acc: 0.8773, test_acc: \u001b[31m0.8723314606741573\u001b[0m, time: 86.46\n",
      "epoch: 78, loss: 76.84008, loss1: 0.61275, loss2_3: 76.22733\n",
      "\ttrain_acc: 0.8757, test_acc: \u001b[31m0.8717977528089887\u001b[0m, time: 87.68\n",
      "epoch: 79, loss: 76.85603, loss1: 0.61260, loss2_3: 76.24343\n",
      "\ttrain_acc: 0.8764, test_acc: \u001b[31m0.8710393258426966\u001b[0m, time: 87.07\n",
      "epoch: 80, loss: 76.81060, loss1: 0.61262, loss2_3: 76.19798\n",
      "\ttrain_acc: 0.8758, test_acc: \u001b[31m0.8694943820224719\u001b[0m, time: 86.70\n",
      "epoch: 81, loss: 76.67795, loss1: 0.61148, loss2_3: 76.06647\n",
      "\ttrain_acc: 0.8733, test_acc: \u001b[31m0.8657584269662921\u001b[0m, time: 87.13\n",
      "epoch: 82, loss: 76.48602, loss1: 0.61439, loss2_3: 75.87164\n",
      "\ttrain_acc: 0.8769, test_acc: \u001b[31m0.8703932584269662\u001b[0m, time: 86.79\n",
      "epoch: 83, loss: 76.46828, loss1: 0.61178, loss2_3: 75.85651\n",
      "\ttrain_acc: 0.8752, test_acc: \u001b[31m0.8676966292134831\u001b[0m, time: 87.49\n",
      "epoch: 84, loss: 76.51205, loss1: 0.61293, loss2_3: 75.89912\n",
      "\ttrain_acc: 0.8779, test_acc: \u001b[31m0.8726685393258427\u001b[0m, time: 86.08\n",
      "epoch: 85, loss: 76.45970, loss1: 0.61212, loss2_3: 75.84758\n",
      "\ttrain_acc: 0.8777, test_acc: \u001b[31m0.8719101123595505\u001b[0m, time: 87.32\n",
      "epoch: 86, loss: 76.33333, loss1: 0.60986, loss2_3: 75.72347\n",
      "\ttrain_acc: 0.8783, test_acc: \u001b[31m0.8710112359550561\u001b[0m, time: 87.22\n",
      "epoch: 87, loss: 76.45170, loss1: 0.61093, loss2_3: 75.84077\n",
      "\ttrain_acc: 0.8763, test_acc: \u001b[31m0.8690730337078652\u001b[0m, time: 86.95\n",
      "epoch: 88, loss: 76.31300, loss1: 0.61022, loss2_3: 75.70278\n",
      "\ttrain_acc: 0.8757, test_acc: \u001b[31m0.8691573033707866\u001b[0m, time: 87.42\n",
      "epoch: 89, loss: 76.25039, loss1: 0.60788, loss2_3: 75.64251\n",
      "\ttrain_acc: 0.8785, test_acc: \u001b[31m0.8726685393258427\u001b[0m, time: 86.03\n",
      "epoch: 90, loss: 76.20867, loss1: 0.60758, loss2_3: 75.60109\n",
      "\ttrain_acc: 0.8771, test_acc: \u001b[31m0.8715730337078652\u001b[0m, time: 87.99\n",
      "epoch: 91, loss: 76.26501, loss1: 0.60985, loss2_3: 75.65515\n",
      "\ttrain_acc: 0.8775, test_acc: \u001b[31m0.8718258426966292\u001b[0m, time: 87.16\n",
      "epoch: 92, loss: 76.26132, loss1: 0.61211, loss2_3: 75.64921\n",
      "\ttrain_acc: 0.8780, test_acc: \u001b[31m0.8710955056179776\u001b[0m, time: 87.29\n",
      "epoch: 93, loss: 76.18268, loss1: 0.60890, loss2_3: 75.57378\n",
      "\ttrain_acc: 0.8763, test_acc: \u001b[31m0.8690449438202247\u001b[0m, time: 87.16\n",
      "epoch: 94, loss: 76.32375, loss1: 0.60674, loss2_3: 75.71702\n",
      "\ttrain_acc: 0.8792, test_acc: \u001b[31m0.8730056179775281\u001b[0m, time: 86.76\n",
      "epoch: 95, loss: 76.08522, loss1: 0.60825, loss2_3: 75.47697\n",
      "\ttrain_acc: 0.8788, test_acc: \u001b[31m0.8726966292134831\u001b[0m, time: 87.20\n",
      "epoch: 96, loss: 75.67634, loss1: 0.60899, loss2_3: 75.06734\n",
      "\ttrain_acc: 0.8784, test_acc: \u001b[31m0.8723314606741573\u001b[0m, time: 85.85\n",
      "epoch: 97, loss: 75.85596, loss1: 0.60848, loss2_3: 75.24748\n",
      "\ttrain_acc: 0.8775, test_acc: \u001b[31m0.8713202247191011\u001b[0m, time: 87.28\n",
      "epoch: 98, loss: 75.97566, loss1: 0.61037, loss2_3: 75.36528\n",
      "\ttrain_acc: 0.8773, test_acc: \u001b[31m0.8721067415730337\u001b[0m, time: 87.31\n",
      "epoch: 99, loss: 75.79807, loss1: 0.60620, loss2_3: 75.19187\n",
      "\ttrain_acc: 0.8784, test_acc: \u001b[31m0.8715730337078652\u001b[0m, time: 87.33\n",
      "epoch: 100, loss: 75.78546, loss1: 0.60696, loss2_3: 75.17850\n",
      "\ttrain_acc: 0.8775, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 87.31\n",
      "epoch: 101, loss: 75.87062, loss1: 0.60377, loss2_3: 75.26685\n",
      "\ttrain_acc: 0.8786, test_acc: \u001b[31m0.8706741573033708\u001b[0m, time: 86.47\n",
      "epoch: 102, loss: 75.92164, loss1: 0.60994, loss2_3: 75.31170\n",
      "\ttrain_acc: 0.8780, test_acc: \u001b[31m0.8703089887640449\u001b[0m, time: 87.75\n",
      "epoch: 103, loss: 75.68464, loss1: 0.60564, loss2_3: 75.07901\n",
      "\ttrain_acc: 0.8783, test_acc: \u001b[31m0.8708146067415731\u001b[0m, time: 86.50\n",
      "epoch: 104, loss: 75.70762, loss1: 0.60662, loss2_3: 75.10101\n",
      "\ttrain_acc: 0.8789, test_acc: \u001b[31m0.8709831460674158\u001b[0m, time: 87.27\n",
      "epoch: 105, loss: 75.55639, loss1: 0.60530, loss2_3: 74.95109\n",
      "\ttrain_acc: 0.8782, test_acc: \u001b[31m0.8681460674157303\u001b[0m, time: 86.88\n",
      "epoch: 106, loss: 75.65615, loss1: 0.60584, loss2_3: 75.05031\n",
      "\ttrain_acc: 0.8798, test_acc: \u001b[31m0.8725842696629214\u001b[0m, time: 87.62\n",
      "epoch: 107, loss: 75.55783, loss1: 0.60855, loss2_3: 74.94928\n",
      "\ttrain_acc: 0.8795, test_acc: \u001b[31m0.8721910112359551\u001b[0m, time: 87.73\n",
      "epoch: 108, loss: 75.43188, loss1: 0.60238, loss2_3: 74.82950\n",
      "\ttrain_acc: 0.8786, test_acc: \u001b[31m0.8709550561797753\u001b[0m, time: 85.41\n",
      "epoch: 109, loss: 75.33027, loss1: 0.60436, loss2_3: 74.72591\n",
      "\ttrain_acc: 0.8806, test_acc: \u001b[31m0.8723595505617977\u001b[0m, time: 87.49\n",
      "epoch: 110, loss: 75.40554, loss1: 0.60532, loss2_3: 74.80021\n",
      "\ttrain_acc: 0.8803, test_acc: \u001b[31m0.8708426966292134\u001b[0m, time: 86.49\n",
      "epoch: 111, loss: 75.28052, loss1: 0.60264, loss2_3: 74.67788\n",
      "\ttrain_acc: 0.8811, test_acc: \u001b[31m0.8723876404494382\u001b[0m, time: 87.77\n",
      "epoch: 112, loss: 75.19725, loss1: 0.60197, loss2_3: 74.59529\n",
      "\ttrain_acc: 0.8784, test_acc: \u001b[31m0.8722752808988764\u001b[0m, time: 87.22\n",
      "epoch: 113, loss: 75.29186, loss1: 0.60071, loss2_3: 74.69115\n",
      "\ttrain_acc: 0.8801, test_acc: \u001b[31m0.8735112359550562\u001b[0m, time: 86.70\n",
      "best_acc: 0.8735112359550562\n",
      "epoch: 114, loss: 75.33435, loss1: 0.60238, loss2_3: 74.73197\n",
      "\ttrain_acc: 0.8797, test_acc: \u001b[31m0.8723595505617977\u001b[0m, time: 87.29\n",
      "epoch: 115, loss: 75.16887, loss1: 0.60123, loss2_3: 74.56764\n",
      "\ttrain_acc: 0.8790, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 86.74\n",
      "epoch: 116, loss: 75.32825, loss1: 0.60375, loss2_3: 74.72450\n",
      "\ttrain_acc: 0.8765, test_acc: \u001b[31m0.8664887640449438\u001b[0m, time: 84.63\n",
      "epoch: 117, loss: 75.19009, loss1: 0.60482, loss2_3: 74.58526\n",
      "\ttrain_acc: 0.8798, test_acc: \u001b[31m0.8704775280898877\u001b[0m, time: 80.62\n",
      "epoch: 118, loss: 75.04647, loss1: 0.60473, loss2_3: 74.44174\n",
      "\ttrain_acc: 0.8804, test_acc: \u001b[31m0.8713483146067416\u001b[0m, time: 77.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 119, loss: 75.10066, loss1: 0.60143, loss2_3: 74.49923\n",
      "\ttrain_acc: 0.8807, test_acc: \u001b[31m0.8723876404494382\u001b[0m, time: 77.22\n",
      "epoch: 120, loss: 75.00407, loss1: 0.60148, loss2_3: 74.40259\n",
      "\ttrain_acc: 0.8807, test_acc: \u001b[31m0.8737640449438202\u001b[0m, time: 77.23\n",
      "best_acc: 0.8737640449438202\n",
      "epoch: 121, loss: 74.82857, loss1: 0.60055, loss2_3: 74.22802\n",
      "\ttrain_acc: 0.8794, test_acc: \u001b[31m0.8705337078651686\u001b[0m, time: 77.36\n",
      "epoch: 122, loss: 75.14674, loss1: 0.59943, loss2_3: 74.54732\n",
      "\ttrain_acc: 0.8803, test_acc: \u001b[31m0.8729494382022472\u001b[0m, time: 77.72\n",
      "epoch: 123, loss: 74.88347, loss1: 0.59922, loss2_3: 74.28425\n",
      "\ttrain_acc: 0.8778, test_acc: \u001b[31m0.8705898876404494\u001b[0m, time: 77.64\n",
      "epoch: 124, loss: 74.99961, loss1: 0.60229, loss2_3: 74.39731\n",
      "\ttrain_acc: 0.8810, test_acc: \u001b[31m0.8707584269662921\u001b[0m, time: 76.98\n",
      "epoch: 125, loss: 74.91091, loss1: 0.60010, loss2_3: 74.31081\n",
      "\ttrain_acc: 0.8817, test_acc: \u001b[31m0.8727808988764045\u001b[0m, time: 77.54\n",
      "epoch: 126, loss: 74.77777, loss1: 0.59876, loss2_3: 74.17901\n",
      "\ttrain_acc: 0.8818, test_acc: \u001b[31m0.8715730337078652\u001b[0m, time: 77.55\n",
      "epoch: 127, loss: 74.75017, loss1: 0.60246, loss2_3: 74.14772\n",
      "\ttrain_acc: 0.8802, test_acc: \u001b[31m0.8691573033707866\u001b[0m, time: 77.03\n",
      "epoch: 128, loss: 74.74553, loss1: 0.60195, loss2_3: 74.14358\n",
      "\ttrain_acc: 0.8808, test_acc: \u001b[31m0.8711516853932584\u001b[0m, time: 77.20\n",
      "epoch: 129, loss: 74.94181, loss1: 0.60093, loss2_3: 74.34088\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.871123595505618\u001b[0m, time: 77.61\n",
      "epoch: 130, loss: 74.80833, loss1: 0.59716, loss2_3: 74.21116\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8712921348314607\u001b[0m, time: 77.41\n",
      "epoch: 131, loss: 74.71228, loss1: 0.59747, loss2_3: 74.11482\n",
      "\ttrain_acc: 0.8815, test_acc: \u001b[31m0.8728370786516854\u001b[0m, time: 76.70\n",
      "epoch: 132, loss: 74.80579, loss1: 0.60298, loss2_3: 74.20281\n",
      "\ttrain_acc: 0.8822, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 77.75\n",
      "epoch: 133, loss: 74.54809, loss1: 0.59973, loss2_3: 73.94836\n",
      "\ttrain_acc: 0.8790, test_acc: \u001b[31m0.8670786516853932\u001b[0m, time: 77.78\n",
      "epoch: 134, loss: 74.66460, loss1: 0.59452, loss2_3: 74.07009\n",
      "\ttrain_acc: 0.8825, test_acc: \u001b[31m0.8730898876404495\u001b[0m, time: 76.81\n",
      "epoch: 135, loss: 74.55873, loss1: 0.59784, loss2_3: 73.96089\n",
      "\ttrain_acc: 0.8827, test_acc: \u001b[31m0.8726123595505618\u001b[0m, time: 77.81\n",
      "epoch: 136, loss: 74.35299, loss1: 0.59623, loss2_3: 73.75676\n",
      "\ttrain_acc: 0.8807, test_acc: \u001b[31m0.8700842696629213\u001b[0m, time: 77.65\n",
      "epoch: 137, loss: 74.52306, loss1: 0.60007, loss2_3: 73.92299\n",
      "\ttrain_acc: 0.8813, test_acc: \u001b[31m0.8716011235955056\u001b[0m, time: 78.01\n",
      "epoch: 138, loss: 74.50476, loss1: 0.59640, loss2_3: 73.90835\n",
      "\ttrain_acc: 0.8825, test_acc: \u001b[31m0.8726685393258427\u001b[0m, time: 76.94\n",
      "epoch: 139, loss: 74.32256, loss1: 0.59768, loss2_3: 73.72489\n",
      "\ttrain_acc: 0.8818, test_acc: \u001b[31m0.8727247191011236\u001b[0m, time: 77.57\n",
      "epoch: 140, loss: 74.53228, loss1: 0.59592, loss2_3: 73.93636\n",
      "\ttrain_acc: 0.8810, test_acc: \u001b[31m0.8710393258426966\u001b[0m, time: 77.75\n",
      "epoch: 141, loss: 74.27324, loss1: 0.59385, loss2_3: 73.67939\n",
      "\ttrain_acc: 0.8822, test_acc: \u001b[31m0.8726123595505618\u001b[0m, time: 77.03\n",
      "epoch: 142, loss: 74.24432, loss1: 0.59517, loss2_3: 73.64915\n",
      "\ttrain_acc: 0.8795, test_acc: \u001b[31m0.8673314606741573\u001b[0m, time: 77.24\n",
      "epoch: 143, loss: 74.40126, loss1: 0.59585, loss2_3: 73.80541\n",
      "\ttrain_acc: 0.8819, test_acc: \u001b[31m0.8724719101123596\u001b[0m, time: 77.20\n",
      "epoch: 144, loss: 74.33972, loss1: 0.59447, loss2_3: 73.74525\n",
      "\ttrain_acc: 0.8829, test_acc: \u001b[31m0.8739325842696629\u001b[0m, time: 77.41\n",
      "best_acc: 0.8739325842696629\n",
      "epoch: 145, loss: 74.13388, loss1: 0.59471, loss2_3: 73.53918\n",
      "\ttrain_acc: 0.8814, test_acc: \u001b[31m0.870252808988764\u001b[0m, time: 77.22\n",
      "epoch: 146, loss: 74.35696, loss1: 0.59827, loss2_3: 73.75868\n",
      "\ttrain_acc: 0.8832, test_acc: \u001b[31m0.8728932584269663\u001b[0m, time: 77.42\n",
      "epoch: 147, loss: 74.18295, loss1: 0.59477, loss2_3: 73.58818\n",
      "\ttrain_acc: 0.8833, test_acc: \u001b[31m0.8725280898876404\u001b[0m, time: 77.96\n",
      "epoch: 148, loss: 74.13017, loss1: 0.59400, loss2_3: 73.53617\n",
      "\ttrain_acc: 0.8817, test_acc: \u001b[31m0.871376404494382\u001b[0m, time: 76.82\n",
      "epoch: 149, loss: 74.01366, loss1: 0.59572, loss2_3: 73.41795\n",
      "\ttrain_acc: 0.8804, test_acc: \u001b[31m0.8687921348314607\u001b[0m, time: 77.33\n",
      "epoch: 150, loss: 74.04946, loss1: 0.59612, loss2_3: 73.45334\n",
      "\ttrain_acc: 0.8835, test_acc: \u001b[31m0.8715449438202247\u001b[0m, time: 77.78\n",
      "epoch: 151, loss: 73.98898, loss1: 0.59638, loss2_3: 73.39259\n",
      "\ttrain_acc: 0.8838, test_acc: \u001b[31m0.8728932584269663\u001b[0m, time: 77.56\n",
      "epoch: 152, loss: 73.88116, loss1: 0.59300, loss2_3: 73.28816\n",
      "\ttrain_acc: 0.8829, test_acc: \u001b[31m0.8714887640449438\u001b[0m, time: 77.17\n",
      "epoch: 153, loss: 73.91519, loss1: 0.59108, loss2_3: 73.32411\n",
      "\ttrain_acc: 0.8832, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 77.19\n",
      "epoch: 154, loss: 74.02877, loss1: 0.59442, loss2_3: 73.43435\n",
      "\ttrain_acc: 0.8834, test_acc: \u001b[31m0.8721348314606742\u001b[0m, time: 78.06\n",
      "epoch: 155, loss: 73.73193, loss1: 0.59598, loss2_3: 73.13595\n",
      "\ttrain_acc: 0.8835, test_acc: \u001b[31m0.8720786516853932\u001b[0m, time: 76.75\n",
      "epoch: 156, loss: 73.65991, loss1: 0.59140, loss2_3: 73.06850\n",
      "\ttrain_acc: 0.8845, test_acc: \u001b[31m0.8729213483146068\u001b[0m, time: 77.15\n",
      "epoch: 157, loss: 73.63280, loss1: 0.59195, loss2_3: 73.04085\n",
      "\ttrain_acc: 0.8844, test_acc: \u001b[31m0.871123595505618\u001b[0m, time: 77.84\n",
      "epoch: 158, loss: 73.75398, loss1: 0.59074, loss2_3: 73.16324\n",
      "\ttrain_acc: 0.8845, test_acc: \u001b[31m0.8715449438202247\u001b[0m, time: 76.83\n",
      "epoch: 159, loss: 73.89413, loss1: 0.59545, loss2_3: 73.29868\n",
      "\ttrain_acc: 0.8849, test_acc: \u001b[31m0.8723876404494382\u001b[0m, time: 77.34\n",
      "epoch: 160, loss: 73.67092, loss1: 0.58999, loss2_3: 73.08093\n",
      "\ttrain_acc: 0.8823, test_acc: \u001b[31m0.8691573033707866\u001b[0m, time: 77.35\n",
      "epoch: 161, loss: 73.52621, loss1: 0.59286, loss2_3: 72.93335\n",
      "\ttrain_acc: 0.8844, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 77.68\n",
      "epoch: 162, loss: 73.57364, loss1: 0.58954, loss2_3: 72.98409\n",
      "\ttrain_acc: 0.8854, test_acc: \u001b[31m0.8730898876404495\u001b[0m, time: 76.84\n",
      "epoch: 163, loss: 73.42964, loss1: 0.59275, loss2_3: 72.83689\n",
      "\ttrain_acc: 0.8854, test_acc: \u001b[31m0.8713483146067416\u001b[0m, time: 77.55\n",
      "epoch: 164, loss: 73.46678, loss1: 0.59258, loss2_3: 72.87420\n",
      "\ttrain_acc: 0.8849, test_acc: \u001b[31m0.8713483146067416\u001b[0m, time: 77.87\n",
      "epoch: 165, loss: 73.43964, loss1: 0.59059, loss2_3: 72.84905\n",
      "\ttrain_acc: 0.8851, test_acc: \u001b[31m0.8718258426966292\u001b[0m, time: 76.94\n",
      "epoch: 166, loss: 73.47071, loss1: 0.59011, loss2_3: 72.88061\n",
      "\ttrain_acc: 0.8857, test_acc: \u001b[31m0.8732303370786517\u001b[0m, time: 77.61\n",
      "epoch: 167, loss: 73.39842, loss1: 0.59120, loss2_3: 72.80723\n",
      "\ttrain_acc: 0.8843, test_acc: \u001b[31m0.8706179775280899\u001b[0m, time: 77.18\n",
      "epoch: 168, loss: 73.38456, loss1: 0.58934, loss2_3: 72.79522\n",
      "\ttrain_acc: 0.8862, test_acc: \u001b[31m0.8730337078651685\u001b[0m, time: 78.42\n",
      "epoch: 169, loss: 73.25698, loss1: 0.58971, loss2_3: 72.66727\n",
      "\ttrain_acc: 0.8846, test_acc: \u001b[31m0.8726685393258427\u001b[0m, time: 76.83\n",
      "epoch: 170, loss: 73.23601, loss1: 0.58966, loss2_3: 72.64635\n",
      "\ttrain_acc: 0.8855, test_acc: \u001b[31m0.8740168539325842\u001b[0m, time: 77.13\n",
      "best_acc: 0.8740168539325842\n",
      "epoch: 171, loss: 73.22930, loss1: 0.58866, loss2_3: 72.64064\n",
      "\ttrain_acc: 0.8846, test_acc: \u001b[31m0.8726123595505618\u001b[0m, time: 78.08\n",
      "epoch: 172, loss: 73.23447, loss1: 0.59120, loss2_3: 72.64327\n",
      "\ttrain_acc: 0.8835, test_acc: \u001b[31m0.8692415730337079\u001b[0m, time: 77.00\n",
      "epoch: 173, loss: 73.10781, loss1: 0.58854, loss2_3: 72.51926\n",
      "\ttrain_acc: 0.8856, test_acc: \u001b[31m0.8715168539325843\u001b[0m, time: 77.38\n",
      "epoch: 174, loss: 73.02743, loss1: 0.58798, loss2_3: 72.43945\n",
      "\ttrain_acc: 0.8831, test_acc: \u001b[31m0.868876404494382\u001b[0m, time: 77.22\n",
      "epoch: 175, loss: 73.12489, loss1: 0.58951, loss2_3: 72.53539\n",
      "\ttrain_acc: 0.8855, test_acc: \u001b[31m0.8737078651685394\u001b[0m, time: 78.21\n",
      "epoch: 176, loss: 72.94924, loss1: 0.58928, loss2_3: 72.35997\n",
      "\ttrain_acc: 0.8845, test_acc: \u001b[31m0.8711516853932584\u001b[0m, time: 77.10\n",
      "epoch: 177, loss: 72.96252, loss1: 0.59012, loss2_3: 72.37239\n",
      "\ttrain_acc: 0.8855, test_acc: \u001b[31m0.8706741573033708\u001b[0m, time: 77.13\n",
      "epoch: 178, loss: 73.11157, loss1: 0.58606, loss2_3: 72.52550\n",
      "\ttrain_acc: 0.8855, test_acc: \u001b[31m0.8717977528089887\u001b[0m, time: 78.82\n",
      "epoch: 179, loss: 72.92973, loss1: 0.58633, loss2_3: 72.34340\n",
      "\ttrain_acc: 0.8859, test_acc: \u001b[31m0.8725\u001b[0m, time: 76.06\n",
      "epoch: 180, loss: 72.95653, loss1: 0.58776, loss2_3: 72.36877\n",
      "\ttrain_acc: 0.8864, test_acc: \u001b[31m0.8724438202247191\u001b[0m, time: 77.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 181, loss: 72.96398, loss1: 0.58693, loss2_3: 72.37704\n",
      "\ttrain_acc: 0.8863, test_acc: \u001b[31m0.8719943820224719\u001b[0m, time: 77.21\n",
      "epoch: 182, loss: 72.72593, loss1: 0.58520, loss2_3: 72.14073\n",
      "\ttrain_acc: 0.8871, test_acc: \u001b[31m0.8728651685393258\u001b[0m, time: 77.68\n",
      "epoch: 183, loss: 72.69709, loss1: 0.58592, loss2_3: 72.11117\n",
      "\ttrain_acc: 0.8870, test_acc: \u001b[31m0.8722471910112359\u001b[0m, time: 77.38\n",
      "epoch: 184, loss: 72.79838, loss1: 0.58652, loss2_3: 72.21186\n",
      "\ttrain_acc: 0.8870, test_acc: \u001b[31m0.8717977528089887\u001b[0m, time: 77.11\n",
      "epoch: 185, loss: 72.79235, loss1: 0.58444, loss2_3: 72.20791\n",
      "\ttrain_acc: 0.8852, test_acc: \u001b[31m0.8699157303370787\u001b[0m, time: 78.08\n",
      "epoch: 186, loss: 72.64318, loss1: 0.58375, loss2_3: 72.05943\n",
      "\ttrain_acc: 0.8857, test_acc: \u001b[31m0.8706741573033708\u001b[0m, time: 76.77\n",
      "epoch: 187, loss: 72.75671, loss1: 0.58773, loss2_3: 72.16898\n",
      "\ttrain_acc: 0.8856, test_acc: \u001b[31m0.8703651685393259\u001b[0m, time: 77.65\n",
      "epoch: 188, loss: 72.46326, loss1: 0.58404, loss2_3: 71.87922\n",
      "\ttrain_acc: 0.8866, test_acc: \u001b[31m0.870561797752809\u001b[0m, time: 77.60\n",
      "epoch: 189, loss: 72.64085, loss1: 0.58553, loss2_3: 72.05532\n",
      "\ttrain_acc: 0.8850, test_acc: \u001b[31m0.867808988764045\u001b[0m, time: 77.93\n",
      "epoch: 190, loss: 72.62573, loss1: 0.58238, loss2_3: 72.04335\n",
      "\ttrain_acc: 0.8867, test_acc: \u001b[31m0.8691011235955056\u001b[0m, time: 78.01\n",
      "epoch: 191, loss: 72.26320, loss1: 0.58569, loss2_3: 71.67752\n",
      "\ttrain_acc: 0.8867, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 76.86\n",
      "epoch: 192, loss: 72.45886, loss1: 0.58056, loss2_3: 71.87831\n",
      "\ttrain_acc: 0.8876, test_acc: \u001b[31m0.8734831460674157\u001b[0m, time: 79.77\n",
      "epoch: 193, loss: 72.43685, loss1: 0.58352, loss2_3: 71.85333\n",
      "\ttrain_acc: 0.8874, test_acc: \u001b[31m0.8717415730337079\u001b[0m, time: 77.65\n",
      "epoch: 194, loss: 72.48480, loss1: 0.58049, loss2_3: 71.90431\n",
      "\ttrain_acc: 0.8880, test_acc: \u001b[31m0.8723033707865169\u001b[0m, time: 79.63\n",
      "epoch: 195, loss: 72.29574, loss1: 0.58185, loss2_3: 71.71389\n",
      "\ttrain_acc: 0.8877, test_acc: \u001b[31m0.8710674157303371\u001b[0m, time: 79.66\n",
      "epoch: 196, loss: 72.32340, loss1: 0.58126, loss2_3: 71.74214\n",
      "\ttrain_acc: 0.8858, test_acc: \u001b[31m0.8705056179775281\u001b[0m, time: 78.06\n",
      "epoch: 197, loss: 72.40140, loss1: 0.58357, loss2_3: 71.81783\n",
      "\ttrain_acc: 0.8852, test_acc: \u001b[31m0.8686797752808989\u001b[0m, time: 79.88\n",
      "epoch: 198, loss: 72.15352, loss1: 0.58043, loss2_3: 71.57309\n",
      "\ttrain_acc: 0.8872, test_acc: \u001b[31m0.8725280898876404\u001b[0m, time: 77.06\n",
      "epoch: 199, loss: 72.17002, loss1: 0.58337, loss2_3: 71.58665\n",
      "\ttrain_acc: 0.8866, test_acc: \u001b[31m0.8708988764044944\u001b[0m, time: 79.63\n",
      "epoch: 200, loss: 72.09888, loss1: 0.57992, loss2_3: 71.51896\n",
      "\ttrain_acc: 0.8877, test_acc: \u001b[31m0.8718258426966292\u001b[0m, time: 78.49\n",
      "epoch: 201, loss: 71.94194, loss1: 0.57839, loss2_3: 71.36355\n",
      "\ttrain_acc: 0.8881, test_acc: \u001b[31m0.8726123595505618\u001b[0m, time: 79.26\n",
      "epoch: 202, loss: 72.20352, loss1: 0.58253, loss2_3: 71.62100\n",
      "\ttrain_acc: 0.8885, test_acc: \u001b[31m0.8728651685393258\u001b[0m, time: 80.46\n",
      "epoch: 203, loss: 72.13290, loss1: 0.57777, loss2_3: 71.55513\n",
      "\ttrain_acc: 0.8872, test_acc: \u001b[31m0.8715168539325843\u001b[0m, time: 76.84\n",
      "epoch: 204, loss: 71.85915, loss1: 0.58125, loss2_3: 71.27790\n",
      "\ttrain_acc: 0.8877, test_acc: \u001b[31m0.8721629213483146\u001b[0m, time: 79.49\n",
      "epoch: 205, loss: 71.80895, loss1: 0.57905, loss2_3: 71.22990\n",
      "\ttrain_acc: 0.8891, test_acc: \u001b[31m0.8715449438202247\u001b[0m, time: 76.94\n",
      "epoch: 206, loss: 71.88744, loss1: 0.58041, loss2_3: 71.30703\n",
      "\ttrain_acc: 0.8854, test_acc: \u001b[31m0.868876404494382\u001b[0m, time: 79.77\n",
      "epoch: 207, loss: 71.80797, loss1: 0.58509, loss2_3: 71.22288\n",
      "\ttrain_acc: 0.8893, test_acc: \u001b[31m0.8717134831460674\u001b[0m, time: 81.03\n",
      "epoch: 208, loss: 71.73388, loss1: 0.58225, loss2_3: 71.15163\n",
      "\ttrain_acc: 0.8883, test_acc: \u001b[31m0.8721629213483146\u001b[0m, time: 77.54\n",
      "epoch: 209, loss: 72.08185, loss1: 0.58314, loss2_3: 71.49871\n",
      "\ttrain_acc: 0.8878, test_acc: \u001b[31m0.8700561797752809\u001b[0m, time: 79.23\n",
      "epoch: 210, loss: 71.78944, loss1: 0.58007, loss2_3: 71.20937\n",
      "\ttrain_acc: 0.8875, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 75.85\n",
      "epoch: 211, loss: 71.76743, loss1: 0.57728, loss2_3: 71.19015\n",
      "\ttrain_acc: 0.8866, test_acc: \u001b[31m0.869438202247191\u001b[0m, time: 79.90\n",
      "epoch: 212, loss: 71.69832, loss1: 0.58041, loss2_3: 71.11791\n",
      "\ttrain_acc: 0.8888, test_acc: \u001b[31m0.8718820224719102\u001b[0m, time: 79.70\n",
      "epoch: 213, loss: 71.82081, loss1: 0.57927, loss2_3: 71.24154\n",
      "\ttrain_acc: 0.8900, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 78.68\n",
      "epoch: 214, loss: 71.69680, loss1: 0.57787, loss2_3: 71.11893\n",
      "\ttrain_acc: 0.8880, test_acc: \u001b[31m0.8701404494382022\u001b[0m, time: 80.90\n",
      "epoch: 215, loss: 71.63765, loss1: 0.57849, loss2_3: 71.05915\n",
      "\ttrain_acc: 0.8840, test_acc: \u001b[31m0.8655898876404494\u001b[0m, time: 76.28\n",
      "epoch: 216, loss: 71.53330, loss1: 0.57758, loss2_3: 70.95573\n",
      "\ttrain_acc: 0.8861, test_acc: \u001b[31m0.8679494382022472\u001b[0m, time: 80.35\n",
      "epoch: 217, loss: 71.50438, loss1: 0.57835, loss2_3: 70.92603\n",
      "\ttrain_acc: 0.8885, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 78.01\n",
      "epoch: 218, loss: 71.40151, loss1: 0.57514, loss2_3: 70.82637\n",
      "\ttrain_acc: 0.8899, test_acc: \u001b[31m0.8734550561797753\u001b[0m, time: 80.53\n",
      "epoch: 219, loss: 71.25976, loss1: 0.57973, loss2_3: 70.68004\n",
      "\ttrain_acc: 0.8895, test_acc: \u001b[31m0.8714887640449438\u001b[0m, time: 80.42\n",
      "epoch: 220, loss: 71.36692, loss1: 0.57713, loss2_3: 70.78979\n",
      "\ttrain_acc: 0.8869, test_acc: \u001b[31m0.8687078651685394\u001b[0m, time: 77.72\n",
      "epoch: 221, loss: 71.29078, loss1: 0.57604, loss2_3: 70.71474\n",
      "\ttrain_acc: 0.8894, test_acc: \u001b[31m0.8721067415730337\u001b[0m, time: 80.67\n",
      "epoch: 222, loss: 71.39536, loss1: 0.57745, loss2_3: 70.81791\n",
      "\ttrain_acc: 0.8893, test_acc: \u001b[31m0.8715730337078652\u001b[0m, time: 76.37\n",
      "epoch: 223, loss: 71.24101, loss1: 0.57542, loss2_3: 70.66559\n",
      "\ttrain_acc: 0.8906, test_acc: \u001b[31m0.873370786516854\u001b[0m, time: 79.62\n",
      "epoch: 224, loss: 70.95706, loss1: 0.57745, loss2_3: 70.37961\n",
      "\ttrain_acc: 0.8895, test_acc: \u001b[31m0.8718539325842697\u001b[0m, time: 79.09\n",
      "epoch: 225, loss: 71.20074, loss1: 0.57510, loss2_3: 70.62564\n",
      "\ttrain_acc: 0.8903, test_acc: \u001b[31m0.8721629213483146\u001b[0m, time: 78.74\n",
      "epoch: 226, loss: 71.07047, loss1: 0.57632, loss2_3: 70.49415\n",
      "\ttrain_acc: 0.8876, test_acc: \u001b[31m0.8693258426966292\u001b[0m, time: 80.40\n",
      "epoch: 227, loss: 71.06124, loss1: 0.57674, loss2_3: 70.48450\n",
      "\ttrain_acc: 0.8905, test_acc: \u001b[31m0.8717696629213483\u001b[0m, time: 75.78\n",
      "epoch: 228, loss: 70.86676, loss1: 0.57817, loss2_3: 70.28858\n",
      "\ttrain_acc: 0.8906, test_acc: \u001b[31m0.8701123595505618\u001b[0m, time: 79.54\n",
      "epoch: 229, loss: 71.00548, loss1: 0.57646, loss2_3: 70.42902\n",
      "\ttrain_acc: 0.8914, test_acc: \u001b[31m0.8708707865168539\u001b[0m, time: 77.93\n",
      "epoch: 230, loss: 70.91788, loss1: 0.57603, loss2_3: 70.34185\n",
      "\ttrain_acc: 0.8905, test_acc: \u001b[31m0.8710393258426966\u001b[0m, time: 79.96\n",
      "epoch: 231, loss: 70.76631, loss1: 0.57656, loss2_3: 70.18974\n",
      "\ttrain_acc: 0.8909, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 80.46\n",
      "epoch: 232, loss: 70.82504, loss1: 0.57366, loss2_3: 70.25138\n",
      "\ttrain_acc: 0.8906, test_acc: \u001b[31m0.8697752808988765\u001b[0m, time: 76.55\n",
      "epoch: 233, loss: 70.69710, loss1: 0.57094, loss2_3: 70.12616\n",
      "\ttrain_acc: 0.8919, test_acc: \u001b[31m0.8719662921348315\u001b[0m, time: 79.52\n",
      "epoch: 234, loss: 70.84431, loss1: 0.57597, loss2_3: 70.26834\n",
      "\ttrain_acc: 0.8880, test_acc: \u001b[31m0.8666573033707865\u001b[0m, time: 76.57\n",
      "epoch: 235, loss: 70.69997, loss1: 0.57203, loss2_3: 70.12794\n",
      "\ttrain_acc: 0.8903, test_acc: \u001b[31m0.8682303370786517\u001b[0m, time: 80.51\n",
      "epoch: 236, loss: 70.53660, loss1: 0.57514, loss2_3: 69.96146\n",
      "\ttrain_acc: 0.8915, test_acc: \u001b[31m0.8720505617977528\u001b[0m, time: 79.43\n",
      "epoch: 237, loss: 70.70271, loss1: 0.57521, loss2_3: 70.12749\n",
      "\ttrain_acc: 0.8899, test_acc: \u001b[31m0.871376404494382\u001b[0m, time: 78.00\n",
      "epoch: 238, loss: 70.55537, loss1: 0.57218, loss2_3: 69.98319\n",
      "\ttrain_acc: 0.8900, test_acc: \u001b[31m0.8700842696629213\u001b[0m, time: 79.71\n",
      "epoch: 239, loss: 70.49117, loss1: 0.57092, loss2_3: 69.92025\n",
      "\ttrain_acc: 0.8921, test_acc: \u001b[31m0.8720224719101124\u001b[0m, time: 76.58\n",
      "epoch: 240, loss: 70.22276, loss1: 0.57339, loss2_3: 69.64937\n",
      "\ttrain_acc: 0.8921, test_acc: \u001b[31m0.8727528089887641\u001b[0m, time: 80.56\n",
      "epoch: 241, loss: 70.39281, loss1: 0.56981, loss2_3: 69.82300\n",
      "\ttrain_acc: 0.8842, test_acc: \u001b[31m0.8650842696629214\u001b[0m, time: 78.31\n",
      "epoch: 242, loss: 70.39698, loss1: 0.57539, loss2_3: 69.82159\n",
      "\ttrain_acc: 0.8924, test_acc: \u001b[31m0.8721910112359551\u001b[0m, time: 78.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 243, loss: 70.12056, loss1: 0.57140, loss2_3: 69.54916\n",
      "\ttrain_acc: 0.8921, test_acc: \u001b[31m0.8704775280898877\u001b[0m, time: 79.63\n",
      "epoch: 244, loss: 70.04170, loss1: 0.57363, loss2_3: 69.46807\n",
      "\ttrain_acc: 0.8924, test_acc: \u001b[31m0.8712359550561798\u001b[0m, time: 77.12\n",
      "epoch: 245, loss: 70.42904, loss1: 0.57237, loss2_3: 69.85667\n",
      "\ttrain_acc: 0.8922, test_acc: \u001b[31m0.8711797752808988\u001b[0m, time: 80.31\n",
      "epoch: 246, loss: 70.24167, loss1: 0.56843, loss2_3: 69.67324\n",
      "\ttrain_acc: 0.8924, test_acc: \u001b[31m0.8704775280898877\u001b[0m, time: 77.25\n",
      "epoch: 247, loss: 70.03180, loss1: 0.57369, loss2_3: 69.45811\n",
      "\ttrain_acc: 0.8937, test_acc: \u001b[31m0.8709831460674158\u001b[0m, time: 80.86\n",
      "epoch: 248, loss: 70.24867, loss1: 0.57074, loss2_3: 69.67793\n",
      "\ttrain_acc: 0.8937, test_acc: \u001b[31m0.8722471910112359\u001b[0m, time: 79.91\n",
      "epoch: 249, loss: 69.87408, loss1: 0.56721, loss2_3: 69.30687\n",
      "\ttrain_acc: 0.8927, test_acc: \u001b[31m0.8679775280898876\u001b[0m, time: 78.58\n",
      "epoch: 250, loss: 70.10058, loss1: 0.56949, loss2_3: 69.53109\n",
      "\ttrain_acc: 0.8937, test_acc: \u001b[31m0.8701685393258427\u001b[0m, time: 79.83\n"
     ]
    }
   ],
   "source": [
    "for num_model in range(1):  # just one train\n",
    "    net=newModel().to(device)\n",
    "    lr = 0.0001\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr,weight_decay=5e-4)\n",
    "    criterion = ContrastiveLoss()\n",
    "    criterion_model = nn.CrossEntropyLoss(reduction='sum')\n",
    "    \n",
    "    best_acc=0\n",
    "    EPOCH=250\n",
    "    for epoch in range(EPOCH):\n",
    "        loss_ls=[]\n",
    "        loss1_ls=[]\n",
    "        loss2_3_ls=[]\n",
    "        t0=time.time()\n",
    "        net.train()\n",
    "        for seq1,seq2,label,label1,label2 in train_iter_cont:\n",
    "                output1=net(seq1)\n",
    "                output2=net(seq2)\n",
    "                output3=net.trainModel(seq1)\n",
    "                output4=net.trainModel(seq2)\n",
    "                \n",
    "                loss1=criterion(output1, output2, label)\n",
    "                loss2=criterion_model(output3,label1)\n",
    "                loss3=criterion_model(output4,label2)\n",
    "                loss=loss1+loss2+loss3\n",
    "    #             print(loss)\n",
    "                optimizer.zero_grad() \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_ls.append(loss.item())\n",
    "                loss1_ls.append(loss1.item())\n",
    "                loss2_3_ls.append((loss2+loss3).item())\n",
    "\n",
    "\n",
    "        net.eval() \n",
    "        with torch.no_grad(): \n",
    "            train_acc=evaluate_accuracy(train_iter,net)\n",
    "            test_acc=evaluate_accuracy(val_iter,net)\n",
    "            \n",
    "        results=f\"epoch: {epoch+1}, loss: {np.mean(loss_ls):.5f}, loss1: {np.mean(loss1_ls):.5f}, loss2_3: {np.mean(loss2_3_ls):.5f}\\n\"\n",
    "        results+=f'\\ttrain_acc: {train_acc:.4f}, test_acc: {colored(test_acc,\"red\")}, time: {time.time()-t0:.2f}'\n",
    "        print(results)\n",
    "        if test_acc>best_acc:\n",
    "            best_acc=test_acc\n",
    "#             torch.save({\"best_acc\":best_acc,\"model\":net.state_dict()},f'compareModel/2021ACS_PepFormer/Model/{num_model}.pl')\n",
    "            print(f\"best_acc: {best_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T22:26:37.233250Z",
     "start_time": "2021-09-30T22:26:37.195375Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T22:26:37.237768Z",
     "start_time": "2021-09-30T22:26:37.234600Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs.argmax(dim=1):\n",
    "            y_pred.append(int(_))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T22:26:37.243212Z",
     "start_time": "2021-09-30T22:26:37.238832Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred_prob(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs:\n",
    "            y_pred.append(list(map(float, _)))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T22:26:45.810303Z",
     "start_time": "2021-09-30T22:26:37.244209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8685813164340772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.87     22330\n",
      "           1       0.85      0.89      0.87     22169\n",
      "\n",
      "    accuracy                           0.87     44499\n",
      "   macro avg       0.87      0.87      0.87     44499\n",
      "weighted avg       0.87      0.87      0.87     44499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate_accuracy(test_iter,net)\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "# prediction\n",
    "y_pred = pred(test_iter, net)\n",
    "print(classification_report(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T22:26:51.749175Z",
     "start_time": "2021-09-30T22:26:45.811553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf auc : 0.9394461048586644\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AUC\n",
    "probs = np.array(pred_prob(test_iter, net))[:, 1]\n",
    "\n",
    "rf_auc = roc_auc_score(test_label, probs)\n",
    "print('rf auc : {}'.format(rf_auc))\n",
    "# plot the roc curve for the model81\n",
    "rf_fpr, rf_tpr, _ = roc_curve(test_label, probs)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='RF AUC = {:.4f}'.format(rf_auc), color='orange')\n",
    "plt.title('ROC curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "cf_matrix = confusion_matrix(test_label, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=',.0f')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
