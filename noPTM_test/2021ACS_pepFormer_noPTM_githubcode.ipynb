{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T04:08:26.599535Z",
     "start_time": "2021-10-01T04:08:25.889907Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T04:08:28.304927Z",
     "start_time": "2021-10-01T04:08:27.604901Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import time\n",
    "import pickle\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T04:08:28.312146Z",
     "start_time": "2021-10-01T04:08:28.306225Z"
    }
   },
   "outputs": [],
   "source": [
    "def genData(file,max_len):\n",
    "    aa_dict={'A':1,'R':2,'N':3,'D':4,'C':5,'Q':6,'E':7,'G':8,'H':9,'I':10,\n",
    "             'L':11,'K':12,'M':13,'F':14,'P':15,'O':16,'S':17,'U':18,'T':19,\n",
    "             'W':20,'Y':21,'V':22,'X':23}\n",
    "    with open(file, 'r') as inf:\n",
    "        lines = inf.read().splitlines()\n",
    "        \n",
    "    long_pep_counter=0\n",
    "    pep_codes=[]\n",
    "    labels=[]\n",
    "    for pep in lines:\n",
    "        pep,label=pep.split(\",\")\n",
    "        labels.append(int(label))\n",
    "        if not len(pep) > max_len:\n",
    "            current_pep=[]\n",
    "            for aa in pep:\n",
    "                current_pep.append(aa_dict[aa])\n",
    "            pep_codes.append(torch.tensor(current_pep))\n",
    "        else:\n",
    "            long_pep_counter += 1\n",
    "    print(\"length > 81:\",long_pep_counter)\n",
    "    data = rnn_utils.pad_sequence(pep_codes,batch_first=True)\n",
    "    return data,torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T04:08:28.324650Z",
     "start_time": "2021-10-01T04:08:28.313421Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        acc_sum += (outputs.argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "def to_log(log):\n",
    "    with open(\"../compareModel/2021ACS_PepFormer/modelLog.log\",\"a+\") as f:\n",
    "        f.write(log+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T04:08:28.331366Z",
     "start_time": "2021-10-01T04:08:28.325727Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    seq1_ls=[]\n",
    "    seq2_ls=[]\n",
    "    label1_ls=[]\n",
    "    label2_ls=[]\n",
    "    label_ls=[]\n",
    "    batch_size=len(batch)\n",
    "    for i in range(int(batch_size/2)):\n",
    "        seq1,label1=batch[i][0],batch[i][1]\n",
    "        seq2,label2=batch[i+int(batch_size/2)][0],batch[i+int(batch_size/2)][1]\n",
    "        label1_ls.append(label1.unsqueeze(0))\n",
    "        label2_ls.append(label2.unsqueeze(0))\n",
    "        label=(label1^label2)\n",
    "        seq1_ls.append(seq1.unsqueeze(0))\n",
    "        seq2_ls.append(seq2.unsqueeze(0))\n",
    "        label_ls.append(label.unsqueeze(0))\n",
    "    seq1=torch.cat(seq1_ls).to(device)\n",
    "    seq2=torch.cat(seq2_ls).to(device)\n",
    "    label=torch.cat(label_ls).to(device)\n",
    "    label1=torch.cat(label1_ls).to(device)\n",
    "    label2=torch.cat(label2_ls).to(device)\n",
    "    return seq1,seq2,label,label1,label2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Data X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T04:08:31.269477Z",
     "start_time": "2021-10-01T04:08:29.356484Z"
    }
   },
   "outputs": [],
   "source": [
    "df_detect_peptide_train = pd.read_csv('../data/df_detect_peptide_train_noptm_210930_includeDigest.csv')\n",
    "df_detect_peptide_test = pd.read_csv('../data/df_detect_peptide_test_noptm_210930_includeDigest.csv')\n",
    "\n",
    "tra, val = train_test_split(df_detect_peptide_train[['PEP', 'ID']], test_size=0.2, random_state=7)\n",
    "tra.to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_train_noptm_includeDigest.csv', header=False, index=False)\n",
    "val.to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_val_noptm_includeDigest.csv', header=False, index=False)\n",
    "df_detect_peptide_test[['PEP', 'ID']].to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_test_noptm_includeDigest.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T04:08:39.524161Z",
     "start_time": "2021-10-01T04:08:31.271125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length > 81: 0\n",
      "torch.Size([337179, 30]) torch.Size([337179])\n",
      "length > 81: 0\n",
      "torch.Size([84295, 30]) torch.Size([84295])\n",
      "length > 81: 0\n",
      "torch.Size([88998, 30]) torch.Size([88998])\n"
     ]
    }
   ],
   "source": [
    "train_data,train_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_train_noptm_includeDigest.csv\",81)\n",
    "print(train_data.shape, train_label.shape)\n",
    "train_dataset = Data.TensorDataset(train_data, train_label)\n",
    "\n",
    "val_data,val_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_val_noptm_includeDigest.csv\",81)\n",
    "print(val_data.shape, val_label.shape)\n",
    "val_dataset = Data.TensorDataset(val_data, val_label)\n",
    "\n",
    "test_data,test_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_test_noptm_includeDigest.csv\",81)\n",
    "print(test_data.shape, test_label.shape)\n",
    "test_dataset = Data.TensorDataset(test_data, test_label)\n",
    "\n",
    "batch_size=256\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_iter_cont = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                                                  shuffle=True, collate_fn=collate)\n",
    "val_iter = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T04:08:39.527954Z",
     "start_time": "2021-10-01T04:08:39.525589Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T04:08:39.541264Z",
     "start_time": "2021-10-01T04:08:39.529073Z"
    }
   },
   "outputs": [],
   "source": [
    "class newModel(nn.Module):\n",
    "    def __init__(self, vocab_size=24):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 25\n",
    "        self.batch_size = 256\n",
    "        self.emb_dim = 512\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, self.emb_dim, padding_idx=0)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.gru = nn.GRU(self.emb_dim, self.hidden_dim, num_layers=2, \n",
    "                               bidirectional=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.block1=nn.Sequential(nn.Linear(1600,1024),\n",
    "                                            nn.BatchNorm1d(1024),\n",
    "                                            nn.LeakyReLU(),\n",
    "                                            nn.Linear(1024,256),\n",
    "                                 )\n",
    "\n",
    "        self.block2=nn.Sequential(\n",
    "                                               nn.BatchNorm1d(256),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(256,128),\n",
    "                                               nn.BatchNorm1d(128),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(128,64),\n",
    "                                               nn.BatchNorm1d(64),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(64,2)\n",
    "                                            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.embedding(x)\n",
    "        output=self.transformer_encoder(x).permute(1, 0, 2)\n",
    "        output,hn=self.gru(output)\n",
    "        output=output.permute(1,0,2)\n",
    "        hn=hn.permute(1,0,2)\n",
    "        output=output.reshape(output.shape[0],-1)\n",
    "        hn=hn.reshape(output.shape[0],-1)\n",
    "        output=torch.cat([output,hn],1)\n",
    "#         print(output.shape,hn.shape)\n",
    "        return self.block1(output)\n",
    "\n",
    "    def trainModel(self, x):\n",
    "        with torch.no_grad():\n",
    "            output=self.forward(x)\n",
    "        return self.block2(output)\n",
    "\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # euclidean_distance: [128]\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +     # calmp夹断用法\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))     \n",
    "        \n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T15:40:59.644760Z",
     "start_time": "2021-10-01T04:08:49.741722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 135.46430, loss1: 1.27142, loss2_3: 134.19288\n",
      "\ttrain_acc: 0.8065, test_acc: \u001b[31m0.8152093305467538\u001b[0m, time: 90.75\n",
      "best_acc: 0.8152093305467538\n",
      "epoch: 2, loss: 106.53827, loss1: 0.86574, loss2_3: 105.67253\n",
      "\ttrain_acc: 0.8153, test_acc: \u001b[31m0.8230184947976359\u001b[0m, time: 90.89\n",
      "best_acc: 0.8230184947976359\n",
      "epoch: 3, loss: 100.84002, loss1: 0.82444, loss2_3: 100.01558\n",
      "\ttrain_acc: 0.8223, test_acc: \u001b[31m0.8286590709903593\u001b[0m, time: 91.21\n",
      "best_acc: 0.8286590709903593\n",
      "epoch: 4, loss: 97.11487, loss1: 0.78895, loss2_3: 96.32592\n",
      "\ttrain_acc: 0.8376, test_acc: \u001b[31m0.84833367041956\u001b[0m, time: 91.16\n",
      "best_acc: 0.84833367041956\n",
      "epoch: 5, loss: 95.64570, loss1: 0.77491, loss2_3: 94.87080\n",
      "\ttrain_acc: 0.8338, test_acc: \u001b[31m0.8381986112047461\u001b[0m, time: 91.14\n",
      "epoch: 6, loss: 94.62451, loss1: 0.76370, loss2_3: 93.86081\n",
      "\ttrain_acc: 0.8400, test_acc: \u001b[31m0.8545922380278208\u001b[0m, time: 86.60\n",
      "best_acc: 0.8545922380278208\n",
      "epoch: 7, loss: 93.74237, loss1: 0.75399, loss2_3: 92.98837\n",
      "\ttrain_acc: 0.8407, test_acc: \u001b[31m0.8558506932740062\u001b[0m, time: 82.61\n",
      "best_acc: 0.8558506932740062\n",
      "epoch: 8, loss: 93.22643, loss1: 0.74707, loss2_3: 92.47936\n",
      "\ttrain_acc: 0.8416, test_acc: \u001b[31m0.8498393222319602\u001b[0m, time: 82.63\n",
      "epoch: 9, loss: 92.33615, loss1: 0.74130, loss2_3: 91.59485\n",
      "\ttrain_acc: 0.8450, test_acc: \u001b[31m0.8537607586687341\u001b[0m, time: 82.52\n",
      "epoch: 10, loss: 92.12829, loss1: 0.73623, loss2_3: 91.39206\n",
      "\ttrain_acc: 0.8449, test_acc: \u001b[31m0.857828265803726\u001b[0m, time: 82.61\n",
      "best_acc: 0.857828265803726\n",
      "epoch: 11, loss: 91.65147, loss1: 0.72957, loss2_3: 90.92190\n",
      "\ttrain_acc: 0.8455, test_acc: \u001b[31m0.8578732106339468\u001b[0m, time: 82.56\n",
      "best_acc: 0.8578732106339468\n",
      "epoch: 12, loss: 91.10722, loss1: 0.72589, loss2_3: 90.38133\n",
      "\ttrain_acc: 0.8475, test_acc: \u001b[31m0.8574687071619587\u001b[0m, time: 82.52\n",
      "epoch: 13, loss: 90.86157, loss1: 0.72021, loss2_3: 90.14137\n",
      "\ttrain_acc: 0.8458, test_acc: \u001b[31m0.8538394121216207\u001b[0m, time: 82.48\n",
      "epoch: 14, loss: 90.39549, loss1: 0.71866, loss2_3: 89.67683\n",
      "\ttrain_acc: 0.8473, test_acc: \u001b[31m0.8572102743881885\u001b[0m, time: 82.40\n",
      "epoch: 15, loss: 89.88404, loss1: 0.71350, loss2_3: 89.17053\n",
      "\ttrain_acc: 0.8485, test_acc: \u001b[31m0.8578732106339468\u001b[0m, time: 82.36\n",
      "epoch: 16, loss: 89.50184, loss1: 0.71257, loss2_3: 88.78928\n",
      "\ttrain_acc: 0.8476, test_acc: \u001b[31m0.8536034517629609\u001b[0m, time: 82.51\n",
      "epoch: 17, loss: 89.03295, loss1: 0.70453, loss2_3: 88.32841\n",
      "\ttrain_acc: 0.8512, test_acc: \u001b[31m0.860817097013416\u001b[0m, time: 82.52\n",
      "best_acc: 0.860817097013416\n",
      "epoch: 18, loss: 88.50546, loss1: 0.70195, loss2_3: 87.80351\n",
      "\ttrain_acc: 0.8498, test_acc: \u001b[31m0.8608283332209713\u001b[0m, time: 82.46\n",
      "best_acc: 0.8608283332209713\n",
      "epoch: 19, loss: 88.40337, loss1: 0.69937, loss2_3: 87.70399\n",
      "\ttrain_acc: 0.8520, test_acc: \u001b[31m0.8624351109013686\u001b[0m, time: 82.49\n",
      "best_acc: 0.8624351109013686\n",
      "epoch: 20, loss: 88.00488, loss1: 0.69653, loss2_3: 87.30835\n",
      "\ttrain_acc: 0.8506, test_acc: \u001b[31m0.8653228162430616\u001b[0m, time: 82.49\n",
      "best_acc: 0.8653228162430616\n",
      "epoch: 21, loss: 87.59079, loss1: 0.68915, loss2_3: 86.90164\n",
      "\ttrain_acc: 0.8502, test_acc: \u001b[31m0.8599631452392189\u001b[0m, time: 82.45\n",
      "epoch: 22, loss: 87.27239, loss1: 0.68906, loss2_3: 86.58333\n",
      "\ttrain_acc: 0.8524, test_acc: \u001b[31m0.8614687970516192\u001b[0m, time: 82.41\n",
      "epoch: 23, loss: 86.92497, loss1: 0.69065, loss2_3: 86.23433\n",
      "\ttrain_acc: 0.8537, test_acc: \u001b[31m0.8598170745410009\u001b[0m, time: 82.46\n",
      "epoch: 24, loss: 86.52737, loss1: 0.68406, loss2_3: 85.84331\n",
      "\ttrain_acc: 0.8527, test_acc: \u001b[31m0.862805905750691\u001b[0m, time: 82.43\n",
      "epoch: 25, loss: 86.33958, loss1: 0.68231, loss2_3: 85.65727\n",
      "\ttrain_acc: 0.8555, test_acc: \u001b[31m0.8616710487876132\u001b[0m, time: 82.49\n",
      "epoch: 26, loss: 86.12547, loss1: 0.68130, loss2_3: 85.44416\n",
      "\ttrain_acc: 0.8553, test_acc: \u001b[31m0.8600979797298816\u001b[0m, time: 82.51\n",
      "epoch: 27, loss: 85.96515, loss1: 0.67911, loss2_3: 85.28604\n",
      "\ttrain_acc: 0.8554, test_acc: \u001b[31m0.8619856625991595\u001b[0m, time: 82.34\n",
      "epoch: 28, loss: 85.52786, loss1: 0.67831, loss2_3: 84.84955\n",
      "\ttrain_acc: 0.8553, test_acc: \u001b[31m0.8616373401649475\u001b[0m, time: 82.41\n",
      "epoch: 29, loss: 85.50929, loss1: 0.67692, loss2_3: 84.83237\n",
      "\ttrain_acc: 0.8555, test_acc: \u001b[31m0.8646261713746376\u001b[0m, time: 82.39\n",
      "epoch: 30, loss: 85.32089, loss1: 0.67523, loss2_3: 84.64567\n",
      "\ttrain_acc: 0.8557, test_acc: \u001b[31m0.8604238297489831\u001b[0m, time: 82.38\n",
      "epoch: 31, loss: 85.26561, loss1: 0.67313, loss2_3: 84.59248\n",
      "\ttrain_acc: 0.8567, test_acc: \u001b[31m0.8644801006764197\u001b[0m, time: 82.39\n",
      "epoch: 32, loss: 84.88605, loss1: 0.67314, loss2_3: 84.21291\n",
      "\ttrain_acc: 0.8565, test_acc: \u001b[31m0.8661205869794827\u001b[0m, time: 82.45\n",
      "best_acc: 0.8661205869794827\n",
      "epoch: 33, loss: 85.03491, loss1: 0.67148, loss2_3: 84.36344\n",
      "\ttrain_acc: 0.8569, test_acc: \u001b[31m0.8625587091844761\u001b[0m, time: 82.39\n",
      "epoch: 34, loss: 84.69605, loss1: 0.67001, loss2_3: 84.02604\n",
      "\ttrain_acc: 0.8546, test_acc: \u001b[31m0.856637227802872\u001b[0m, time: 82.40\n",
      "epoch: 35, loss: 84.58130, loss1: 0.67029, loss2_3: 83.91101\n",
      "\ttrain_acc: 0.8575, test_acc: \u001b[31m0.8622440953729297\u001b[0m, time: 82.41\n",
      "epoch: 36, loss: 84.42030, loss1: 0.66752, loss2_3: 83.75277\n",
      "\ttrain_acc: 0.8551, test_acc: \u001b[31m0.8566709364255376\u001b[0m, time: 82.47\n",
      "epoch: 37, loss: 84.31541, loss1: 0.66894, loss2_3: 83.64647\n",
      "\ttrain_acc: 0.8578, test_acc: \u001b[31m0.8630081574866851\u001b[0m, time: 82.42\n",
      "epoch: 38, loss: 84.25775, loss1: 0.66787, loss2_3: 83.58988\n",
      "\ttrain_acc: 0.8580, test_acc: \u001b[31m0.8657610283377154\u001b[0m, time: 82.40\n",
      "epoch: 39, loss: 84.25384, loss1: 0.66465, loss2_3: 83.58920\n",
      "\ttrain_acc: 0.8565, test_acc: \u001b[31m0.8584237848041529\u001b[0m, time: 82.36\n",
      "epoch: 40, loss: 84.12195, loss1: 0.66460, loss2_3: 83.45735\n",
      "\ttrain_acc: 0.8577, test_acc: \u001b[31m0.8632890626755657\u001b[0m, time: 82.40\n",
      "epoch: 41, loss: 84.18385, loss1: 0.66386, loss2_3: 83.51999\n",
      "\ttrain_acc: 0.8585, test_acc: \u001b[31m0.8656936110923841\u001b[0m, time: 82.40\n",
      "epoch: 42, loss: 83.97254, loss1: 0.66437, loss2_3: 83.30817\n",
      "\ttrain_acc: 0.8566, test_acc: \u001b[31m0.860019326276995\u001b[0m, time: 82.38\n",
      "epoch: 43, loss: 84.03063, loss1: 0.66593, loss2_3: 83.36470\n",
      "\ttrain_acc: 0.8590, test_acc: \u001b[31m0.8641654868648734\u001b[0m, time: 82.50\n",
      "epoch: 44, loss: 83.78235, loss1: 0.66700, loss2_3: 83.11535\n",
      "\ttrain_acc: 0.8594, test_acc: \u001b[31m0.8637722196004405\u001b[0m, time: 82.42\n",
      "epoch: 45, loss: 83.83765, loss1: 0.66385, loss2_3: 83.17379\n",
      "\ttrain_acc: 0.8589, test_acc: \u001b[31m0.8636710937324434\u001b[0m, time: 82.43\n",
      "epoch: 46, loss: 83.71632, loss1: 0.66232, loss2_3: 83.05399\n",
      "\ttrain_acc: 0.8597, test_acc: \u001b[31m0.8653565248657273\u001b[0m, time: 82.42\n",
      "epoch: 47, loss: 83.73221, loss1: 0.66067, loss2_3: 83.07154\n",
      "\ttrain_acc: 0.8593, test_acc: \u001b[31m0.8658509179981573\u001b[0m, time: 82.46\n",
      "epoch: 48, loss: 83.66164, loss1: 0.66259, loss2_3: 82.99905\n",
      "\ttrain_acc: 0.8591, test_acc: \u001b[31m0.8653677610732825\u001b[0m, time: 82.36\n",
      "epoch: 49, loss: 83.52300, loss1: 0.66422, loss2_3: 82.85878\n",
      "\ttrain_acc: 0.8603, test_acc: \u001b[31m0.8659632800737095\u001b[0m, time: 85.21\n",
      "epoch: 50, loss: 83.58981, loss1: 0.66145, loss2_3: 82.92836\n",
      "\ttrain_acc: 0.8577, test_acc: \u001b[31m0.8593339176161262\u001b[0m, time: 82.60\n",
      "epoch: 51, loss: 83.40360, loss1: 0.66261, loss2_3: 82.74099\n",
      "\ttrain_acc: 0.8583, test_acc: \u001b[31m0.8697948268500416\u001b[0m, time: 82.28\n",
      "best_acc: 0.8697948268500416\n",
      "epoch: 52, loss: 83.48329, loss1: 0.65965, loss2_3: 82.82364\n",
      "\ttrain_acc: 0.8547, test_acc: \u001b[31m0.8537158138385132\u001b[0m, time: 82.48\n",
      "epoch: 53, loss: 83.24844, loss1: 0.65936, loss2_3: 82.58907\n",
      "\ttrain_acc: 0.8578, test_acc: \u001b[31m0.8592665003707949\u001b[0m, time: 82.51\n",
      "epoch: 54, loss: 83.22872, loss1: 0.66087, loss2_3: 82.56785\n",
      "\ttrain_acc: 0.8562, test_acc: \u001b[31m0.855940582934448\u001b[0m, time: 82.42\n",
      "epoch: 55, loss: 83.17221, loss1: 0.65921, loss2_3: 82.51300\n",
      "\ttrain_acc: 0.8579, test_acc: \u001b[31m0.8587945796534754\u001b[0m, time: 82.49\n",
      "epoch: 56, loss: 83.10694, loss1: 0.65839, loss2_3: 82.44855\n",
      "\ttrain_acc: 0.8603, test_acc: \u001b[31m0.865839681790602\u001b[0m, time: 82.45\n",
      "epoch: 57, loss: 83.06354, loss1: 0.65995, loss2_3: 82.40359\n",
      "\ttrain_acc: 0.8586, test_acc: \u001b[31m0.8610755297871863\u001b[0m, time: 82.33\n",
      "epoch: 58, loss: 83.09367, loss1: 0.65912, loss2_3: 82.43455\n",
      "\ttrain_acc: 0.8590, test_acc: \u001b[31m0.8603901211263174\u001b[0m, time: 82.32\n",
      "epoch: 59, loss: 83.08366, loss1: 0.66128, loss2_3: 82.42238\n",
      "\ttrain_acc: 0.8609, test_acc: \u001b[31m0.8690644733589519\u001b[0m, time: 82.29\n",
      "epoch: 60, loss: 82.96318, loss1: 0.65672, loss2_3: 82.30646\n",
      "\ttrain_acc: 0.8570, test_acc: \u001b[31m0.8569518416144183\u001b[0m, time: 82.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 61, loss: 82.86112, loss1: 0.65623, loss2_3: 82.20489\n",
      "\ttrain_acc: 0.8585, test_acc: \u001b[31m0.8585024382570395\u001b[0m, time: 82.31\n",
      "epoch: 62, loss: 82.88854, loss1: 0.65713, loss2_3: 82.23141\n",
      "\ttrain_acc: 0.8612, test_acc: \u001b[31m0.8658509179981573\u001b[0m, time: 90.73\n",
      "epoch: 63, loss: 82.67262, loss1: 0.65797, loss2_3: 82.01465\n",
      "\ttrain_acc: 0.8587, test_acc: \u001b[31m0.858929414144138\u001b[0m, time: 86.42\n",
      "epoch: 64, loss: 82.76833, loss1: 0.65732, loss2_3: 82.11101\n",
      "\ttrain_acc: 0.8598, test_acc: \u001b[31m0.8650194386390705\u001b[0m, time: 82.35\n",
      "epoch: 65, loss: 82.64031, loss1: 0.65937, loss2_3: 81.98094\n",
      "\ttrain_acc: 0.8608, test_acc: \u001b[31m0.8653003438279512\u001b[0m, time: 82.36\n",
      "epoch: 66, loss: 82.67654, loss1: 0.65603, loss2_3: 82.02051\n",
      "\ttrain_acc: 0.8613, test_acc: \u001b[31m0.8681992853771995\u001b[0m, time: 82.42\n",
      "epoch: 67, loss: 82.73009, loss1: 0.65737, loss2_3: 82.07271\n",
      "\ttrain_acc: 0.8591, test_acc: \u001b[31m0.8600417986921054\u001b[0m, time: 82.41\n",
      "epoch: 68, loss: 82.68544, loss1: 0.65635, loss2_3: 82.02909\n",
      "\ttrain_acc: 0.8615, test_acc: \u001b[31m0.8666374525270231\u001b[0m, time: 82.44\n",
      "epoch: 69, loss: 82.57922, loss1: 0.65121, loss2_3: 81.92801\n",
      "\ttrain_acc: 0.8614, test_acc: \u001b[31m0.8633227712982314\u001b[0m, time: 82.32\n",
      "epoch: 70, loss: 82.57526, loss1: 0.65465, loss2_3: 81.92062\n",
      "\ttrain_acc: 0.8607, test_acc: \u001b[31m0.8687386233398503\u001b[0m, time: 82.35\n",
      "epoch: 71, loss: 82.52945, loss1: 0.65431, loss2_3: 81.87514\n",
      "\ttrain_acc: 0.8608, test_acc: \u001b[31m0.8692105440571698\u001b[0m, time: 82.32\n",
      "epoch: 72, loss: 82.57973, loss1: 0.65437, loss2_3: 81.92536\n",
      "\ttrain_acc: 0.8602, test_acc: \u001b[31m0.8604575383716488\u001b[0m, time: 82.40\n",
      "epoch: 73, loss: 82.42910, loss1: 0.65367, loss2_3: 81.77543\n",
      "\ttrain_acc: 0.8613, test_acc: \u001b[31m0.8640418885817659\u001b[0m, time: 82.51\n",
      "epoch: 74, loss: 82.38723, loss1: 0.65396, loss2_3: 81.73327\n",
      "\ttrain_acc: 0.8591, test_acc: \u001b[31m0.8588619968988067\u001b[0m, time: 82.39\n",
      "epoch: 75, loss: 82.37158, loss1: 0.65513, loss2_3: 81.71645\n",
      "\ttrain_acc: 0.8605, test_acc: \u001b[31m0.8625137643542552\u001b[0m, time: 82.29\n",
      "epoch: 76, loss: 82.41823, loss1: 0.65553, loss2_3: 81.76269\n",
      "\ttrain_acc: 0.8621, test_acc: \u001b[31m0.866131823187038\u001b[0m, time: 82.39\n",
      "epoch: 77, loss: 82.32635, loss1: 0.65369, loss2_3: 81.67267\n",
      "\ttrain_acc: 0.8616, test_acc: \u001b[31m0.8636823299399986\u001b[0m, time: 82.34\n",
      "epoch: 78, loss: 82.26915, loss1: 0.65414, loss2_3: 81.61500\n",
      "\ttrain_acc: 0.8614, test_acc: \u001b[31m0.8627946695431358\u001b[0m, time: 82.27\n",
      "epoch: 79, loss: 82.24786, loss1: 0.65322, loss2_3: 81.59465\n",
      "\ttrain_acc: 0.8611, test_acc: \u001b[31m0.8621204970898222\u001b[0m, time: 82.33\n",
      "epoch: 80, loss: 82.18309, loss1: 0.65369, loss2_3: 81.52940\n",
      "\ttrain_acc: 0.8627, test_acc: \u001b[31m0.8678509629429875\u001b[0m, time: 82.30\n",
      "epoch: 81, loss: 82.16421, loss1: 0.65366, loss2_3: 81.51055\n",
      "\ttrain_acc: 0.8624, test_acc: \u001b[31m0.8672554439425605\u001b[0m, time: 82.23\n",
      "epoch: 82, loss: 82.07505, loss1: 0.65212, loss2_3: 81.42293\n",
      "\ttrain_acc: 0.8599, test_acc: \u001b[31m0.858581091709926\u001b[0m, time: 82.28\n",
      "epoch: 83, loss: 82.03172, loss1: 0.65096, loss2_3: 81.38076\n",
      "\ttrain_acc: 0.8629, test_acc: \u001b[31m0.8639519989213241\u001b[0m, time: 82.27\n",
      "epoch: 84, loss: 82.05716, loss1: 0.65072, loss2_3: 81.40644\n",
      "\ttrain_acc: 0.8625, test_acc: \u001b[31m0.8643677386008675\u001b[0m, time: 82.33\n",
      "epoch: 85, loss: 82.16722, loss1: 0.65247, loss2_3: 81.51475\n",
      "\ttrain_acc: 0.8614, test_acc: \u001b[31m0.8683004112451965\u001b[0m, time: 82.63\n",
      "epoch: 86, loss: 82.06013, loss1: 0.65398, loss2_3: 81.40614\n",
      "\ttrain_acc: 0.8622, test_acc: \u001b[31m0.8632104092226791\u001b[0m, time: 82.48\n",
      "epoch: 87, loss: 81.81931, loss1: 0.65267, loss2_3: 81.16664\n",
      "\ttrain_acc: 0.8626, test_acc: \u001b[31m0.8669295939234589\u001b[0m, time: 82.42\n",
      "epoch: 88, loss: 81.97471, loss1: 0.65181, loss2_3: 81.32290\n",
      "\ttrain_acc: 0.8623, test_acc: \u001b[31m0.8667161059799097\u001b[0m, time: 84.10\n",
      "epoch: 89, loss: 82.09852, loss1: 0.65315, loss2_3: 81.44537\n",
      "\ttrain_acc: 0.8633, test_acc: \u001b[31m0.8665475628665813\u001b[0m, time: 90.98\n",
      "epoch: 90, loss: 81.93845, loss1: 0.65124, loss2_3: 81.28720\n",
      "\ttrain_acc: 0.8614, test_acc: \u001b[31m0.86200813501427\u001b[0m, time: 90.89\n",
      "epoch: 91, loss: 81.74675, loss1: 0.64901, loss2_3: 81.09774\n",
      "\ttrain_acc: 0.8632, test_acc: \u001b[31m0.8644239196386435\u001b[0m, time: 85.58\n",
      "epoch: 92, loss: 81.70602, loss1: 0.64910, loss2_3: 81.05692\n",
      "\ttrain_acc: 0.8635, test_acc: \u001b[31m0.8686599698869637\u001b[0m, time: 83.76\n",
      "epoch: 93, loss: 81.77742, loss1: 0.64961, loss2_3: 81.12781\n",
      "\ttrain_acc: 0.8631, test_acc: \u001b[31m0.8661542956021484\u001b[0m, time: 82.43\n",
      "epoch: 94, loss: 81.66161, loss1: 0.64822, loss2_3: 81.01338\n",
      "\ttrain_acc: 0.8636, test_acc: \u001b[31m0.8670082473763455\u001b[0m, time: 82.52\n",
      "epoch: 95, loss: 81.67134, loss1: 0.64940, loss2_3: 81.02195\n",
      "\ttrain_acc: 0.8635, test_acc: \u001b[31m0.8661655318097036\u001b[0m, time: 82.54\n",
      "epoch: 96, loss: 81.54882, loss1: 0.65221, loss2_3: 80.89660\n",
      "\ttrain_acc: 0.8614, test_acc: \u001b[31m0.8692891975100564\u001b[0m, time: 82.42\n",
      "epoch: 97, loss: 81.57710, loss1: 0.64986, loss2_3: 80.92724\n",
      "\ttrain_acc: 0.8632, test_acc: \u001b[31m0.867828490527877\u001b[0m, time: 82.47\n",
      "epoch: 98, loss: 81.65427, loss1: 0.65018, loss2_3: 81.00409\n",
      "\ttrain_acc: 0.8620, test_acc: \u001b[31m0.8625811815995865\u001b[0m, time: 82.48\n",
      "epoch: 99, loss: 81.62741, loss1: 0.64658, loss2_3: 80.98083\n",
      "\ttrain_acc: 0.8606, test_acc: \u001b[31m0.8584687296343738\u001b[0m, time: 82.39\n",
      "epoch: 100, loss: 81.56922, loss1: 0.64839, loss2_3: 80.92083\n",
      "\ttrain_acc: 0.8641, test_acc: \u001b[31m0.8676936560372143\u001b[0m, time: 82.47\n",
      "epoch: 101, loss: 81.57243, loss1: 0.64902, loss2_3: 80.92342\n",
      "\ttrain_acc: 0.8638, test_acc: \u001b[31m0.8670194835839008\u001b[0m, time: 82.46\n",
      "epoch: 102, loss: 81.52150, loss1: 0.64980, loss2_3: 80.87170\n",
      "\ttrain_acc: 0.8628, test_acc: \u001b[31m0.8680082698487607\u001b[0m, time: 82.41\n",
      "epoch: 103, loss: 81.49151, loss1: 0.64896, loss2_3: 80.84255\n",
      "\ttrain_acc: 0.8613, test_acc: \u001b[31m0.8586485089552575\u001b[0m, time: 82.47\n",
      "epoch: 104, loss: 81.50420, loss1: 0.64833, loss2_3: 80.85587\n",
      "\ttrain_acc: 0.8631, test_acc: \u001b[31m0.8635025506191151\u001b[0m, time: 82.51\n",
      "epoch: 105, loss: 81.53149, loss1: 0.64679, loss2_3: 80.88470\n",
      "\ttrain_acc: 0.8636, test_acc: \u001b[31m0.8647385334501899\u001b[0m, time: 82.44\n",
      "epoch: 106, loss: 81.32752, loss1: 0.64814, loss2_3: 80.67938\n",
      "\ttrain_acc: 0.8636, test_acc: \u001b[31m0.8645587541293063\u001b[0m, time: 82.71\n",
      "epoch: 107, loss: 81.28503, loss1: 0.64604, loss2_3: 80.63899\n",
      "\ttrain_acc: 0.8639, test_acc: \u001b[31m0.8653115800355065\u001b[0m, time: 82.50\n",
      "epoch: 108, loss: 81.25562, loss1: 0.64754, loss2_3: 80.60807\n",
      "\ttrain_acc: 0.8645, test_acc: \u001b[31m0.8699746061709251\u001b[0m, time: 82.30\n",
      "best_acc: 0.8699746061709251\n",
      "epoch: 109, loss: 81.25982, loss1: 0.64521, loss2_3: 80.61460\n",
      "\ttrain_acc: 0.8632, test_acc: \u001b[31m0.8625025281466999\u001b[0m, time: 82.44\n",
      "epoch: 110, loss: 81.13642, loss1: 0.64510, loss2_3: 80.49132\n",
      "\ttrain_acc: 0.8627, test_acc: \u001b[31m0.8618733005236072\u001b[0m, time: 82.43\n",
      "epoch: 111, loss: 81.32106, loss1: 0.64598, loss2_3: 80.67508\n",
      "\ttrain_acc: 0.8616, test_acc: \u001b[31m0.8604575383716488\u001b[0m, time: 82.37\n",
      "epoch: 112, loss: 81.26510, loss1: 0.64588, loss2_3: 80.61921\n",
      "\ttrain_acc: 0.8649, test_acc: \u001b[31m0.8644239196386435\u001b[0m, time: 82.49\n",
      "epoch: 113, loss: 81.33910, loss1: 0.64541, loss2_3: 80.69369\n",
      "\ttrain_acc: 0.8634, test_acc: \u001b[31m0.8632441178453448\u001b[0m, time: 82.49\n",
      "epoch: 114, loss: 81.25967, loss1: 0.64554, loss2_3: 80.61414\n",
      "\ttrain_acc: 0.8650, test_acc: \u001b[31m0.8665925076968022\u001b[0m, time: 82.51\n",
      "epoch: 115, loss: 81.13002, loss1: 0.64431, loss2_3: 80.48571\n",
      "\ttrain_acc: 0.8648, test_acc: \u001b[31m0.8635362592417807\u001b[0m, time: 82.58\n",
      "epoch: 116, loss: 81.20207, loss1: 0.64325, loss2_3: 80.55882\n",
      "\ttrain_acc: 0.8615, test_acc: \u001b[31m0.8587159262005888\u001b[0m, time: 82.55\n",
      "epoch: 117, loss: 81.04705, loss1: 0.64558, loss2_3: 80.40146\n",
      "\ttrain_acc: 0.8645, test_acc: \u001b[31m0.865289107620396\u001b[0m, time: 82.48\n",
      "epoch: 118, loss: 81.00817, loss1: 0.64763, loss2_3: 80.36053\n",
      "\ttrain_acc: 0.8641, test_acc: \u001b[31m0.8616036315422818\u001b[0m, time: 82.57\n",
      "epoch: 119, loss: 80.99588, loss1: 0.64553, loss2_3: 80.35035\n",
      "\ttrain_acc: 0.8634, test_acc: \u001b[31m0.8714690217757702\u001b[0m, time: 82.54\n",
      "best_acc: 0.8714690217757702\n",
      "epoch: 120, loss: 80.96489, loss1: 0.64439, loss2_3: 80.32050\n",
      "\ttrain_acc: 0.8649, test_acc: \u001b[31m0.869120654396728\u001b[0m, time: 82.49\n",
      "epoch: 121, loss: 81.06157, loss1: 0.64506, loss2_3: 80.41652\n",
      "\ttrain_acc: 0.8654, test_acc: \u001b[31m0.8688509854154026\u001b[0m, time: 82.53\n",
      "epoch: 122, loss: 80.90667, loss1: 0.64473, loss2_3: 80.26194\n",
      "\ttrain_acc: 0.8607, test_acc: \u001b[31m0.8563787950291017\u001b[0m, time: 82.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 123, loss: 81.01443, loss1: 0.64330, loss2_3: 80.37113\n",
      "\ttrain_acc: 0.8633, test_acc: \u001b[31m0.8596148228050069\u001b[0m, time: 82.46\n",
      "epoch: 124, loss: 80.98179, loss1: 0.64354, loss2_3: 80.33825\n",
      "\ttrain_acc: 0.8661, test_acc: \u001b[31m0.8669183577159038\u001b[0m, time: 82.51\n",
      "epoch: 125, loss: 80.96778, loss1: 0.64245, loss2_3: 80.32532\n",
      "\ttrain_acc: 0.8646, test_acc: \u001b[31m0.8618395919009416\u001b[0m, time: 82.52\n",
      "epoch: 126, loss: 80.98571, loss1: 0.64325, loss2_3: 80.34246\n",
      "\ttrain_acc: 0.8647, test_acc: \u001b[31m0.8674689318861099\u001b[0m, time: 82.40\n",
      "epoch: 127, loss: 80.86840, loss1: 0.64444, loss2_3: 80.22395\n",
      "\ttrain_acc: 0.8644, test_acc: \u001b[31m0.870660014831794\u001b[0m, time: 82.46\n",
      "epoch: 128, loss: 80.93152, loss1: 0.64542, loss2_3: 80.28610\n",
      "\ttrain_acc: 0.8653, test_acc: \u001b[31m0.8637048023551092\u001b[0m, time: 82.46\n",
      "epoch: 129, loss: 80.86535, loss1: 0.64326, loss2_3: 80.22208\n",
      "\ttrain_acc: 0.8657, test_acc: \u001b[31m0.8691768354345042\u001b[0m, time: 82.35\n",
      "epoch: 130, loss: 80.70077, loss1: 0.64402, loss2_3: 80.05675\n",
      "\ttrain_acc: 0.8643, test_acc: \u001b[31m0.8623901660711477\u001b[0m, time: 82.41\n",
      "epoch: 131, loss: 80.77835, loss1: 0.64171, loss2_3: 80.13664\n",
      "\ttrain_acc: 0.8663, test_acc: \u001b[31m0.8686037888491877\u001b[0m, time: 82.41\n",
      "epoch: 132, loss: 80.75002, loss1: 0.64335, loss2_3: 80.10666\n",
      "\ttrain_acc: 0.8658, test_acc: \u001b[31m0.8649183127710736\u001b[0m, time: 82.39\n",
      "epoch: 133, loss: 80.61739, loss1: 0.64425, loss2_3: 79.97314\n",
      "\ttrain_acc: 0.8660, test_acc: \u001b[31m0.8674464594709993\u001b[0m, time: 82.50\n",
      "epoch: 134, loss: 80.70094, loss1: 0.64070, loss2_3: 80.06024\n",
      "\ttrain_acc: 0.8659, test_acc: \u001b[31m0.8701206768691431\u001b[0m, time: 82.59\n",
      "epoch: 135, loss: 80.59553, loss1: 0.64275, loss2_3: 79.95279\n",
      "\ttrain_acc: 0.8664, test_acc: \u001b[31m0.8671206094518978\u001b[0m, time: 82.53\n",
      "epoch: 136, loss: 80.67880, loss1: 0.64210, loss2_3: 80.03670\n",
      "\ttrain_acc: 0.8660, test_acc: \u001b[31m0.8689745836985101\u001b[0m, time: 82.59\n",
      "epoch: 137, loss: 80.74077, loss1: 0.64331, loss2_3: 80.09746\n",
      "\ttrain_acc: 0.8665, test_acc: \u001b[31m0.8707386682846806\u001b[0m, time: 82.60\n",
      "epoch: 138, loss: 80.59268, loss1: 0.64198, loss2_3: 79.95070\n",
      "\ttrain_acc: 0.8658, test_acc: \u001b[31m0.8718622890402031\u001b[0m, time: 82.49\n",
      "best_acc: 0.8718622890402031\n",
      "epoch: 139, loss: 80.63714, loss1: 0.64281, loss2_3: 79.99433\n",
      "\ttrain_acc: 0.8668, test_acc: \u001b[31m0.8681880491696443\u001b[0m, time: 82.44\n",
      "epoch: 140, loss: 80.60895, loss1: 0.64212, loss2_3: 79.96683\n",
      "\ttrain_acc: 0.8661, test_acc: \u001b[31m0.8697835906424863\u001b[0m, time: 82.39\n",
      "epoch: 141, loss: 80.54985, loss1: 0.64182, loss2_3: 79.90803\n",
      "\ttrain_acc: 0.8658, test_acc: \u001b[31m0.8684914267736353\u001b[0m, time: 82.34\n",
      "epoch: 142, loss: 80.67196, loss1: 0.64311, loss2_3: 80.02885\n",
      "\ttrain_acc: 0.8654, test_acc: \u001b[31m0.8625362367693656\u001b[0m, time: 82.40\n",
      "epoch: 143, loss: 80.52750, loss1: 0.64232, loss2_3: 79.88518\n",
      "\ttrain_acc: 0.8658, test_acc: \u001b[31m0.8657160835074945\u001b[0m, time: 82.42\n",
      "epoch: 144, loss: 80.51882, loss1: 0.64048, loss2_3: 79.87834\n",
      "\ttrain_acc: 0.8662, test_acc: \u001b[31m0.8693004337176117\u001b[0m, time: 82.40\n",
      "epoch: 145, loss: 80.51193, loss1: 0.64127, loss2_3: 79.87065\n",
      "\ttrain_acc: 0.8670, test_acc: \u001b[31m0.8663340749230319\u001b[0m, time: 82.46\n",
      "epoch: 146, loss: 80.41018, loss1: 0.63920, loss2_3: 79.77098\n",
      "\ttrain_acc: 0.8667, test_acc: \u001b[31m0.8670869008292321\u001b[0m, time: 82.48\n",
      "epoch: 147, loss: 80.39112, loss1: 0.64099, loss2_3: 79.75013\n",
      "\ttrain_acc: 0.8631, test_acc: \u001b[31m0.8584687296343738\u001b[0m, time: 82.30\n",
      "epoch: 148, loss: 80.56894, loss1: 0.64126, loss2_3: 79.92768\n",
      "\ttrain_acc: 0.8660, test_acc: \u001b[31m0.8680644508865368\u001b[0m, time: 82.35\n",
      "epoch: 149, loss: 80.41595, loss1: 0.64215, loss2_3: 79.77380\n",
      "\ttrain_acc: 0.8648, test_acc: \u001b[31m0.8620418436369357\u001b[0m, time: 82.35\n",
      "epoch: 150, loss: 80.41481, loss1: 0.64235, loss2_3: 79.77246\n",
      "\ttrain_acc: 0.8669, test_acc: \u001b[31m0.8663790197532529\u001b[0m, time: 82.29\n",
      "epoch: 151, loss: 80.35584, loss1: 0.63968, loss2_3: 79.71617\n",
      "\ttrain_acc: 0.8630, test_acc: \u001b[31m0.8719297062855345\u001b[0m, time: 82.34\n",
      "best_acc: 0.8719297062855345\n",
      "epoch: 152, loss: 80.31473, loss1: 0.64113, loss2_3: 79.67360\n",
      "\ttrain_acc: 0.8668, test_acc: \u001b[31m0.8645362817141958\u001b[0m, time: 82.36\n",
      "epoch: 153, loss: 80.32361, loss1: 0.64019, loss2_3: 79.68343\n",
      "\ttrain_acc: 0.8664, test_acc: \u001b[31m0.8645138092990854\u001b[0m, time: 82.32\n",
      "epoch: 154, loss: 80.30655, loss1: 0.63990, loss2_3: 79.66665\n",
      "\ttrain_acc: 0.8666, test_acc: \u001b[31m0.8703791096429133\u001b[0m, time: 82.37\n",
      "epoch: 155, loss: 80.32043, loss1: 0.64212, loss2_3: 79.67831\n",
      "\ttrain_acc: 0.8631, test_acc: \u001b[31m0.8586035641250365\u001b[0m, time: 82.43\n",
      "epoch: 156, loss: 80.31257, loss1: 0.63930, loss2_3: 79.67327\n",
      "\ttrain_acc: 0.8661, test_acc: \u001b[31m0.8699296613407043\u001b[0m, time: 82.33\n",
      "epoch: 157, loss: 80.34878, loss1: 0.64005, loss2_3: 79.70873\n",
      "\ttrain_acc: 0.8656, test_acc: \u001b[31m0.8614463246365087\u001b[0m, time: 82.45\n",
      "epoch: 158, loss: 80.25383, loss1: 0.64046, loss2_3: 79.61337\n",
      "\ttrain_acc: 0.8611, test_acc: \u001b[31m0.8545810018202656\u001b[0m, time: 85.22\n",
      "epoch: 159, loss: 80.24649, loss1: 0.63868, loss2_3: 79.60781\n",
      "\ttrain_acc: 0.8585, test_acc: \u001b[31m0.8511539585159217\u001b[0m, time: 85.28\n",
      "epoch: 160, loss: 80.27911, loss1: 0.63930, loss2_3: 79.63981\n",
      "\ttrain_acc: 0.8668, test_acc: \u001b[31m0.8662778938852559\u001b[0m, time: 83.62\n",
      "epoch: 161, loss: 80.26422, loss1: 0.64163, loss2_3: 79.62259\n",
      "\ttrain_acc: 0.8678, test_acc: \u001b[31m0.8652104541675094\u001b[0m, time: 82.38\n",
      "epoch: 162, loss: 80.16776, loss1: 0.64159, loss2_3: 79.52617\n",
      "\ttrain_acc: 0.8680, test_acc: \u001b[31m0.8662441852625902\u001b[0m, time: 82.32\n",
      "epoch: 163, loss: 80.18351, loss1: 0.63966, loss2_3: 79.54385\n",
      "\ttrain_acc: 0.8639, test_acc: \u001b[31m0.8591316658801321\u001b[0m, time: 82.41\n",
      "epoch: 164, loss: 80.11241, loss1: 0.64000, loss2_3: 79.47241\n",
      "\ttrain_acc: 0.8680, test_acc: \u001b[31m0.8681318681318682\u001b[0m, time: 82.38\n",
      "epoch: 165, loss: 80.21146, loss1: 0.63948, loss2_3: 79.57199\n",
      "\ttrain_acc: 0.8663, test_acc: \u001b[31m0.8628283781658015\u001b[0m, time: 82.43\n",
      "epoch: 166, loss: 80.15388, loss1: 0.63907, loss2_3: 79.51481\n",
      "\ttrain_acc: 0.8663, test_acc: \u001b[31m0.869367850962943\u001b[0m, time: 82.52\n",
      "epoch: 167, loss: 80.05975, loss1: 0.64072, loss2_3: 79.41903\n",
      "\ttrain_acc: 0.8678, test_acc: \u001b[31m0.8654014696959482\u001b[0m, time: 82.41\n",
      "epoch: 168, loss: 80.15532, loss1: 0.63916, loss2_3: 79.51616\n",
      "\ttrain_acc: 0.8658, test_acc: \u001b[31m0.8614350884289534\u001b[0m, time: 82.37\n",
      "epoch: 169, loss: 79.99843, loss1: 0.63819, loss2_3: 79.36024\n",
      "\ttrain_acc: 0.8675, test_acc: \u001b[31m0.8680419784714263\u001b[0m, time: 82.43\n",
      "epoch: 170, loss: 80.20269, loss1: 0.64052, loss2_3: 79.56217\n",
      "\ttrain_acc: 0.8674, test_acc: \u001b[31m0.8663902559608081\u001b[0m, time: 82.35\n",
      "epoch: 171, loss: 79.96131, loss1: 0.63831, loss2_3: 79.32300\n",
      "\ttrain_acc: 0.8678, test_acc: \u001b[31m0.8671992629047843\u001b[0m, time: 82.28\n",
      "epoch: 172, loss: 80.02476, loss1: 0.63906, loss2_3: 79.38570\n",
      "\ttrain_acc: 0.8684, test_acc: \u001b[31m0.8672104991123396\u001b[0m, time: 82.42\n",
      "epoch: 173, loss: 80.07812, loss1: 0.63761, loss2_3: 79.44050\n",
      "\ttrain_acc: 0.8668, test_acc: \u001b[31m0.8620306074293804\u001b[0m, time: 82.45\n",
      "epoch: 174, loss: 79.94744, loss1: 0.63953, loss2_3: 79.30791\n",
      "\ttrain_acc: 0.8678, test_acc: \u001b[31m0.8681992853771995\u001b[0m, time: 82.48\n",
      "epoch: 175, loss: 79.96348, loss1: 0.63727, loss2_3: 79.32621\n",
      "\ttrain_acc: 0.8680, test_acc: \u001b[31m0.8668059956403514\u001b[0m, time: 82.47\n",
      "epoch: 176, loss: 79.90408, loss1: 0.64028, loss2_3: 79.26381\n",
      "\ttrain_acc: 0.8663, test_acc: \u001b[31m0.8613564349760668\u001b[0m, time: 82.51\n",
      "epoch: 177, loss: 79.92334, loss1: 0.63912, loss2_3: 79.28421\n",
      "\ttrain_acc: 0.8666, test_acc: \u001b[31m0.8634913144115598\u001b[0m, time: 82.47\n",
      "epoch: 178, loss: 79.89717, loss1: 0.63609, loss2_3: 79.26109\n",
      "\ttrain_acc: 0.8682, test_acc: \u001b[31m0.8711881165868895\u001b[0m, time: 82.55\n",
      "epoch: 179, loss: 79.83344, loss1: 0.63708, loss2_3: 79.19636\n",
      "\ttrain_acc: 0.8677, test_acc: \u001b[31m0.8646598799973033\u001b[0m, time: 82.52\n",
      "epoch: 180, loss: 79.86608, loss1: 0.63807, loss2_3: 79.22801\n",
      "\ttrain_acc: 0.8678, test_acc: \u001b[31m0.8696599923593789\u001b[0m, time: 82.45\n",
      "epoch: 181, loss: 79.76839, loss1: 0.63818, loss2_3: 79.13021\n",
      "\ttrain_acc: 0.8668, test_acc: \u001b[31m0.8642778489404256\u001b[0m, time: 82.51\n",
      "epoch: 182, loss: 79.81390, loss1: 0.63795, loss2_3: 79.17595\n",
      "\ttrain_acc: 0.8652, test_acc: \u001b[31m0.8604238297489831\u001b[0m, time: 82.43\n",
      "epoch: 183, loss: 79.76524, loss1: 0.63639, loss2_3: 79.12884\n",
      "\ttrain_acc: 0.8683, test_acc: \u001b[31m0.8697948268500416\u001b[0m, time: 82.38\n",
      "epoch: 184, loss: 79.80087, loss1: 0.63759, loss2_3: 79.16328\n",
      "\ttrain_acc: 0.8670, test_acc: \u001b[31m0.8630868109395716\u001b[0m, time: 82.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 185, loss: 79.84035, loss1: 0.63672, loss2_3: 79.20364\n",
      "\ttrain_acc: 0.8687, test_acc: \u001b[31m0.8683341198678622\u001b[0m, time: 82.53\n",
      "epoch: 186, loss: 79.85279, loss1: 0.63834, loss2_3: 79.21445\n",
      "\ttrain_acc: 0.8688, test_acc: \u001b[31m0.8684801905660802\u001b[0m, time: 82.42\n",
      "epoch: 187, loss: 79.66783, loss1: 0.63452, loss2_3: 79.03330\n",
      "\ttrain_acc: 0.8674, test_acc: \u001b[31m0.8641542506573181\u001b[0m, time: 82.45\n",
      "epoch: 188, loss: 79.68611, loss1: 0.63746, loss2_3: 79.04865\n",
      "\ttrain_acc: 0.8659, test_acc: \u001b[31m0.8602328142205443\u001b[0m, time: 82.42\n",
      "epoch: 189, loss: 79.72118, loss1: 0.63814, loss2_3: 79.08303\n",
      "\ttrain_acc: 0.8667, test_acc: \u001b[31m0.8627384885053597\u001b[0m, time: 82.30\n",
      "epoch: 190, loss: 79.74695, loss1: 0.63589, loss2_3: 79.11106\n",
      "\ttrain_acc: 0.8688, test_acc: \u001b[31m0.8683116474527518\u001b[0m, time: 82.36\n",
      "epoch: 191, loss: 79.64823, loss1: 0.63698, loss2_3: 79.01126\n",
      "\ttrain_acc: 0.8683, test_acc: \u001b[31m0.8675363491314412\u001b[0m, time: 82.37\n",
      "epoch: 192, loss: 79.83357, loss1: 0.63608, loss2_3: 79.19748\n",
      "\ttrain_acc: 0.8653, test_acc: \u001b[31m0.8589181779365829\u001b[0m, time: 82.34\n",
      "epoch: 193, loss: 79.58868, loss1: 0.63496, loss2_3: 78.95372\n",
      "\ttrain_acc: 0.8677, test_acc: \u001b[31m0.8627834333355806\u001b[0m, time: 82.41\n",
      "epoch: 194, loss: 79.68194, loss1: 0.63600, loss2_3: 79.04595\n",
      "\ttrain_acc: 0.8633, test_acc: \u001b[31m0.8562214881233287\u001b[0m, time: 83.32\n",
      "epoch: 195, loss: 79.63206, loss1: 0.63505, loss2_3: 78.99702\n",
      "\ttrain_acc: 0.8676, test_acc: \u001b[31m0.8630081574866851\u001b[0m, time: 82.47\n",
      "epoch: 196, loss: 79.59173, loss1: 0.63525, loss2_3: 78.95648\n",
      "\ttrain_acc: 0.8681, test_acc: \u001b[31m0.8697835906424863\u001b[0m, time: 82.55\n",
      "epoch: 197, loss: 79.70770, loss1: 0.63670, loss2_3: 79.07100\n",
      "\ttrain_acc: 0.8688, test_acc: \u001b[31m0.8672891525652262\u001b[0m, time: 82.48\n",
      "epoch: 198, loss: 79.58909, loss1: 0.63944, loss2_3: 78.94965\n",
      "\ttrain_acc: 0.8690, test_acc: \u001b[31m0.8669295939234589\u001b[0m, time: 82.40\n",
      "epoch: 199, loss: 79.61750, loss1: 0.63624, loss2_3: 78.98126\n",
      "\ttrain_acc: 0.8697, test_acc: \u001b[31m0.8682217577923099\u001b[0m, time: 82.46\n",
      "epoch: 200, loss: 79.59472, loss1: 0.63660, loss2_3: 78.95812\n",
      "\ttrain_acc: 0.8660, test_acc: \u001b[31m0.8619968988067147\u001b[0m, time: 82.51\n",
      "epoch: 201, loss: 79.58868, loss1: 0.63626, loss2_3: 78.95243\n",
      "\ttrain_acc: 0.8693, test_acc: \u001b[31m0.8664127283759185\u001b[0m, time: 82.49\n",
      "epoch: 202, loss: 79.59387, loss1: 0.63624, loss2_3: 78.95763\n",
      "\ttrain_acc: 0.8684, test_acc: \u001b[31m0.8635587316568911\u001b[0m, time: 82.51\n",
      "epoch: 203, loss: 79.48289, loss1: 0.63699, loss2_3: 78.84589\n",
      "\ttrain_acc: 0.8691, test_acc: \u001b[31m0.8706263062091283\u001b[0m, time: 82.47\n",
      "epoch: 204, loss: 79.46612, loss1: 0.63692, loss2_3: 78.82920\n",
      "\ttrain_acc: 0.8690, test_acc: \u001b[31m0.8651542731297333\u001b[0m, time: 82.37\n",
      "epoch: 205, loss: 79.45926, loss1: 0.63788, loss2_3: 78.82138\n",
      "\ttrain_acc: 0.8697, test_acc: \u001b[31m0.8658958628283782\u001b[0m, time: 82.41\n",
      "epoch: 206, loss: 79.53840, loss1: 0.63605, loss2_3: 78.90235\n",
      "\ttrain_acc: 0.8654, test_acc: \u001b[31m0.8597946021258904\u001b[0m, time: 82.41\n",
      "epoch: 207, loss: 79.43148, loss1: 0.63522, loss2_3: 78.79626\n",
      "\ttrain_acc: 0.8674, test_acc: \u001b[31m0.8623115126182611\u001b[0m, time: 82.40\n",
      "epoch: 208, loss: 79.36199, loss1: 0.63298, loss2_3: 78.72901\n",
      "\ttrain_acc: 0.8687, test_acc: \u001b[31m0.8672442077350053\u001b[0m, time: 82.46\n",
      "epoch: 209, loss: 79.48385, loss1: 0.63357, loss2_3: 78.85028\n",
      "\ttrain_acc: 0.8693, test_acc: \u001b[31m0.8645250455066406\u001b[0m, time: 82.47\n",
      "epoch: 210, loss: 79.41516, loss1: 0.63526, loss2_3: 78.77990\n",
      "\ttrain_acc: 0.8700, test_acc: \u001b[31m0.8698847165104834\u001b[0m, time: 82.28\n",
      "epoch: 211, loss: 79.31503, loss1: 0.63511, loss2_3: 78.67992\n",
      "\ttrain_acc: 0.8678, test_acc: \u001b[31m0.862255331580485\u001b[0m, time: 82.38\n",
      "epoch: 212, loss: 79.36203, loss1: 0.63533, loss2_3: 78.72671\n",
      "\ttrain_acc: 0.8672, test_acc: \u001b[31m0.8611092384098519\u001b[0m, time: 82.35\n",
      "epoch: 213, loss: 79.45065, loss1: 0.63468, loss2_3: 78.81597\n",
      "\ttrain_acc: 0.8637, test_acc: \u001b[31m0.8552888828962448\u001b[0m, time: 82.30\n",
      "epoch: 214, loss: 79.38892, loss1: 0.63646, loss2_3: 78.75247\n",
      "\ttrain_acc: 0.8687, test_acc: \u001b[31m0.86374974718533\u001b[0m, time: 82.34\n",
      "epoch: 215, loss: 79.23075, loss1: 0.63582, loss2_3: 78.59494\n",
      "\ttrain_acc: 0.8678, test_acc: \u001b[31m0.8644126834310883\u001b[0m, time: 82.34\n",
      "epoch: 216, loss: 79.37247, loss1: 0.63530, loss2_3: 78.73717\n",
      "\ttrain_acc: 0.8689, test_acc: \u001b[31m0.8659857524888199\u001b[0m, time: 82.31\n",
      "epoch: 217, loss: 79.31184, loss1: 0.63286, loss2_3: 78.67898\n",
      "\ttrain_acc: 0.8670, test_acc: \u001b[31m0.8599631452392189\u001b[0m, time: 82.34\n",
      "epoch: 218, loss: 79.40066, loss1: 0.63410, loss2_3: 78.76656\n",
      "\ttrain_acc: 0.8695, test_acc: \u001b[31m0.8655250679790557\u001b[0m, time: 82.34\n",
      "epoch: 219, loss: 79.24526, loss1: 0.63518, loss2_3: 78.61008\n",
      "\ttrain_acc: 0.8699, test_acc: \u001b[31m0.8666374525270231\u001b[0m, time: 82.31\n",
      "epoch: 220, loss: 79.30152, loss1: 0.63355, loss2_3: 78.66796\n",
      "\ttrain_acc: 0.8673, test_acc: \u001b[31m0.861165419447628\u001b[0m, time: 82.39\n",
      "epoch: 221, loss: 79.32403, loss1: 0.63403, loss2_3: 78.68999\n",
      "\ttrain_acc: 0.8701, test_acc: \u001b[31m0.8673565698105575\u001b[0m, time: 82.36\n",
      "epoch: 222, loss: 79.21474, loss1: 0.63358, loss2_3: 78.58116\n",
      "\ttrain_acc: 0.8674, test_acc: \u001b[31m0.8603564125036518\u001b[0m, time: 82.34\n",
      "epoch: 223, loss: 79.25141, loss1: 0.63436, loss2_3: 78.61705\n",
      "\ttrain_acc: 0.8673, test_acc: \u001b[31m0.8609406952965235\u001b[0m, time: 82.36\n",
      "epoch: 224, loss: 79.04810, loss1: 0.63446, loss2_3: 78.41364\n",
      "\ttrain_acc: 0.8701, test_acc: \u001b[31m0.8662104766399245\u001b[0m, time: 82.45\n",
      "epoch: 225, loss: 79.21695, loss1: 0.63581, loss2_3: 78.58114\n",
      "\ttrain_acc: 0.8683, test_acc: \u001b[31m0.8614013798062878\u001b[0m, time: 82.41\n",
      "epoch: 226, loss: 79.10028, loss1: 0.63228, loss2_3: 78.46801\n",
      "\ttrain_acc: 0.8676, test_acc: \u001b[31m0.862255331580485\u001b[0m, time: 82.47\n",
      "epoch: 227, loss: 79.13429, loss1: 0.63356, loss2_3: 78.50073\n",
      "\ttrain_acc: 0.8688, test_acc: \u001b[31m0.8637722196004405\u001b[0m, time: 82.35\n",
      "epoch: 228, loss: 79.11331, loss1: 0.63362, loss2_3: 78.47969\n",
      "\ttrain_acc: 0.8648, test_acc: \u001b[31m0.8564349760668779\u001b[0m, time: 82.24\n",
      "epoch: 229, loss: 79.34283, loss1: 0.63373, loss2_3: 78.70910\n",
      "\ttrain_acc: 0.8693, test_acc: \u001b[31m0.863895817883548\u001b[0m, time: 82.30\n",
      "epoch: 230, loss: 79.12545, loss1: 0.63447, loss2_3: 78.49098\n",
      "\ttrain_acc: 0.8706, test_acc: \u001b[31m0.8650306748466258\u001b[0m, time: 82.29\n",
      "epoch: 231, loss: 79.03514, loss1: 0.63315, loss2_3: 78.40198\n",
      "\ttrain_acc: 0.8705, test_acc: \u001b[31m0.8654688869412795\u001b[0m, time: 82.28\n",
      "epoch: 232, loss: 78.96726, loss1: 0.63376, loss2_3: 78.33350\n",
      "\ttrain_acc: 0.8696, test_acc: \u001b[31m0.8638171644306614\u001b[0m, time: 82.34\n",
      "epoch: 233, loss: 79.01696, loss1: 0.63219, loss2_3: 78.38477\n",
      "\ttrain_acc: 0.8706, test_acc: \u001b[31m0.8691768354345042\u001b[0m, time: 82.31\n",
      "epoch: 234, loss: 79.07264, loss1: 0.63137, loss2_3: 78.44127\n",
      "\ttrain_acc: 0.8676, test_acc: \u001b[31m0.860468774579204\u001b[0m, time: 82.26\n",
      "epoch: 235, loss: 79.10177, loss1: 0.63242, loss2_3: 78.46935\n",
      "\ttrain_acc: 0.8696, test_acc: \u001b[31m0.8613002539382908\u001b[0m, time: 82.38\n",
      "epoch: 236, loss: 79.07539, loss1: 0.63311, loss2_3: 78.44228\n",
      "\ttrain_acc: 0.8699, test_acc: \u001b[31m0.8707274320771253\u001b[0m, time: 82.47\n",
      "epoch: 237, loss: 79.17143, loss1: 0.63239, loss2_3: 78.53904\n",
      "\ttrain_acc: 0.8692, test_acc: \u001b[31m0.8718735252477584\u001b[0m, time: 85.53\n",
      "epoch: 238, loss: 79.09259, loss1: 0.63258, loss2_3: 78.46000\n",
      "\ttrain_acc: 0.8709, test_acc: \u001b[31m0.8701206768691431\u001b[0m, time: 90.89\n",
      "epoch: 239, loss: 78.97285, loss1: 0.63143, loss2_3: 78.34142\n",
      "\ttrain_acc: 0.8695, test_acc: \u001b[31m0.8675251129238859\u001b[0m, time: 90.87\n",
      "epoch: 240, loss: 79.03728, loss1: 0.63199, loss2_3: 78.40529\n",
      "\ttrain_acc: 0.8708, test_acc: \u001b[31m0.86723297152745\u001b[0m, time: 90.82\n",
      "epoch: 241, loss: 79.08314, loss1: 0.63241, loss2_3: 78.45073\n",
      "\ttrain_acc: 0.8708, test_acc: \u001b[31m0.8680195060563158\u001b[0m, time: 90.86\n",
      "epoch: 242, loss: 78.96098, loss1: 0.63131, loss2_3: 78.32967\n",
      "\ttrain_acc: 0.8658, test_acc: \u001b[31m0.8566484640104272\u001b[0m, time: 90.88\n",
      "epoch: 243, loss: 78.98935, loss1: 0.63286, loss2_3: 78.35649\n",
      "\ttrain_acc: 0.8705, test_acc: \u001b[31m0.8676936560372143\u001b[0m, time: 87.19\n",
      "epoch: 244, loss: 78.93082, loss1: 0.63184, loss2_3: 78.29898\n",
      "\ttrain_acc: 0.8669, test_acc: \u001b[31m0.8587046899930335\u001b[0m, time: 82.32\n",
      "epoch: 245, loss: 79.04077, loss1: 0.63084, loss2_3: 78.40993\n",
      "\ttrain_acc: 0.8712, test_acc: \u001b[31m0.8681318681318682\u001b[0m, time: 82.28\n",
      "epoch: 246, loss: 78.99557, loss1: 0.63278, loss2_3: 78.36279\n",
      "\ttrain_acc: 0.8702, test_acc: \u001b[31m0.8663116025079215\u001b[0m, time: 82.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 247, loss: 78.92826, loss1: 0.63159, loss2_3: 78.29667\n",
      "\ttrain_acc: 0.8705, test_acc: \u001b[31m0.8670419559990112\u001b[0m, time: 82.36\n",
      "epoch: 248, loss: 78.78976, loss1: 0.63162, loss2_3: 78.15814\n",
      "\ttrain_acc: 0.8710, test_acc: \u001b[31m0.8674689318861099\u001b[0m, time: 82.35\n",
      "epoch: 249, loss: 78.85884, loss1: 0.63213, loss2_3: 78.22671\n",
      "\ttrain_acc: 0.8704, test_acc: \u001b[31m0.8670981370367874\u001b[0m, time: 82.30\n",
      "epoch: 250, loss: 78.84117, loss1: 0.63037, loss2_3: 78.21080\n",
      "\ttrain_acc: 0.8691, test_acc: \u001b[31m0.8616148677498371\u001b[0m, time: 82.36\n",
      "epoch: 1, loss: 133.96328, loss1: 1.23908, loss2_3: 132.72421\n",
      "\ttrain_acc: 0.7746, test_acc: \u001b[31m0.7780736645767321\u001b[0m, time: 82.65\n",
      "best_acc: 0.7780736645767321\n",
      "epoch: 2, loss: 103.84906, loss1: 0.85089, loss2_3: 102.99818\n",
      "\ttrain_acc: 0.8002, test_acc: \u001b[31m0.8012539607631632\u001b[0m, time: 82.62\n",
      "best_acc: 0.8012539607631632\n",
      "epoch: 3, loss: 98.78650, loss1: 0.80861, loss2_3: 97.97789\n",
      "\ttrain_acc: 0.8338, test_acc: \u001b[31m0.8439627856805771\u001b[0m, time: 82.68\n",
      "best_acc: 0.8439627856805771\n",
      "epoch: 4, loss: 96.29155, loss1: 0.78258, loss2_3: 95.50897\n",
      "\ttrain_acc: 0.8371, test_acc: \u001b[31m0.8477493876266883\u001b[0m, time: 82.62\n",
      "best_acc: 0.8477493876266883\n",
      "epoch: 5, loss: 94.94003, loss1: 0.76861, loss2_3: 94.17142\n",
      "\ttrain_acc: 0.8346, test_acc: \u001b[31m0.8444234701903414\u001b[0m, time: 82.52\n",
      "epoch: 6, loss: 93.62604, loss1: 0.75783, loss2_3: 92.86822\n",
      "\ttrain_acc: 0.8418, test_acc: \u001b[31m0.8496145980808557\u001b[0m, time: 82.60\n",
      "best_acc: 0.8496145980808557\n",
      "epoch: 7, loss: 92.77581, loss1: 0.74522, loss2_3: 92.03058\n",
      "\ttrain_acc: 0.8447, test_acc: \u001b[31m0.8569406054068631\u001b[0m, time: 82.60\n",
      "best_acc: 0.8569406054068631\n",
      "epoch: 8, loss: 92.28466, loss1: 0.74108, loss2_3: 91.54358\n",
      "\ttrain_acc: 0.8453, test_acc: \u001b[31m0.8532326569136385\u001b[0m, time: 82.54\n",
      "epoch: 9, loss: 91.44888, loss1: 0.72954, loss2_3: 90.71934\n",
      "\ttrain_acc: 0.8443, test_acc: \u001b[31m0.8593451538236815\u001b[0m, time: 82.57\n",
      "best_acc: 0.8593451538236815\n",
      "epoch: 10, loss: 91.03514, loss1: 0.72511, loss2_3: 90.31003\n",
      "\ttrain_acc: 0.8460, test_acc: \u001b[31m0.8567046450482033\u001b[0m, time: 82.52\n",
      "epoch: 11, loss: 90.57605, loss1: 0.72094, loss2_3: 89.85511\n",
      "\ttrain_acc: 0.8468, test_acc: \u001b[31m0.8577945571810602\u001b[0m, time: 82.51\n",
      "epoch: 12, loss: 90.25198, loss1: 0.71863, loss2_3: 89.53335\n",
      "\ttrain_acc: 0.8484, test_acc: \u001b[31m0.857333872671296\u001b[0m, time: 82.59\n",
      "epoch: 13, loss: 89.86390, loss1: 0.71286, loss2_3: 89.15104\n",
      "\ttrain_acc: 0.8500, test_acc: \u001b[31m0.8565922829726511\u001b[0m, time: 82.56\n",
      "epoch: 14, loss: 89.21484, loss1: 0.70928, loss2_3: 88.50557\n",
      "\ttrain_acc: 0.8459, test_acc: \u001b[31m0.846547113418279\u001b[0m, time: 84.84\n",
      "epoch: 15, loss: 88.71926, loss1: 0.70406, loss2_3: 88.01521\n",
      "\ttrain_acc: 0.8513, test_acc: \u001b[31m0.8622890402031507\u001b[0m, time: 84.35\n",
      "best_acc: 0.8622890402031507\n",
      "epoch: 16, loss: 88.38080, loss1: 0.69928, loss2_3: 87.68152\n",
      "\ttrain_acc: 0.8497, test_acc: \u001b[31m0.8569967864446392\u001b[0m, time: 82.54\n",
      "epoch: 17, loss: 88.16210, loss1: 0.69850, loss2_3: 87.46360\n",
      "\ttrain_acc: 0.8493, test_acc: \u001b[31m0.8545697656127104\u001b[0m, time: 82.53\n",
      "epoch: 18, loss: 87.78712, loss1: 0.69392, loss2_3: 87.09320\n",
      "\ttrain_acc: 0.8536, test_acc: \u001b[31m0.8589069417290276\u001b[0m, time: 82.59\n",
      "epoch: 19, loss: 87.28969, loss1: 0.69112, loss2_3: 86.59858\n",
      "\ttrain_acc: 0.8530, test_acc: \u001b[31m0.8627834333355806\u001b[0m, time: 82.52\n",
      "best_acc: 0.8627834333355806\n",
      "epoch: 20, loss: 87.12783, loss1: 0.68891, loss2_3: 86.43892\n",
      "\ttrain_acc: 0.8519, test_acc: \u001b[31m0.8576709588979528\u001b[0m, time: 82.44\n",
      "epoch: 21, loss: 86.72855, loss1: 0.68406, loss2_3: 86.04449\n",
      "\ttrain_acc: 0.8532, test_acc: \u001b[31m0.8554574260095732\u001b[0m, time: 82.41\n",
      "epoch: 22, loss: 86.47364, loss1: 0.68497, loss2_3: 85.78867\n",
      "\ttrain_acc: 0.8551, test_acc: \u001b[31m0.8655138317715004\u001b[0m, time: 82.34\n",
      "best_acc: 0.8655138317715004\n",
      "epoch: 23, loss: 86.20654, loss1: 0.67906, loss2_3: 85.52748\n",
      "\ttrain_acc: 0.8554, test_acc: \u001b[31m0.8625362367693656\u001b[0m, time: 82.29\n",
      "epoch: 24, loss: 86.16655, loss1: 0.67659, loss2_3: 85.48996\n",
      "\ttrain_acc: 0.8528, test_acc: \u001b[31m0.8534910896874087\u001b[0m, time: 82.34\n",
      "epoch: 25, loss: 85.88357, loss1: 0.67767, loss2_3: 85.20590\n",
      "\ttrain_acc: 0.8556, test_acc: \u001b[31m0.8585698555023709\u001b[0m, time: 82.34\n",
      "epoch: 26, loss: 85.72650, loss1: 0.67631, loss2_3: 85.05019\n",
      "\ttrain_acc: 0.8540, test_acc: \u001b[31m0.8568731881615317\u001b[0m, time: 82.34\n",
      "epoch: 27, loss: 85.54773, loss1: 0.67883, loss2_3: 84.86890\n",
      "\ttrain_acc: 0.8566, test_acc: \u001b[31m0.862109260882267\u001b[0m, time: 82.42\n",
      "epoch: 28, loss: 85.31553, loss1: 0.67441, loss2_3: 84.64112\n",
      "\ttrain_acc: 0.8568, test_acc: \u001b[31m0.8648733679408526\u001b[0m, time: 82.42\n",
      "epoch: 29, loss: 85.16511, loss1: 0.67229, loss2_3: 84.49282\n",
      "\ttrain_acc: 0.8559, test_acc: \u001b[31m0.858232769275714\u001b[0m, time: 82.37\n",
      "epoch: 30, loss: 84.89694, loss1: 0.67017, loss2_3: 84.22677\n",
      "\ttrain_acc: 0.8571, test_acc: \u001b[31m0.8623676936560372\u001b[0m, time: 82.42\n",
      "epoch: 31, loss: 84.78749, loss1: 0.67173, loss2_3: 84.11575\n",
      "\ttrain_acc: 0.8567, test_acc: \u001b[31m0.860817097013416\u001b[0m, time: 89.24\n",
      "epoch: 32, loss: 84.74113, loss1: 0.66922, loss2_3: 84.07191\n",
      "\ttrain_acc: 0.8559, test_acc: \u001b[31m0.8591653745027978\u001b[0m, time: 90.95\n",
      "epoch: 33, loss: 84.74431, loss1: 0.67055, loss2_3: 84.07376\n",
      "\ttrain_acc: 0.8563, test_acc: \u001b[31m0.8584125485965977\u001b[0m, time: 91.05\n",
      "epoch: 34, loss: 84.54651, loss1: 0.67021, loss2_3: 83.87630\n",
      "\ttrain_acc: 0.8582, test_acc: \u001b[31m0.8651992179599541\u001b[0m, time: 91.00\n",
      "epoch: 35, loss: 84.52465, loss1: 0.66792, loss2_3: 83.85673\n",
      "\ttrain_acc: 0.8581, test_acc: \u001b[31m0.8615699229196162\u001b[0m, time: 82.94\n",
      "epoch: 36, loss: 84.48528, loss1: 0.66657, loss2_3: 83.81871\n",
      "\ttrain_acc: 0.8568, test_acc: \u001b[31m0.8596148228050069\u001b[0m, time: 82.56\n",
      "epoch: 37, loss: 84.35163, loss1: 0.66816, loss2_3: 83.68348\n",
      "\ttrain_acc: 0.8584, test_acc: \u001b[31m0.8609856401267444\u001b[0m, time: 82.54\n",
      "epoch: 38, loss: 84.18431, loss1: 0.66640, loss2_3: 83.51791\n",
      "\ttrain_acc: 0.8593, test_acc: \u001b[31m0.8646598799973033\u001b[0m, time: 82.52\n",
      "epoch: 39, loss: 84.12911, loss1: 0.66343, loss2_3: 83.46569\n",
      "\ttrain_acc: 0.8577, test_acc: \u001b[31m0.8639070540911031\u001b[0m, time: 82.56\n",
      "epoch: 40, loss: 84.13707, loss1: 0.66608, loss2_3: 83.47099\n",
      "\ttrain_acc: 0.8572, test_acc: \u001b[31m0.8593676262387919\u001b[0m, time: 82.50\n",
      "epoch: 41, loss: 84.06836, loss1: 0.66404, loss2_3: 83.40432\n",
      "\ttrain_acc: 0.8591, test_acc: \u001b[31m0.8656711386772736\u001b[0m, time: 82.35\n",
      "best_acc: 0.8656711386772736\n",
      "epoch: 42, loss: 83.97941, loss1: 0.66522, loss2_3: 83.31419\n",
      "\ttrain_acc: 0.8578, test_acc: \u001b[31m0.8594462796916784\u001b[0m, time: 82.39\n",
      "epoch: 43, loss: 83.77260, loss1: 0.66481, loss2_3: 83.10779\n",
      "\ttrain_acc: 0.8538, test_acc: \u001b[31m0.8527157913660981\u001b[0m, time: 82.38\n",
      "epoch: 44, loss: 83.82161, loss1: 0.66321, loss2_3: 83.15840\n",
      "\ttrain_acc: 0.8592, test_acc: \u001b[31m0.8642104316950943\u001b[0m, time: 82.40\n",
      "epoch: 45, loss: 83.71651, loss1: 0.66236, loss2_3: 83.05415\n",
      "\ttrain_acc: 0.8593, test_acc: \u001b[31m0.8680082698487607\u001b[0m, time: 82.48\n",
      "best_acc: 0.8680082698487607\n",
      "epoch: 46, loss: 83.64555, loss1: 0.66125, loss2_3: 82.98430\n",
      "\ttrain_acc: 0.8599, test_acc: \u001b[31m0.8657048472999394\u001b[0m, time: 82.52\n",
      "epoch: 47, loss: 83.60246, loss1: 0.66294, loss2_3: 82.93952\n",
      "\ttrain_acc: 0.8560, test_acc: \u001b[31m0.8564125036517675\u001b[0m, time: 82.49\n",
      "epoch: 48, loss: 83.53089, loss1: 0.65967, loss2_3: 82.87123\n",
      "\ttrain_acc: 0.8588, test_acc: \u001b[31m0.8635587316568911\u001b[0m, time: 82.55\n",
      "epoch: 49, loss: 83.38135, loss1: 0.66224, loss2_3: 82.71911\n",
      "\ttrain_acc: 0.8602, test_acc: \u001b[31m0.8631205195622373\u001b[0m, time: 82.48\n",
      "epoch: 50, loss: 83.43993, loss1: 0.66065, loss2_3: 82.77928\n",
      "\ttrain_acc: 0.8595, test_acc: \u001b[31m0.8619631901840491\u001b[0m, time: 82.43\n",
      "epoch: 51, loss: 83.43301, loss1: 0.65868, loss2_3: 82.77433\n",
      "\ttrain_acc: 0.8604, test_acc: \u001b[31m0.8679633250185398\u001b[0m, time: 82.50\n",
      "epoch: 52, loss: 83.26477, loss1: 0.66014, loss2_3: 82.60463\n",
      "\ttrain_acc: 0.8595, test_acc: \u001b[31m0.8627609609204702\u001b[0m, time: 82.50\n",
      "epoch: 53, loss: 83.24634, loss1: 0.65867, loss2_3: 82.58767\n",
      "\ttrain_acc: 0.8597, test_acc: \u001b[31m0.8624800557315895\u001b[0m, time: 82.44\n",
      "epoch: 54, loss: 83.17042, loss1: 0.66137, loss2_3: 82.50905\n",
      "\ttrain_acc: 0.8607, test_acc: \u001b[31m0.8638508730533271\u001b[0m, time: 82.48\n",
      "epoch: 55, loss: 83.12519, loss1: 0.65951, loss2_3: 82.46569\n",
      "\ttrain_acc: 0.8597, test_acc: \u001b[31m0.8634576057888941\u001b[0m, time: 82.47\n",
      "epoch: 56, loss: 83.21371, loss1: 0.65729, loss2_3: 82.55643\n",
      "\ttrain_acc: 0.8585, test_acc: \u001b[31m0.8582215330681588\u001b[0m, time: 82.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 57, loss: 82.91711, loss1: 0.65784, loss2_3: 82.25926\n",
      "\ttrain_acc: 0.8601, test_acc: \u001b[31m0.8618508281084968\u001b[0m, time: 82.48\n",
      "epoch: 58, loss: 82.96880, loss1: 0.65622, loss2_3: 82.31258\n",
      "\ttrain_acc: 0.8615, test_acc: \u001b[31m0.8682105215847548\u001b[0m, time: 82.48\n",
      "best_acc: 0.8682105215847548\n",
      "epoch: 59, loss: 82.94936, loss1: 0.65539, loss2_3: 82.29397\n",
      "\ttrain_acc: 0.8574, test_acc: \u001b[31m0.8554237173869076\u001b[0m, time: 82.39\n",
      "epoch: 60, loss: 82.86931, loss1: 0.65812, loss2_3: 82.21119\n",
      "\ttrain_acc: 0.8611, test_acc: \u001b[31m0.8638621092608822\u001b[0m, time: 82.40\n",
      "epoch: 61, loss: 82.86738, loss1: 0.65858, loss2_3: 82.20881\n",
      "\ttrain_acc: 0.8618, test_acc: \u001b[31m0.8648059506955212\u001b[0m, time: 82.38\n",
      "epoch: 62, loss: 82.74398, loss1: 0.65609, loss2_3: 82.08790\n",
      "\ttrain_acc: 0.8605, test_acc: \u001b[31m0.860963167711634\u001b[0m, time: 82.31\n",
      "epoch: 63, loss: 82.85135, loss1: 0.65750, loss2_3: 82.19384\n",
      "\ttrain_acc: 0.8595, test_acc: \u001b[31m0.8586148003325917\u001b[0m, time: 83.42\n",
      "epoch: 64, loss: 82.63147, loss1: 0.65642, loss2_3: 81.97505\n",
      "\ttrain_acc: 0.8603, test_acc: \u001b[31m0.8624126384862582\u001b[0m, time: 82.51\n",
      "epoch: 65, loss: 82.55591, loss1: 0.65541, loss2_3: 81.90050\n",
      "\ttrain_acc: 0.8623, test_acc: \u001b[31m0.8677723094901009\u001b[0m, time: 89.78\n",
      "epoch: 66, loss: 82.63983, loss1: 0.65525, loss2_3: 81.98457\n",
      "\ttrain_acc: 0.8618, test_acc: \u001b[31m0.8646374075821929\u001b[0m, time: 84.66\n",
      "epoch: 67, loss: 82.53195, loss1: 0.65566, loss2_3: 81.87628\n",
      "\ttrain_acc: 0.8581, test_acc: \u001b[31m0.8565698105575407\u001b[0m, time: 82.40\n",
      "epoch: 68, loss: 82.37503, loss1: 0.65353, loss2_3: 81.72151\n",
      "\ttrain_acc: 0.8611, test_acc: \u001b[31m0.8706263062091283\u001b[0m, time: 82.34\n",
      "best_acc: 0.8706263062091283\n",
      "epoch: 69, loss: 82.49236, loss1: 0.65627, loss2_3: 81.83608\n",
      "\ttrain_acc: 0.8611, test_acc: \u001b[31m0.8607496797680847\u001b[0m, time: 82.38\n",
      "epoch: 70, loss: 82.40748, loss1: 0.65406, loss2_3: 81.75342\n",
      "\ttrain_acc: 0.8609, test_acc: \u001b[31m0.8622216229578192\u001b[0m, time: 82.38\n",
      "epoch: 71, loss: 82.36658, loss1: 0.65382, loss2_3: 81.71276\n",
      "\ttrain_acc: 0.8629, test_acc: \u001b[31m0.8655812490168319\u001b[0m, time: 82.41\n",
      "epoch: 72, loss: 82.41757, loss1: 0.65569, loss2_3: 81.76188\n",
      "\ttrain_acc: 0.8618, test_acc: \u001b[31m0.8635025506191151\u001b[0m, time: 82.50\n",
      "epoch: 73, loss: 82.35245, loss1: 0.65378, loss2_3: 81.69867\n",
      "\ttrain_acc: 0.8618, test_acc: \u001b[31m0.8628957954111328\u001b[0m, time: 82.48\n",
      "epoch: 74, loss: 82.28422, loss1: 0.65292, loss2_3: 81.63130\n",
      "\ttrain_acc: 0.8604, test_acc: \u001b[31m0.8610755297871863\u001b[0m, time: 82.44\n",
      "epoch: 75, loss: 82.20670, loss1: 0.65205, loss2_3: 81.55464\n",
      "\ttrain_acc: 0.8630, test_acc: \u001b[31m0.8646598799973033\u001b[0m, time: 82.47\n",
      "epoch: 76, loss: 82.26521, loss1: 0.65516, loss2_3: 81.61005\n",
      "\ttrain_acc: 0.8617, test_acc: \u001b[31m0.8640755972044316\u001b[0m, time: 82.43\n",
      "epoch: 77, loss: 82.00028, loss1: 0.65174, loss2_3: 81.34855\n",
      "\ttrain_acc: 0.8622, test_acc: \u001b[31m0.8665026180363604\u001b[0m, time: 82.41\n",
      "epoch: 78, loss: 82.17300, loss1: 0.65177, loss2_3: 81.52123\n",
      "\ttrain_acc: 0.8631, test_acc: \u001b[31m0.8701656216993641\u001b[0m, time: 82.56\n",
      "epoch: 79, loss: 82.01694, loss1: 0.65162, loss2_3: 81.36532\n",
      "\ttrain_acc: 0.8640, test_acc: \u001b[31m0.868075687094092\u001b[0m, time: 82.50\n",
      "epoch: 80, loss: 81.99772, loss1: 0.65097, loss2_3: 81.34675\n",
      "\ttrain_acc: 0.8606, test_acc: \u001b[31m0.8620867884671566\u001b[0m, time: 82.47\n",
      "epoch: 81, loss: 81.97157, loss1: 0.64879, loss2_3: 81.32278\n",
      "\ttrain_acc: 0.8627, test_acc: \u001b[31m0.8644351558461988\u001b[0m, time: 82.51\n",
      "epoch: 82, loss: 81.94640, loss1: 0.65167, loss2_3: 81.29473\n",
      "\ttrain_acc: 0.8634, test_acc: \u001b[31m0.8648846041484078\u001b[0m, time: 82.52\n",
      "epoch: 83, loss: 81.89882, loss1: 0.65092, loss2_3: 81.24790\n",
      "\ttrain_acc: 0.8634, test_acc: \u001b[31m0.8656823748848289\u001b[0m, time: 82.44\n",
      "epoch: 84, loss: 81.80152, loss1: 0.65015, loss2_3: 81.15136\n",
      "\ttrain_acc: 0.8636, test_acc: \u001b[31m0.8687498595474056\u001b[0m, time: 82.48\n",
      "epoch: 85, loss: 81.90110, loss1: 0.65031, loss2_3: 81.25079\n",
      "\ttrain_acc: 0.8643, test_acc: \u001b[31m0.8666374525270231\u001b[0m, time: 82.47\n",
      "epoch: 86, loss: 81.72183, loss1: 0.64975, loss2_3: 81.07209\n",
      "\ttrain_acc: 0.8635, test_acc: \u001b[31m0.8688734578305131\u001b[0m, time: 82.47\n",
      "epoch: 87, loss: 81.82026, loss1: 0.64926, loss2_3: 81.17100\n",
      "\ttrain_acc: 0.8645, test_acc: \u001b[31m0.8665026180363604\u001b[0m, time: 82.44\n",
      "epoch: 88, loss: 81.74106, loss1: 0.64843, loss2_3: 81.09264\n",
      "\ttrain_acc: 0.8643, test_acc: \u001b[31m0.8666374525270231\u001b[0m, time: 82.43\n",
      "epoch: 89, loss: 81.73963, loss1: 0.65126, loss2_3: 81.08837\n",
      "\ttrain_acc: 0.8627, test_acc: \u001b[31m0.8626935436751387\u001b[0m, time: 83.89\n",
      "epoch: 90, loss: 81.65040, loss1: 0.64941, loss2_3: 81.00099\n",
      "\ttrain_acc: 0.8628, test_acc: \u001b[31m0.8611317108249623\u001b[0m, time: 84.56\n",
      "epoch: 91, loss: 81.64115, loss1: 0.64785, loss2_3: 80.99331\n",
      "\ttrain_acc: 0.8640, test_acc: \u001b[31m0.8653340524506169\u001b[0m, time: 82.42\n",
      "epoch: 92, loss: 81.55636, loss1: 0.64662, loss2_3: 80.90975\n",
      "\ttrain_acc: 0.8640, test_acc: \u001b[31m0.8699521337558147\u001b[0m, time: 82.39\n",
      "epoch: 93, loss: 81.59268, loss1: 0.64899, loss2_3: 80.94369\n",
      "\ttrain_acc: 0.8645, test_acc: \u001b[31m0.8674239870558889\u001b[0m, time: 82.47\n",
      "epoch: 94, loss: 81.60711, loss1: 0.64902, loss2_3: 80.95809\n",
      "\ttrain_acc: 0.8643, test_acc: \u001b[31m0.8697948268500416\u001b[0m, time: 90.91\n",
      "epoch: 95, loss: 81.51634, loss1: 0.64938, loss2_3: 80.86697\n",
      "\ttrain_acc: 0.8641, test_acc: \u001b[31m0.863996943751545\u001b[0m, time: 84.19\n",
      "epoch: 96, loss: 81.56423, loss1: 0.64719, loss2_3: 80.91704\n",
      "\ttrain_acc: 0.8641, test_acc: \u001b[31m0.867131845659453\u001b[0m, time: 82.48\n",
      "epoch: 97, loss: 81.46643, loss1: 0.64878, loss2_3: 80.81765\n",
      "\ttrain_acc: 0.8623, test_acc: \u001b[31m0.860367648711207\u001b[0m, time: 82.42\n",
      "epoch: 98, loss: 81.31027, loss1: 0.64648, loss2_3: 80.66379\n",
      "\ttrain_acc: 0.8621, test_acc: \u001b[31m0.8587496348232545\u001b[0m, time: 82.33\n",
      "epoch: 99, loss: 81.35489, loss1: 0.64821, loss2_3: 80.70668\n",
      "\ttrain_acc: 0.8636, test_acc: \u001b[31m0.8617159936178341\u001b[0m, time: 82.46\n",
      "epoch: 100, loss: 81.50572, loss1: 0.64779, loss2_3: 80.85793\n",
      "\ttrain_acc: 0.8603, test_acc: \u001b[31m0.857682195105508\u001b[0m, time: 82.57\n",
      "epoch: 101, loss: 81.33492, loss1: 0.64757, loss2_3: 80.68735\n",
      "\ttrain_acc: 0.8649, test_acc: \u001b[31m0.8682779388300861\u001b[0m, time: 82.40\n",
      "epoch: 102, loss: 81.29924, loss1: 0.64690, loss2_3: 80.65234\n",
      "\ttrain_acc: 0.8645, test_acc: \u001b[31m0.8703678734353582\u001b[0m, time: 82.47\n",
      "epoch: 103, loss: 81.42371, loss1: 0.64697, loss2_3: 80.77673\n",
      "\ttrain_acc: 0.8548, test_acc: \u001b[31m0.8491651497786468\u001b[0m, time: 82.48\n",
      "epoch: 104, loss: 81.34311, loss1: 0.64638, loss2_3: 80.69673\n",
      "\ttrain_acc: 0.8645, test_acc: \u001b[31m0.8644014472235331\u001b[0m, time: 90.28\n",
      "epoch: 105, loss: 81.27942, loss1: 0.64693, loss2_3: 80.63249\n",
      "\ttrain_acc: 0.8651, test_acc: \u001b[31m0.8667498146025754\u001b[0m, time: 91.00\n",
      "epoch: 106, loss: 81.35776, loss1: 0.64648, loss2_3: 80.71127\n",
      "\ttrain_acc: 0.8649, test_acc: \u001b[31m0.8697386458122655\u001b[0m, time: 91.00\n",
      "epoch: 107, loss: 81.35381, loss1: 0.64653, loss2_3: 80.70728\n",
      "\ttrain_acc: 0.8657, test_acc: \u001b[31m0.866435200791029\u001b[0m, time: 90.98\n",
      "epoch: 108, loss: 81.32269, loss1: 0.64586, loss2_3: 80.67683\n",
      "\ttrain_acc: 0.8650, test_acc: \u001b[31m0.8667947594327963\u001b[0m, time: 91.11\n",
      "epoch: 109, loss: 81.13341, loss1: 0.64597, loss2_3: 80.48744\n",
      "\ttrain_acc: 0.8630, test_acc: \u001b[31m0.8617946470707207\u001b[0m, time: 91.03\n",
      "epoch: 110, loss: 81.20919, loss1: 0.64482, loss2_3: 80.56437\n",
      "\ttrain_acc: 0.8660, test_acc: \u001b[31m0.8704352906806895\u001b[0m, time: 91.00\n",
      "epoch: 111, loss: 81.08750, loss1: 0.64658, loss2_3: 80.44092\n",
      "\ttrain_acc: 0.8636, test_acc: \u001b[31m0.8626148902222522\u001b[0m, time: 91.06\n",
      "epoch: 112, loss: 81.05662, loss1: 0.64723, loss2_3: 80.40940\n",
      "\ttrain_acc: 0.8645, test_acc: \u001b[31m0.8627272522978044\u001b[0m, time: 91.09\n",
      "epoch: 113, loss: 81.07079, loss1: 0.64461, loss2_3: 80.42618\n",
      "\ttrain_acc: 0.8626, test_acc: \u001b[31m0.8592889727859053\u001b[0m, time: 91.00\n",
      "epoch: 114, loss: 81.03007, loss1: 0.64539, loss2_3: 80.38468\n",
      "\ttrain_acc: 0.8617, test_acc: \u001b[31m0.8581091709926065\u001b[0m, time: 91.05\n",
      "epoch: 115, loss: 81.12271, loss1: 0.64379, loss2_3: 80.47892\n",
      "\ttrain_acc: 0.8657, test_acc: \u001b[31m0.8672891525652262\u001b[0m, time: 89.53\n",
      "epoch: 116, loss: 81.03833, loss1: 0.64503, loss2_3: 80.39330\n",
      "\ttrain_acc: 0.8626, test_acc: \u001b[31m0.8596934762578934\u001b[0m, time: 82.46\n",
      "epoch: 117, loss: 81.04480, loss1: 0.64521, loss2_3: 80.39958\n",
      "\ttrain_acc: 0.8648, test_acc: \u001b[31m0.8631542281849031\u001b[0m, time: 82.41\n",
      "epoch: 118, loss: 80.84097, loss1: 0.64401, loss2_3: 80.19695\n",
      "\ttrain_acc: 0.8663, test_acc: \u001b[31m0.8690307647362862\u001b[0m, time: 82.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 119, loss: 81.01380, loss1: 0.64325, loss2_3: 80.37055\n",
      "\ttrain_acc: 0.8663, test_acc: \u001b[31m0.8676599474145487\u001b[0m, time: 82.28\n",
      "epoch: 120, loss: 81.00325, loss1: 0.64472, loss2_3: 80.35853\n",
      "\ttrain_acc: 0.8654, test_acc: \u001b[31m0.8681206319243129\u001b[0m, time: 82.35\n",
      "epoch: 121, loss: 80.92506, loss1: 0.64221, loss2_3: 80.28285\n",
      "\ttrain_acc: 0.8612, test_acc: \u001b[31m0.8565810467650958\u001b[0m, time: 82.51\n",
      "epoch: 122, loss: 80.86154, loss1: 0.64345, loss2_3: 80.21809\n",
      "\ttrain_acc: 0.8626, test_acc: \u001b[31m0.8588844693139172\u001b[0m, time: 82.40\n",
      "epoch: 123, loss: 80.81881, loss1: 0.64247, loss2_3: 80.17634\n",
      "\ttrain_acc: 0.8653, test_acc: \u001b[31m0.8646374075821929\u001b[0m, time: 84.98\n",
      "epoch: 124, loss: 80.80821, loss1: 0.64514, loss2_3: 80.16307\n",
      "\ttrain_acc: 0.8661, test_acc: \u001b[31m0.8661205869794827\u001b[0m, time: 82.70\n",
      "epoch: 125, loss: 80.83305, loss1: 0.64193, loss2_3: 80.19113\n",
      "\ttrain_acc: 0.8593, test_acc: \u001b[31m0.8532326569136385\u001b[0m, time: 82.36\n",
      "epoch: 126, loss: 80.77242, loss1: 0.64331, loss2_3: 80.12911\n",
      "\ttrain_acc: 0.8657, test_acc: \u001b[31m0.8685476078114115\u001b[0m, time: 82.41\n",
      "epoch: 127, loss: 80.84555, loss1: 0.64212, loss2_3: 80.20344\n",
      "\ttrain_acc: 0.8646, test_acc: \u001b[31m0.862704779882694\u001b[0m, time: 82.37\n",
      "epoch: 128, loss: 80.82050, loss1: 0.64311, loss2_3: 80.17739\n",
      "\ttrain_acc: 0.8668, test_acc: \u001b[31m0.8686037888491877\u001b[0m, time: 82.34\n",
      "epoch: 129, loss: 80.59123, loss1: 0.64119, loss2_3: 79.95004\n",
      "\ttrain_acc: 0.8658, test_acc: \u001b[31m0.8654351783186139\u001b[0m, time: 82.43\n",
      "epoch: 130, loss: 80.75902, loss1: 0.63908, loss2_3: 80.11995\n",
      "\ttrain_acc: 0.8623, test_acc: \u001b[31m0.8582102968606036\u001b[0m, time: 82.45\n",
      "epoch: 131, loss: 80.70683, loss1: 0.64271, loss2_3: 80.06412\n",
      "\ttrain_acc: 0.8650, test_acc: \u001b[31m0.8643565023933122\u001b[0m, time: 82.38\n",
      "epoch: 132, loss: 80.58424, loss1: 0.64184, loss2_3: 79.94240\n",
      "\ttrain_acc: 0.8670, test_acc: \u001b[31m0.8683116474527518\u001b[0m, time: 82.44\n",
      "epoch: 133, loss: 80.73213, loss1: 0.64135, loss2_3: 80.09078\n",
      "\ttrain_acc: 0.8662, test_acc: \u001b[31m0.8673678060181128\u001b[0m, time: 82.40\n",
      "epoch: 134, loss: 80.64193, loss1: 0.64159, loss2_3: 80.00034\n",
      "\ttrain_acc: 0.8574, test_acc: \u001b[31m0.8512887930065844\u001b[0m, time: 82.38\n",
      "epoch: 135, loss: 80.56661, loss1: 0.64481, loss2_3: 79.92180\n",
      "\ttrain_acc: 0.8665, test_acc: \u001b[31m0.8673116249803366\u001b[0m, time: 82.53\n",
      "epoch: 136, loss: 80.67894, loss1: 0.64148, loss2_3: 80.03747\n",
      "\ttrain_acc: 0.8646, test_acc: \u001b[31m0.860367648711207\u001b[0m, time: 82.51\n",
      "epoch: 137, loss: 80.60409, loss1: 0.64035, loss2_3: 79.96374\n",
      "\ttrain_acc: 0.8654, test_acc: \u001b[31m0.8630868109395716\u001b[0m, time: 82.41\n",
      "epoch: 138, loss: 80.63179, loss1: 0.64343, loss2_3: 79.98836\n",
      "\ttrain_acc: 0.8650, test_acc: \u001b[31m0.8723566821726331\u001b[0m, time: 82.46\n",
      "best_acc: 0.8723566821726331\n",
      "epoch: 139, loss: 80.60236, loss1: 0.64239, loss2_3: 79.95997\n",
      "\ttrain_acc: 0.8653, test_acc: \u001b[31m0.8625699453920312\u001b[0m, time: 82.45\n",
      "epoch: 140, loss: 80.59159, loss1: 0.64229, loss2_3: 79.94930\n",
      "\ttrain_acc: 0.8669, test_acc: \u001b[31m0.8681880491696443\u001b[0m, time: 82.43\n",
      "epoch: 141, loss: 80.45640, loss1: 0.64138, loss2_3: 79.81502\n",
      "\ttrain_acc: 0.8651, test_acc: \u001b[31m0.8623115126182611\u001b[0m, time: 82.48\n",
      "epoch: 142, loss: 80.50741, loss1: 0.64313, loss2_3: 79.86428\n",
      "\ttrain_acc: 0.8672, test_acc: \u001b[31m0.866536326659026\u001b[0m, time: 82.47\n",
      "epoch: 143, loss: 80.53951, loss1: 0.64265, loss2_3: 79.89685\n",
      "\ttrain_acc: 0.8657, test_acc: \u001b[31m0.8634238971662285\u001b[0m, time: 82.40\n",
      "epoch: 144, loss: 80.45744, loss1: 0.64075, loss2_3: 79.81669\n",
      "\ttrain_acc: 0.8664, test_acc: \u001b[31m0.8667498146025754\u001b[0m, time: 82.51\n",
      "epoch: 145, loss: 80.45450, loss1: 0.64146, loss2_3: 79.81304\n",
      "\ttrain_acc: 0.8676, test_acc: \u001b[31m0.8674239870558889\u001b[0m, time: 82.48\n",
      "epoch: 146, loss: 80.32793, loss1: 0.63978, loss2_3: 79.68815\n",
      "\ttrain_acc: 0.8585, test_acc: \u001b[31m0.8519067844221219\u001b[0m, time: 82.39\n",
      "epoch: 147, loss: 80.36083, loss1: 0.64160, loss2_3: 79.71924\n",
      "\ttrain_acc: 0.8667, test_acc: \u001b[31m0.8660419335265961\u001b[0m, time: 82.40\n",
      "epoch: 148, loss: 80.42240, loss1: 0.64091, loss2_3: 79.78149\n",
      "\ttrain_acc: 0.8679, test_acc: \u001b[31m0.8664014921683634\u001b[0m, time: 82.36\n",
      "epoch: 149, loss: 80.29539, loss1: 0.64010, loss2_3: 79.65529\n",
      "\ttrain_acc: 0.8656, test_acc: \u001b[31m0.8636598575248882\u001b[0m, time: 82.29\n",
      "epoch: 150, loss: 80.29836, loss1: 0.64029, loss2_3: 79.65807\n",
      "\ttrain_acc: 0.8673, test_acc: \u001b[31m0.8674689318861099\u001b[0m, time: 82.35\n",
      "epoch: 151, loss: 80.34932, loss1: 0.64185, loss2_3: 79.70747\n",
      "\ttrain_acc: 0.8660, test_acc: \u001b[31m0.8638396368457718\u001b[0m, time: 82.37\n",
      "epoch: 152, loss: 80.35448, loss1: 0.64072, loss2_3: 79.71376\n",
      "\ttrain_acc: 0.8656, test_acc: \u001b[31m0.8712892424548866\u001b[0m, time: 82.32\n",
      "epoch: 153, loss: 80.34983, loss1: 0.63881, loss2_3: 79.71102\n",
      "\ttrain_acc: 0.8673, test_acc: \u001b[31m0.8675363491314412\u001b[0m, time: 82.37\n",
      "epoch: 154, loss: 80.25698, loss1: 0.64210, loss2_3: 79.61488\n",
      "\ttrain_acc: 0.8675, test_acc: \u001b[31m0.8699184251331491\u001b[0m, time: 82.36\n",
      "epoch: 155, loss: 80.19565, loss1: 0.63982, loss2_3: 79.55583\n",
      "\ttrain_acc: 0.8666, test_acc: \u001b[31m0.8712442976246657\u001b[0m, time: 82.31\n",
      "epoch: 156, loss: 80.26775, loss1: 0.64026, loss2_3: 79.62749\n",
      "\ttrain_acc: 0.8669, test_acc: \u001b[31m0.8654464145261691\u001b[0m, time: 82.38\n",
      "epoch: 157, loss: 80.27051, loss1: 0.63908, loss2_3: 79.63143\n",
      "\ttrain_acc: 0.8653, test_acc: \u001b[31m0.8608283332209713\u001b[0m, time: 82.39\n",
      "epoch: 158, loss: 80.16068, loss1: 0.63996, loss2_3: 79.52071\n",
      "\ttrain_acc: 0.8669, test_acc: \u001b[31m0.870412818265579\u001b[0m, time: 82.33\n",
      "epoch: 159, loss: 80.28515, loss1: 0.64114, loss2_3: 79.64401\n",
      "\ttrain_acc: 0.8647, test_acc: \u001b[31m0.8611317108249623\u001b[0m, time: 82.45\n",
      "epoch: 160, loss: 80.23741, loss1: 0.63818, loss2_3: 79.59923\n",
      "\ttrain_acc: 0.8632, test_acc: \u001b[31m0.8568619519539765\u001b[0m, time: 82.49\n",
      "epoch: 161, loss: 80.16912, loss1: 0.64098, loss2_3: 79.52813\n",
      "\ttrain_acc: 0.8653, test_acc: \u001b[31m0.8597833659183353\u001b[0m, time: 82.43\n",
      "epoch: 162, loss: 80.19581, loss1: 0.63899, loss2_3: 79.55681\n",
      "\ttrain_acc: 0.8657, test_acc: \u001b[31m0.8617834108631655\u001b[0m, time: 82.47\n",
      "epoch: 163, loss: 80.09630, loss1: 0.63987, loss2_3: 79.45643\n",
      "\ttrain_acc: 0.8678, test_acc: \u001b[31m0.8678397267354323\u001b[0m, time: 82.42\n",
      "epoch: 164, loss: 79.94669, loss1: 0.64013, loss2_3: 79.30656\n",
      "\ttrain_acc: 0.8682, test_acc: \u001b[31m0.8657947369603811\u001b[0m, time: 82.35\n",
      "epoch: 165, loss: 80.13727, loss1: 0.64024, loss2_3: 79.49703\n",
      "\ttrain_acc: 0.8651, test_acc: \u001b[31m0.8607946245983056\u001b[0m, time: 82.36\n",
      "epoch: 166, loss: 80.00061, loss1: 0.63900, loss2_3: 79.36161\n",
      "\ttrain_acc: 0.8685, test_acc: \u001b[31m0.8699296613407043\u001b[0m, time: 82.32\n",
      "epoch: 167, loss: 80.06877, loss1: 0.64040, loss2_3: 79.42838\n",
      "\ttrain_acc: 0.8673, test_acc: \u001b[31m0.865244162790175\u001b[0m, time: 82.31\n",
      "epoch: 168, loss: 79.99389, loss1: 0.63750, loss2_3: 79.35639\n",
      "\ttrain_acc: 0.8682, test_acc: \u001b[31m0.8693903233780534\u001b[0m, time: 82.38\n",
      "epoch: 169, loss: 80.05725, loss1: 0.63737, loss2_3: 79.41988\n",
      "\ttrain_acc: 0.8681, test_acc: \u001b[31m0.8682217577923099\u001b[0m, time: 82.37\n",
      "epoch: 170, loss: 80.03578, loss1: 0.63770, loss2_3: 79.39808\n",
      "\ttrain_acc: 0.8658, test_acc: \u001b[31m0.8624126384862582\u001b[0m, time: 82.30\n",
      "epoch: 171, loss: 79.96447, loss1: 0.63979, loss2_3: 79.32469\n",
      "\ttrain_acc: 0.8686, test_acc: \u001b[31m0.8706263062091283\u001b[0m, time: 82.36\n",
      "epoch: 172, loss: 80.01663, loss1: 0.63956, loss2_3: 79.37707\n",
      "\ttrain_acc: 0.8651, test_acc: \u001b[31m0.859468752106789\u001b[0m, time: 82.31\n",
      "epoch: 173, loss: 80.02894, loss1: 0.63899, loss2_3: 79.38995\n",
      "\ttrain_acc: 0.8667, test_acc: \u001b[31m0.8630081574866851\u001b[0m, time: 82.22\n",
      "epoch: 174, loss: 79.87770, loss1: 0.63610, loss2_3: 79.24160\n",
      "\ttrain_acc: 0.8686, test_acc: \u001b[31m0.868176812962089\u001b[0m, time: 82.32\n",
      "epoch: 175, loss: 79.86480, loss1: 0.63871, loss2_3: 79.22609\n",
      "\ttrain_acc: 0.8683, test_acc: \u001b[31m0.8697049371895997\u001b[0m, time: 82.31\n",
      "epoch: 176, loss: 79.97372, loss1: 0.63882, loss2_3: 79.33490\n",
      "\ttrain_acc: 0.8655, test_acc: \u001b[31m0.8604912469943145\u001b[0m, time: 82.27\n",
      "epoch: 177, loss: 79.83217, loss1: 0.63838, loss2_3: 79.19379\n",
      "\ttrain_acc: 0.8680, test_acc: \u001b[31m0.8715813838513226\u001b[0m, time: 82.33\n",
      "epoch: 178, loss: 79.92667, loss1: 0.63920, loss2_3: 79.28747\n",
      "\ttrain_acc: 0.8644, test_acc: \u001b[31m0.860019326276995\u001b[0m, time: 82.30\n",
      "epoch: 179, loss: 79.87721, loss1: 0.63768, loss2_3: 79.23953\n",
      "\ttrain_acc: 0.8687, test_acc: \u001b[31m0.8675363491314412\u001b[0m, time: 82.27\n",
      "epoch: 180, loss: 79.69183, loss1: 0.63621, loss2_3: 79.05561\n",
      "\ttrain_acc: 0.8688, test_acc: \u001b[31m0.8661430593945931\u001b[0m, time: 82.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 181, loss: 79.69778, loss1: 0.63504, loss2_3: 79.06273\n",
      "\ttrain_acc: 0.8684, test_acc: \u001b[31m0.8671767904896739\u001b[0m, time: 82.37\n",
      "epoch: 182, loss: 79.99693, loss1: 0.63825, loss2_3: 79.35868\n",
      "\ttrain_acc: 0.8683, test_acc: \u001b[31m0.8641654868648734\u001b[0m, time: 82.28\n",
      "epoch: 183, loss: 79.80497, loss1: 0.63737, loss2_3: 79.16759\n",
      "\ttrain_acc: 0.8687, test_acc: \u001b[31m0.866086878356817\u001b[0m, time: 82.34\n",
      "epoch: 184, loss: 79.75655, loss1: 0.63564, loss2_3: 79.12091\n",
      "\ttrain_acc: 0.8683, test_acc: \u001b[31m0.8686824423020743\u001b[0m, time: 82.28\n",
      "epoch: 185, loss: 79.81234, loss1: 0.63814, loss2_3: 79.17420\n",
      "\ttrain_acc: 0.8674, test_acc: \u001b[31m0.864300321355536\u001b[0m, time: 82.23\n",
      "epoch: 186, loss: 79.69365, loss1: 0.63637, loss2_3: 79.05728\n",
      "\ttrain_acc: 0.8688, test_acc: \u001b[31m0.8665587990741365\u001b[0m, time: 82.31\n",
      "epoch: 187, loss: 79.64382, loss1: 0.63761, loss2_3: 79.00621\n",
      "\ttrain_acc: 0.8689, test_acc: \u001b[31m0.8697498820198206\u001b[0m, time: 82.30\n",
      "epoch: 188, loss: 79.65617, loss1: 0.63740, loss2_3: 79.01878\n",
      "\ttrain_acc: 0.8684, test_acc: \u001b[31m0.8650980920919571\u001b[0m, time: 82.24\n",
      "epoch: 189, loss: 79.70113, loss1: 0.63605, loss2_3: 79.06508\n",
      "\ttrain_acc: 0.8687, test_acc: \u001b[31m0.8703903458504686\u001b[0m, time: 82.30\n",
      "epoch: 190, loss: 79.54574, loss1: 0.63724, loss2_3: 78.90850\n",
      "\ttrain_acc: 0.8687, test_acc: \u001b[31m0.8660531697341514\u001b[0m, time: 83.51\n",
      "epoch: 191, loss: 79.53923, loss1: 0.63572, loss2_3: 78.90351\n",
      "\ttrain_acc: 0.8674, test_acc: \u001b[31m0.8614912694667296\u001b[0m, time: 84.41\n",
      "epoch: 192, loss: 79.56432, loss1: 0.63685, loss2_3: 78.92747\n",
      "\ttrain_acc: 0.8693, test_acc: \u001b[31m0.8667610508101306\u001b[0m, time: 82.38\n",
      "epoch: 193, loss: 79.59688, loss1: 0.63550, loss2_3: 78.96139\n",
      "\ttrain_acc: 0.8679, test_acc: \u001b[31m0.8706824872469044\u001b[0m, time: 82.36\n",
      "epoch: 194, loss: 79.61011, loss1: 0.63653, loss2_3: 78.97357\n",
      "\ttrain_acc: 0.8643, test_acc: \u001b[31m0.8582215330681588\u001b[0m, time: 82.32\n",
      "epoch: 195, loss: 79.41452, loss1: 0.63503, loss2_3: 78.77949\n",
      "\ttrain_acc: 0.8667, test_acc: \u001b[31m0.8614912694667296\u001b[0m, time: 82.45\n",
      "epoch: 196, loss: 79.57823, loss1: 0.63711, loss2_3: 78.94112\n",
      "\ttrain_acc: 0.8698, test_acc: \u001b[31m0.8675588215465516\u001b[0m, time: 82.45\n",
      "epoch: 197, loss: 79.40554, loss1: 0.63333, loss2_3: 78.77221\n",
      "\ttrain_acc: 0.8652, test_acc: \u001b[31m0.8588395244836963\u001b[0m, time: 82.35\n",
      "epoch: 198, loss: 79.49452, loss1: 0.63450, loss2_3: 78.86002\n",
      "\ttrain_acc: 0.8697, test_acc: \u001b[31m0.8675475853389963\u001b[0m, time: 82.44\n",
      "epoch: 199, loss: 79.51903, loss1: 0.63558, loss2_3: 78.88346\n",
      "\ttrain_acc: 0.8658, test_acc: \u001b[31m0.8586372727477022\u001b[0m, time: 88.60\n",
      "epoch: 200, loss: 79.36441, loss1: 0.63514, loss2_3: 78.72927\n",
      "\ttrain_acc: 0.8693, test_acc: \u001b[31m0.8668284680554619\u001b[0m, time: 82.35\n",
      "epoch: 201, loss: 79.40015, loss1: 0.63428, loss2_3: 78.76588\n",
      "\ttrain_acc: 0.8692, test_acc: \u001b[31m0.8669633025461246\u001b[0m, time: 82.39\n",
      "epoch: 202, loss: 79.45495, loss1: 0.63546, loss2_3: 78.81949\n",
      "\ttrain_acc: 0.8687, test_acc: \u001b[31m0.865289107620396\u001b[0m, time: 82.37\n",
      "epoch: 203, loss: 79.36699, loss1: 0.63615, loss2_3: 78.73084\n",
      "\ttrain_acc: 0.8688, test_acc: \u001b[31m0.8691880716420594\u001b[0m, time: 82.34\n",
      "epoch: 204, loss: 79.37213, loss1: 0.63409, loss2_3: 78.73804\n",
      "\ttrain_acc: 0.8669, test_acc: \u001b[31m0.8603002314658756\u001b[0m, time: 82.38\n",
      "epoch: 205, loss: 79.31952, loss1: 0.63563, loss2_3: 78.68389\n",
      "\ttrain_acc: 0.8699, test_acc: \u001b[31m0.8674015146407784\u001b[0m, time: 82.36\n",
      "epoch: 206, loss: 79.38264, loss1: 0.63393, loss2_3: 78.74871\n",
      "\ttrain_acc: 0.8694, test_acc: \u001b[31m0.8641991954875391\u001b[0m, time: 82.36\n",
      "epoch: 207, loss: 79.38762, loss1: 0.63385, loss2_3: 78.75377\n",
      "\ttrain_acc: 0.8698, test_acc: \u001b[31m0.8664014921683634\u001b[0m, time: 82.43\n",
      "epoch: 208, loss: 79.31536, loss1: 0.63646, loss2_3: 78.67890\n",
      "\ttrain_acc: 0.8664, test_acc: \u001b[31m0.8588170520685858\u001b[0m, time: 82.41\n",
      "epoch: 209, loss: 79.34069, loss1: 0.63597, loss2_3: 78.70472\n",
      "\ttrain_acc: 0.8689, test_acc: \u001b[31m0.8634126609586732\u001b[0m, time: 82.36\n",
      "epoch: 210, loss: 79.35867, loss1: 0.63356, loss2_3: 78.72511\n",
      "\ttrain_acc: 0.8695, test_acc: \u001b[31m0.8670869008292321\u001b[0m, time: 82.41\n",
      "epoch: 211, loss: 79.25667, loss1: 0.63340, loss2_3: 78.62328\n",
      "\ttrain_acc: 0.8680, test_acc: \u001b[31m0.865289107620396\u001b[0m, time: 82.45\n",
      "epoch: 212, loss: 79.33313, loss1: 0.63609, loss2_3: 78.69703\n",
      "\ttrain_acc: 0.8687, test_acc: \u001b[31m0.8624351109013686\u001b[0m, time: 82.44\n",
      "epoch: 213, loss: 79.22581, loss1: 0.63517, loss2_3: 78.59064\n",
      "\ttrain_acc: 0.8700, test_acc: \u001b[31m0.8709521562282299\u001b[0m, time: 82.49\n",
      "epoch: 214, loss: 79.25778, loss1: 0.63420, loss2_3: 78.62358\n",
      "\ttrain_acc: 0.8702, test_acc: \u001b[31m0.8690532371513967\u001b[0m, time: 82.43\n",
      "epoch: 215, loss: 79.17771, loss1: 0.63243, loss2_3: 78.54528\n",
      "\ttrain_acc: 0.8690, test_acc: \u001b[31m0.8646374075821929\u001b[0m, time: 82.27\n",
      "epoch: 216, loss: 79.26534, loss1: 0.63469, loss2_3: 78.63065\n",
      "\ttrain_acc: 0.8692, test_acc: \u001b[31m0.8644014472235331\u001b[0m, time: 82.36\n",
      "epoch: 217, loss: 79.21316, loss1: 0.63380, loss2_3: 78.57937\n",
      "\ttrain_acc: 0.8695, test_acc: \u001b[31m0.8696937009820446\u001b[0m, time: 82.32\n",
      "epoch: 218, loss: 79.21639, loss1: 0.63406, loss2_3: 78.58233\n",
      "\ttrain_acc: 0.8680, test_acc: \u001b[31m0.8618733005236072\u001b[0m, time: 82.30\n",
      "epoch: 219, loss: 79.24551, loss1: 0.63263, loss2_3: 78.61289\n",
      "\ttrain_acc: 0.8675, test_acc: \u001b[31m0.861165419447628\u001b[0m, time: 82.31\n",
      "epoch: 220, loss: 79.19439, loss1: 0.63195, loss2_3: 78.56244\n",
      "\ttrain_acc: 0.8692, test_acc: \u001b[31m0.8643789748084226\u001b[0m, time: 82.33\n",
      "epoch: 221, loss: 79.20098, loss1: 0.63220, loss2_3: 78.56878\n",
      "\ttrain_acc: 0.8706, test_acc: \u001b[31m0.866086878356817\u001b[0m, time: 82.31\n",
      "epoch: 222, loss: 79.06453, loss1: 0.63368, loss2_3: 78.43084\n",
      "\ttrain_acc: 0.8686, test_acc: \u001b[31m0.862805905750691\u001b[0m, time: 82.34\n",
      "epoch: 223, loss: 79.08708, loss1: 0.63396, loss2_3: 78.45311\n",
      "\ttrain_acc: 0.8698, test_acc: \u001b[31m0.8705813613789074\u001b[0m, time: 82.30\n",
      "epoch: 224, loss: 79.19726, loss1: 0.63196, loss2_3: 78.56530\n",
      "\ttrain_acc: 0.8641, test_acc: \u001b[31m0.8538618845367312\u001b[0m, time: 82.29\n",
      "epoch: 225, loss: 79.12004, loss1: 0.63573, loss2_3: 78.48430\n",
      "\ttrain_acc: 0.8703, test_acc: \u001b[31m0.8651767455448437\u001b[0m, time: 82.35\n",
      "epoch: 226, loss: 79.10654, loss1: 0.63494, loss2_3: 78.47160\n",
      "\ttrain_acc: 0.8704, test_acc: \u001b[31m0.866289130092811\u001b[0m, time: 82.39\n",
      "epoch: 227, loss: 79.01096, loss1: 0.63250, loss2_3: 78.37845\n",
      "\ttrain_acc: 0.8697, test_acc: \u001b[31m0.8643115575630913\u001b[0m, time: 82.41\n",
      "epoch: 228, loss: 78.98290, loss1: 0.63345, loss2_3: 78.34945\n",
      "\ttrain_acc: 0.8697, test_acc: \u001b[31m0.8641430144497629\u001b[0m, time: 82.50\n",
      "epoch: 229, loss: 79.02134, loss1: 0.63092, loss2_3: 78.39042\n",
      "\ttrain_acc: 0.8711, test_acc: \u001b[31m0.8684801905660802\u001b[0m, time: 82.44\n",
      "epoch: 230, loss: 79.05401, loss1: 0.63430, loss2_3: 78.41971\n",
      "\ttrain_acc: 0.8704, test_acc: \u001b[31m0.8674352232634441\u001b[0m, time: 82.37\n",
      "epoch: 231, loss: 78.99337, loss1: 0.63270, loss2_3: 78.36067\n",
      "\ttrain_acc: 0.8702, test_acc: \u001b[31m0.8666149801119126\u001b[0m, time: 82.49\n",
      "epoch: 232, loss: 79.01416, loss1: 0.63307, loss2_3: 78.38109\n",
      "\ttrain_acc: 0.8706, test_acc: \u001b[31m0.8688846940380682\u001b[0m, time: 82.45\n",
      "epoch: 233, loss: 79.04059, loss1: 0.63408, loss2_3: 78.40651\n",
      "\ttrain_acc: 0.8687, test_acc: \u001b[31m0.8685700802265219\u001b[0m, time: 82.40\n",
      "epoch: 234, loss: 78.91364, loss1: 0.63330, loss2_3: 78.28034\n",
      "\ttrain_acc: 0.8710, test_acc: \u001b[31m0.8648621317332974\u001b[0m, time: 82.47\n",
      "epoch: 235, loss: 78.86738, loss1: 0.63268, loss2_3: 78.23470\n",
      "\ttrain_acc: 0.8711, test_acc: \u001b[31m0.8647947144879661\u001b[0m, time: 82.44\n",
      "epoch: 236, loss: 78.88858, loss1: 0.63392, loss2_3: 78.25466\n",
      "\ttrain_acc: 0.8691, test_acc: \u001b[31m0.8625362367693656\u001b[0m, time: 82.41\n",
      "epoch: 237, loss: 78.87896, loss1: 0.63239, loss2_3: 78.24657\n",
      "\ttrain_acc: 0.8712, test_acc: \u001b[31m0.8678172543203218\u001b[0m, time: 82.48\n",
      "epoch: 238, loss: 78.90073, loss1: 0.63393, loss2_3: 78.26680\n",
      "\ttrain_acc: 0.8707, test_acc: \u001b[31m0.8709858648508956\u001b[0m, time: 82.47\n",
      "epoch: 239, loss: 78.76136, loss1: 0.63135, loss2_3: 78.13001\n",
      "\ttrain_acc: 0.8709, test_acc: \u001b[31m0.8684914267736353\u001b[0m, time: 82.38\n",
      "epoch: 240, loss: 78.83084, loss1: 0.63238, loss2_3: 78.19845\n",
      "\ttrain_acc: 0.8679, test_acc: \u001b[31m0.8593676262387919\u001b[0m, time: 82.39\n",
      "epoch: 241, loss: 78.83471, loss1: 0.63302, loss2_3: 78.20169\n",
      "\ttrain_acc: 0.8708, test_acc: \u001b[31m0.8686374974718533\u001b[0m, time: 82.32\n",
      "epoch: 242, loss: 78.88727, loss1: 0.63180, loss2_3: 78.25547\n",
      "\ttrain_acc: 0.8704, test_acc: \u001b[31m0.8703903458504686\u001b[0m, time: 82.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 243, loss: 78.90943, loss1: 0.63258, loss2_3: 78.27685\n",
      "\ttrain_acc: 0.8708, test_acc: \u001b[31m0.8656711386772736\u001b[0m, time: 82.43\n",
      "epoch: 244, loss: 78.77490, loss1: 0.63236, loss2_3: 78.14253\n",
      "\ttrain_acc: 0.8714, test_acc: \u001b[31m0.8688734578305131\u001b[0m, time: 82.38\n",
      "epoch: 245, loss: 78.72956, loss1: 0.63213, loss2_3: 78.09743\n",
      "\ttrain_acc: 0.8721, test_acc: \u001b[31m0.8676150025843278\u001b[0m, time: 82.34\n",
      "epoch: 246, loss: 78.74630, loss1: 0.63237, loss2_3: 78.11393\n",
      "\ttrain_acc: 0.8676, test_acc: \u001b[31m0.8602889952583204\u001b[0m, time: 82.39\n",
      "epoch: 247, loss: 78.78618, loss1: 0.63219, loss2_3: 78.15399\n",
      "\ttrain_acc: 0.8709, test_acc: \u001b[31m0.8663902559608081\u001b[0m, time: 82.36\n",
      "epoch: 248, loss: 78.80808, loss1: 0.63023, loss2_3: 78.17785\n",
      "\ttrain_acc: 0.8703, test_acc: \u001b[31m0.8684689543585249\u001b[0m, time: 82.31\n",
      "epoch: 249, loss: 78.63874, loss1: 0.63209, loss2_3: 78.00665\n",
      "\ttrain_acc: 0.8675, test_acc: \u001b[31m0.8593002089934605\u001b[0m, time: 82.37\n",
      "epoch: 250, loss: 78.66298, loss1: 0.63194, loss2_3: 78.03104\n",
      "\ttrain_acc: 0.8715, test_acc: \u001b[31m0.8703229286051372\u001b[0m, time: 82.33\n"
     ]
    }
   ],
   "source": [
    "for num_model in range(2):\n",
    "    net=newModel().to(device)\n",
    "    lr = 0.0001\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr,weight_decay=5e-4)\n",
    "    criterion = ContrastiveLoss()\n",
    "    criterion_model = nn.CrossEntropyLoss(reduction='sum')\n",
    "    best_acc=0\n",
    "    EPOCH=250\n",
    "    for epoch in range(EPOCH):\n",
    "        loss_ls=[]\n",
    "        loss1_ls=[]\n",
    "        loss2_3_ls=[]\n",
    "        t0=time.time()\n",
    "        net.train()\n",
    "        for seq1,seq2,label,label1,label2 in train_iter_cont:\n",
    "                output1=net(seq1)\n",
    "                output2=net(seq2)\n",
    "                output3=net.trainModel(seq1)\n",
    "                output4=net.trainModel(seq2)\n",
    "                loss1=criterion(output1, output2, label)\n",
    "                loss2=criterion_model(output3,label1)\n",
    "                loss3=criterion_model(output4,label2)\n",
    "                loss=loss1+loss2+loss3\n",
    "    #             print(loss)\n",
    "                optimizer.zero_grad() \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_ls.append(loss.item())\n",
    "                loss1_ls.append(loss1.item())\n",
    "                loss2_3_ls.append((loss2+loss3).item())\n",
    "\n",
    "\n",
    "        net.eval() \n",
    "        with torch.no_grad(): \n",
    "            train_acc=evaluate_accuracy(train_iter,net)\n",
    "            test_acc=evaluate_accuracy(test_iter,net)\n",
    "        results=f\"epoch: {epoch+1}, loss: {np.mean(loss_ls):.5f}, loss1: {np.mean(loss1_ls):.5f}, loss2_3: {np.mean(loss2_3_ls):.5f}\\n\"\n",
    "        results+=f'\\ttrain_acc: {train_acc:.4f}, test_acc: {colored(test_acc,\"red\")}, time: {time.time()-t0:.2f}'\n",
    "        print(results)\n",
    "#         to_log(results)\n",
    "        if test_acc>best_acc:\n",
    "            best_acc=test_acc\n",
    "#             torch.save({\"best_acc\":best_acc,\"model\":net.state_dict()},f'./Model/{num_model}.pl')\n",
    "            print(f\"best_acc: {best_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T15:40:59.668902Z",
     "start_time": "2021-10-01T15:40:59.646033Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T15:40:59.673299Z",
     "start_time": "2021-10-01T15:40:59.670223Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs.argmax(dim=1):\n",
    "            y_pred.append(int(_))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T15:40:59.678611Z",
     "start_time": "2021-10-01T15:40:59.674351Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred_prob(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs:\n",
    "            y_pred.append(list(map(float, _)))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T15:41:07.478416Z",
     "start_time": "2021-10-01T15:40:59.679572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8703229286051372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.86     44509\n",
      "           1       0.84      0.91      0.88     44489\n",
      "\n",
      "    accuracy                           0.87     88998\n",
      "   macro avg       0.87      0.87      0.87     88998\n",
      "weighted avg       0.87      0.87      0.87     88998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate_accuracy(test_iter,net)\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "# prediction\n",
    "y_pred = pred(test_iter, net)\n",
    "print(classification_report(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-01T15:41:14.413881Z",
     "start_time": "2021-10-01T15:41:07.479521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf auc : 0.9417901527892052\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AUC\n",
    "probs = np.array(pred_prob(test_iter, net))[:, 1]\n",
    "\n",
    "rf_auc = roc_auc_score(test_label, probs)\n",
    "print('rf auc : {}'.format(rf_auc))\n",
    "# plot the roc curve for the model81\n",
    "rf_fpr, rf_tpr, _ = roc_curve(test_label, probs)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='RF AUC = {:.4f}'.format(rf_auc), color='orange')\n",
    "plt.title('ROC curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "cf_matrix = confusion_matrix(test_label, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=',.0f')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
