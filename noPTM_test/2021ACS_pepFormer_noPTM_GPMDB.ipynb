{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T15:20:50.203578Z",
     "start_time": "2021-10-06T15:20:49.290659Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T15:20:51.303981Z",
     "start_time": "2021-10-06T15:20:50.205076Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import time\n",
    "import pickle\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T15:20:51.311247Z",
     "start_time": "2021-10-06T15:20:51.305364Z"
    }
   },
   "outputs": [],
   "source": [
    "def genData(file,max_len):\n",
    "    aa_dict={'A':1,'R':2,'N':3,'D':4,'C':5,'Q':6,'E':7,'G':8,'H':9,'I':10,\n",
    "             'L':11,'K':12,'M':13,'F':14,'P':15,'O':16,'S':17,'U':18,'T':19,\n",
    "             'W':20,'Y':21,'V':22,'X':23}\n",
    "    with open(file, 'r') as inf:\n",
    "        lines = inf.read().splitlines()\n",
    "        \n",
    "    long_pep_counter=0\n",
    "    pep_codes=[]\n",
    "    labels=[]\n",
    "    for pep in lines:\n",
    "        pep,label=pep.split(\",\")\n",
    "        labels.append(int(label))\n",
    "        if not len(pep) > max_len:\n",
    "            current_pep=[]\n",
    "            for aa in pep:\n",
    "                current_pep.append(aa_dict[aa])\n",
    "            pep_codes.append(torch.tensor(current_pep))\n",
    "        else:\n",
    "            long_pep_counter += 1\n",
    "    print(\"length > 81:\",long_pep_counter)\n",
    "    data = rnn_utils.pad_sequence(pep_codes,batch_first=True)\n",
    "    return data,torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T15:20:52.292093Z",
     "start_time": "2021-10-06T15:20:52.287938Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        acc_sum += (outputs.argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "def to_log(log):\n",
    "    with open(\"../compareModel/2021ACS_PepFormer/modelLog.log\",\"a+\") as f:\n",
    "        f.write(log+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T15:20:54.189088Z",
     "start_time": "2021-10-06T15:20:54.182937Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    seq1_ls=[]\n",
    "    seq2_ls=[]\n",
    "    label1_ls=[]\n",
    "    label2_ls=[]\n",
    "    label_ls=[]\n",
    "    batch_size=len(batch)\n",
    "    for i in range(int(batch_size/2)):\n",
    "        seq1,label1=batch[i][0],batch[i][1]\n",
    "        seq2,label2=batch[i+int(batch_size/2)][0],batch[i+int(batch_size/2)][1]\n",
    "        label1_ls.append(label1.unsqueeze(0))\n",
    "        label2_ls.append(label2.unsqueeze(0))\n",
    "        label=(label1^label2)\n",
    "        seq1_ls.append(seq1.unsqueeze(0))\n",
    "        seq2_ls.append(seq2.unsqueeze(0))\n",
    "        label_ls.append(label.unsqueeze(0))\n",
    "    seq1=torch.cat(seq1_ls).to(device)\n",
    "    seq2=torch.cat(seq2_ls).to(device)\n",
    "    label=torch.cat(label_ls).to(device)\n",
    "    label1=torch.cat(label1_ls).to(device)\n",
    "    label2=torch.cat(label2_ls).to(device)\n",
    "    return seq1,seq2,label,label1,label2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Data X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T15:24:56.411693Z",
     "start_time": "2021-10-06T15:24:54.951357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length > 81: 0\n",
      "torch.Size([90000, 79]) torch.Size([90000])\n"
     ]
    }
   ],
   "source": [
    "data,label=genData(\"../compareModel/2021ACS_PepFormer/dataset/Homo_sapiens.csv\",81)\n",
    "print(data.shape,label.shape)\n",
    "\n",
    "train_data,train_label=data[:70000],label[:70000]\n",
    "test_data,test_label=data[70000:],label[70000:]\n",
    "\n",
    "train_dataset = Data.TensorDataset(train_data, train_label)\n",
    "test_dataset = Data.TensorDataset(test_data, test_label)\n",
    "\n",
    "batch_size=256\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_iter_cont = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                                                  shuffle=True, collate_fn=collate)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T15:25:01.111422Z",
     "start_time": "2021-10-06T15:25:01.108260Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T15:25:19.760496Z",
     "start_time": "2021-10-06T15:25:19.748826Z"
    }
   },
   "outputs": [],
   "source": [
    "class newModel(nn.Module):\n",
    "    def __init__(self, vocab_size=24):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 25\n",
    "        self.batch_size = 256\n",
    "        self.emb_dim = 512\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, self.emb_dim, padding_idx=0)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.gru = nn.GRU(self.emb_dim, self.hidden_dim, num_layers=2, \n",
    "                               bidirectional=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.block1=nn.Sequential(nn.Linear(4050,1024),\n",
    "                                            nn.BatchNorm1d(1024),\n",
    "                                            nn.LeakyReLU(),\n",
    "                                            nn.Linear(1024,256),\n",
    "                                 )\n",
    "\n",
    "        self.block2=nn.Sequential(\n",
    "                                               nn.BatchNorm1d(256),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(256,128),\n",
    "                                               nn.BatchNorm1d(128),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(128,64),\n",
    "                                               nn.BatchNorm1d(64),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(64,2)\n",
    "                                            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.embedding(x)\n",
    "        output=self.transformer_encoder(x).permute(1, 0, 2)\n",
    "        output,hn=self.gru(output)\n",
    "        output=output.permute(1,0,2)\n",
    "        hn=hn.permute(1,0,2)\n",
    "        output=output.reshape(output.shape[0],-1)\n",
    "        \n",
    "        hn=hn.reshape(output.shape[0],-1)\n",
    "        output=torch.cat([output,hn],1)\n",
    "#         print(output.shape, hn.shape)\n",
    "        return self.block1(output)\n",
    "\n",
    "    def trainModel(self, x):\n",
    "        with torch.no_grad():\n",
    "            output=self.forward(x)\n",
    "        return self.block2(output)\n",
    "\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # euclidean_distance: [128]\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +     # calmp夹断用法\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))     \n",
    "        \n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T17:56:58.311504Z",
     "start_time": "2021-10-06T15:26:01.717624Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 179.49525, loss1: 2.51021, loss2_3: 176.98504\n",
      "\ttrain_acc: 0.5602, test_acc: \u001b[31m0.557\u001b[0m, time: 35.93\n",
      "best_acc: 0.557\n",
      "epoch: 2, loss: 172.71200, loss1: 1.02709, loss2_3: 171.68491\n",
      "\ttrain_acc: 0.6019, test_acc: \u001b[31m0.60275\u001b[0m, time: 36.14\n",
      "best_acc: 0.60275\n",
      "epoch: 3, loss: 152.66300, loss1: 1.00927, loss2_3: 151.65373\n",
      "\ttrain_acc: 0.7281, test_acc: \u001b[31m0.7263\u001b[0m, time: 36.35\n",
      "best_acc: 0.7263\n",
      "epoch: 4, loss: 136.49091, loss1: 0.97324, loss2_3: 135.51767\n",
      "\ttrain_acc: 0.7323, test_acc: \u001b[31m0.7325\u001b[0m, time: 36.31\n",
      "best_acc: 0.7325\n",
      "epoch: 5, loss: 132.55767, loss1: 0.95647, loss2_3: 131.60120\n",
      "\ttrain_acc: 0.7468, test_acc: \u001b[31m0.74935\u001b[0m, time: 36.56\n",
      "best_acc: 0.74935\n",
      "epoch: 6, loss: 130.13147, loss1: 0.94320, loss2_3: 129.18827\n",
      "\ttrain_acc: 0.7478, test_acc: \u001b[31m0.7438\u001b[0m, time: 36.41\n",
      "epoch: 7, loss: 129.67819, loss1: 0.94165, loss2_3: 128.73654\n",
      "\ttrain_acc: 0.7601, test_acc: \u001b[31m0.75915\u001b[0m, time: 36.60\n",
      "best_acc: 0.75915\n",
      "epoch: 8, loss: 127.22454, loss1: 0.93126, loss2_3: 126.29327\n",
      "\ttrain_acc: 0.7729, test_acc: \u001b[31m0.77245\u001b[0m, time: 36.42\n",
      "best_acc: 0.77245\n",
      "epoch: 9, loss: 127.69206, loss1: 0.92798, loss2_3: 126.76409\n",
      "\ttrain_acc: 0.7560, test_acc: \u001b[31m0.75625\u001b[0m, time: 36.48\n",
      "epoch: 10, loss: 126.61606, loss1: 0.92808, loss2_3: 125.68799\n",
      "\ttrain_acc: 0.7760, test_acc: \u001b[31m0.77565\u001b[0m, time: 36.42\n",
      "best_acc: 0.77565\n",
      "epoch: 11, loss: 125.33509, loss1: 0.91929, loss2_3: 124.41580\n",
      "\ttrain_acc: 0.7654, test_acc: \u001b[31m0.76245\u001b[0m, time: 36.48\n",
      "epoch: 12, loss: 125.12422, loss1: 0.91297, loss2_3: 124.21125\n",
      "\ttrain_acc: 0.7627, test_acc: \u001b[31m0.7615\u001b[0m, time: 36.41\n",
      "epoch: 13, loss: 124.35061, loss1: 0.90831, loss2_3: 123.44230\n",
      "\ttrain_acc: 0.7790, test_acc: \u001b[31m0.77815\u001b[0m, time: 37.01\n",
      "best_acc: 0.77815\n",
      "epoch: 14, loss: 124.71762, loss1: 0.91604, loss2_3: 123.80157\n",
      "\ttrain_acc: 0.7810, test_acc: \u001b[31m0.7798\u001b[0m, time: 36.82\n",
      "best_acc: 0.7798\n",
      "epoch: 15, loss: 123.69160, loss1: 0.90205, loss2_3: 122.78955\n",
      "\ttrain_acc: 0.7744, test_acc: \u001b[31m0.775\u001b[0m, time: 36.46\n",
      "epoch: 16, loss: 123.52740, loss1: 0.90727, loss2_3: 122.62013\n",
      "\ttrain_acc: 0.7582, test_acc: \u001b[31m0.7575\u001b[0m, time: 36.42\n",
      "epoch: 17, loss: 122.91598, loss1: 0.90316, loss2_3: 122.01282\n",
      "\ttrain_acc: 0.7670, test_acc: \u001b[31m0.76915\u001b[0m, time: 36.49\n",
      "epoch: 18, loss: 122.66876, loss1: 0.89386, loss2_3: 121.77489\n",
      "\ttrain_acc: 0.7762, test_acc: \u001b[31m0.77905\u001b[0m, time: 36.41\n",
      "epoch: 19, loss: 121.90763, loss1: 0.89432, loss2_3: 121.01331\n",
      "\ttrain_acc: 0.7810, test_acc: \u001b[31m0.78135\u001b[0m, time: 36.47\n",
      "best_acc: 0.78135\n",
      "epoch: 20, loss: 122.18043, loss1: 0.89180, loss2_3: 121.28862\n",
      "\ttrain_acc: 0.7897, test_acc: \u001b[31m0.78785\u001b[0m, time: 36.38\n",
      "best_acc: 0.78785\n",
      "epoch: 21, loss: 121.63736, loss1: 0.89350, loss2_3: 120.74386\n",
      "\ttrain_acc: 0.7803, test_acc: \u001b[31m0.7809\u001b[0m, time: 36.45\n",
      "epoch: 22, loss: 121.38595, loss1: 0.89446, loss2_3: 120.49149\n",
      "\ttrain_acc: 0.7839, test_acc: \u001b[31m0.7833\u001b[0m, time: 36.35\n",
      "epoch: 23, loss: 120.73005, loss1: 0.87634, loss2_3: 119.85371\n",
      "\ttrain_acc: 0.7818, test_acc: \u001b[31m0.7818\u001b[0m, time: 36.43\n",
      "epoch: 24, loss: 120.84664, loss1: 0.88013, loss2_3: 119.96651\n",
      "\ttrain_acc: 0.7886, test_acc: \u001b[31m0.78675\u001b[0m, time: 36.34\n",
      "epoch: 25, loss: 120.79913, loss1: 0.87710, loss2_3: 119.92203\n",
      "\ttrain_acc: 0.7815, test_acc: \u001b[31m0.7814\u001b[0m, time: 36.42\n",
      "epoch: 26, loss: 120.52609, loss1: 0.87787, loss2_3: 119.64822\n",
      "\ttrain_acc: 0.7913, test_acc: \u001b[31m0.7888\u001b[0m, time: 36.35\n",
      "best_acc: 0.7888\n",
      "epoch: 27, loss: 119.74900, loss1: 0.87939, loss2_3: 118.86961\n",
      "\ttrain_acc: 0.7899, test_acc: \u001b[31m0.7897\u001b[0m, time: 36.40\n",
      "best_acc: 0.7897\n",
      "epoch: 28, loss: 120.42931, loss1: 0.88461, loss2_3: 119.54470\n",
      "\ttrain_acc: 0.7854, test_acc: \u001b[31m0.7844\u001b[0m, time: 36.34\n",
      "epoch: 29, loss: 120.18577, loss1: 0.87493, loss2_3: 119.31084\n",
      "\ttrain_acc: 0.7909, test_acc: \u001b[31m0.78905\u001b[0m, time: 36.40\n",
      "epoch: 30, loss: 120.04437, loss1: 0.87895, loss2_3: 119.16542\n",
      "\ttrain_acc: 0.7945, test_acc: \u001b[31m0.79265\u001b[0m, time: 36.35\n",
      "best_acc: 0.79265\n",
      "epoch: 31, loss: 119.44368, loss1: 0.87927, loss2_3: 118.56441\n",
      "\ttrain_acc: 0.7905, test_acc: \u001b[31m0.78795\u001b[0m, time: 36.45\n",
      "epoch: 32, loss: 119.41783, loss1: 0.87354, loss2_3: 118.54430\n",
      "\ttrain_acc: 0.7915, test_acc: \u001b[31m0.7891\u001b[0m, time: 36.33\n",
      "epoch: 33, loss: 119.51755, loss1: 0.87140, loss2_3: 118.64616\n",
      "\ttrain_acc: 0.7917, test_acc: \u001b[31m0.791\u001b[0m, time: 36.40\n",
      "epoch: 34, loss: 118.78758, loss1: 0.86406, loss2_3: 117.92352\n",
      "\ttrain_acc: 0.7918, test_acc: \u001b[31m0.78935\u001b[0m, time: 36.45\n",
      "epoch: 35, loss: 119.05546, loss1: 0.87069, loss2_3: 118.18477\n",
      "\ttrain_acc: 0.7955, test_acc: \u001b[31m0.79225\u001b[0m, time: 36.55\n",
      "epoch: 36, loss: 118.62941, loss1: 0.86673, loss2_3: 117.76268\n",
      "\ttrain_acc: 0.7871, test_acc: \u001b[31m0.7852\u001b[0m, time: 36.44\n",
      "epoch: 37, loss: 118.79935, loss1: 0.86861, loss2_3: 117.93075\n",
      "\ttrain_acc: 0.7951, test_acc: \u001b[31m0.7931\u001b[0m, time: 36.40\n",
      "best_acc: 0.7931\n",
      "epoch: 38, loss: 118.48600, loss1: 0.86623, loss2_3: 117.61977\n",
      "\ttrain_acc: 0.7894, test_acc: \u001b[31m0.7871\u001b[0m, time: 36.26\n",
      "epoch: 39, loss: 118.67899, loss1: 0.86671, loss2_3: 117.81228\n",
      "\ttrain_acc: 0.7909, test_acc: \u001b[31m0.7907\u001b[0m, time: 36.25\n",
      "epoch: 40, loss: 118.47077, loss1: 0.86905, loss2_3: 117.60171\n",
      "\ttrain_acc: 0.7969, test_acc: \u001b[31m0.7949\u001b[0m, time: 36.25\n",
      "best_acc: 0.7949\n",
      "epoch: 41, loss: 117.99784, loss1: 0.86379, loss2_3: 117.13406\n",
      "\ttrain_acc: 0.7921, test_acc: \u001b[31m0.78965\u001b[0m, time: 36.25\n",
      "epoch: 42, loss: 118.06094, loss1: 0.86195, loss2_3: 117.19900\n",
      "\ttrain_acc: 0.7939, test_acc: \u001b[31m0.79335\u001b[0m, time: 36.24\n",
      "epoch: 43, loss: 117.87392, loss1: 0.86345, loss2_3: 117.01047\n",
      "\ttrain_acc: 0.7903, test_acc: \u001b[31m0.7884\u001b[0m, time: 36.24\n",
      "epoch: 44, loss: 117.68288, loss1: 0.86275, loss2_3: 116.82012\n",
      "\ttrain_acc: 0.7928, test_acc: \u001b[31m0.79085\u001b[0m, time: 36.25\n",
      "epoch: 45, loss: 117.75725, loss1: 0.85915, loss2_3: 116.89810\n",
      "\ttrain_acc: 0.7899, test_acc: \u001b[31m0.7893\u001b[0m, time: 36.26\n",
      "epoch: 46, loss: 117.33215, loss1: 0.86153, loss2_3: 116.47062\n",
      "\ttrain_acc: 0.7959, test_acc: \u001b[31m0.7919\u001b[0m, time: 36.26\n",
      "epoch: 47, loss: 117.52663, loss1: 0.85649, loss2_3: 116.67013\n",
      "\ttrain_acc: 0.7911, test_acc: \u001b[31m0.7887\u001b[0m, time: 36.27\n",
      "epoch: 48, loss: 117.57175, loss1: 0.85953, loss2_3: 116.71222\n",
      "\ttrain_acc: 0.7979, test_acc: \u001b[31m0.79465\u001b[0m, time: 36.28\n",
      "epoch: 49, loss: 117.30631, loss1: 0.85127, loss2_3: 116.45503\n",
      "\ttrain_acc: 0.7974, test_acc: \u001b[31m0.7944\u001b[0m, time: 36.29\n",
      "epoch: 50, loss: 117.27303, loss1: 0.85768, loss2_3: 116.41535\n",
      "\ttrain_acc: 0.7954, test_acc: \u001b[31m0.79225\u001b[0m, time: 36.25\n",
      "epoch: 51, loss: 117.35439, loss1: 0.85842, loss2_3: 116.49597\n",
      "\ttrain_acc: 0.7960, test_acc: \u001b[31m0.7924\u001b[0m, time: 36.26\n",
      "epoch: 52, loss: 116.64379, loss1: 0.85330, loss2_3: 115.79050\n",
      "\ttrain_acc: 0.7933, test_acc: \u001b[31m0.7908\u001b[0m, time: 36.22\n",
      "epoch: 53, loss: 117.21179, loss1: 0.85409, loss2_3: 116.35770\n",
      "\ttrain_acc: 0.7990, test_acc: \u001b[31m0.79545\u001b[0m, time: 36.23\n",
      "best_acc: 0.79545\n",
      "epoch: 54, loss: 116.93297, loss1: 0.85565, loss2_3: 116.07732\n",
      "\ttrain_acc: 0.8015, test_acc: \u001b[31m0.7962\u001b[0m, time: 36.21\n",
      "best_acc: 0.7962\n",
      "epoch: 55, loss: 116.77581, loss1: 0.85468, loss2_3: 115.92114\n",
      "\ttrain_acc: 0.7985, test_acc: \u001b[31m0.7947\u001b[0m, time: 36.25\n",
      "epoch: 56, loss: 116.46087, loss1: 0.85057, loss2_3: 115.61030\n",
      "\ttrain_acc: 0.7898, test_acc: \u001b[31m0.78765\u001b[0m, time: 36.24\n",
      "epoch: 57, loss: 116.21038, loss1: 0.85504, loss2_3: 115.35534\n",
      "\ttrain_acc: 0.7991, test_acc: \u001b[31m0.7961\u001b[0m, time: 36.25\n",
      "epoch: 58, loss: 116.26030, loss1: 0.85572, loss2_3: 115.40458\n",
      "\ttrain_acc: 0.8013, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.24\n",
      "best_acc: 0.79765\n",
      "epoch: 59, loss: 116.27732, loss1: 0.85217, loss2_3: 115.42516\n",
      "\ttrain_acc: 0.7988, test_acc: \u001b[31m0.79585\u001b[0m, time: 36.24\n",
      "epoch: 60, loss: 116.40169, loss1: 0.85082, loss2_3: 115.55086\n",
      "\ttrain_acc: 0.7979, test_acc: \u001b[31m0.79625\u001b[0m, time: 36.26\n",
      "epoch: 61, loss: 116.11699, loss1: 0.84667, loss2_3: 115.27032\n",
      "\ttrain_acc: 0.7982, test_acc: \u001b[31m0.794\u001b[0m, time: 36.25\n",
      "epoch: 62, loss: 116.28278, loss1: 0.84773, loss2_3: 115.43505\n",
      "\ttrain_acc: 0.7986, test_acc: \u001b[31m0.79715\u001b[0m, time: 36.32\n",
      "epoch: 63, loss: 116.20360, loss1: 0.84917, loss2_3: 115.35443\n",
      "\ttrain_acc: 0.7991, test_acc: \u001b[31m0.7962\u001b[0m, time: 36.23\n",
      "epoch: 64, loss: 116.01006, loss1: 0.85217, loss2_3: 115.15788\n",
      "\ttrain_acc: 0.7975, test_acc: \u001b[31m0.79565\u001b[0m, time: 36.24\n",
      "epoch: 65, loss: 115.76398, loss1: 0.85444, loss2_3: 114.90954\n",
      "\ttrain_acc: 0.8011, test_acc: \u001b[31m0.7975\u001b[0m, time: 36.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66, loss: 116.40796, loss1: 0.85105, loss2_3: 115.55692\n",
      "\ttrain_acc: 0.7987, test_acc: \u001b[31m0.7944\u001b[0m, time: 36.22\n",
      "epoch: 67, loss: 115.68871, loss1: 0.84702, loss2_3: 114.84169\n",
      "\ttrain_acc: 0.7998, test_acc: \u001b[31m0.79515\u001b[0m, time: 36.25\n",
      "epoch: 68, loss: 116.25465, loss1: 0.84674, loss2_3: 115.40792\n",
      "\ttrain_acc: 0.7981, test_acc: \u001b[31m0.79605\u001b[0m, time: 36.32\n",
      "epoch: 69, loss: 116.06147, loss1: 0.84184, loss2_3: 115.21963\n",
      "\ttrain_acc: 0.7998, test_acc: \u001b[31m0.79735\u001b[0m, time: 36.22\n",
      "epoch: 70, loss: 115.78343, loss1: 0.84503, loss2_3: 114.93840\n",
      "\ttrain_acc: 0.8002, test_acc: \u001b[31m0.79715\u001b[0m, time: 36.27\n",
      "epoch: 71, loss: 115.59026, loss1: 0.84468, loss2_3: 114.74558\n",
      "\ttrain_acc: 0.7940, test_acc: \u001b[31m0.7913\u001b[0m, time: 36.22\n",
      "epoch: 72, loss: 115.07238, loss1: 0.84143, loss2_3: 114.23094\n",
      "\ttrain_acc: 0.8014, test_acc: \u001b[31m0.79675\u001b[0m, time: 36.26\n",
      "epoch: 73, loss: 115.54565, loss1: 0.84630, loss2_3: 114.69936\n",
      "\ttrain_acc: 0.8002, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.23\n",
      "best_acc: 0.7987\n",
      "epoch: 74, loss: 115.21403, loss1: 0.84043, loss2_3: 114.37360\n",
      "\ttrain_acc: 0.8013, test_acc: \u001b[31m0.7985\u001b[0m, time: 36.24\n",
      "epoch: 75, loss: 114.96926, loss1: 0.84557, loss2_3: 114.12369\n",
      "\ttrain_acc: 0.7986, test_acc: \u001b[31m0.7947\u001b[0m, time: 36.24\n",
      "epoch: 76, loss: 114.86660, loss1: 0.83736, loss2_3: 114.02924\n",
      "\ttrain_acc: 0.8017, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.24\n",
      "best_acc: 0.79885\n",
      "epoch: 77, loss: 115.51032, loss1: 0.84655, loss2_3: 114.66377\n",
      "\ttrain_acc: 0.8009, test_acc: \u001b[31m0.7973\u001b[0m, time: 36.26\n",
      "epoch: 78, loss: 115.22808, loss1: 0.84136, loss2_3: 114.38672\n",
      "\ttrain_acc: 0.7990, test_acc: \u001b[31m0.7954\u001b[0m, time: 36.24\n",
      "epoch: 79, loss: 114.84066, loss1: 0.83895, loss2_3: 114.00171\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.23\n",
      "best_acc: 0.79955\n",
      "epoch: 80, loss: 114.34988, loss1: 0.83714, loss2_3: 113.51274\n",
      "\ttrain_acc: 0.8036, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.22\n",
      "epoch: 81, loss: 114.58192, loss1: 0.84072, loss2_3: 113.74120\n",
      "\ttrain_acc: 0.8009, test_acc: \u001b[31m0.7962\u001b[0m, time: 36.21\n",
      "epoch: 82, loss: 114.69334, loss1: 0.83367, loss2_3: 113.85967\n",
      "\ttrain_acc: 0.8011, test_acc: \u001b[31m0.7967\u001b[0m, time: 36.21\n",
      "epoch: 83, loss: 114.70296, loss1: 0.83751, loss2_3: 113.86544\n",
      "\ttrain_acc: 0.8011, test_acc: \u001b[31m0.7984\u001b[0m, time: 36.19\n",
      "epoch: 84, loss: 114.71689, loss1: 0.83913, loss2_3: 113.87776\n",
      "\ttrain_acc: 0.8014, test_acc: \u001b[31m0.797\u001b[0m, time: 36.22\n",
      "epoch: 85, loss: 114.26520, loss1: 0.83741, loss2_3: 113.42779\n",
      "\ttrain_acc: 0.8046, test_acc: \u001b[31m0.7984\u001b[0m, time: 36.20\n",
      "epoch: 86, loss: 114.22898, loss1: 0.83226, loss2_3: 113.39672\n",
      "\ttrain_acc: 0.8029, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.19\n",
      "best_acc: 0.8006\n",
      "epoch: 87, loss: 114.29433, loss1: 0.84471, loss2_3: 113.44962\n",
      "\ttrain_acc: 0.8032, test_acc: \u001b[31m0.79725\u001b[0m, time: 36.21\n",
      "epoch: 88, loss: 114.18340, loss1: 0.83902, loss2_3: 113.34438\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.802\u001b[0m, time: 36.19\n",
      "best_acc: 0.802\n",
      "epoch: 89, loss: 114.15417, loss1: 0.84413, loss2_3: 113.31003\n",
      "\ttrain_acc: 0.8034, test_acc: \u001b[31m0.7987\u001b[0m, time: 36.21\n",
      "epoch: 90, loss: 114.13580, loss1: 0.83726, loss2_3: 113.29854\n",
      "\ttrain_acc: 0.8049, test_acc: \u001b[31m0.80025\u001b[0m, time: 36.19\n",
      "epoch: 91, loss: 113.94732, loss1: 0.83285, loss2_3: 113.11447\n",
      "\ttrain_acc: 0.8050, test_acc: \u001b[31m0.80085\u001b[0m, time: 36.20\n",
      "epoch: 92, loss: 113.98538, loss1: 0.84062, loss2_3: 113.14476\n",
      "\ttrain_acc: 0.8047, test_acc: \u001b[31m0.8009\u001b[0m, time: 36.27\n",
      "epoch: 93, loss: 114.09432, loss1: 0.83805, loss2_3: 113.25626\n",
      "\ttrain_acc: 0.7993, test_acc: \u001b[31m0.79545\u001b[0m, time: 36.21\n",
      "epoch: 94, loss: 113.92691, loss1: 0.83441, loss2_3: 113.09250\n",
      "\ttrain_acc: 0.8027, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.23\n",
      "epoch: 95, loss: 113.57494, loss1: 0.82975, loss2_3: 112.74519\n",
      "\ttrain_acc: 0.8009, test_acc: \u001b[31m0.795\u001b[0m, time: 36.24\n",
      "epoch: 96, loss: 113.53230, loss1: 0.83131, loss2_3: 112.70100\n",
      "\ttrain_acc: 0.8040, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.24\n",
      "epoch: 97, loss: 113.73648, loss1: 0.82944, loss2_3: 112.90704\n",
      "\ttrain_acc: 0.8007, test_acc: \u001b[31m0.79515\u001b[0m, time: 36.23\n",
      "epoch: 98, loss: 113.63031, loss1: 0.83179, loss2_3: 112.79852\n",
      "\ttrain_acc: 0.8069, test_acc: \u001b[31m0.80085\u001b[0m, time: 36.31\n",
      "epoch: 99, loss: 113.56442, loss1: 0.82850, loss2_3: 112.73592\n",
      "\ttrain_acc: 0.8014, test_acc: \u001b[31m0.79605\u001b[0m, time: 36.25\n",
      "epoch: 100, loss: 113.71404, loss1: 0.82883, loss2_3: 112.88521\n",
      "\ttrain_acc: 0.8024, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.22\n",
      "epoch: 101, loss: 113.60302, loss1: 0.83546, loss2_3: 112.76756\n",
      "\ttrain_acc: 0.8075, test_acc: \u001b[31m0.8005\u001b[0m, time: 36.22\n",
      "epoch: 102, loss: 113.38581, loss1: 0.83187, loss2_3: 112.55394\n",
      "\ttrain_acc: 0.8048, test_acc: \u001b[31m0.7991\u001b[0m, time: 36.23\n",
      "epoch: 103, loss: 113.40392, loss1: 0.83350, loss2_3: 112.57042\n",
      "\ttrain_acc: 0.8004, test_acc: \u001b[31m0.7947\u001b[0m, time: 36.21\n",
      "epoch: 104, loss: 113.20317, loss1: 0.82746, loss2_3: 112.37571\n",
      "\ttrain_acc: 0.8026, test_acc: \u001b[31m0.7976\u001b[0m, time: 36.23\n",
      "epoch: 105, loss: 113.30190, loss1: 0.82723, loss2_3: 112.47467\n",
      "\ttrain_acc: 0.8047, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.21\n",
      "epoch: 106, loss: 113.20354, loss1: 0.82751, loss2_3: 112.37603\n",
      "\ttrain_acc: 0.8063, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.22\n",
      "epoch: 107, loss: 113.12519, loss1: 0.82853, loss2_3: 112.29666\n",
      "\ttrain_acc: 0.8056, test_acc: \u001b[31m0.7992\u001b[0m, time: 36.20\n",
      "epoch: 108, loss: 112.91293, loss1: 0.82585, loss2_3: 112.08708\n",
      "\ttrain_acc: 0.8054, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.20\n",
      "epoch: 109, loss: 113.15825, loss1: 0.82845, loss2_3: 112.32980\n",
      "\ttrain_acc: 0.8066, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.23\n",
      "epoch: 110, loss: 112.98466, loss1: 0.83264, loss2_3: 112.15202\n",
      "\ttrain_acc: 0.8045, test_acc: \u001b[31m0.7993\u001b[0m, time: 36.21\n",
      "epoch: 111, loss: 113.04807, loss1: 0.82550, loss2_3: 112.22257\n",
      "\ttrain_acc: 0.8071, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.21\n",
      "epoch: 112, loss: 112.92882, loss1: 0.82441, loss2_3: 112.10441\n",
      "\ttrain_acc: 0.8056, test_acc: \u001b[31m0.7982\u001b[0m, time: 36.21\n",
      "epoch: 113, loss: 112.72502, loss1: 0.83125, loss2_3: 111.89377\n",
      "\ttrain_acc: 0.8056, test_acc: \u001b[31m0.7988\u001b[0m, time: 36.20\n",
      "epoch: 114, loss: 112.80005, loss1: 0.83009, loss2_3: 111.96996\n",
      "\ttrain_acc: 0.8055, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.21\n",
      "epoch: 115, loss: 112.45811, loss1: 0.82387, loss2_3: 111.63424\n",
      "\ttrain_acc: 0.8086, test_acc: \u001b[31m0.8022\u001b[0m, time: 36.20\n",
      "best_acc: 0.8022\n",
      "epoch: 116, loss: 112.25254, loss1: 0.82172, loss2_3: 111.43083\n",
      "\ttrain_acc: 0.8048, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.20\n",
      "epoch: 117, loss: 112.27021, loss1: 0.82792, loss2_3: 111.44229\n",
      "\ttrain_acc: 0.8069, test_acc: \u001b[31m0.801\u001b[0m, time: 36.19\n",
      "epoch: 118, loss: 112.51823, loss1: 0.82670, loss2_3: 111.69153\n",
      "\ttrain_acc: 0.8081, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.18\n",
      "epoch: 119, loss: 112.12872, loss1: 0.82175, loss2_3: 111.30697\n",
      "\ttrain_acc: 0.8077, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.19\n",
      "epoch: 120, loss: 112.12011, loss1: 0.82713, loss2_3: 111.29298\n",
      "\ttrain_acc: 0.8066, test_acc: \u001b[31m0.7979\u001b[0m, time: 36.17\n",
      "epoch: 121, loss: 112.00997, loss1: 0.82485, loss2_3: 111.18511\n",
      "\ttrain_acc: 0.8081, test_acc: \u001b[31m0.80195\u001b[0m, time: 36.20\n",
      "epoch: 122, loss: 112.08145, loss1: 0.82108, loss2_3: 111.26037\n",
      "\ttrain_acc: 0.8093, test_acc: \u001b[31m0.8009\u001b[0m, time: 36.27\n",
      "epoch: 123, loss: 112.23718, loss1: 0.82475, loss2_3: 111.41243\n",
      "\ttrain_acc: 0.8081, test_acc: \u001b[31m0.80095\u001b[0m, time: 36.19\n",
      "epoch: 124, loss: 111.86638, loss1: 0.82190, loss2_3: 111.04449\n",
      "\ttrain_acc: 0.8087, test_acc: \u001b[31m0.80115\u001b[0m, time: 36.20\n",
      "epoch: 125, loss: 111.74446, loss1: 0.81817, loss2_3: 110.92629\n",
      "\ttrain_acc: 0.8074, test_acc: \u001b[31m0.7985\u001b[0m, time: 36.19\n",
      "epoch: 126, loss: 111.61659, loss1: 0.82341, loss2_3: 110.79318\n",
      "\ttrain_acc: 0.8082, test_acc: \u001b[31m0.7992\u001b[0m, time: 36.19\n",
      "epoch: 127, loss: 111.38692, loss1: 0.82390, loss2_3: 110.56301\n",
      "\ttrain_acc: 0.8101, test_acc: \u001b[31m0.8028\u001b[0m, time: 36.20\n",
      "best_acc: 0.8028\n",
      "epoch: 128, loss: 111.38082, loss1: 0.82089, loss2_3: 110.55992\n",
      "\ttrain_acc: 0.8081, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.25\n",
      "epoch: 129, loss: 111.59901, loss1: 0.82319, loss2_3: 110.77582\n",
      "\ttrain_acc: 0.8109, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.16\n",
      "epoch: 130, loss: 111.29861, loss1: 0.81868, loss2_3: 110.47993\n",
      "\ttrain_acc: 0.8071, test_acc: \u001b[31m0.79925\u001b[0m, time: 36.19\n",
      "epoch: 131, loss: 111.33510, loss1: 0.81989, loss2_3: 110.51522\n",
      "\ttrain_acc: 0.8096, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 132, loss: 111.26822, loss1: 0.81923, loss2_3: 110.44899\n",
      "\ttrain_acc: 0.8057, test_acc: \u001b[31m0.79685\u001b[0m, time: 36.18\n",
      "epoch: 133, loss: 111.32790, loss1: 0.82491, loss2_3: 110.50299\n",
      "\ttrain_acc: 0.8086, test_acc: \u001b[31m0.799\u001b[0m, time: 36.19\n",
      "epoch: 134, loss: 111.15986, loss1: 0.81897, loss2_3: 110.34089\n",
      "\ttrain_acc: 0.8082, test_acc: \u001b[31m0.80075\u001b[0m, time: 36.18\n",
      "epoch: 135, loss: 110.99658, loss1: 0.81874, loss2_3: 110.17785\n",
      "\ttrain_acc: 0.8094, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.21\n",
      "epoch: 136, loss: 110.72304, loss1: 0.81451, loss2_3: 109.90853\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.21\n",
      "epoch: 137, loss: 110.85392, loss1: 0.82107, loss2_3: 110.03285\n",
      "\ttrain_acc: 0.8080, test_acc: \u001b[31m0.79785\u001b[0m, time: 36.20\n",
      "epoch: 138, loss: 110.67957, loss1: 0.82009, loss2_3: 109.85948\n",
      "\ttrain_acc: 0.8115, test_acc: \u001b[31m0.80405\u001b[0m, time: 36.21\n",
      "best_acc: 0.80405\n",
      "epoch: 139, loss: 110.69231, loss1: 0.81820, loss2_3: 109.87411\n",
      "\ttrain_acc: 0.8106, test_acc: \u001b[31m0.8007\u001b[0m, time: 36.17\n",
      "epoch: 140, loss: 110.68918, loss1: 0.81961, loss2_3: 109.86957\n",
      "\ttrain_acc: 0.8125, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.20\n",
      "epoch: 141, loss: 110.64455, loss1: 0.82088, loss2_3: 109.82366\n",
      "\ttrain_acc: 0.8124, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.18\n",
      "epoch: 142, loss: 110.56672, loss1: 0.81538, loss2_3: 109.75134\n",
      "\ttrain_acc: 0.8119, test_acc: \u001b[31m0.80205\u001b[0m, time: 36.18\n",
      "epoch: 143, loss: 110.38734, loss1: 0.81363, loss2_3: 109.57371\n",
      "\ttrain_acc: 0.8096, test_acc: \u001b[31m0.79895\u001b[0m, time: 36.18\n",
      "epoch: 144, loss: 110.50798, loss1: 0.81999, loss2_3: 109.68799\n",
      "\ttrain_acc: 0.8111, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.17\n",
      "epoch: 145, loss: 110.33795, loss1: 0.81389, loss2_3: 109.52406\n",
      "\ttrain_acc: 0.8133, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.19\n",
      "epoch: 146, loss: 110.29816, loss1: 0.81644, loss2_3: 109.48172\n",
      "\ttrain_acc: 0.8128, test_acc: \u001b[31m0.80335\u001b[0m, time: 36.16\n",
      "epoch: 147, loss: 110.16389, loss1: 0.81555, loss2_3: 109.34834\n",
      "\ttrain_acc: 0.8139, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.16\n",
      "epoch: 148, loss: 110.24355, loss1: 0.81756, loss2_3: 109.42600\n",
      "\ttrain_acc: 0.8130, test_acc: \u001b[31m0.80045\u001b[0m, time: 36.15\n",
      "epoch: 149, loss: 109.78727, loss1: 0.82170, loss2_3: 108.96557\n",
      "\ttrain_acc: 0.8111, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.16\n",
      "epoch: 150, loss: 110.00161, loss1: 0.81495, loss2_3: 109.18666\n",
      "\ttrain_acc: 0.8132, test_acc: \u001b[31m0.80055\u001b[0m, time: 36.18\n",
      "epoch: 151, loss: 109.76616, loss1: 0.81134, loss2_3: 108.95481\n",
      "\ttrain_acc: 0.8119, test_acc: \u001b[31m0.80165\u001b[0m, time: 36.15\n",
      "epoch: 152, loss: 109.66737, loss1: 0.80954, loss2_3: 108.85782\n",
      "\ttrain_acc: 0.8130, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.32\n",
      "epoch: 153, loss: 109.73697, loss1: 0.81532, loss2_3: 108.92165\n",
      "\ttrain_acc: 0.8127, test_acc: \u001b[31m0.7995\u001b[0m, time: 36.21\n",
      "epoch: 154, loss: 109.70657, loss1: 0.80955, loss2_3: 108.89702\n",
      "\ttrain_acc: 0.8156, test_acc: \u001b[31m0.8012\u001b[0m, time: 36.20\n",
      "epoch: 155, loss: 109.70449, loss1: 0.81227, loss2_3: 108.89222\n",
      "\ttrain_acc: 0.8139, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.20\n",
      "epoch: 156, loss: 109.56657, loss1: 0.81214, loss2_3: 108.75443\n",
      "\ttrain_acc: 0.8148, test_acc: \u001b[31m0.80265\u001b[0m, time: 36.19\n",
      "epoch: 157, loss: 109.33574, loss1: 0.81511, loss2_3: 108.52062\n",
      "\ttrain_acc: 0.8144, test_acc: \u001b[31m0.8003\u001b[0m, time: 36.20\n",
      "epoch: 158, loss: 109.25922, loss1: 0.81143, loss2_3: 108.44779\n",
      "\ttrain_acc: 0.8147, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.25\n",
      "epoch: 159, loss: 109.06298, loss1: 0.81248, loss2_3: 108.25049\n",
      "\ttrain_acc: 0.8166, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.17\n",
      "epoch: 160, loss: 108.90166, loss1: 0.80936, loss2_3: 108.09230\n",
      "\ttrain_acc: 0.8140, test_acc: \u001b[31m0.80015\u001b[0m, time: 36.20\n",
      "epoch: 161, loss: 108.88351, loss1: 0.80742, loss2_3: 108.07609\n",
      "\ttrain_acc: 0.8119, test_acc: \u001b[31m0.799\u001b[0m, time: 36.15\n",
      "epoch: 162, loss: 108.87887, loss1: 0.81791, loss2_3: 108.06097\n",
      "\ttrain_acc: 0.8164, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.16\n",
      "epoch: 163, loss: 108.79938, loss1: 0.81189, loss2_3: 107.98748\n",
      "\ttrain_acc: 0.8153, test_acc: \u001b[31m0.80185\u001b[0m, time: 36.16\n",
      "epoch: 164, loss: 108.68358, loss1: 0.80792, loss2_3: 107.87566\n",
      "\ttrain_acc: 0.8135, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.15\n",
      "epoch: 165, loss: 108.55126, loss1: 0.80829, loss2_3: 107.74297\n",
      "\ttrain_acc: 0.8146, test_acc: \u001b[31m0.8012\u001b[0m, time: 36.16\n",
      "epoch: 166, loss: 108.51413, loss1: 0.80952, loss2_3: 107.70461\n",
      "\ttrain_acc: 0.8143, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.19\n",
      "epoch: 167, loss: 108.59564, loss1: 0.81024, loss2_3: 107.78539\n",
      "\ttrain_acc: 0.8161, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.16\n",
      "epoch: 168, loss: 108.00808, loss1: 0.81079, loss2_3: 107.19729\n",
      "\ttrain_acc: 0.8163, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.15\n",
      "epoch: 169, loss: 108.32410, loss1: 0.80904, loss2_3: 107.51506\n",
      "\ttrain_acc: 0.8170, test_acc: \u001b[31m0.80135\u001b[0m, time: 36.25\n",
      "epoch: 170, loss: 108.01315, loss1: 0.81078, loss2_3: 107.20237\n",
      "\ttrain_acc: 0.8158, test_acc: \u001b[31m0.80065\u001b[0m, time: 36.21\n",
      "epoch: 171, loss: 108.31865, loss1: 0.80905, loss2_3: 107.50961\n",
      "\ttrain_acc: 0.8149, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.18\n",
      "epoch: 172, loss: 107.98019, loss1: 0.80912, loss2_3: 107.17107\n",
      "\ttrain_acc: 0.8180, test_acc: \u001b[31m0.80125\u001b[0m, time: 36.17\n",
      "epoch: 173, loss: 107.65883, loss1: 0.80858, loss2_3: 106.85024\n",
      "\ttrain_acc: 0.8157, test_acc: \u001b[31m0.80295\u001b[0m, time: 36.18\n",
      "epoch: 174, loss: 107.82193, loss1: 0.80688, loss2_3: 107.01505\n",
      "\ttrain_acc: 0.8174, test_acc: \u001b[31m0.80155\u001b[0m, time: 36.15\n",
      "epoch: 175, loss: 107.70086, loss1: 0.80737, loss2_3: 106.89349\n",
      "\ttrain_acc: 0.8188, test_acc: \u001b[31m0.8011\u001b[0m, time: 36.18\n",
      "epoch: 176, loss: 107.46187, loss1: 0.80606, loss2_3: 106.65580\n",
      "\ttrain_acc: 0.8162, test_acc: \u001b[31m0.7989\u001b[0m, time: 36.17\n",
      "epoch: 177, loss: 107.59694, loss1: 0.80799, loss2_3: 106.78895\n",
      "\ttrain_acc: 0.8187, test_acc: \u001b[31m0.8029\u001b[0m, time: 36.17\n",
      "epoch: 178, loss: 107.40563, loss1: 0.80597, loss2_3: 106.59965\n",
      "\ttrain_acc: 0.8180, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.17\n",
      "epoch: 179, loss: 107.42034, loss1: 0.80454, loss2_3: 106.61580\n",
      "\ttrain_acc: 0.8208, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.17\n",
      "epoch: 180, loss: 107.07575, loss1: 0.80315, loss2_3: 106.27260\n",
      "\ttrain_acc: 0.8206, test_acc: \u001b[31m0.802\u001b[0m, time: 36.13\n",
      "epoch: 181, loss: 107.21843, loss1: 0.80344, loss2_3: 106.41500\n",
      "\ttrain_acc: 0.8187, test_acc: \u001b[31m0.8\u001b[0m, time: 36.15\n",
      "epoch: 182, loss: 106.90497, loss1: 0.80301, loss2_3: 106.10197\n",
      "\ttrain_acc: 0.8198, test_acc: \u001b[31m0.8019\u001b[0m, time: 36.14\n",
      "epoch: 183, loss: 107.11237, loss1: 0.80471, loss2_3: 106.30766\n",
      "\ttrain_acc: 0.8206, test_acc: \u001b[31m0.79875\u001b[0m, time: 36.22\n",
      "epoch: 184, loss: 107.05809, loss1: 0.80733, loss2_3: 106.25076\n",
      "\ttrain_acc: 0.8186, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.19\n",
      "epoch: 185, loss: 106.88581, loss1: 0.80592, loss2_3: 106.07989\n",
      "\ttrain_acc: 0.8213, test_acc: \u001b[31m0.8027\u001b[0m, time: 36.16\n",
      "epoch: 186, loss: 106.86750, loss1: 0.80173, loss2_3: 106.06577\n",
      "\ttrain_acc: 0.8202, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.15\n",
      "epoch: 187, loss: 106.43257, loss1: 0.80467, loss2_3: 105.62791\n",
      "\ttrain_acc: 0.8210, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.16\n",
      "epoch: 188, loss: 106.70014, loss1: 0.80343, loss2_3: 105.89671\n",
      "\ttrain_acc: 0.8212, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.14\n",
      "epoch: 189, loss: 106.31549, loss1: 0.80746, loss2_3: 105.50804\n",
      "\ttrain_acc: 0.8218, test_acc: \u001b[31m0.8028\u001b[0m, time: 36.21\n",
      "epoch: 190, loss: 106.33916, loss1: 0.80293, loss2_3: 105.53623\n",
      "\ttrain_acc: 0.8225, test_acc: \u001b[31m0.7996\u001b[0m, time: 36.14\n",
      "epoch: 191, loss: 105.94903, loss1: 0.80593, loss2_3: 105.14309\n",
      "\ttrain_acc: 0.8222, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.15\n",
      "epoch: 192, loss: 106.19928, loss1: 0.80469, loss2_3: 105.39458\n",
      "\ttrain_acc: 0.8235, test_acc: \u001b[31m0.8004\u001b[0m, time: 36.12\n",
      "epoch: 193, loss: 106.47767, loss1: 0.80230, loss2_3: 105.67537\n",
      "\ttrain_acc: 0.8207, test_acc: \u001b[31m0.79985\u001b[0m, time: 36.14\n",
      "epoch: 194, loss: 105.91772, loss1: 0.79946, loss2_3: 105.11826\n",
      "\ttrain_acc: 0.8191, test_acc: \u001b[31m0.7963\u001b[0m, time: 36.13\n",
      "epoch: 195, loss: 106.11709, loss1: 0.80321, loss2_3: 105.31388\n",
      "\ttrain_acc: 0.8196, test_acc: \u001b[31m0.8013\u001b[0m, time: 36.12\n",
      "epoch: 196, loss: 105.77072, loss1: 0.79951, loss2_3: 104.97120\n",
      "\ttrain_acc: 0.8231, test_acc: \u001b[31m0.8021\u001b[0m, time: 36.14\n",
      "epoch: 197, loss: 105.54313, loss1: 0.80404, loss2_3: 104.73910\n",
      "\ttrain_acc: 0.8224, test_acc: \u001b[31m0.80105\u001b[0m, time: 36.14\n",
      "epoch: 198, loss: 105.45468, loss1: 0.79769, loss2_3: 104.65699\n",
      "\ttrain_acc: 0.8245, test_acc: \u001b[31m0.80145\u001b[0m, time: 36.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 199, loss: 105.26603, loss1: 0.80217, loss2_3: 104.46387\n",
      "\ttrain_acc: 0.8255, test_acc: \u001b[31m0.7984\u001b[0m, time: 36.17\n",
      "epoch: 200, loss: 105.43357, loss1: 0.80488, loss2_3: 104.62869\n",
      "\ttrain_acc: 0.8225, test_acc: \u001b[31m0.80005\u001b[0m, time: 36.15\n",
      "epoch: 201, loss: 105.35899, loss1: 0.79915, loss2_3: 104.55983\n",
      "\ttrain_acc: 0.8237, test_acc: \u001b[31m0.79725\u001b[0m, time: 36.16\n",
      "epoch: 202, loss: 105.02731, loss1: 0.79860, loss2_3: 104.22871\n",
      "\ttrain_acc: 0.8248, test_acc: \u001b[31m0.8001\u001b[0m, time: 36.17\n",
      "epoch: 203, loss: 105.18689, loss1: 0.80117, loss2_3: 104.38572\n",
      "\ttrain_acc: 0.8258, test_acc: \u001b[31m0.7997\u001b[0m, time: 36.11\n",
      "epoch: 204, loss: 105.02794, loss1: 0.79887, loss2_3: 104.22906\n",
      "\ttrain_acc: 0.8270, test_acc: \u001b[31m0.79945\u001b[0m, time: 36.14\n",
      "epoch: 205, loss: 104.88311, loss1: 0.79934, loss2_3: 104.08378\n",
      "\ttrain_acc: 0.8215, test_acc: \u001b[31m0.79875\u001b[0m, time: 36.14\n",
      "epoch: 206, loss: 104.51846, loss1: 0.80381, loss2_3: 103.71466\n",
      "\ttrain_acc: 0.8246, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.14\n",
      "epoch: 207, loss: 104.83395, loss1: 0.79671, loss2_3: 104.03724\n",
      "\ttrain_acc: 0.8265, test_acc: \u001b[31m0.8008\u001b[0m, time: 36.13\n",
      "epoch: 208, loss: 104.59441, loss1: 0.79608, loss2_3: 103.79833\n",
      "\ttrain_acc: 0.8243, test_acc: \u001b[31m0.7968\u001b[0m, time: 36.12\n",
      "epoch: 209, loss: 104.88907, loss1: 0.79866, loss2_3: 104.09041\n",
      "\ttrain_acc: 0.8205, test_acc: \u001b[31m0.7979\u001b[0m, time: 36.13\n",
      "epoch: 210, loss: 104.60089, loss1: 0.79743, loss2_3: 103.80345\n",
      "\ttrain_acc: 0.8256, test_acc: \u001b[31m0.8009\u001b[0m, time: 36.20\n",
      "epoch: 211, loss: 104.33149, loss1: 0.80019, loss2_3: 103.53130\n",
      "\ttrain_acc: 0.8260, test_acc: \u001b[31m0.7995\u001b[0m, time: 36.18\n",
      "epoch: 212, loss: 104.16285, loss1: 0.79696, loss2_3: 103.36590\n",
      "\ttrain_acc: 0.8233, test_acc: \u001b[31m0.7997\u001b[0m, time: 36.15\n",
      "epoch: 213, loss: 104.37481, loss1: 0.79639, loss2_3: 103.57842\n",
      "\ttrain_acc: 0.8245, test_acc: \u001b[31m0.8006\u001b[0m, time: 36.23\n",
      "epoch: 214, loss: 104.18715, loss1: 0.79432, loss2_3: 103.39283\n",
      "\ttrain_acc: 0.8235, test_acc: \u001b[31m0.8014\u001b[0m, time: 36.17\n",
      "epoch: 215, loss: 103.98546, loss1: 0.79600, loss2_3: 103.18945\n",
      "\ttrain_acc: 0.8288, test_acc: \u001b[31m0.7995\u001b[0m, time: 36.16\n",
      "epoch: 216, loss: 104.02870, loss1: 0.79384, loss2_3: 103.23486\n",
      "\ttrain_acc: 0.8293, test_acc: \u001b[31m0.79885\u001b[0m, time: 36.15\n",
      "epoch: 217, loss: 103.80722, loss1: 0.79502, loss2_3: 103.01219\n",
      "\ttrain_acc: 0.8291, test_acc: \u001b[31m0.8015\u001b[0m, time: 36.14\n",
      "epoch: 218, loss: 103.48002, loss1: 0.79437, loss2_3: 102.68564\n",
      "\ttrain_acc: 0.8280, test_acc: \u001b[31m0.79695\u001b[0m, time: 36.15\n",
      "epoch: 219, loss: 103.35644, loss1: 0.79724, loss2_3: 102.55919\n",
      "\ttrain_acc: 0.8295, test_acc: \u001b[31m0.8002\u001b[0m, time: 36.24\n",
      "epoch: 220, loss: 103.62678, loss1: 0.79369, loss2_3: 102.83310\n",
      "\ttrain_acc: 0.8301, test_acc: \u001b[31m0.79765\u001b[0m, time: 36.13\n",
      "epoch: 221, loss: 103.18560, loss1: 0.79636, loss2_3: 102.38924\n",
      "\ttrain_acc: 0.8238, test_acc: \u001b[31m0.7968\u001b[0m, time: 36.17\n",
      "epoch: 222, loss: 103.27487, loss1: 0.79481, loss2_3: 102.48006\n",
      "\ttrain_acc: 0.8281, test_acc: \u001b[31m0.79705\u001b[0m, time: 36.12\n",
      "epoch: 223, loss: 103.10863, loss1: 0.79840, loss2_3: 102.31023\n",
      "\ttrain_acc: 0.8291, test_acc: \u001b[31m0.79905\u001b[0m, time: 36.14\n",
      "epoch: 224, loss: 102.91238, loss1: 0.79175, loss2_3: 102.12062\n",
      "\ttrain_acc: 0.8322, test_acc: \u001b[31m0.79955\u001b[0m, time: 36.13\n",
      "epoch: 225, loss: 102.67317, loss1: 0.79101, loss2_3: 101.88215\n",
      "\ttrain_acc: 0.8288, test_acc: \u001b[31m0.79595\u001b[0m, time: 36.13\n",
      "epoch: 226, loss: 102.76038, loss1: 0.78801, loss2_3: 101.97237\n",
      "\ttrain_acc: 0.8303, test_acc: \u001b[31m0.7994\u001b[0m, time: 36.14\n",
      "epoch: 227, loss: 102.79111, loss1: 0.79786, loss2_3: 101.99326\n",
      "\ttrain_acc: 0.8330, test_acc: \u001b[31m0.7995\u001b[0m, time: 36.12\n",
      "epoch: 228, loss: 102.23573, loss1: 0.78857, loss2_3: 101.44716\n",
      "\ttrain_acc: 0.8306, test_acc: \u001b[31m0.7954\u001b[0m, time: 36.16\n",
      "epoch: 229, loss: 102.23465, loss1: 0.79005, loss2_3: 101.44460\n",
      "\ttrain_acc: 0.8312, test_acc: \u001b[31m0.79715\u001b[0m, time: 36.14\n",
      "epoch: 230, loss: 101.95372, loss1: 0.79375, loss2_3: 101.15997\n",
      "\ttrain_acc: 0.8354, test_acc: \u001b[31m0.7965\u001b[0m, time: 36.16\n",
      "epoch: 231, loss: 102.33547, loss1: 0.78984, loss2_3: 101.54562\n",
      "\ttrain_acc: 0.8320, test_acc: \u001b[31m0.79975\u001b[0m, time: 36.13\n",
      "epoch: 232, loss: 101.78700, loss1: 0.79046, loss2_3: 100.99653\n",
      "\ttrain_acc: 0.8320, test_acc: \u001b[31m0.79465\u001b[0m, time: 36.15\n",
      "epoch: 233, loss: 102.16225, loss1: 0.78736, loss2_3: 101.37489\n",
      "\ttrain_acc: 0.8304, test_acc: \u001b[31m0.7973\u001b[0m, time: 36.14\n",
      "epoch: 234, loss: 101.86343, loss1: 0.78767, loss2_3: 101.07576\n",
      "\ttrain_acc: 0.8363, test_acc: \u001b[31m0.7971\u001b[0m, time: 36.13\n",
      "epoch: 235, loss: 102.12604, loss1: 0.78505, loss2_3: 101.34099\n",
      "\ttrain_acc: 0.8345, test_acc: \u001b[31m0.79875\u001b[0m, time: 36.13\n",
      "epoch: 236, loss: 101.64022, loss1: 0.78572, loss2_3: 100.85450\n",
      "\ttrain_acc: 0.8344, test_acc: \u001b[31m0.79835\u001b[0m, time: 36.14\n",
      "epoch: 237, loss: 101.43000, loss1: 0.78221, loss2_3: 100.64779\n",
      "\ttrain_acc: 0.8340, test_acc: \u001b[31m0.79785\u001b[0m, time: 36.13\n",
      "epoch: 238, loss: 101.14890, loss1: 0.78763, loss2_3: 100.36127\n",
      "\ttrain_acc: 0.8353, test_acc: \u001b[31m0.797\u001b[0m, time: 36.12\n",
      "epoch: 239, loss: 101.15824, loss1: 0.78530, loss2_3: 100.37293\n",
      "\ttrain_acc: 0.8374, test_acc: \u001b[31m0.79715\u001b[0m, time: 36.13\n",
      "epoch: 240, loss: 101.23787, loss1: 0.78065, loss2_3: 100.45721\n",
      "\ttrain_acc: 0.8370, test_acc: \u001b[31m0.79915\u001b[0m, time: 36.12\n",
      "epoch: 241, loss: 100.90083, loss1: 0.78082, loss2_3: 100.12001\n",
      "\ttrain_acc: 0.8372, test_acc: \u001b[31m0.79625\u001b[0m, time: 36.12\n",
      "epoch: 242, loss: 100.55599, loss1: 0.78343, loss2_3: 99.77256\n",
      "\ttrain_acc: 0.8360, test_acc: \u001b[31m0.79665\u001b[0m, time: 36.11\n",
      "epoch: 243, loss: 100.84867, loss1: 0.78248, loss2_3: 100.06619\n",
      "\ttrain_acc: 0.8359, test_acc: \u001b[31m0.79835\u001b[0m, time: 36.20\n",
      "epoch: 244, loss: 100.35263, loss1: 0.78478, loss2_3: 99.56785\n",
      "\ttrain_acc: 0.8379, test_acc: \u001b[31m0.79645\u001b[0m, time: 36.11\n",
      "epoch: 245, loss: 100.35252, loss1: 0.78199, loss2_3: 99.57053\n",
      "\ttrain_acc: 0.8352, test_acc: \u001b[31m0.79815\u001b[0m, time: 36.11\n",
      "epoch: 246, loss: 100.15016, loss1: 0.78123, loss2_3: 99.36893\n",
      "\ttrain_acc: 0.8359, test_acc: \u001b[31m0.79815\u001b[0m, time: 36.10\n",
      "epoch: 247, loss: 99.91352, loss1: 0.78122, loss2_3: 99.13231\n",
      "\ttrain_acc: 0.8339, test_acc: \u001b[31m0.793\u001b[0m, time: 36.12\n",
      "epoch: 248, loss: 99.83668, loss1: 0.78734, loss2_3: 99.04933\n",
      "\ttrain_acc: 0.8398, test_acc: \u001b[31m0.79015\u001b[0m, time: 36.13\n",
      "epoch: 249, loss: 99.88340, loss1: 0.78356, loss2_3: 99.09984\n",
      "\ttrain_acc: 0.8333, test_acc: \u001b[31m0.7971\u001b[0m, time: 36.20\n",
      "epoch: 250, loss: 99.95394, loss1: 0.77860, loss2_3: 99.17534\n",
      "\ttrain_acc: 0.8362, test_acc: \u001b[31m0.7998\u001b[0m, time: 36.13\n"
     ]
    }
   ],
   "source": [
    "for num_model in range(1):\n",
    "    net=newModel().to(device)\n",
    "    lr = 0.0001\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr,weight_decay=5e-4)\n",
    "    criterion = ContrastiveLoss()\n",
    "    criterion_model = nn.CrossEntropyLoss(reduction='sum')\n",
    "    best_acc=0\n",
    "    EPOCH=250\n",
    "    for epoch in range(EPOCH):\n",
    "        loss_ls=[]\n",
    "        loss1_ls=[]\n",
    "        loss2_3_ls=[]\n",
    "        t0=time.time()\n",
    "        net.train()\n",
    "        for seq1,seq2,label,label1,label2 in train_iter_cont:\n",
    "                output1=net(seq1)\n",
    "                output2=net(seq2)\n",
    "                output3=net.trainModel(seq1)\n",
    "                output4=net.trainModel(seq2)\n",
    "                loss1=criterion(output1, output2, label)\n",
    "                loss2=criterion_model(output3,label1)\n",
    "                loss3=criterion_model(output4,label2)\n",
    "                loss=loss1+loss2+loss3\n",
    "    #             print(loss)\n",
    "                optimizer.zero_grad() \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_ls.append(loss.item())\n",
    "                loss1_ls.append(loss1.item())\n",
    "                loss2_3_ls.append((loss2+loss3).item())\n",
    "\n",
    "\n",
    "        net.eval() \n",
    "        with torch.no_grad(): \n",
    "            train_acc=evaluate_accuracy(train_iter,net)\n",
    "            test_acc=evaluate_accuracy(test_iter,net)\n",
    "        results=f\"epoch: {epoch+1}, loss: {np.mean(loss_ls):.5f}, loss1: {np.mean(loss1_ls):.5f}, loss2_3: {np.mean(loss2_3_ls):.5f}\\n\"\n",
    "        results+=f'\\ttrain_acc: {train_acc:.4f}, test_acc: {colored(test_acc,\"red\")}, time: {time.time()-t0:.2f}'\n",
    "        print(results)\n",
    "#         to_log(results)\n",
    "        if test_acc>best_acc:\n",
    "            best_acc=test_acc\n",
    "#             torch.save({\"best_acc\":best_acc,\"model\":net.state_dict()},f'./Model/{num_model}.pl')\n",
    "            print(f\"best_acc: {best_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T21:22:02.434965Z",
     "start_time": "2021-10-04T21:22:02.410718Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T21:22:02.439656Z",
     "start_time": "2021-10-04T21:22:02.436313Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs.argmax(dim=1):\n",
    "            y_pred.append(int(_))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T21:22:02.445110Z",
     "start_time": "2021-10-04T21:22:02.440723Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred_prob(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs:\n",
    "            y_pred.append(list(map(float, _)))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T09:04:25.557066Z",
     "start_time": "2021-10-06T09:04:10.104412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8678172543203218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86     22330\n",
      "           1       0.85      0.90      0.87     22169\n",
      "\n",
      "    accuracy                           0.87     44499\n",
      "   macro avg       0.87      0.87      0.87     44499\n",
      "weighted avg       0.87      0.87      0.87     44499\n",
      "\n",
      "rf auc : 0.9391573548608613\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_acc = evaluate_accuracy(test_iter,net)\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "# prediction\n",
    "y_pred = pred(test_iter, net)\n",
    "print(classification_report(test_label, y_pred))\n",
    "\n",
    "# AUC\n",
    "probs = np.array(pred_prob(test_iter, net))[:, 1]\n",
    "\n",
    "rf_auc = roc_auc_score(test_label, probs)\n",
    "print('rf auc : {}'.format(rf_auc))\n",
    "# plot the roc curve for the model81\n",
    "rf_fpr, rf_tpr, _ = roc_curve(test_label, probs)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='RF AUC = {:.4f}'.format(rf_auc), color='orange')\n",
    "plt.title('ROC curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "cf_matrix = confusion_matrix(test_label, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=',.0f')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
