{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-17T11:59:32.118228Z",
     "start_time": "2021-08-17T11:59:30.968652Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-17T12:02:35.286362Z",
     "start_time": "2021-08-17T12:02:35.283987Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = 'compareModel/2019Bioinformatics_DeepMSPeptide/DeepMSPeptide/'\n",
    "\n",
    "args = file_path + 'inputExample.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-17T12:02:11.643086Z",
     "start_time": "2021-08-17T12:02:11.636704Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pep_and_codify(file, max_len):\n",
    "    aa_dict={'A':1,'R':2,'N':3,'D':4,'C':5,'Q':6,'E':7,'G':8,'H':9,'I':10,'L':11,'K':12,'M':13,'F':14,\n",
    "        'P':15,'O':16,'S':17,'U':18,'T':19,'W':20,'Y':21,'V':22}\n",
    "    with open(file, 'r') as inf:\n",
    "        lines = inf.read().splitlines()\n",
    "    pep_codes=[]\n",
    "    long_pep_counter = 0\n",
    "    newLines = []\n",
    "    for pep in lines:\n",
    "        if not len(pep) > max_len:\n",
    "            current_pep=[]\n",
    "            for aa in pep:\n",
    "                current_pep.append(aa_dict[aa])\n",
    "            pep_codes.append(current_pep)\n",
    "            newLines.extend([pep])\n",
    "        else:\n",
    "            long_pep_counter += 1\n",
    "    predict_data = keras.preprocessing.sequence.pad_sequences(pep_codes, value=0, padding='post', maxlen=max_len)\n",
    "    return predict_data, long_pep_counter, newLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-17T12:02:47.832603Z",
     "start_time": "2021-08-17T12:02:47.100514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "WARNING:tensorflow:From /home/bis/miniconda3/envs/TF1.14/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/bis/miniconda3/envs/TF1.14/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/bis/miniconda3/envs/TF1.14/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/bis/miniconda3/envs/TF1.14/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/bis/miniconda3/envs/TF1.14/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 81, 50)            1150      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 81, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 81, 128)           19328     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 80, 64)            16448     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 41,151\n",
      "Trainable params: 41,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Loading model...')\n",
    "model_2_1D = keras.models.load_model(file_path + 'model_2_1D.h5')\n",
    "print(model_2_1D.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-17T12:03:10.519276Z",
     "start_time": "2021-08-17T12:03:10.363357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading input peptides\n",
      "Succesfully loaded 24997 peptides and skipped 0\n"
     ]
    }
   ],
   "source": [
    "print('Loading input peptides')\n",
    "predict_data, skipped,  lines = load_pep_and_codify(args, 81)\n",
    "print('Succesfully loaded {0} peptides and skipped {1}'.format(len(lines), str(skipped)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-17T12:03:40.032164Z",
     "start_time": "2021-08-17T12:03:37.811449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n"
     ]
    }
   ],
   "source": [
    "print('Making predictions')\n",
    "model_2_1D_pred = model_2_1D.predict(predict_data)\n",
    "model_2_1D_pred = np.hstack((np.array(lines).reshape(len(lines), 1),model_2_1D_pred)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-17T12:03:45.361802Z",
     "start_time": "2021-08-17T12:03:45.316306Z"
    }
   },
   "outputs": [],
   "source": [
    "Pred_output = []\n",
    "for pred in model_2_1D_pred:\n",
    "    if float(pred[1]) > 0.5:\n",
    "        # pred.extend('0')\n",
    "        Pred_output.append([pred[0], str(1-float(pred[1])), '0'])\n",
    "    else:\n",
    "        Pred_output.append([pred[0], str(1-float(pred[1])), '1'])\n",
    "        # pred.extend('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outFile = '{0}_Predictions.txt'.format(args.infile[0].split('.')[0])\n",
    "print('Saving predictions to file {}'.format(outFile))\n",
    "with open(outFile, 'w') as outf:\n",
    "    outf.write('Peptide\\tProb\\tDetectability\\n')\n",
    "    outf.writelines('\\t'.join(i) + '\\n' for i in Pred_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-17T12:17:25.063822Z",
     "start_time": "2021-08-17T12:17:25.060237Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-17T12:16:00.154981Z",
     "start_time": "2021-08-17T12:16:00.042603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 81, 50)            1150      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 81, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 81, 128)           19328     \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 80, 64)            16448     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 41,151\n",
      "Trainable params: 41,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(23, 50, input_length=81),  \n",
    "    \n",
    "    # vacabulary size 23 (22 AminoAcid + zero padding)\n",
    "    # embedding vector size 50\n",
    "    # input length (including padding) 81\n",
    "    \n",
    "    tf.keras.layers.Dropout(np.random.uniform(0, 0.2)),\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=3, strides=1, padding='same'),\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=2, strides=1),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dropout(np.random.uniform(0, 0.2)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-17T12:16:09.666597Z",
     "start_time": "2021-08-17T12:16:09.622332Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Data X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, \n",
    "                    batch_size=100,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.subplot(1,2,2)\n",
    "plot_graphs(history, 'loss')\n",
    "\n",
    "# prediction\n",
    "y_pred = [1 if i>=0.5 else 0 for i in model.predict(X_test)]\n",
    "print(classification_report(y_test, y_pred))\n",
    "# AUC\n",
    "probs = model.predict(X_test)\n",
    "rf_auc = roc_auc_score(y_test, probs)\n",
    "print('rf auc : {}'.format(rf_auc))\n",
    "# plot the roc curve for the model\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, probs)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='RF AUC = {:.4f}'.format(rf_auc), color='orange')\n",
    "plt.title('ROC curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=',.0f')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF1.14",
   "language": "python",
   "name": "tf1.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
