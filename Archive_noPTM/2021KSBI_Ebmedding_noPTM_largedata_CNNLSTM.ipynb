{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T02:27:48.961586Z",
     "start_time": "2021-10-20T02:27:47.966139Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T02:27:48.974921Z",
     "start_time": "2021-10-20T02:27:48.963424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 21)\n"
     ]
    }
   ],
   "source": [
    "df_aaindex = pd.read_csv('../data/aaindex/df_aaindex19.csv')\n",
    "print(df_aaindex.shape)\n",
    "df_aaindex.head(1)\n",
    "tmp = df_aaindex.drop('Unnamed: 0',axis=1).T\n",
    "aa2val = dict()\n",
    "for aa, val in zip(tmp.index, tmp.values):\n",
    "    aa2val[aa]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T02:27:53.138288Z",
     "start_time": "2021-10-20T02:27:49.725521Z"
    }
   },
   "outputs": [],
   "source": [
    "df_detect_peptide_train = pd.read_csv('../data/df_detect_peptide_train_noptm_211018_includeDigest.csv')\n",
    "test = pd.read_csv('../data/df_detect_peptide_test_noptm_211018_includeDigest.csv')\n",
    "train, val = train_test_split(df_detect_peptide_train, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T02:27:53.160524Z",
     "start_time": "2021-10-20T02:27:53.140735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide</th>\n",
       "      <th>En</th>\n",
       "      <th>Ec</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>protein</th>\n",
       "      <th>PEP</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>548709</th>\n",
       "      <td>K.AIGSSPLGSGEGLLGLSPGPNGHSHLLKVR.A</td>\n",
       "      <td>LKQSHLSKAIGSSPL</td>\n",
       "      <td>HSHLLKVRAGGGDMQ</td>\n",
       "      <td>NGHSHLLKVRAGGGD</td>\n",
       "      <td>-</td>\n",
       "      <td>sp|Q8IY67|RAVR1_HUMAN</td>\n",
       "      <td>AIGSSPLGSGEGLLGLSPGPNGHSHLLKVR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   peptide               En               Ec  \\\n",
       "548709  K.AIGSSPLGSGEGLLGLSPGPNGHSHLLKVR.A  LKQSHLSKAIGSSPL  HSHLLKVRAGGGDMQ   \n",
       "\n",
       "                     E1 E2                protein  \\\n",
       "548709  NGHSHLLKVRAGGGD  -  sp|Q8IY67|RAVR1_HUMAN   \n",
       "\n",
       "                                   PEP  ID  \n",
       "548709  AIGSSPLGSGEGLLGLSPGPNGHSHLLKVR   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T02:27:53.169317Z",
     "start_time": "2021-10-20T02:27:53.161973Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_labelEnc(df):\n",
    "    label_enc = {v:k+1 for k, v in enumerate('ARNDCQEGHILKMFPSTWYV')}\n",
    "    label_enc['Z']=0\n",
    "    aa_data = [np.array([seq.count(a) for a in 'ARNDCQEGHILKMFPSTWYV'] + list(np.array([aa2val[aa] for aa in seq]).sum(axis=0)))\n",
    "               for seq in df.PEP.values]\n",
    "    pep_data = [[label_enc[aa] for aa in seq] + [0]*(30-len(seq))\n",
    "               for seq in df.PEP.values]\n",
    "    en_data = [[label_enc[aa] for aa in seq]\n",
    "               for seq in df.En.values]\n",
    "    ec_data = [[label_enc[aa] for aa in seq]\n",
    "               for seq in df.Ec.values]\n",
    "    e1_data = [[label_enc[aa] for aa in seq]\n",
    "               if seq != '-' else [0 for _ in range(15)]\n",
    "               for seq in df.E1.values]\n",
    "    e2_data = [[label_enc[aa] for aa in seq]\n",
    "               if seq != '-' else [0 for _ in range(15)]\n",
    "               for seq in df.E2.values]\n",
    "    return np.array(aa_data), np.array(pep_data), np.array(en_data), np.array(ec_data), np.array(e1_data), np.array(e2_data), np.array(df.ID.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T02:28:38.370434Z",
     "start_time": "2021-10-20T02:27:53.170337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513513, 39) (513513, 30) (513513, 15) (513513, 15) (513513, 15) (513513, 15) (513513,)\n",
      "(128379, 39) (128379, 30) (128379, 15) (128379, 15) (128379, 15) (128379, 15) (128379,)\n",
      "(129204, 39) (129204, 30) (129204, 15) (129204, 15) (129204, 15) (129204, 15) (129204,)\n"
     ]
    }
   ],
   "source": [
    "aa_train, pep_train, en_train, ec_train, e1_train, e2_train, y_train = get_data_labelEnc(train)\n",
    "aa_val, pep_val, en_val, ec_val, e1_val, e2_val, y_val = get_data_labelEnc(val)\n",
    "aa_test, pep_test, en_test, ec_test, e1_test, e2_test, y_test = get_data_labelEnc(test)\n",
    "print(aa_train.shape, pep_train.shape, en_train.shape, ec_train.shape, e1_train.shape, e2_train.shape, y_train.shape)\n",
    "print(aa_val.shape, pep_val.shape, en_val.shape, ec_val.shape, e1_val.shape, e2_val.shape, y_val.shape)\n",
    "print(aa_test.shape, pep_test.shape, en_test.shape, ec_test.shape, e1_test.shape, e2_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T02:28:39.805945Z",
     "start_time": "2021-10-20T02:28:38.372554Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*16)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:14:54.097335Z",
     "start_time": "2021-10-20T12:14:54.094290Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# high param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T02:31:05.102577Z",
     "start_time": "2021-10-20T02:31:05.100387Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T02:32:01.205341Z",
     "start_time": "2021-10-20T02:31:58.017716Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 30, 32)       672         input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 15, 16)       336         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 15, 16)       336         input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 15, 16)       336         input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 15, 16)       336         input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 30, 32)       0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 15, 16)       0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 15, 16)       0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 15, 16)       0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 15, 16)       0           embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_5 (TFOpLambda)       (None, 30, 32, 1)    0           dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_6 (TFOpLambda)       (None, 15, 16, 1)    0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_7 (TFOpLambda)       (None, 15, 16, 1)    0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_8 (TFOpLambda)       (None, 15, 16, 1)    0           dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_9 (TFOpLambda)       (None, 15, 16, 1)    0           dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 30, 32, 32)   96          tf.reshape_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 15, 16, 16)   48          tf.reshape_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_19 (TimeDistri (None, 15, 16, 16)   48          tf.reshape_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_22 (TimeDistri (None, 15, 16, 16)   48          tf.reshape_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_25 (TimeDistri (None, 15, 16, 16)   48          tf.reshape_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 30, 16, 32)   0           time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistri (None, 15, 8, 16)    0           time_distributed_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_20 (TimeDistri (None, 15, 8, 16)    0           time_distributed_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_23 (TimeDistri (None, 15, 8, 16)    0           time_distributed_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_26 (TimeDistri (None, 15, 8, 16)    0           time_distributed_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 30, 512)      0           time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_18 (TimeDistri (None, 15, 128)      0           time_distributed_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_21 (TimeDistri (None, 15, 128)      0           time_distributed_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_24 (TimeDistri (None, 15, 128)      0           time_distributed_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_27 (TimeDistri (None, 15, 128)      0           time_distributed_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 32)           67712       time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 39)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 16)           8768        time_distributed_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 16)           8768        time_distributed_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 16)           8768        time_distributed_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 16)           8768        time_distributed_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           528         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           1280        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 8)            136         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8)            136         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 8)            136         bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 8)            136         bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 8)            0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 8)            0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 8)            0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 8)            0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 80)           0           dropout_20[0][0]                 \n",
      "                                                                 dropout_21[0][0]                 \n",
      "                                                                 dropout_22[0][0]                 \n",
      "                                                                 dropout_23[0][0]                 \n",
      "                                                                 dropout_24[0][0]                 \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 64)           5184        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 64)           0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           2080        dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 32)           0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            33          dropout_27[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 114,737\n",
      "Trainable params: 114,737\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pep = tf.keras.layers.Input(shape=((30,)))\n",
    "input1_ = tf.keras.layers.Embedding(21, 32, input_length=30, mask_zero=True)(pep)\n",
    "input1 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(input1_)\n",
    "\n",
    "input2 = tf.keras.layers.Input(shape=((39,)))  # peptide info\n",
    "\n",
    "n = tf.keras.layers.Input(shape=((15,)))\n",
    "input3_ = tf.keras.layers.Embedding(21, 16, input_length=15, mask_zero=True)(n)\n",
    "input3 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(input3_)\n",
    "\n",
    "c = tf.keras.layers.Input(shape=((15,)))\n",
    "input4_ = tf.keras.layers.Embedding(21, 16, input_length=15, mask_zero=True)(c)\n",
    "input4 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(input4_)\n",
    "\n",
    "m1 = tf.keras.layers.Input(shape=((15,)))\n",
    "input5_ = tf.keras.layers.Embedding(21, 16, input_length=15, mask_zero=True)(m1)\n",
    "input5 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(input5_)\n",
    "\n",
    "m2 = tf.keras.layers.Input(shape=((15,)))\n",
    "input6_ = tf.keras.layers.Embedding(21, 16, input_length=15, mask_zero=True)(m2)\n",
    "input6 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(input6_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reshap1 = keras.backend.reshape(input1, [-1, 30, 32, 1])\n",
    "cnn1 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.Conv1D(\n",
    "        filters=32, kernel_size=2, strides=1, padding='same')\n",
    "    )(reshap1)\n",
    "avgpool1 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.AveragePooling1D(pool_size=2)\n",
    "    )(cnn1)\n",
    "flat1 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.Flatten()\n",
    "    )(avgpool1)\n",
    "lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16))(flat1)\n",
    "net_lstm_ = tf.keras.layers.Dense(16, activation='relu')(lstm1)\n",
    "net_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_lstm_)\n",
    "\n",
    "net_dense1_ = tf.keras.layers.Dense(32, activation='relu')(input2)\n",
    "net_dense1 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_dense1_)\n",
    "\n",
    "reshap3 = keras.backend.reshape(input3, [-1, 15, 16, 1])\n",
    "cnn3 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.Conv1D(\n",
    "        filters=16, kernel_size=2, strides=1, padding='same')\n",
    "    )(reshap3)\n",
    "avgpool3 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.AveragePooling1D(pool_size=2)\n",
    "    )(cnn3)\n",
    "flat3 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.Flatten()\n",
    "    )(avgpool3)\n",
    "digest_n = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8))(flat3)\n",
    "net_n_ = tf.keras.layers.Dense(8, activation='relu')(digest_n)\n",
    "net_n = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_n_)\n",
    "\n",
    "reshap4 = keras.backend.reshape(input4, [-1, 15, 16, 1])\n",
    "cnn4 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.Conv1D(\n",
    "        filters=16, kernel_size=2, strides=1, padding='same')\n",
    "    )(reshap4)\n",
    "avgpool4 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.AveragePooling1D(pool_size=2)\n",
    "    )(cnn4)\n",
    "flat4 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.Flatten()\n",
    "    )(avgpool4)\n",
    "digest_c = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8))(flat4)\n",
    "net_c_ = tf.keras.layers.Dense(8, activation='relu')(digest_c)\n",
    "net_c = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_c_)\n",
    "\n",
    "reshap5 = keras.backend.reshape(input5, [-1, 15, 16, 1])\n",
    "cnn5 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.Conv1D(\n",
    "        filters=16, kernel_size=2, strides=1, padding='same')\n",
    "    )(reshap5)\n",
    "avgpool5 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.AveragePooling1D(pool_size=2)\n",
    "    )(cnn5)\n",
    "flat5 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.Flatten()\n",
    "    )(avgpool5)\n",
    "digest_m1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8))(flat5)\n",
    "net_m1_ = tf.keras.layers.Dense(8, activation='relu')(digest_m1)\n",
    "net_m1 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_m1_)\n",
    "\n",
    "reshap6 = keras.backend.reshape(input6, [-1, 15, 16, 1])\n",
    "cnn6 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.Conv1D(\n",
    "        filters=16, kernel_size=2, strides=1, padding='same')\n",
    "    )(reshap6)\n",
    "avgpool6 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.AveragePooling1D(pool_size=2)\n",
    "    )(cnn6)\n",
    "flat6 = tf.keras.layers.TimeDistributed(\n",
    "    tf.keras.layers.Flatten()\n",
    "    )(avgpool6)\n",
    "digest_m2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8))(flat6)\n",
    "net_m2_ = tf.keras.layers.Dense(8, activation='relu')(digest_m2)\n",
    "net_m2 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_m2_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "merge = tf.keras.layers.concatenate([net_lstm, \n",
    "                                     net_dense1,\n",
    "                                     net_n,\n",
    "                                     net_c,\n",
    "                                     net_m1,\n",
    "                                     net_m2])\n",
    "\n",
    "\n",
    "\n",
    "net1 = tf.keras.layers.Dense(64, activation='relu')(merge)\n",
    "net1_drop = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net1)\n",
    "net3 = tf.keras.layers.Dense(32, activation='relu')(net1_drop)\n",
    "net3_drop = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net3)\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation = 'sigmoid')(net3_drop)\n",
    "\n",
    "model_high = tf.keras.Model(inputs=[pep, input2,\n",
    "                              n, c,\n",
    "                              m1, m2],\n",
    "                       outputs=[output])\n",
    "\n",
    "model_high.summary()\n",
    "\n",
    "model_high.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                      mode='min', \n",
    "                                      verbose=1,\n",
    "                                      patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T11:15:32.739949Z",
     "start_time": "2021-10-20T02:32:15.642761Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2006/2006 [==============================] - 119s 49ms/step - loss: 5.5984 - accuracy: 0.5111 - val_loss: 0.6887 - val_accuracy: 0.5562\n",
      "Epoch 2/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.7022 - accuracy: 0.5397 - val_loss: 0.6680 - val_accuracy: 0.6297\n",
      "Epoch 3/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.6649 - accuracy: 0.6110 - val_loss: 0.6005 - val_accuracy: 0.7033\n",
      "Epoch 4/300\n",
      "2006/2006 [==============================] - 91s 46ms/step - loss: 0.6150 - accuracy: 0.6812 - val_loss: 0.5492 - val_accuracy: 0.7260\n",
      "Epoch 5/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.5646 - accuracy: 0.7079 - val_loss: 0.5045 - val_accuracy: 0.7597\n",
      "Epoch 6/300\n",
      "2006/2006 [==============================] - 91s 46ms/step - loss: 0.5217 - accuracy: 0.7469 - val_loss: 0.4755 - val_accuracy: 0.7764\n",
      "Epoch 7/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.4981 - accuracy: 0.7632 - val_loss: 0.4657 - val_accuracy: 0.7812\n",
      "Epoch 8/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4882 - accuracy: 0.7692 - val_loss: 0.4586 - val_accuracy: 0.7852\n",
      "Epoch 9/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4799 - accuracy: 0.7752 - val_loss: 0.4536 - val_accuracy: 0.7881\n",
      "Epoch 10/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.4744 - accuracy: 0.7781 - val_loss: 0.4480 - val_accuracy: 0.7905\n",
      "Epoch 11/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4681 - accuracy: 0.7809 - val_loss: 0.4418 - val_accuracy: 0.7946\n",
      "Epoch 12/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4619 - accuracy: 0.7850 - val_loss: 0.4417 - val_accuracy: 0.7926\n",
      "Epoch 13/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4585 - accuracy: 0.7856 - val_loss: 0.4356 - val_accuracy: 0.7976\n",
      "Epoch 14/300\n",
      "2006/2006 [==============================] - 91s 46ms/step - loss: 0.4546 - accuracy: 0.7888 - val_loss: 0.4316 - val_accuracy: 0.8002\n",
      "Epoch 15/300\n",
      "2006/2006 [==============================] - 91s 46ms/step - loss: 0.4513 - accuracy: 0.7900 - val_loss: 0.4326 - val_accuracy: 0.7992\n",
      "Epoch 16/300\n",
      "2006/2006 [==============================] - 91s 46ms/step - loss: 0.4461 - accuracy: 0.7930 - val_loss: 0.4274 - val_accuracy: 0.8030\n",
      "Epoch 17/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4420 - accuracy: 0.7962 - val_loss: 0.4240 - val_accuracy: 0.8050\n",
      "Epoch 18/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4378 - accuracy: 0.7984 - val_loss: 0.4198 - val_accuracy: 0.8071\n",
      "Epoch 19/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4358 - accuracy: 0.7993 - val_loss: 0.4193 - val_accuracy: 0.8080\n",
      "Epoch 20/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4332 - accuracy: 0.8007 - val_loss: 0.4165 - val_accuracy: 0.8095\n",
      "Epoch 21/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4317 - accuracy: 0.8016 - val_loss: 0.4160 - val_accuracy: 0.8105\n",
      "Epoch 22/300\n",
      "2006/2006 [==============================] - 91s 46ms/step - loss: 0.4293 - accuracy: 0.8034 - val_loss: 0.4139 - val_accuracy: 0.8106\n",
      "Epoch 23/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.4279 - accuracy: 0.8043 - val_loss: 0.4141 - val_accuracy: 0.8119\n",
      "Epoch 24/300\n",
      "2006/2006 [==============================] - 93s 46ms/step - loss: 0.4257 - accuracy: 0.8052 - val_loss: 0.4096 - val_accuracy: 0.8145\n",
      "Epoch 25/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4224 - accuracy: 0.8078 - val_loss: 0.4080 - val_accuracy: 0.8154\n",
      "Epoch 26/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4224 - accuracy: 0.8081 - val_loss: 0.4092 - val_accuracy: 0.8148\n",
      "Epoch 27/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4227 - accuracy: 0.8079 - val_loss: 0.4075 - val_accuracy: 0.8152\n",
      "Epoch 28/300\n",
      "2006/2006 [==============================] - 93s 46ms/step - loss: 0.4196 - accuracy: 0.8102 - val_loss: 0.4145 - val_accuracy: 0.8098\n",
      "Epoch 29/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4185 - accuracy: 0.8104 - val_loss: 0.4062 - val_accuracy: 0.8169\n",
      "Epoch 30/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.4174 - accuracy: 0.8107 - val_loss: 0.4040 - val_accuracy: 0.8177\n",
      "Epoch 31/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4157 - accuracy: 0.8121 - val_loss: 0.4039 - val_accuracy: 0.8174\n",
      "Epoch 32/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4156 - accuracy: 0.8115 - val_loss: 0.4068 - val_accuracy: 0.8158\n",
      "Epoch 33/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4152 - accuracy: 0.8111 - val_loss: 0.4028 - val_accuracy: 0.8179\n",
      "Epoch 34/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4146 - accuracy: 0.8125 - val_loss: 0.4029 - val_accuracy: 0.8183\n",
      "Epoch 35/300\n",
      "2006/2006 [==============================] - 90s 45ms/step - loss: 0.4148 - accuracy: 0.8121 - val_loss: 0.4010 - val_accuracy: 0.8188\n",
      "Epoch 36/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4128 - accuracy: 0.8141 - val_loss: 0.4013 - val_accuracy: 0.8192\n",
      "Epoch 37/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.4119 - accuracy: 0.8141 - val_loss: 0.4011 - val_accuracy: 0.8196\n",
      "Epoch 38/300\n",
      "2006/2006 [==============================] - 91s 46ms/step - loss: 0.4116 - accuracy: 0.8142 - val_loss: 0.3998 - val_accuracy: 0.8197\n",
      "Epoch 39/300\n",
      "2006/2006 [==============================] - 91s 46ms/step - loss: 0.4106 - accuracy: 0.8150 - val_loss: 0.4007 - val_accuracy: 0.8198\n",
      "Epoch 40/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4089 - accuracy: 0.8159 - val_loss: 0.3981 - val_accuracy: 0.8211\n",
      "Epoch 41/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4107 - accuracy: 0.8151 - val_loss: 0.3984 - val_accuracy: 0.8207\n",
      "Epoch 42/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.4087 - accuracy: 0.8152 - val_loss: 0.3987 - val_accuracy: 0.8192\n",
      "Epoch 43/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4084 - accuracy: 0.8156 - val_loss: 0.3958 - val_accuracy: 0.8218\n",
      "Epoch 44/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4067 - accuracy: 0.8176 - val_loss: 0.3960 - val_accuracy: 0.8220\n",
      "Epoch 45/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.4076 - accuracy: 0.8166 - val_loss: 0.3959 - val_accuracy: 0.8217\n",
      "Epoch 46/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.4068 - accuracy: 0.8169 - val_loss: 0.3983 - val_accuracy: 0.8210\n",
      "Epoch 47/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4065 - accuracy: 0.8169 - val_loss: 0.3946 - val_accuracy: 0.8223\n",
      "Epoch 48/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4041 - accuracy: 0.8177 - val_loss: 0.3942 - val_accuracy: 0.8225\n",
      "Epoch 49/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.4050 - accuracy: 0.8188 - val_loss: 0.3943 - val_accuracy: 0.8228\n",
      "Epoch 50/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.4048 - accuracy: 0.8182 - val_loss: 0.3935 - val_accuracy: 0.8231\n",
      "Epoch 51/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.4048 - accuracy: 0.8176 - val_loss: 0.3938 - val_accuracy: 0.8229\n",
      "Epoch 52/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.4035 - accuracy: 0.8185 - val_loss: 0.3938 - val_accuracy: 0.8230\n",
      "Epoch 53/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.4024 - accuracy: 0.8190 - val_loss: 0.3950 - val_accuracy: 0.8220\n",
      "Epoch 54/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.4021 - accuracy: 0.8192 - val_loss: 0.3935 - val_accuracy: 0.8226\n",
      "Epoch 55/300\n",
      "2006/2006 [==============================] - 93s 46ms/step - loss: 0.4025 - accuracy: 0.8194 - val_loss: 0.3924 - val_accuracy: 0.8239\n",
      "Epoch 56/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.4012 - accuracy: 0.8199 - val_loss: 0.3942 - val_accuracy: 0.8221\n",
      "Epoch 57/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.4008 - accuracy: 0.8198 - val_loss: 0.3939 - val_accuracy: 0.8228\n",
      "Epoch 58/300\n",
      "2006/2006 [==============================] - 95s 48ms/step - loss: 0.4001 - accuracy: 0.8205 - val_loss: 0.3909 - val_accuracy: 0.8242\n",
      "Epoch 59/300\n",
      "2006/2006 [==============================] - 93s 46ms/step - loss: 0.4000 - accuracy: 0.8204 - val_loss: 0.3923 - val_accuracy: 0.8234\n",
      "Epoch 60/300\n",
      "2006/2006 [==============================] - 93s 46ms/step - loss: 0.4008 - accuracy: 0.8201 - val_loss: 0.3938 - val_accuracy: 0.8228\n",
      "Epoch 61/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3996 - accuracy: 0.8208 - val_loss: 0.3913 - val_accuracy: 0.8245\n",
      "Epoch 62/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3995 - accuracy: 0.8210 - val_loss: 0.3930 - val_accuracy: 0.8232\n",
      "Epoch 63/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.3991 - accuracy: 0.8204 - val_loss: 0.3939 - val_accuracy: 0.8224\n",
      "Epoch 64/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3987 - accuracy: 0.8208 - val_loss: 0.3911 - val_accuracy: 0.8244\n",
      "Epoch 65/300\n",
      "2006/2006 [==============================] - 95s 47ms/step - loss: 0.3983 - accuracy: 0.8215 - val_loss: 0.3916 - val_accuracy: 0.8243\n",
      "Epoch 66/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.3995 - accuracy: 0.8208 - val_loss: 0.3929 - val_accuracy: 0.8234\n",
      "Epoch 67/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3975 - accuracy: 0.8215 - val_loss: 0.3907 - val_accuracy: 0.8247\n",
      "Epoch 68/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3982 - accuracy: 0.8216 - val_loss: 0.3897 - val_accuracy: 0.8253\n",
      "Epoch 69/300\n",
      "2006/2006 [==============================] - 95s 47ms/step - loss: 0.3972 - accuracy: 0.8223 - val_loss: 0.3913 - val_accuracy: 0.8246\n",
      "Epoch 70/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.3970 - accuracy: 0.8218 - val_loss: 0.3876 - val_accuracy: 0.8262\n",
      "Epoch 71/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.3968 - accuracy: 0.8223 - val_loss: 0.3886 - val_accuracy: 0.8261\n",
      "Epoch 72/300\n",
      "2006/2006 [==============================] - 95s 47ms/step - loss: 0.3962 - accuracy: 0.8228 - val_loss: 0.3905 - val_accuracy: 0.8248\n",
      "Epoch 73/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.3964 - accuracy: 0.8221 - val_loss: 0.3907 - val_accuracy: 0.8243\n",
      "Epoch 74/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.3966 - accuracy: 0.8217 - val_loss: 0.3893 - val_accuracy: 0.8252\n",
      "Epoch 75/300\n",
      "2006/2006 [==============================] - 95s 47ms/step - loss: 0.3960 - accuracy: 0.8220 - val_loss: 0.3879 - val_accuracy: 0.8254\n",
      "Epoch 76/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3961 - accuracy: 0.8223 - val_loss: 0.3895 - val_accuracy: 0.8245\n",
      "Epoch 77/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3941 - accuracy: 0.8234 - val_loss: 0.3886 - val_accuracy: 0.8256\n",
      "Epoch 78/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3951 - accuracy: 0.8228 - val_loss: 0.3865 - val_accuracy: 0.8265\n",
      "Epoch 79/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3951 - accuracy: 0.8231 - val_loss: 0.3896 - val_accuracy: 0.8248\n",
      "Epoch 80/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3938 - accuracy: 0.8239 - val_loss: 0.3886 - val_accuracy: 0.8259\n",
      "Epoch 81/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3952 - accuracy: 0.8231 - val_loss: 0.3884 - val_accuracy: 0.8258\n",
      "Epoch 82/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3948 - accuracy: 0.8237 - val_loss: 0.3862 - val_accuracy: 0.8270\n",
      "Epoch 83/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3929 - accuracy: 0.8238 - val_loss: 0.3871 - val_accuracy: 0.8264\n",
      "Epoch 84/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3947 - accuracy: 0.8228 - val_loss: 0.3865 - val_accuracy: 0.8270\n",
      "Epoch 85/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3931 - accuracy: 0.8237 - val_loss: 0.3862 - val_accuracy: 0.8267\n",
      "Epoch 86/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3919 - accuracy: 0.8243 - val_loss: 0.3890 - val_accuracy: 0.8244\n",
      "Epoch 87/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3923 - accuracy: 0.8247 - val_loss: 0.3880 - val_accuracy: 0.8260\n",
      "Epoch 88/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.3934 - accuracy: 0.8237 - val_loss: 0.3848 - val_accuracy: 0.8279\n",
      "Epoch 89/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3905 - accuracy: 0.8264 - val_loss: 0.3865 - val_accuracy: 0.8265\n",
      "Epoch 90/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3923 - accuracy: 0.8244 - val_loss: 0.3866 - val_accuracy: 0.8260\n",
      "Epoch 91/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.3928 - accuracy: 0.8245 - val_loss: 0.3852 - val_accuracy: 0.8279\n",
      "Epoch 92/300\n",
      "2006/2006 [==============================] - 95s 47ms/step - loss: 0.3924 - accuracy: 0.8245 - val_loss: 0.3860 - val_accuracy: 0.8268\n",
      "Epoch 93/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3923 - accuracy: 0.8241 - val_loss: 0.3841 - val_accuracy: 0.8281\n",
      "Epoch 94/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.3917 - accuracy: 0.8250 - val_loss: 0.3846 - val_accuracy: 0.8279\n",
      "Epoch 95/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3922 - accuracy: 0.8249 - val_loss: 0.3842 - val_accuracy: 0.8278\n",
      "Epoch 96/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3921 - accuracy: 0.8248 - val_loss: 0.3836 - val_accuracy: 0.8286\n",
      "Epoch 97/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.3907 - accuracy: 0.8253 - val_loss: 0.3857 - val_accuracy: 0.8271\n",
      "Epoch 98/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3908 - accuracy: 0.8253 - val_loss: 0.3834 - val_accuracy: 0.8283\n",
      "Epoch 99/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3904 - accuracy: 0.8263 - val_loss: 0.3834 - val_accuracy: 0.8289\n",
      "Epoch 100/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3914 - accuracy: 0.8248 - val_loss: 0.3844 - val_accuracy: 0.8280\n",
      "Epoch 101/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3907 - accuracy: 0.8249 - val_loss: 0.3853 - val_accuracy: 0.8269\n",
      "Epoch 102/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3898 - accuracy: 0.8256 - val_loss: 0.3831 - val_accuracy: 0.8292\n",
      "Epoch 103/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3894 - accuracy: 0.8262 - val_loss: 0.3868 - val_accuracy: 0.8250\n",
      "Epoch 104/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3907 - accuracy: 0.8259 - val_loss: 0.3882 - val_accuracy: 0.8257\n",
      "Epoch 105/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.3883 - accuracy: 0.8267 - val_loss: 0.3827 - val_accuracy: 0.8285\n",
      "Epoch 106/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3890 - accuracy: 0.8258 - val_loss: 0.3859 - val_accuracy: 0.8272\n",
      "Epoch 107/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3883 - accuracy: 0.8266 - val_loss: 0.3861 - val_accuracy: 0.8276\n",
      "Epoch 108/300\n",
      "2006/2006 [==============================] - 93s 46ms/step - loss: 0.3887 - accuracy: 0.8267 - val_loss: 0.3827 - val_accuracy: 0.8296\n",
      "Epoch 109/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3881 - accuracy: 0.8272 - val_loss: 0.3840 - val_accuracy: 0.8286\n",
      "Epoch 110/300\n",
      "2006/2006 [==============================] - 95s 48ms/step - loss: 0.3881 - accuracy: 0.8262 - val_loss: 0.3811 - val_accuracy: 0.8298\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.3866 - accuracy: 0.8279 - val_loss: 0.3818 - val_accuracy: 0.8294\n",
      "Epoch 112/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3882 - accuracy: 0.8267 - val_loss: 0.3841 - val_accuracy: 0.8282\n",
      "Epoch 113/300\n",
      "2006/2006 [==============================] - 95s 47ms/step - loss: 0.3888 - accuracy: 0.8268 - val_loss: 0.3846 - val_accuracy: 0.8270\n",
      "Epoch 114/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3874 - accuracy: 0.8264 - val_loss: 0.3824 - val_accuracy: 0.8284\n",
      "Epoch 115/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3876 - accuracy: 0.8272 - val_loss: 0.3809 - val_accuracy: 0.8297\n",
      "Epoch 116/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3880 - accuracy: 0.8272 - val_loss: 0.3843 - val_accuracy: 0.8273\n",
      "Epoch 117/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3878 - accuracy: 0.8267 - val_loss: 0.3818 - val_accuracy: 0.8290\n",
      "Epoch 118/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3867 - accuracy: 0.8275 - val_loss: 0.3823 - val_accuracy: 0.8285\n",
      "Epoch 119/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3865 - accuracy: 0.8272 - val_loss: 0.3845 - val_accuracy: 0.8278\n",
      "Epoch 120/300\n",
      "2006/2006 [==============================] - 95s 47ms/step - loss: 0.3882 - accuracy: 0.8268 - val_loss: 0.3792 - val_accuracy: 0.8309\n",
      "Epoch 121/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3870 - accuracy: 0.8271 - val_loss: 0.3833 - val_accuracy: 0.8281\n",
      "Epoch 122/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3870 - accuracy: 0.8271 - val_loss: 0.3813 - val_accuracy: 0.8301\n",
      "Epoch 123/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3858 - accuracy: 0.8275 - val_loss: 0.3828 - val_accuracy: 0.8285\n",
      "Epoch 124/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3862 - accuracy: 0.8282 - val_loss: 0.3793 - val_accuracy: 0.8304\n",
      "Epoch 125/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3866 - accuracy: 0.8276 - val_loss: 0.3812 - val_accuracy: 0.8295\n",
      "Epoch 126/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3845 - accuracy: 0.8286 - val_loss: 0.3808 - val_accuracy: 0.8304\n",
      "Epoch 127/300\n",
      "2006/2006 [==============================] - 95s 47ms/step - loss: 0.3842 - accuracy: 0.8291 - val_loss: 0.3793 - val_accuracy: 0.8311\n",
      "Epoch 128/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.3854 - accuracy: 0.8280 - val_loss: 0.3834 - val_accuracy: 0.8287\n",
      "Epoch 129/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.3863 - accuracy: 0.8278 - val_loss: 0.3806 - val_accuracy: 0.8296\n",
      "Epoch 130/300\n",
      "2006/2006 [==============================] - 93s 46ms/step - loss: 0.3861 - accuracy: 0.8280 - val_loss: 0.3801 - val_accuracy: 0.8292\n",
      "Epoch 131/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.3860 - accuracy: 0.8276 - val_loss: 0.3808 - val_accuracy: 0.8299\n",
      "Epoch 132/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.3851 - accuracy: 0.8279 - val_loss: 0.3811 - val_accuracy: 0.8295\n",
      "Epoch 133/300\n",
      "2006/2006 [==============================] - 93s 46ms/step - loss: 0.3839 - accuracy: 0.8287 - val_loss: 0.3791 - val_accuracy: 0.8309\n",
      "Epoch 134/300\n",
      "2006/2006 [==============================] - 94s 47ms/step - loss: 0.3845 - accuracy: 0.8288 - val_loss: 0.3807 - val_accuracy: 0.8299\n",
      "Epoch 135/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.3855 - accuracy: 0.8282 - val_loss: 0.3821 - val_accuracy: 0.8286\n",
      "Epoch 136/300\n",
      "2006/2006 [==============================] - 90s 45ms/step - loss: 0.3818 - accuracy: 0.8300 - val_loss: 0.3795 - val_accuracy: 0.8310\n",
      "Epoch 137/300\n",
      "2006/2006 [==============================] - 88s 44ms/step - loss: 0.3840 - accuracy: 0.8294 - val_loss: 0.3793 - val_accuracy: 0.8309\n",
      "Epoch 138/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3844 - accuracy: 0.8280 - val_loss: 0.3777 - val_accuracy: 0.8318\n",
      "Epoch 139/300\n",
      "2006/2006 [==============================] - 83s 41ms/step - loss: 0.3835 - accuracy: 0.8288 - val_loss: 0.3804 - val_accuracy: 0.8295\n",
      "Epoch 140/300\n",
      "2006/2006 [==============================] - 81s 40ms/step - loss: 0.3845 - accuracy: 0.8285 - val_loss: 0.3778 - val_accuracy: 0.8308\n",
      "Epoch 141/300\n",
      "2006/2006 [==============================] - 81s 41ms/step - loss: 0.3862 - accuracy: 0.8281 - val_loss: 0.3779 - val_accuracy: 0.8310\n",
      "Epoch 142/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3832 - accuracy: 0.8292 - val_loss: 0.3789 - val_accuracy: 0.8311\n",
      "Epoch 143/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3823 - accuracy: 0.8303 - val_loss: 0.3796 - val_accuracy: 0.8297\n",
      "Epoch 144/300\n",
      "2006/2006 [==============================] - 83s 41ms/step - loss: 0.3830 - accuracy: 0.8295 - val_loss: 0.3801 - val_accuracy: 0.8300\n",
      "Epoch 145/300\n",
      "2006/2006 [==============================] - 84s 42ms/step - loss: 0.3829 - accuracy: 0.8290 - val_loss: 0.3792 - val_accuracy: 0.8304\n",
      "Epoch 146/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3828 - accuracy: 0.8298 - val_loss: 0.3773 - val_accuracy: 0.8317\n",
      "Epoch 147/300\n",
      "2006/2006 [==============================] - 81s 41ms/step - loss: 0.3830 - accuracy: 0.8293 - val_loss: 0.3786 - val_accuracy: 0.8305\n",
      "Epoch 148/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3819 - accuracy: 0.8295 - val_loss: 0.3797 - val_accuracy: 0.8299\n",
      "Epoch 149/300\n",
      "2006/2006 [==============================] - 83s 42ms/step - loss: 0.3825 - accuracy: 0.8294 - val_loss: 0.3776 - val_accuracy: 0.8307\n",
      "Epoch 150/300\n",
      "2006/2006 [==============================] - 84s 42ms/step - loss: 0.3812 - accuracy: 0.8305 - val_loss: 0.3760 - val_accuracy: 0.8326\n",
      "Epoch 151/300\n",
      "2006/2006 [==============================] - 84s 42ms/step - loss: 0.3809 - accuracy: 0.8304 - val_loss: 0.3789 - val_accuracy: 0.8308\n",
      "Epoch 152/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3821 - accuracy: 0.8304 - val_loss: 0.3768 - val_accuracy: 0.8319\n",
      "Epoch 153/300\n",
      "2006/2006 [==============================] - 81s 41ms/step - loss: 0.3816 - accuracy: 0.8297 - val_loss: 0.3763 - val_accuracy: 0.8322\n",
      "Epoch 154/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3827 - accuracy: 0.8294 - val_loss: 0.3761 - val_accuracy: 0.8325\n",
      "Epoch 155/300\n",
      "2006/2006 [==============================] - 83s 41ms/step - loss: 0.3806 - accuracy: 0.8310 - val_loss: 0.3779 - val_accuracy: 0.8314\n",
      "Epoch 156/300\n",
      "2006/2006 [==============================] - 84s 42ms/step - loss: 0.3813 - accuracy: 0.8303 - val_loss: 0.3773 - val_accuracy: 0.8313\n",
      "Epoch 157/300\n",
      "2006/2006 [==============================] - 83s 41ms/step - loss: 0.3806 - accuracy: 0.8309 - val_loss: 0.3782 - val_accuracy: 0.8308\n",
      "Epoch 158/300\n",
      "2006/2006 [==============================] - 81s 41ms/step - loss: 0.3812 - accuracy: 0.8301 - val_loss: 0.3779 - val_accuracy: 0.8306\n",
      "Epoch 159/300\n",
      "2006/2006 [==============================] - 81s 40ms/step - loss: 0.3804 - accuracy: 0.8301 - val_loss: 0.3802 - val_accuracy: 0.8293\n",
      "Epoch 160/300\n",
      "2006/2006 [==============================] - 81s 40ms/step - loss: 0.3783 - accuracy: 0.8325 - val_loss: 0.3753 - val_accuracy: 0.8325\n",
      "Epoch 161/300\n",
      "2006/2006 [==============================] - 81s 41ms/step - loss: 0.3806 - accuracy: 0.8305 - val_loss: 0.3754 - val_accuracy: 0.8326\n",
      "Epoch 162/300\n",
      "2006/2006 [==============================] - 83s 41ms/step - loss: 0.3802 - accuracy: 0.8308 - val_loss: 0.3759 - val_accuracy: 0.8324\n",
      "Epoch 163/300\n",
      "2006/2006 [==============================] - 85s 42ms/step - loss: 0.3798 - accuracy: 0.8305 - val_loss: 0.3774 - val_accuracy: 0.8310\n",
      "Epoch 164/300\n",
      "2006/2006 [==============================] - 93s 47ms/step - loss: 0.3807 - accuracy: 0.8302 - val_loss: 0.3770 - val_accuracy: 0.8317\n",
      "Epoch 165/300\n",
      "2006/2006 [==============================] - 97s 48ms/step - loss: 0.3809 - accuracy: 0.8307 - val_loss: 0.3786 - val_accuracy: 0.8306\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006/2006 [==============================] - 95s 47ms/step - loss: 0.3800 - accuracy: 0.8306 - val_loss: 0.3754 - val_accuracy: 0.8326\n",
      "Epoch 167/300\n",
      "2006/2006 [==============================] - 92s 46ms/step - loss: 0.3805 - accuracy: 0.8305 - val_loss: 0.3786 - val_accuracy: 0.8297\n",
      "Epoch 168/300\n",
      "2006/2006 [==============================] - 93s 46ms/step - loss: 0.3820 - accuracy: 0.8299 - val_loss: 0.3756 - val_accuracy: 0.8321\n",
      "Epoch 169/300\n",
      "2006/2006 [==============================] - 154s 77ms/step - loss: 0.3806 - accuracy: 0.8298 - val_loss: 0.3762 - val_accuracy: 0.8323\n",
      "Epoch 170/300\n",
      "2006/2006 [==============================] - 253s 126ms/step - loss: 0.3776 - accuracy: 0.8322 - val_loss: 0.3771 - val_accuracy: 0.8306\n",
      "Epoch 171/300\n",
      "2006/2006 [==============================] - 351s 175ms/step - loss: 0.3786 - accuracy: 0.8317 - val_loss: 0.3764 - val_accuracy: 0.8319\n",
      "Epoch 172/300\n",
      "2006/2006 [==============================] - 280s 140ms/step - loss: 0.3797 - accuracy: 0.8315 - val_loss: 0.3761 - val_accuracy: 0.8320\n",
      "Epoch 173/300\n",
      "2006/2006 [==============================] - 242s 121ms/step - loss: 0.3791 - accuracy: 0.8315 - val_loss: 0.3755 - val_accuracy: 0.8323\n",
      "Epoch 174/300\n",
      "2006/2006 [==============================] - 305s 152ms/step - loss: 0.3788 - accuracy: 0.8317 - val_loss: 0.3748 - val_accuracy: 0.8333\n",
      "Epoch 175/300\n",
      "2006/2006 [==============================] - 306s 153ms/step - loss: 0.3806 - accuracy: 0.8302 - val_loss: 0.3782 - val_accuracy: 0.8309\n",
      "Epoch 176/300\n",
      "2006/2006 [==============================] - 300s 150ms/step - loss: 0.3810 - accuracy: 0.8307 - val_loss: 0.3752 - val_accuracy: 0.8326\n",
      "Epoch 177/300\n",
      "2006/2006 [==============================] - 305s 152ms/step - loss: 0.3800 - accuracy: 0.8304 - val_loss: 0.3746 - val_accuracy: 0.8329\n",
      "Epoch 178/300\n",
      "2006/2006 [==============================] - 395s 197ms/step - loss: 0.3787 - accuracy: 0.8317 - val_loss: 0.3751 - val_accuracy: 0.8325\n",
      "Epoch 179/300\n",
      "2006/2006 [==============================] - 318s 158ms/step - loss: 0.3785 - accuracy: 0.8313 - val_loss: 0.3749 - val_accuracy: 0.8329\n",
      "Epoch 180/300\n",
      "2006/2006 [==============================] - 319s 159ms/step - loss: 0.3784 - accuracy: 0.8314 - val_loss: 0.3757 - val_accuracy: 0.8325\n",
      "Epoch 181/300\n",
      "2006/2006 [==============================] - 332s 165ms/step - loss: 0.3792 - accuracy: 0.8310 - val_loss: 0.3739 - val_accuracy: 0.8331\n",
      "Epoch 182/300\n",
      "2006/2006 [==============================] - 262s 131ms/step - loss: 0.3804 - accuracy: 0.8304 - val_loss: 0.3740 - val_accuracy: 0.8329\n",
      "Epoch 183/300\n",
      "2006/2006 [==============================] - 170s 85ms/step - loss: 0.3768 - accuracy: 0.8325 - val_loss: 0.3767 - val_accuracy: 0.8321\n",
      "Epoch 184/300\n",
      "2006/2006 [==============================] - 84s 42ms/step - loss: 0.3783 - accuracy: 0.8317 - val_loss: 0.3752 - val_accuracy: 0.8323\n",
      "Epoch 185/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3783 - accuracy: 0.8311 - val_loss: 0.3741 - val_accuracy: 0.8330\n",
      "Epoch 186/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3789 - accuracy: 0.8317 - val_loss: 0.3747 - val_accuracy: 0.8324\n",
      "Epoch 187/300\n",
      "2006/2006 [==============================] - 83s 41ms/step - loss: 0.3793 - accuracy: 0.8309 - val_loss: 0.3747 - val_accuracy: 0.8325\n",
      "Epoch 188/300\n",
      "2006/2006 [==============================] - 80s 40ms/step - loss: 0.3780 - accuracy: 0.8322 - val_loss: 0.3746 - val_accuracy: 0.8332\n",
      "Epoch 189/300\n",
      "2006/2006 [==============================] - 80s 40ms/step - loss: 0.3777 - accuracy: 0.8320 - val_loss: 0.3771 - val_accuracy: 0.8313\n",
      "Epoch 190/300\n",
      "2006/2006 [==============================] - 80s 40ms/step - loss: 0.3769 - accuracy: 0.8322 - val_loss: 0.3729 - val_accuracy: 0.8341\n",
      "Epoch 191/300\n",
      "2006/2006 [==============================] - 83s 41ms/step - loss: 0.3772 - accuracy: 0.8313 - val_loss: 0.3758 - val_accuracy: 0.8319\n",
      "Epoch 192/300\n",
      "2006/2006 [==============================] - 80s 40ms/step - loss: 0.3767 - accuracy: 0.8320 - val_loss: 0.3766 - val_accuracy: 0.8315\n",
      "Epoch 193/300\n",
      "2006/2006 [==============================] - 80s 40ms/step - loss: 0.3780 - accuracy: 0.8319 - val_loss: 0.3747 - val_accuracy: 0.8327\n",
      "Epoch 194/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3785 - accuracy: 0.8314 - val_loss: 0.3737 - val_accuracy: 0.8332\n",
      "Epoch 195/300\n",
      "2006/2006 [==============================] - 80s 40ms/step - loss: 0.3776 - accuracy: 0.8319 - val_loss: 0.3734 - val_accuracy: 0.8325\n",
      "Epoch 196/300\n",
      "2006/2006 [==============================] - 80s 40ms/step - loss: 0.3776 - accuracy: 0.8320 - val_loss: 0.3744 - val_accuracy: 0.8329\n",
      "Epoch 197/300\n",
      "2006/2006 [==============================] - 81s 41ms/step - loss: 0.3768 - accuracy: 0.8318 - val_loss: 0.3734 - val_accuracy: 0.8331\n",
      "Epoch 198/300\n",
      "2006/2006 [==============================] - 80s 40ms/step - loss: 0.3767 - accuracy: 0.8327 - val_loss: 0.3740 - val_accuracy: 0.8328\n",
      "Epoch 199/300\n",
      "2006/2006 [==============================] - 78s 39ms/step - loss: 0.3760 - accuracy: 0.8336 - val_loss: 0.3743 - val_accuracy: 0.8330\n",
      "Epoch 200/300\n",
      "2006/2006 [==============================] - 80s 40ms/step - loss: 0.3770 - accuracy: 0.8322 - val_loss: 0.3733 - val_accuracy: 0.8335\n",
      "Epoch 201/300\n",
      "2006/2006 [==============================] - 80s 40ms/step - loss: 0.3767 - accuracy: 0.8325 - val_loss: 0.3742 - val_accuracy: 0.8326\n",
      "Epoch 202/300\n",
      "2006/2006 [==============================] - 84s 42ms/step - loss: 0.3756 - accuracy: 0.8333 - val_loss: 0.3738 - val_accuracy: 0.8330\n",
      "Epoch 203/300\n",
      "2006/2006 [==============================] - 83s 41ms/step - loss: 0.3755 - accuracy: 0.8333 - val_loss: 0.3758 - val_accuracy: 0.8317\n",
      "Epoch 204/300\n",
      "2006/2006 [==============================] - 81s 41ms/step - loss: 0.3760 - accuracy: 0.8327 - val_loss: 0.3726 - val_accuracy: 0.8338\n",
      "Epoch 205/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3767 - accuracy: 0.8321 - val_loss: 0.3734 - val_accuracy: 0.8332\n",
      "Epoch 206/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3765 - accuracy: 0.8325 - val_loss: 0.3735 - val_accuracy: 0.8334\n",
      "Epoch 207/300\n",
      "2006/2006 [==============================] - 84s 42ms/step - loss: 0.3756 - accuracy: 0.8330 - val_loss: 0.3737 - val_accuracy: 0.8330\n",
      "Epoch 208/300\n",
      "2006/2006 [==============================] - 83s 42ms/step - loss: 0.3767 - accuracy: 0.8327 - val_loss: 0.3725 - val_accuracy: 0.8340\n",
      "Epoch 209/300\n",
      "2006/2006 [==============================] - 83s 41ms/step - loss: 0.3749 - accuracy: 0.8332 - val_loss: 0.3729 - val_accuracy: 0.8340\n",
      "Epoch 210/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3770 - accuracy: 0.8316 - val_loss: 0.3732 - val_accuracy: 0.8334\n",
      "Epoch 211/300\n",
      "2006/2006 [==============================] - 83s 41ms/step - loss: 0.3766 - accuracy: 0.8322 - val_loss: 0.3737 - val_accuracy: 0.8334\n",
      "Epoch 212/300\n",
      "2006/2006 [==============================] - 83s 41ms/step - loss: 0.3751 - accuracy: 0.8333 - val_loss: 0.3730 - val_accuracy: 0.8342\n",
      "Epoch 213/300\n",
      "2006/2006 [==============================] - 84s 42ms/step - loss: 0.3744 - accuracy: 0.8337 - val_loss: 0.3725 - val_accuracy: 0.8343\n",
      "Epoch 214/300\n",
      "2006/2006 [==============================] - 83s 42ms/step - loss: 0.3750 - accuracy: 0.8330 - val_loss: 0.3739 - val_accuracy: 0.8335\n",
      "Epoch 215/300\n",
      "2006/2006 [==============================] - 83s 41ms/step - loss: 0.3753 - accuracy: 0.8335 - val_loss: 0.3723 - val_accuracy: 0.8346\n",
      "Epoch 216/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3760 - accuracy: 0.8326 - val_loss: 0.3723 - val_accuracy: 0.8350\n",
      "Epoch 217/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3753 - accuracy: 0.8338 - val_loss: 0.3734 - val_accuracy: 0.8330\n",
      "Epoch 218/300\n",
      "2006/2006 [==============================] - 81s 41ms/step - loss: 0.3760 - accuracy: 0.8326 - val_loss: 0.3720 - val_accuracy: 0.8346\n",
      "Epoch 219/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3748 - accuracy: 0.8335 - val_loss: 0.3722 - val_accuracy: 0.8339\n",
      "Epoch 220/300\n",
      "2006/2006 [==============================] - 82s 41ms/step - loss: 0.3761 - accuracy: 0.8327 - val_loss: 0.3726 - val_accuracy: 0.8334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/300\n",
      "2006/2006 [==============================] - 83s 41ms/step - loss: 0.3748 - accuracy: 0.8338 - val_loss: 0.3742 - val_accuracy: 0.8334\n",
      "Epoch 222/300\n",
      "2006/2006 [==============================] - 89s 45ms/step - loss: 0.3754 - accuracy: 0.8325 - val_loss: 0.3723 - val_accuracy: 0.8339\n",
      "Epoch 223/300\n",
      "2006/2006 [==============================] - 89s 44ms/step - loss: 0.3727 - accuracy: 0.8345 - val_loss: 0.3732 - val_accuracy: 0.8338\n",
      "Epoch 224/300\n",
      "2006/2006 [==============================] - 89s 44ms/step - loss: 0.3754 - accuracy: 0.8335 - val_loss: 0.3713 - val_accuracy: 0.8352\n",
      "Epoch 225/300\n",
      "2006/2006 [==============================] - 91s 45ms/step - loss: 0.3734 - accuracy: 0.8344 - val_loss: 0.3723 - val_accuracy: 0.8347\n",
      "Epoch 226/300\n",
      "2006/2006 [==============================] - 95s 47ms/step - loss: 0.3744 - accuracy: 0.8333 - val_loss: 0.3716 - val_accuracy: 0.8347\n",
      "Epoch 227/300\n",
      "2006/2006 [==============================] - 180s 90ms/step - loss: 0.3755 - accuracy: 0.8328 - val_loss: 0.3744 - val_accuracy: 0.8327\n",
      "Epoch 228/300\n",
      "2006/2006 [==============================] - 285s 142ms/step - loss: 0.3737 - accuracy: 0.8345 - val_loss: 0.3729 - val_accuracy: 0.8336\n",
      "Epoch 229/300\n",
      "2006/2006 [==============================] - 230s 115ms/step - loss: 0.3742 - accuracy: 0.8340 - val_loss: 0.3766 - val_accuracy: 0.8311\n",
      "Epoch 230/300\n",
      "2006/2006 [==============================] - 288s 144ms/step - loss: 0.3732 - accuracy: 0.8343 - val_loss: 0.3724 - val_accuracy: 0.8346\n",
      "Epoch 231/300\n",
      "2006/2006 [==============================] - 317s 158ms/step - loss: 0.3733 - accuracy: 0.8346 - val_loss: 0.3751 - val_accuracy: 0.8326\n",
      "Epoch 232/300\n",
      "2006/2006 [==============================] - 245s 122ms/step - loss: 0.3740 - accuracy: 0.8343 - val_loss: 0.3714 - val_accuracy: 0.8347\n",
      "Epoch 233/300\n",
      "2006/2006 [==============================] - 292s 146ms/step - loss: 0.3736 - accuracy: 0.8337 - val_loss: 0.3718 - val_accuracy: 0.8344\n",
      "Epoch 234/300\n",
      "2006/2006 [==============================] - 248s 123ms/step - loss: 0.3744 - accuracy: 0.8338 - val_loss: 0.3716 - val_accuracy: 0.8342\n",
      "Epoch 235/300\n",
      "2006/2006 [==============================] - 307s 153ms/step - loss: 0.3733 - accuracy: 0.8345 - val_loss: 0.3737 - val_accuracy: 0.8332\n",
      "Epoch 236/300\n",
      "2006/2006 [==============================] - 328s 163ms/step - loss: 0.3746 - accuracy: 0.8333 - val_loss: 0.3714 - val_accuracy: 0.8353\n",
      "Epoch 237/300\n",
      "2006/2006 [==============================] - 264s 131ms/step - loss: 0.3731 - accuracy: 0.8347 - val_loss: 0.3724 - val_accuracy: 0.8336\n",
      "Epoch 238/300\n",
      "2006/2006 [==============================] - 352s 176ms/step - loss: 0.3734 - accuracy: 0.8342 - val_loss: 0.3727 - val_accuracy: 0.8342\n",
      "Epoch 239/300\n",
      "2006/2006 [==============================] - 281s 140ms/step - loss: 0.3745 - accuracy: 0.8336 - val_loss: 0.3742 - val_accuracy: 0.8338\n",
      "Epoch 240/300\n",
      "2006/2006 [==============================] - 225s 112ms/step - loss: 0.3752 - accuracy: 0.8335 - val_loss: 0.3723 - val_accuracy: 0.8340\n",
      "Epoch 241/300\n",
      "2006/2006 [==============================] - 195s 97ms/step - loss: 0.3728 - accuracy: 0.8344 - val_loss: 0.3713 - val_accuracy: 0.8343\n",
      "Epoch 242/300\n",
      "2006/2006 [==============================] - 131s 65ms/step - loss: 0.3729 - accuracy: 0.8340 - val_loss: 0.3714 - val_accuracy: 0.8354\n",
      "Epoch 243/300\n",
      "2006/2006 [==============================] - 107s 53ms/step - loss: 0.3724 - accuracy: 0.8351 - val_loss: 0.3707 - val_accuracy: 0.8349\n",
      "Epoch 244/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3716 - accuracy: 0.8355 - val_loss: 0.3707 - val_accuracy: 0.8346\n",
      "Epoch 245/300\n",
      "2006/2006 [==============================] - 65s 32ms/step - loss: 0.3737 - accuracy: 0.8339 - val_loss: 0.3710 - val_accuracy: 0.8350\n",
      "Epoch 246/300\n",
      "2006/2006 [==============================] - 66s 33ms/step - loss: 0.3730 - accuracy: 0.8345 - val_loss: 0.3699 - val_accuracy: 0.8348\n",
      "Epoch 247/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3729 - accuracy: 0.8345 - val_loss: 0.3727 - val_accuracy: 0.8334\n",
      "Epoch 248/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3727 - accuracy: 0.8346 - val_loss: 0.3707 - val_accuracy: 0.8352\n",
      "Epoch 249/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3737 - accuracy: 0.8343 - val_loss: 0.3714 - val_accuracy: 0.8349\n",
      "Epoch 250/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3724 - accuracy: 0.8340 - val_loss: 0.3714 - val_accuracy: 0.8349\n",
      "Epoch 251/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3719 - accuracy: 0.8344 - val_loss: 0.3699 - val_accuracy: 0.8354\n",
      "Epoch 252/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3726 - accuracy: 0.8349 - val_loss: 0.3710 - val_accuracy: 0.8349\n",
      "Epoch 253/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3727 - accuracy: 0.8348 - val_loss: 0.3720 - val_accuracy: 0.8352\n",
      "Epoch 254/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3706 - accuracy: 0.8358 - val_loss: 0.3722 - val_accuracy: 0.8345\n",
      "Epoch 255/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3732 - accuracy: 0.8345 - val_loss: 0.3695 - val_accuracy: 0.8357\n",
      "Epoch 256/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3710 - accuracy: 0.8360 - val_loss: 0.3734 - val_accuracy: 0.8331\n",
      "Epoch 257/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3707 - accuracy: 0.8352 - val_loss: 0.3693 - val_accuracy: 0.8354\n",
      "Epoch 258/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3708 - accuracy: 0.8362 - val_loss: 0.3712 - val_accuracy: 0.8347\n",
      "Epoch 259/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3731 - accuracy: 0.8343 - val_loss: 0.3701 - val_accuracy: 0.8353\n",
      "Epoch 260/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3715 - accuracy: 0.8352 - val_loss: 0.3706 - val_accuracy: 0.8352\n",
      "Epoch 261/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3713 - accuracy: 0.8350 - val_loss: 0.3705 - val_accuracy: 0.8351\n",
      "Epoch 262/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3714 - accuracy: 0.8354 - val_loss: 0.3710 - val_accuracy: 0.8352\n",
      "Epoch 263/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3714 - accuracy: 0.8354 - val_loss: 0.3700 - val_accuracy: 0.8356\n",
      "Epoch 264/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3718 - accuracy: 0.8352 - val_loss: 0.3702 - val_accuracy: 0.8349\n",
      "Epoch 265/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3711 - accuracy: 0.8351 - val_loss: 0.3711 - val_accuracy: 0.8353\n",
      "Epoch 266/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3714 - accuracy: 0.8346 - val_loss: 0.3704 - val_accuracy: 0.8352\n",
      "Epoch 267/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3717 - accuracy: 0.8354 - val_loss: 0.3730 - val_accuracy: 0.8336\n",
      "Epoch 268/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3712 - accuracy: 0.8348 - val_loss: 0.3699 - val_accuracy: 0.8349\n",
      "Epoch 269/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3706 - accuracy: 0.8351 - val_loss: 0.3698 - val_accuracy: 0.8358\n",
      "Epoch 270/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3708 - accuracy: 0.8355 - val_loss: 0.3690 - val_accuracy: 0.8361\n",
      "Epoch 271/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3695 - accuracy: 0.8359 - val_loss: 0.3697 - val_accuracy: 0.8359\n",
      "Epoch 272/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3714 - accuracy: 0.8359 - val_loss: 0.3702 - val_accuracy: 0.8353\n",
      "Epoch 273/300\n",
      "2006/2006 [==============================] - 67s 34ms/step - loss: 0.3700 - accuracy: 0.8357 - val_loss: 0.3694 - val_accuracy: 0.8361\n",
      "Epoch 274/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3697 - accuracy: 0.8353 - val_loss: 0.3692 - val_accuracy: 0.8360\n",
      "Epoch 275/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3704 - accuracy: 0.8359 - val_loss: 0.3709 - val_accuracy: 0.8349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3696 - accuracy: 0.8354 - val_loss: 0.3706 - val_accuracy: 0.8352\n",
      "Epoch 277/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3693 - accuracy: 0.8353 - val_loss: 0.3693 - val_accuracy: 0.8352\n",
      "Epoch 278/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3720 - accuracy: 0.8350 - val_loss: 0.3697 - val_accuracy: 0.8360\n",
      "Epoch 279/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3700 - accuracy: 0.8359 - val_loss: 0.3720 - val_accuracy: 0.8348\n",
      "Epoch 280/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3701 - accuracy: 0.8360 - val_loss: 0.3695 - val_accuracy: 0.8363\n",
      "Epoch 281/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3698 - accuracy: 0.8358 - val_loss: 0.3692 - val_accuracy: 0.8358\n",
      "Epoch 282/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3716 - accuracy: 0.8356 - val_loss: 0.3706 - val_accuracy: 0.8349\n",
      "Epoch 283/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3707 - accuracy: 0.8359 - val_loss: 0.3696 - val_accuracy: 0.8353\n",
      "Epoch 284/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3685 - accuracy: 0.8364 - val_loss: 0.3698 - val_accuracy: 0.8348\n",
      "Epoch 285/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3703 - accuracy: 0.8357 - val_loss: 0.3685 - val_accuracy: 0.8363\n",
      "Epoch 286/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3707 - accuracy: 0.8354 - val_loss: 0.3689 - val_accuracy: 0.8358\n",
      "Epoch 287/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3701 - accuracy: 0.8354 - val_loss: 0.3709 - val_accuracy: 0.8348\n",
      "Epoch 288/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3696 - accuracy: 0.8366 - val_loss: 0.3701 - val_accuracy: 0.8353\n",
      "Epoch 289/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3708 - accuracy: 0.8353 - val_loss: 0.3695 - val_accuracy: 0.8359\n",
      "Epoch 290/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3695 - accuracy: 0.8359 - val_loss: 0.3687 - val_accuracy: 0.8367\n",
      "Epoch 291/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3703 - accuracy: 0.8358 - val_loss: 0.3692 - val_accuracy: 0.8363\n",
      "Epoch 292/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3701 - accuracy: 0.8363 - val_loss: 0.3693 - val_accuracy: 0.8354\n",
      "Epoch 293/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3687 - accuracy: 0.8364 - val_loss: 0.3693 - val_accuracy: 0.8360\n",
      "Epoch 294/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3679 - accuracy: 0.8367 - val_loss: 0.3696 - val_accuracy: 0.8364\n",
      "Epoch 295/300\n",
      "2006/2006 [==============================] - 68s 34ms/step - loss: 0.3678 - accuracy: 0.8373 - val_loss: 0.3698 - val_accuracy: 0.8359\n",
      "Epoch 296/300\n",
      "2006/2006 [==============================] - 71s 35ms/step - loss: 0.3698 - accuracy: 0.8358 - val_loss: 0.3684 - val_accuracy: 0.8363\n",
      "Epoch 297/300\n",
      "2006/2006 [==============================] - 75s 38ms/step - loss: 0.3689 - accuracy: 0.8370 - val_loss: 0.3682 - val_accuracy: 0.8364\n",
      "Epoch 298/300\n",
      "2006/2006 [==============================] - 74s 37ms/step - loss: 0.3706 - accuracy: 0.8352 - val_loss: 0.3696 - val_accuracy: 0.8365\n",
      "Epoch 299/300\n",
      "2006/2006 [==============================] - 76s 38ms/step - loss: 0.3685 - accuracy: 0.8370 - val_loss: 0.3691 - val_accuracy: 0.8360\n",
      "Epoch 300/300\n",
      "2006/2006 [==============================] - 76s 38ms/step - loss: 0.3689 - accuracy: 0.8366 - val_loss: 0.3695 - val_accuracy: 0.8359\n"
     ]
    }
   ],
   "source": [
    "history = model_high.fit([pep_train, aa_train, en_train, ec_train, e1_train, e2_train],\n",
    "                    y_train, \n",
    "                    epochs=300,\n",
    "                    batch_size=256,\n",
    "                    validation_data=([pep_val, aa_val, en_val, ec_val, e1_val, e2_val], y_val),\n",
    "                    callbacks=[es]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:14:57.684993Z",
     "start_time": "2021-10-20T12:14:57.467522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,2))\n",
    "plt.subplot(1,2,1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.subplot(1,2,2)\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T12:20:12.709709Z",
     "start_time": "2021-10-20T12:14:59.607138Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4038/4038 [==============================] - 215s 53ms/step - loss: 0.3705 - accuracy: 0.8341\n",
      "Test Loss: 0.370479553937912\n",
      "Test Accuracy: 0.8341150283813477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83     64602\n",
      "           1       0.81      0.88      0.84     64602\n",
      "\n",
      "    accuracy                           0.83    129204\n",
      "   macro avg       0.84      0.83      0.83    129204\n",
      "weighted avg       0.84      0.83      0.83    129204\n",
      "\n",
      "rf auc : 0.9170031519801578\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARIAAAEWCAYAAACqphg1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAhBklEQVR4nO3deZhV9X3H8feHLYAie5rIEhDRAAZQRqkmtqBxQ01CgwFMW5s2j5pqGtM2wSxNaZKmTWOzWE0MjZaYCrhFYyxRI8RgEjdURMAlrAIBRVREFGHg2z/OmeEyzHJmzpyZuTOf1/PcZ+4553fP+c7o/fA72+8oIjAzy6NTaxdgZuXPQWJmuTlIzCw3B4mZ5eYgMbPcHCRmlpuDxMxyc5B0QJLWS3pL0huStkqaK+nwGm1OkbRY0k5JOyT9XNLoGm2OkPRdSS+k61qdTg9o2d/IWpuDpOM6PyIOB8YDxwNfqFog6WTgPuBnwJHAcOAp4LeSjkrbdAMWAWOAs4EjgFOA7cBJRRUtqUtR67amc5B0cBGxFbiXJFCq/AdwY0R8LyJ2RsQrEfFl4GFgdtrmL4GhwNSIWBUR+yPipYj4WkQsrG1bksZI+qWkVyS9KOmL6fy5kr5e0m6SpE0l0+slzZK0HNgl6cuSbqux7u9Jujp931vS9ZK2SNos6euSOuf7S1l9HCQdnKTBwDnA6nS6J0nP4tZamt8CnJG+/yBwT0S8kXE7vYD7gXtIejlHk/RospoJnAv0AX4CTJF0RLruzsDHgHlp2x8Dlek2jgfOBD7ZiG1ZIzlIOq47Je0ENgIvAf+czu9H8v/Fllo+swWoOv7Rv442dTkP2BoR/xkRu9OeziON+PzVEbExIt6KiA3AE8BH0mWnAW9GxMOS/ogkGK+IiF0R8RLwHWBGI7ZljeQg6bg+EhG9gEnAezkQEK8C+4F31/KZdwMvp++319GmLkOANU2qNLGxxvQ8kl4KwIUc6I28B+gKbJH0mqTXgB8C78yxbWuAg6SDi4hfA3OBq9LpXcBDwAW1NP8YB3ZH7gfOknRYxk1tBEbUsWwX0LNk+l21lVpj+lZgUrprNpUDQbIReBsYEBF90tcRETEmY53WBA4SA/gucIak8en0lcBFkv5OUi9JfdODoScD/5K2+QnJl/Z2Se+V1ElSf0lflDSllm3cDbxL0hWS3pGud2K6bBnJMY9+kt4FXNFQwRGxDXgA+B9gXUQ8k87fQnLG6T/T09OdJI2Q9KeN/JtYIzhIrOpLeSPwT+n0b4CzgD8jOQ6ygeSg5Qci4vdpm7dJDrg+C/wSeB14lGQX6ZBjHxGxk+RA7fnAVuD3wOR08U9ITi+vJwmBmzOWPi+tYV6N+X8JdANWkeyq3UbjdsOskeSBjcwsL/dIzCw3B4mZ5eYgMbPcHCRmllvZ3QA1YMCAGDZsWGuXYdbhPP744y9HxMDalpVdkAwbNoylS5e2dhlmHY6kDXUt866NmeXmIDGz3BwkZpabg8TMcnOQmFluhQWJpBskvSRpRR3LJenqdMDg5ZJOKKoWMytWkad/5wLXkNxVWptzgJHpayLwg/SnWXm7+QjYt7OZV9oZ2Hdgsms/qNwJUQmdukLnw2HvKyXtBV0Oh317IN4+MLvne2DgB+CFW0BK17MDBp4Kp93b5OoKC5KIWCJpWD1NPkwywHAAD0vqI+nd6XgSZvn8fDTsfKa1q2hG+w6eLA2N/Xtg/ysHLyeSoKnpzQ2wYUN1E97emrzfeh8sPqvJYdKaF6QN4uDh8zal8w4JEkkXAxcDDB06tEWKszZknlq7go5h24NN/mhrBklt/3fUOjhKRMwB5gBUVFR4AJX2xCHRdgw8tckfbc0g2UQyIHCVwcAfWqkWK8ris5Jus+XUQY+RZHAXcLmkBSQHWXf4+EiZc+/iYO86M9eXs1Dv/99mXV1hQSJpPsmjDgakT037Z5LHBBAR1wELgSkkD2Z6E/hEUbVYAcopNC703nDRijxrM7OB5QFcVtT2rRm1pdBwKLRJZTeMgLWA1goOh0TZcpBYywWHg6LdcpB0VEWHh0OjQ3GQdDRFBIhDo8NzkLR38zpRx3V+TePQsFo4SNqr5up5ODgsAwdJe9Ic4eHgsCZwkLQHeQPE4WE5OUjKVd7w6DUKzl/VPLVYh+cgKTd5AsQ9DyuIg6RcNDVAOveC6a83by1mNThI2rqmBoh7H9aCHCRtlQPEyoiDpK1pSoA4PKyVOUjaiidnwTP/0bjPOECsjXCQtAWN7YU4QKyNcZC0JgeItRMOktbSmBBxgFgb5yBpaY05FuIAsTLhIGlJWXshDhArM4U9RNxqcIhYO+YeSUvIEiIOECtj7pEUzSFiHYB7JEVqKEQcINZOuEdSFIeIdSAOkiI4RKyDcZA0N4eIdUAOkubkELEOykHSXBwi1oE5SJqDQ8Q6OAdJXg4Rs2KDRNLZkp6TtFrSlbUs7y3p55KekrRS0ieKrKfZOUTMgAKDRFJn4FrgHGA0MFPS6BrNLgNWRcQ4YBLwn5K6FVVTi3KIWAdSZI/kJGB1RKyNiD3AAuDDNdoE0EuSgMOBV4DKAmtqPvX1Rhwi1sEUGSSDgI0l05vSeaWuAUYBfwCeBj4TEftrrkjSxZKWSlq6bdu2ourNziFidpAig6S2b1vNb9lZwDLgSGA8cI2kIw75UMSciKiIiIqBAwc2d52NU1+IvONdLVeHWRtSZJBsAoaUTA8m6XmU+gTw00isBtYB7y2wpmJ9dEtrV2DWKooMkseAkZKGpwdQZwB31WjzAnA6gKQ/Ao4F1hZYUz7epTGrVWHDCEREpaTLgXuBzsANEbFS0qXp8uuArwFzJT1Nsis0KyJeLqqmXJ6cVfcyh4h1cIWORxIRC4GFNeZdV/L+D8CZRdbQbBr78CqzDsRXtmbhXRqzejlI8nCImAEOkoY15aHeZh2Mg6Sp3Bsxq+YgqY97I2aZOEiawr0Rs4M4SOri3ohZZg6SxnJvxOwQDpLaLD6rtSswKysOktpsva/2+e6NmNUqc5BIOqzIQsysfDUYJJJOkbQKeCadHifp+4VX1lrqOsjq3ohZnbL0SL5DMgDRdoCIeAr4kyKLMrPykmnXJiI21pi1r4BaWp9P+Zo1SZZhBDZKOgWIdICivyPdzekwvFtjVq8sPZJLSR4bMYhk+MTxwN8WWJOZlZksPZJjI+LjpTMkvR/4bTEltRIfZDVrsiw9kv/KOM/MOqg6eySSTgZOAQZK+vuSRUeQjMFqZgbUv2vTjeTpd12AXiXzXwemFVlUi/NujVkudQZJRPwa+LWkuRGxoQVrMrMyk+Vg65uSvgWMAbpXzYyI0wqryszKSpaDrTcBzwLDgX8B1pM8/Kp98G6NWW5ZgqR/RFwP7I2IX0fEXwN/XHBdZlZGsuza7E1/bpF0LsnzewcXV5KZlZssQfJ1Sb2BfyC5fuQI4Ioii2p13q0xa5QGgyQi7k7f7gAmQ/WVreXPN+mZNYv6LkjrDHyM5B6beyJihaTzgC8CPYDjW6ZEM2vr6uuRXA8MAR4Frpa0ATgZuDIi7myB2sysTNQXJBXA2IjYL6k78DJwdERsbZnSWomPj5g1Wn2nf/dExH6AiNgNPN/YEJF0tqTnJK2WdGUdbSZJWiZppaRfN2b9ufj4iFmzqa9H8l5Jy9P3Akak0wIiIsbWt+L0GMu1wBkk45g8JumuiFhV0qYP8H3g7Ih4QdI7m/6rmFlrqS9IRuVc90nA6ohYCyBpAfBhYFVJmwuBn0bECwAR8VLObZpZK6jvpr28N+oNAkrHet0ETKzR5higq6QHSO4w/l5E3FhzRZIuBi4GGDp0aM6y6uHjI2ZNUuQDsmo7CFHzm9oFmACcSzJS/T9JOuaQD0XMiYiKiKgYOHBg81dqZrlkubK1qTaRnD6uMpjk8vqabV6OiF3ALklLgHHA8wXW5QOtZs0sU49EUg9JxzZy3Y8BIyUNT0efnwHcVaPNz4BTJXWR1JNk16djjVBv1g5kedLe+cAy4J50erykmoFwiIioBC4H7iUJh1siYqWkSyVdmrZ5Jl3vcpIL334UESua+Lvk5NEjzZoqy67NbJIzMA8ARMQyScOyrDwiFgILa8y7rsb0t4BvZVlfoS6sbO0KzMpWll2byojYUXglZla2svRIVki6EOgsaSTJk/Z+V2xZBfKBVrNml6VH8mmS8VrfBuaRDCdwRYE1mVmZyfqkvS8BXyq6GDMrT1l6JN+W9Kykr0kaU3hFrcFXtJrl0mCQRMRkYBKwDZgj6WlJXy66MDMrH5kuSIuIrRFxNXApyTUlXymyKDMrL1kuSBslabakFcA1JGdsynMUeZ+xMStEloOt/wPMB86MiJr3ypiZZRpF3g/DMrN61TeK/C0R8TFJT3Pw7f+ZRkgrGz5jY5ZbfT2Sz6Q/z2uJQsysfNV5sDUitqRv/zYiNpS+gL9tmfLMrBxkOf17Ri3zzmnuQgp38xGtXYFZu1XfMZJPkfQ8jioZTR6SsVV/W3RhzW7fztauwKzdqu8YyTzgF8C/AaXPpNkZEa8UWpWZlZX6giQiYr2ky2oukNSvXYSJz9iYNYuGeiTnAY+TnP4tvSw0gKMKrMvMykh9z7U5L/05vOXKMbNylOVem/dLOix9/+eSvi2pwKdUmVm5yXL69wfAm5LGAZ8HNgA/KbQqMysrWQd/DpLn9n4vIr5HcgrYzAzIdvfvTklfAP6C5GFWnYGuxZbVzDx8gFmhsvRIppMM/PzXEbGV5OHgrf8cGjNrM7IMtbgVuAnoLek8YHdE3Fh4ZWZWNrKctfkYyeM0LwA+BjwiaVrRhRXOF6OZNZssx0i+BJwYES8BSBoI3A/cVmRhZlY+shwj6VQVIqntGT9nZh1Elh7JPZLuJRm3FZKDrwvraW9mHUyWMVs/J+nPgA+Q3G8zJyLuKLwyMysb9Y1HMhK4ChgBPA38Y0RsbqnCzKx81Hes4wbgbuCjJHcA/1djVy7pbEnPSVot6cp62p0oaV+7OBtk1gHVt2vTKyL+O33/nKQnGrPi9ArYa0mGatwEPCbprohYVUu7bwL3Nmb9mfmqVrPC1Rck3SUdz4FxSHqUTkdEQ8FyErA6ItYCSFpAcr/OqhrtPg3cDpzYyNrNrI2oL0i2AN8umd5aMh3AaQ2sexCwsWR6EzCxtIGkQcDUdF11Bomki4GLAYYObYYRDEZ9Pv86zKxafQMbTc657tr2KWpeTvpdYFZE7JPq3gWJiDnAHICKior8l6Qe/83cqzCzA7JcR9JUm4AhJdODgZrPDq4AFqQhMgCYIqkyIu4ssC4za2ZFBsljwEhJw4HNwAzgwtIGpcM4SpoL3O0QMSs/hQVJRFRKupzkbExn4IaIWCnp0nT5dUVt28xaVoNBomS/4+PAURHx1XS81ndFxKMNfTYiFlLjcvq6AiQi/ipTxWbW5mS5+e77wMnAzHR6J8n1IWZmQLZdm4kRcYKkJwEi4lVJ3Qquy8zKSJYeyd706tOA6vFI9hdalZmVlSxBcjVwB/BOSf8K/Ab4RqFVNRdfHm/WIrIMI3CTpMeB00kuMvtIRDxTeGVmVjaynLUZCrwJ/Lx0XkS8UGRhZlY+shxs/T8OPES8OzAceA4YU2BdxfGgz2bNLsuuzftKpyWdAFxSWEVmVnYaPYhzOnyAb/k3s2pZjpH8fclkJ+AEYFthFZlZ2clyjKT0geGVJMdMbi+mHDMrR/UGSXoh2uER8bkWqsfMylCdx0gkdYmIfSS7MmZmdaqvR/IoSYgsk3QXcCuwq2phRPy04NrMrExkOUbSj+Qxnadx4HqSABwkZgbUHyTvTM/YrOBAgFTxVV1mVq2+IOkMHE62QZzNrAOr93EUEfHVFqvEzMpWfVe2lvc9+B5CwKzF1Bckp7dYFWZW1uoMkoh4pSULaRG9RrV2BWbtUqNv2itr59d87LCZNYeOFSRmVggHiZnl5iAxs9wcJGaWm4PEzHJzkJhZbg4SM8vNQWJmuRUaJJLOlvScpNWSrqxl+cclLU9fv5M0rsh6zKwYhQVJOt7rtcA5wGhgpqTRNZqtA/40IsYCXwPmFFWPmRWnyB7JScDqiFgbEXuABcCHSxtExO8i4tV08mFgcIH1mFlBigySQcDGkulN6by6/A3wi9oWSLpY0lJJS7dt8yN1zNqaIoMk88hqkiaTBMms2pZHxJyIqIiIioEDBzZjiWbWHLIM/txUm4AhJdODgT/UbCRpLPAj4JyI2F5gPWZWkCJ7JI8BIyUNl9QNmAHcVdpA0lCS0ej/IiKeL7AWMytQYT2SiKiUdDlwL8lA0jdExEpJl6bLrwO+AvQHvi8JoDIiKnJv3MMsmrWoIndtiIiFwMIa864ref9J4JNF1mBmxes4V7Z27dfaFZi1Wx0nSC7wcVyzonScIDGzwjhIzCw3B4mZ5eYgMbPcHCRmlpuDxMxyc5CYWW4OEjPLzUFiZrk5SMwsNweJmeXmIDGz3BwkZpabg8TMcnOQmFluDhIzy81BYma5OUjMLDcHiZnlVugo8tb+7N27l02bNrF79+7WLsUK0r17dwYPHkzXrl0zf8ZBYo2yadMmevXqxbBhw0ifRWTtSESwfft2Nm3axPDhwzN/zrs21ii7d++mf//+DpF2ShL9+/dvdI/TQWKN5hBp35ry37f9Bcnt727tCsw6nPYXJG9vbe0KrGCdO3dm/PjxHHfccZx//vm89tprAKxfv54ePXowfvz46teePXtqXcdnPvMZBg0axP79+6vnzZ49m6uuuuqgdsOGDePll18GYOvWrcyYMYMRI0YwevRopkyZwvPPP5/rd3n77beZPn06Rx99NBMnTmT9+vW1trv55psZO3YsY8aM4fOf/3z1/CVLlnDCCSfQpUsXbrvttur5v/rVrw76O3Tv3p0777wTgHXr1jFx4kRGjhzJ9OnT6/wbNUb7CxJre7Y9BCv/LfnZDHr06MGyZctYsWIF/fr149prr61eNmLECJYtW1b96tat2yGf379/P3fccQdDhgxhyZIlmbYZEUydOpVJkyaxZs0aVq1axTe+8Q1efPHFXL/L9ddfT9++fVm9ejWf/exnmTVr1iFttm/fzuc+9zkWLVrEypUrefHFF1m0aBEAQ4cOZe7cuVx44YUHfWby5MnVf4PFixfTs2dPzjzzTABmzZrFZz/7WX7/+9/Tt29frr/++ly/A3SUszYXRmtX0D49fgW8uqz+Nnt3wKvLgf1AJ+g7Frr2rrt93/Ew4buZSzj55JNZvnx55vaQ/Gt93HHHMX36dObPn8+kSZMyfaZr165ceuml1fPGjx/fqO3W5mc/+xmzZ88GYNq0aVx++eVExEHHKdauXcsxxxzDwIEDAfjgBz/I7bffzumnn86wYcMA6NSp7j7BbbfdxjnnnEPPnj2JCBYvXsy8efMAuOiii5g9ezaf+tSncv0e7pFYsfbsIAkRkp97djTbqvft28eiRYv40Ic+VD1vzZo11d35yy67rNbPzZ8/n5kzZzJ16lTuvvtu9u7d2+C2VqxYwYQJEzLVdeqppx60W1H1uv/++w9pu3nzZoYMGQJAly5d6N27N9u3H/yc6qOPPppnn32W9evXU1lZyZ133snGjRsz1QKwYMECZs6cCSS9mz59+tClS9KHGDx4MJs3b868rrp0jB6JFSNLz2HbQ7D4dNi/Bzp1g1NugoEn59rsW2+9xfjx41m/fj0TJkzgjDPOqF5WtWtTlz179rBw4UK+853v0KtXLyZOnMh9993HueeeW+fZisaexXjwwQczt404tLdcc3t9+/blBz/4AdOnT6dTp06ccsoprF27NtP6t2zZwtNPP81ZZ52VeXtNUWiPRNLZkp6TtFrSlbUsl6Sr0+XLJZ1QZD3WCgaeDKctgrFfS37mDBE4cIxkw4YN7Nmz56BjJA2555572LFjB+973/sYNmwYv/nNb5g/fz4A/fv359VXXz2o/c6dO+nTpw9jxozh8ccfz7SNxvRIBg8eXN27qKysZMeOHfTr1++Qdueffz6PPPIIDz30EMceeywjR47MVMstt9zC1KlTq69SHTBgAK+99hqVlZVAcoHhkUcemWld9YqIQl5AZ2ANcBTQDXgKGF2jzRTgF4CAPwYeaWi9EyZMiHrdxKEvazarVq1q7RLisMMOq37/xBNPxJAhQ2LPnj2xbt26GDNmTL2fnTFjRsybN696+o033oiBAwfGrl274qmnnorjjjsuXn/99YiIuP3222Py5MkREbF///446aSTYs6cOdWfffTRR+OBBx7I9btcc801cckll0RExPz58+OCCy6otd2LL74YERGvvPJKjBs3Lp577rmDll900UVx6623HvK5iRMnxuLFiw+aN23atJg/f35ERFxyySVx7bXXHvK52v47A0ujru97XQvyvoCTgXtLpr8AfKFGmx8CM0umnwPeXd96HSStq60FSUTEeeedFzfeeGODQbJr167o27dv7Nix46D5U6dOjQULFkRExHXXXRdjx46NcePGxRlnnBFr1qypbrd58+a44IIL4qijjorRo0fHlClT4vnnn8/1u7z11lsxbdq0GDFiRJx44okHbW/cuHHV72fMmBGjRo2KUaNGVYdARBJmgwYNip49e0a/fv1i9OjR1cvWrVsXRx55ZOzbt++gba5ZsyZOPPHEGDFiREybNi127959SF2NDRJFLftMzUHSNODsiPhkOv0XwMSIuLykzd3Av0fEb9LpRcCsiFhaY10XAxcDDB06dMKGDRvq3vC8Wvb3fNam2TzzzDOMGjWqtcuwgtX231nS4xFRUVv7Io+R1HYEp+Y3OksbImJORFREREXVKbA6de1X/7SZNbsig2QTMKRkejDwhya0aZwLth8Ij679kmkzK1SRp38fA0ZKGg5sBmYAF9ZocxdwuaQFwERgR0Rsyb1lh0ehosYFU9a+NOVwR2FBEhGVki4H7iU5g3NDRKyUdGm6/DpgIcmZm9XAm8AniqrHmkf37t3Zvn27hxJopyIdj6R79+6N+lxhB1uLUlFREUuXLm24oRXCI6S1f3WNkFbfwVZf2WqN0rVr10aNnGUdg++1MbPcHCRmlpuDxMxyK7uDrZK2AfVc2lptAPByweXk5Rrza+v1QduvMWt974mIWq8ILbsgyUrS0rqOMLcVrjG/tl4ftP0am6M+79qYWW4OEjPLrT0HyZzWLiAD15hfW68P2n6Nuetrt8dIzKzltOceiZm1EAeJmeVW9kFSDgNMZ6jx42ltyyX9TtK4tlRfSbsTJe1LR79rUVlqlDRJ0jJJKyX9ui3VJ6m3pJ9Leiqtr0XvdJd0g6SXJK2oY3m+70ldYzCWw4uCBphuhRpPAfqm789pyRqz1FfSbjHJ0A/T2uDfsA+wChiaTr+zjdX3ReCb6fuBwCtAtxas8U+AE4AVdSzP9T0p9x7JScDqiFgbEXuABcCHa7T5MHBjJB4G+khqySeNN1hjRPwuIqqeg/AwyUhxbaa+1KeB24GXWrC2KllqvBD4aUS8ABARLVlnlvoC6KVkEJfDSYKksqUKjIgl6Tbrkut7Uu5BMggofeTYpnReY9sUqbHb/xuSfxlaSoP1SRoETAWua8G6SmX5Gx4D9JX0gKTHJf1li1WXrb5rgFEkQ4k+DXwmIvbTduT6npT7eCTNNsB0gTJvX9JkkiD5QKEV1dhsLfNq1vddktH997XSqGhZauwCTABOB3oAD0l6OCKeL7o4stV3FrAMOA0YAfxS0oMR8XrBtWWV63tS7kHSOgNMN06m7UsaC/wIOCciWnLQ2Sz1VQAL0hAZAEyRVBkRd7ZIhdn/O78cEbuAXZKWAOOAlgiSLPV9guTRKwGslrQOeC/waAvUl0W+70lLHewp6ABSF2AtMJwDB7nG1GhzLgcfRHq0DdY4lGTc2lPa4t+wRvu5tPzB1ix/w1HAorRtT2AFcFwbqu8HwOz0/R+RDIg+oIX/jsOo+2Brru9JWfdIogwGmM5Y41eA/sD303/1K6OF7hbNWF+rylJjRDwj6R5gObAf+FFE1HqqszXqA74GzJX0NMmXdVZEtNjQApLmA5OAAZI2Af8MdC2pL9f3xJfIm1lu5X7WxszaAAeJmeXmIDGz3BwkZpabg8TMcnOQlKn0LtxlJa9h9bR9oxm2N1fSunRbT0g6uQnr+JGk0en7L9ZY9ru8Nabrqfq7rEjvtu3TQPvxkqY0x7Y7Mp/+LVOS3oiIw5u7bT3rmAvcHRG3SToTuCoixuZYX+6aGlqvpB8Dz0fEv9bT/q+Aioi4vLlr6UjcI2knJB0uaVHaW3ha0iF38Ep6t6QlJf9in5rOP1PSQ+lnb5XU0Bd8CXB0+tm/T9e1QtIV6bzDJP1fOvbGCknT0/kPSKqQ9O9Aj7SOm9Jlb6Q/by7tIaQ9oY9K6izpW5IeS8fLuCTDn+Uh0hvPJJ2kZKyXJ9Ofx0rqBnwVmJ7WMj2t/YZ0O0/W9ne0WrTkJbp+NevlzvtIbgJbBtxBcpn2EemyASRXKFb1ON9If/4D8KX0fWegV9p2CXBYOn8W8JVatjeX9NJ44ALgEZKb5J4GDiO5NX4lcDzwUeC/Sz7bO/35AMm//tU1lbSpqnEq8OP0fTeSO1J7ABcDX07nvwNYCgyvpc43Sn6/W4Gz0+kjgC7p+w8Ct6fv/wq4puTz3wD+PH3fh+RencNa+793W3+V9SXyHdxbETG+akJSV+Abkv6E5BLxQST3dGwt+cxjwA1p2zsjYpmkPwVGA79NL8/vRvIveW2+JenLwDaSu5RPB+6I5EY5JP0UOBW4B7hK0jdJdocebMTv9QvgaknvAM4GlkTEW+nu1FgdGJ2tNzASWFfj8z0kLSO5r+Rx4Jcl7X8saSTJXa1d69j+mcCHJP1jOt2d5F6oZxrxO3Q4DpL24+MkI29NiIi9ktaTfAmqRcSSNGjOBX4i6VvAq8AvI2Jmhm18LiJuq5qQ9MHaGkXE85ImkNy78W+S7ouIr2b5JSJit6QHSG67nw7Mr9oc8OmIuLeBVbwVEeMl9QbuBi4Dria51+VXETE1PTD9QB2fF/DRiHguS72W8DGS9qM38FIaIpOB99RsIOk9aZv/Bq4nGXrvYeD9kqqOefSUdEzGbS4BPpJ+5jCS3ZIHJR0JvBkR/wtclW6npr1pz6g2C0huGjuV5EY40p+fqvqMpGPSbdYqInYAfwf8Y/qZ3iR33EKyO1NlJ8kuXpV7gU8r7Z5JOr6ubdgBDpL24yagQtJSkt7Js7W0mQQsk/QkyXGM70XENpIv1nxJy0mC5b1ZNhgRT5AcO3mU5JjJjyLiSeB9wKPpLsaXgK/X8vE5wPKqg6013Ecyxuj9kQxdCMlYLauAJ5QMYPxDGuhRp7U8BcwA/oOkd/RbkuMnVX4FjK462ErSc+ma1rYinbYG+PSvmeXmHomZ5eYgMbPcHCRmlpuDxMxyc5CYWW4OEjPLzUFiZrn9P7xR1ZaJTBgaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loss, test_acc = model_high.evaluate([pep_test, aa_test, en_test, ec_test, e1_test, e2_test], y_test)\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "# prediction\n",
    "y_pred = [1 if i>=0.5 else 0 for i in model_high.predict([pep_test, aa_test, en_test, ec_test, e1_test, e2_test])]\n",
    "print(classification_report(y_test, y_pred))\n",
    "# AUC\n",
    "probs = model_high.predict([pep_test, aa_test, en_test, ec_test, e1_test, e2_test])\n",
    "rf_auc = roc_auc_score(y_test, probs)\n",
    "print('rf auc : {}'.format(rf_auc))\n",
    "# plot the roc curve for the model_high\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, probs)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='RF AUC = {:.4f}'.format(rf_auc), color='orange')\n",
    "plt.title('ROC curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=',.0f')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* my : Acc 0.873 AUC 0.949\n",
    "\n",
    "    * CNN + LSTM : Acc 0.867, AUC 0.943\n",
    "    * DeepMSpeptide : Acc 0.854 AUC 0.933\n",
    "    * AP3 : Acc 0.83 AUC 0.913\n",
    "    * PepFormer : Acc 0.867  AUC 0.941"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2.4",
   "language": "python",
   "name": "tf2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
