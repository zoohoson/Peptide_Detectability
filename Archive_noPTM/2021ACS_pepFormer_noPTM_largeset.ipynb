{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:27:03.116227Z",
     "start_time": "2021-10-19T23:27:01.991853Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:27:04.537447Z",
     "start_time": "2021-10-19T23:27:03.118190Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import time\n",
    "import pickle\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:27:08.291497Z",
     "start_time": "2021-10-19T23:27:08.284359Z"
    }
   },
   "outputs": [],
   "source": [
    "def genData(file,max_len):\n",
    "    aa_dict={'A':1,'R':2,'N':3,'D':4,'C':5,'Q':6,'E':7,'G':8,'H':9,'I':10,\n",
    "             'L':11,'K':12,'M':13,'F':14,'P':15,'O':16,'S':17,'U':18,'T':19,\n",
    "             'W':20,'Y':21,'V':22,'X':23}\n",
    "    with open(file, 'r') as inf:\n",
    "        lines = inf.read().splitlines()\n",
    "        \n",
    "    long_pep_counter=0\n",
    "    pep_codes=[]\n",
    "    labels=[]\n",
    "    for pep in lines:\n",
    "        pep,label=pep.split(\",\")\n",
    "        labels.append(int(label))\n",
    "        if not len(pep) > max_len:\n",
    "            current_pep=[]\n",
    "            for aa in pep:\n",
    "                current_pep.append(aa_dict[aa])\n",
    "            pep_codes.append(torch.tensor(current_pep))\n",
    "        else:\n",
    "            long_pep_counter += 1\n",
    "    print(\"length > {}:\".format(max_len),long_pep_counter)\n",
    "    data = rnn_utils.pad_sequence(pep_codes, batch_first=True)  # padding\n",
    "    return data,torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:27:25.001547Z",
     "start_time": "2021-10-19T23:27:24.997104Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        acc_sum += (outputs.argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "def to_log(log):\n",
    "    with open(\"../compareModel/2021ACS_PepFormer/modelLog.log\",\"a+\") as f:\n",
    "        f.write(log+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:27:28.138306Z",
     "start_time": "2021-10-19T23:27:28.131858Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    seq1_ls=[]\n",
    "    seq2_ls=[]\n",
    "    label1_ls=[]\n",
    "    label2_ls=[]\n",
    "    label_ls=[]\n",
    "    batch_size=len(batch)\n",
    "    for i in range(int(batch_size/2)):\n",
    "        seq1,label1=batch[i][0],batch[i][1]\n",
    "        seq2,label2=batch[i+int(batch_size/2)][0],batch[i+int(batch_size/2)][1]\n",
    "        label1_ls.append(label1.unsqueeze(0))\n",
    "        label2_ls.append(label2.unsqueeze(0))\n",
    "        label=(label1^label2)\n",
    "        seq1_ls.append(seq1.unsqueeze(0))\n",
    "        seq2_ls.append(seq2.unsqueeze(0))\n",
    "        label_ls.append(label.unsqueeze(0))\n",
    "    seq1=torch.cat(seq1_ls).to(device)\n",
    "    seq2=torch.cat(seq2_ls).to(device)\n",
    "    label=torch.cat(label_ls).to(device)\n",
    "    label1=torch.cat(label1_ls).to(device)\n",
    "    label2=torch.cat(label2_ls).to(device)\n",
    "    return seq1,seq2,label,label1,label2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Data X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:27:57.407089Z",
     "start_time": "2021-10-19T23:27:53.012549Z"
    }
   },
   "outputs": [],
   "source": [
    "df_detect_peptide_train = pd.read_csv('../data/df_detect_peptide_train_noptm_211018_includeDigest.csv')\n",
    "df_detect_peptide_test = pd.read_csv('../data/df_detect_peptide_test_noptm_211018_includeDigest.csv')\n",
    "\n",
    "tra, val = train_test_split(df_detect_peptide_train[['PEP', 'ID']], test_size=0.2, random_state=7)\n",
    "tra.to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_train_noptm_includeDigest.csv', header=False, index=False)\n",
    "val.to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_val_noptm_includeDigest.csv', header=False, index=False)\n",
    "df_detect_peptide_test[['PEP', 'ID']].to_csv('../compareModel/2021ACS_PepFormer/detect_peptide_test_noptm_includeDigest.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:28:21.206426Z",
     "start_time": "2021-10-19T23:28:04.636286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length > 81: 0\n",
      "torch.Size([513513, 30]) torch.Size([513513])\n",
      "length > 81: 0\n",
      "torch.Size([128379, 30]) torch.Size([128379])\n",
      "length > 81: 0\n",
      "torch.Size([129204, 30]) torch.Size([129204])\n"
     ]
    }
   ],
   "source": [
    "train_data,train_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_train_noptm_includeDigest.csv\",81)\n",
    "print(train_data.shape, train_label.shape)\n",
    "train_dataset = Data.TensorDataset(train_data, train_label)\n",
    "\n",
    "val_data,val_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_val_noptm_includeDigest.csv\",81)\n",
    "print(val_data.shape, val_label.shape)\n",
    "val_dataset = Data.TensorDataset(val_data, val_label)\n",
    "\n",
    "test_data,test_label=genData(\"../compareModel/2021ACS_PepFormer/detect_peptide_test_noptm_includeDigest.csv\",81)\n",
    "print(test_data.shape, test_label.shape)\n",
    "test_dataset = Data.TensorDataset(test_data, test_label)\n",
    "\n",
    "batch_size=256\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_iter_cont = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                                                  shuffle=True, collate_fn=collate)\n",
    "val_iter = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:30:36.154379Z",
     "start_time": "2021-10-19T23:30:36.141325Z"
    }
   },
   "outputs": [],
   "source": [
    "class newModel(nn.Module):\n",
    "    def __init__(self, vocab_size=24):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 25\n",
    "        self.batch_size = 256\n",
    "        self.emb_dim = 512\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, self.emb_dim, padding_idx=0)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n",
    "        \n",
    "        self.gru = nn.GRU(self.emb_dim, self.hidden_dim, num_layers=2, \n",
    "                               bidirectional=True, dropout=0.2)\n",
    "        \n",
    "        \n",
    "        self.block1=nn.Sequential(nn.Linear(1600,1024),\n",
    "                                            nn.BatchNorm1d(1024),\n",
    "                                            nn.LeakyReLU(),\n",
    "                                            nn.Linear(1024,256),\n",
    "                                 )\n",
    "\n",
    "        self.block2=nn.Sequential(\n",
    "                                               nn.BatchNorm1d(256),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(256,128),\n",
    "                                               nn.BatchNorm1d(128),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(128,64),\n",
    "                                               nn.BatchNorm1d(64),\n",
    "                                               nn.LeakyReLU(),\n",
    "                                               nn.Linear(64,2)\n",
    "                                            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.embedding(x)\n",
    "        output=self.transformer_encoder(x).permute(1, 0, 2)\n",
    "        output,hn=self.gru(output)\n",
    "        output=output.permute(1,0,2)\n",
    "        hn=hn.permute(1,0,2)\n",
    "        output=output.reshape(output.shape[0],-1)\n",
    "        hn=hn.reshape(output.shape[0],-1)\n",
    "        output=torch.cat([output,hn],1)\n",
    "        return self.block1(output)\n",
    "\n",
    "    def trainModel(self, x):\n",
    "        with torch.no_grad():\n",
    "            output=self.forward(x)\n",
    "        return self.block2(output)\n",
    "\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # euclidean_distance: [128]\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +     # calmp夹断用法\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))     \n",
    "        \n",
    "        return loss_contrastive\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:30:38.693758Z",
     "start_time": "2021-10-19T23:30:38.683917Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T16:03:40.994705Z",
     "start_time": "2021-10-19T23:35:09.283704Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 142.94299, loss1: 1.14200, loss2_3: 141.80099\n",
      "\ttrain_acc: 0.7658, test_acc: \u001b[31m0.7672672321797178\u001b[0m, time: 207.12\n",
      "best_acc: 0.7672672321797178\n",
      "epoch: 2, loss: 120.70428, loss1: 0.91025, loss2_3: 119.79403\n",
      "\ttrain_acc: 0.7860, test_acc: \u001b[31m0.7863201925548571\u001b[0m, time: 203.51\n",
      "best_acc: 0.7863201925548571\n",
      "epoch: 3, loss: 116.44320, loss1: 0.88006, loss2_3: 115.56314\n",
      "\ttrain_acc: 0.7998, test_acc: \u001b[31m0.8000529681645752\u001b[0m, time: 202.92\n",
      "best_acc: 0.8000529681645752\n",
      "epoch: 4, loss: 113.85338, loss1: 0.85866, loss2_3: 112.99472\n",
      "\ttrain_acc: 0.8033, test_acc: \u001b[31m0.8043916839981617\u001b[0m, time: 202.24\n",
      "best_acc: 0.8043916839981617\n",
      "epoch: 5, loss: 112.17126, loss1: 0.84583, loss2_3: 111.32543\n",
      "\ttrain_acc: 0.8076, test_acc: \u001b[31m0.8083019808535664\u001b[0m, time: 160.09\n",
      "best_acc: 0.8083019808535664\n",
      "epoch: 6, loss: 111.32528, loss1: 0.83751, loss2_3: 110.48777\n",
      "\ttrain_acc: 0.8091, test_acc: \u001b[31m0.8090887138862275\u001b[0m, time: 149.12\n",
      "best_acc: 0.8090887138862275\n",
      "epoch: 7, loss: 110.26829, loss1: 0.83087, loss2_3: 109.43742\n",
      "\ttrain_acc: 0.8101, test_acc: \u001b[31m0.811557965087748\u001b[0m, time: 147.94\n",
      "best_acc: 0.811557965087748\n",
      "epoch: 8, loss: 109.62590, loss1: 0.82443, loss2_3: 108.80147\n",
      "\ttrain_acc: 0.8121, test_acc: \u001b[31m0.8122823826326736\u001b[0m, time: 149.19\n",
      "best_acc: 0.8122823826326736\n",
      "epoch: 9, loss: 108.94250, loss1: 0.81662, loss2_3: 108.12588\n",
      "\ttrain_acc: 0.8128, test_acc: \u001b[31m0.8133962719759462\u001b[0m, time: 148.80\n",
      "best_acc: 0.8133962719759462\n",
      "epoch: 10, loss: 108.19687, loss1: 0.81250, loss2_3: 107.38437\n",
      "\ttrain_acc: 0.8144, test_acc: \u001b[31m0.8151956316843098\u001b[0m, time: 147.89\n",
      "best_acc: 0.8151956316843098\n",
      "epoch: 11, loss: 107.66618, loss1: 0.80618, loss2_3: 106.86000\n",
      "\ttrain_acc: 0.8142, test_acc: \u001b[31m0.8144088986516487\u001b[0m, time: 149.00\n",
      "epoch: 12, loss: 106.92576, loss1: 0.80125, loss2_3: 106.12451\n",
      "\ttrain_acc: 0.8178, test_acc: \u001b[31m0.8173143582673179\u001b[0m, time: 147.86\n",
      "best_acc: 0.8173143582673179\n",
      "epoch: 13, loss: 106.58789, loss1: 0.79713, loss2_3: 105.79076\n",
      "\ttrain_acc: 0.8176, test_acc: \u001b[31m0.8177895138613013\u001b[0m, time: 144.82\n",
      "best_acc: 0.8177895138613013\n",
      "epoch: 14, loss: 106.13088, loss1: 0.79369, loss2_3: 105.33719\n",
      "\ttrain_acc: 0.8175, test_acc: \u001b[31m0.8185139314062269\u001b[0m, time: 145.32\n",
      "best_acc: 0.8185139314062269\n",
      "epoch: 15, loss: 105.55513, loss1: 0.79188, loss2_3: 104.76324\n",
      "\ttrain_acc: 0.8187, test_acc: \u001b[31m0.8192539278230864\u001b[0m, time: 144.62\n",
      "best_acc: 0.8192539278230864\n",
      "epoch: 16, loss: 105.34381, loss1: 0.78645, loss2_3: 104.55736\n",
      "\ttrain_acc: 0.8204, test_acc: \u001b[31m0.8204612903979622\u001b[0m, time: 144.78\n",
      "best_acc: 0.8204612903979622\n",
      "epoch: 17, loss: 104.92975, loss1: 0.78448, loss2_3: 104.14527\n",
      "\ttrain_acc: 0.8188, test_acc: \u001b[31m0.8188644560247392\u001b[0m, time: 144.21\n",
      "epoch: 18, loss: 104.76397, loss1: 0.78391, loss2_3: 103.98006\n",
      "\ttrain_acc: 0.8209, test_acc: \u001b[31m0.8208429727603425\u001b[0m, time: 143.67\n",
      "best_acc: 0.8208429727603425\n",
      "epoch: 19, loss: 104.45847, loss1: 0.77918, loss2_3: 103.67928\n",
      "\ttrain_acc: 0.8212, test_acc: \u001b[31m0.8214505487657638\u001b[0m, time: 144.13\n",
      "best_acc: 0.8214505487657638\n",
      "epoch: 20, loss: 104.30868, loss1: 0.78036, loss2_3: 103.52832\n",
      "\ttrain_acc: 0.8220, test_acc: \u001b[31m0.8221438085668217\u001b[0m, time: 144.38\n",
      "best_acc: 0.8221438085668217\n",
      "epoch: 21, loss: 104.07720, loss1: 0.77939, loss2_3: 103.29781\n",
      "\ttrain_acc: 0.8224, test_acc: \u001b[31m0.8225878064169373\u001b[0m, time: 145.43\n",
      "best_acc: 0.8225878064169373\n",
      "epoch: 22, loss: 103.76726, loss1: 0.77751, loss2_3: 102.98976\n",
      "\ttrain_acc: 0.8224, test_acc: \u001b[31m0.8231875929863919\u001b[0m, time: 144.33\n",
      "best_acc: 0.8231875929863919\n",
      "epoch: 23, loss: 103.67016, loss1: 0.77598, loss2_3: 102.89418\n",
      "\ttrain_acc: 0.8232, test_acc: \u001b[31m0.8235069598610365\u001b[0m, time: 145.16\n",
      "best_acc: 0.8235069598610365\n",
      "epoch: 24, loss: 103.61986, loss1: 0.77690, loss2_3: 102.84296\n",
      "\ttrain_acc: 0.8222, test_acc: \u001b[31m0.8225722275450035\u001b[0m, time: 144.86\n",
      "epoch: 25, loss: 103.46011, loss1: 0.77501, loss2_3: 102.68509\n",
      "\ttrain_acc: 0.8237, test_acc: \u001b[31m0.8231252774986563\u001b[0m, time: 144.20\n",
      "epoch: 26, loss: 103.28634, loss1: 0.77543, loss2_3: 102.51090\n",
      "\ttrain_acc: 0.8235, test_acc: \u001b[31m0.8233122239618629\u001b[0m, time: 145.89\n",
      "epoch: 27, loss: 103.12471, loss1: 0.77127, loss2_3: 102.35343\n",
      "\ttrain_acc: 0.8237, test_acc: \u001b[31m0.8236238014005406\u001b[0m, time: 148.55\n",
      "best_acc: 0.8236238014005406\n",
      "epoch: 28, loss: 103.08072, loss1: 0.77182, loss2_3: 102.30890\n",
      "\ttrain_acc: 0.8238, test_acc: \u001b[31m0.8231019091907555\u001b[0m, time: 147.55\n",
      "epoch: 29, loss: 102.96233, loss1: 0.77030, loss2_3: 102.19203\n",
      "\ttrain_acc: 0.8235, test_acc: \u001b[31m0.8233433817057307\u001b[0m, time: 155.67\n",
      "epoch: 30, loss: 102.89777, loss1: 0.77055, loss2_3: 102.12723\n",
      "\ttrain_acc: 0.8250, test_acc: \u001b[31m0.8242469562778959\u001b[0m, time: 179.98\n",
      "best_acc: 0.8242469562778959\n",
      "epoch: 31, loss: 102.80080, loss1: 0.76999, loss2_3: 102.03082\n",
      "\ttrain_acc: 0.8243, test_acc: \u001b[31m0.8243014823296645\u001b[0m, time: 178.79\n",
      "best_acc: 0.8243014823296645\n",
      "epoch: 32, loss: 102.72759, loss1: 0.77031, loss2_3: 101.95728\n",
      "\ttrain_acc: 0.8249, test_acc: \u001b[31m0.8247922167955818\u001b[0m, time: 176.73\n",
      "best_acc: 0.8247922167955818\n",
      "epoch: 33, loss: 102.57120, loss1: 0.76969, loss2_3: 101.80151\n",
      "\ttrain_acc: 0.8253, test_acc: \u001b[31m0.8245585337165736\u001b[0m, time: 179.96\n",
      "epoch: 34, loss: 102.49190, loss1: 0.76686, loss2_3: 101.72504\n",
      "\ttrain_acc: 0.8242, test_acc: \u001b[31m0.8236315908365075\u001b[0m, time: 180.36\n",
      "epoch: 35, loss: 102.45934, loss1: 0.76721, loss2_3: 101.69212\n",
      "\ttrain_acc: 0.8240, test_acc: \u001b[31m0.8228292789319125\u001b[0m, time: 179.44\n",
      "epoch: 36, loss: 102.46725, loss1: 0.76779, loss2_3: 101.69945\n",
      "\ttrain_acc: 0.8252, test_acc: \u001b[31m0.8248233745394496\u001b[0m, time: 175.12\n",
      "best_acc: 0.8248233745394496\n",
      "epoch: 37, loss: 102.42872, loss1: 0.76759, loss2_3: 101.66113\n",
      "\ttrain_acc: 0.8253, test_acc: \u001b[31m0.8241301147383918\u001b[0m, time: 171.27\n",
      "epoch: 38, loss: 102.32439, loss1: 0.76924, loss2_3: 101.55514\n",
      "\ttrain_acc: 0.8256, test_acc: \u001b[31m0.8251427414140942\u001b[0m, time: 179.95\n",
      "best_acc: 0.8251427414140942\n",
      "epoch: 39, loss: 102.25736, loss1: 0.76653, loss2_3: 101.49082\n",
      "\ttrain_acc: 0.8254, test_acc: \u001b[31m0.824496218228838\u001b[0m, time: 175.85\n",
      "epoch: 40, loss: 102.13924, loss1: 0.76679, loss2_3: 101.37246\n",
      "\ttrain_acc: 0.8224, test_acc: \u001b[31m0.8213804438420614\u001b[0m, time: 177.08\n",
      "epoch: 41, loss: 102.07831, loss1: 0.76492, loss2_3: 101.31339\n",
      "\ttrain_acc: 0.8262, test_acc: \u001b[31m0.8251271625421603\u001b[0m, time: 176.67\n",
      "epoch: 42, loss: 102.03368, loss1: 0.76490, loss2_3: 101.26878\n",
      "\ttrain_acc: 0.8254, test_acc: \u001b[31m0.8243092717656314\u001b[0m, time: 176.83\n",
      "epoch: 43, loss: 102.13043, loss1: 0.76387, loss2_3: 101.36656\n",
      "\ttrain_acc: 0.8267, test_acc: \u001b[31m0.8257347385475817\u001b[0m, time: 178.35\n",
      "best_acc: 0.8257347385475817\n",
      "epoch: 44, loss: 101.86651, loss1: 0.76427, loss2_3: 101.10224\n",
      "\ttrain_acc: 0.8218, test_acc: \u001b[31m0.8207728678366399\u001b[0m, time: 178.30\n",
      "epoch: 45, loss: 101.81627, loss1: 0.76414, loss2_3: 101.05212\n",
      "\ttrain_acc: 0.8264, test_acc: \u001b[31m0.8248000062315488\u001b[0m, time: 178.77\n",
      "epoch: 46, loss: 101.80768, loss1: 0.76328, loss2_3: 101.04440\n",
      "\ttrain_acc: 0.8270, test_acc: \u001b[31m0.8255400026484082\u001b[0m, time: 181.19\n",
      "epoch: 47, loss: 101.79525, loss1: 0.76386, loss2_3: 101.03140\n",
      "\ttrain_acc: 0.8262, test_acc: \u001b[31m0.8251894780298958\u001b[0m, time: 178.51\n",
      "epoch: 48, loss: 101.71010, loss1: 0.76270, loss2_3: 100.94740\n",
      "\ttrain_acc: 0.8272, test_acc: \u001b[31m0.8264669455284743\u001b[0m, time: 179.66\n",
      "best_acc: 0.8264669455284743\n",
      "epoch: 49, loss: 101.72050, loss1: 0.76246, loss2_3: 100.95804\n",
      "\ttrain_acc: 0.8271, test_acc: \u001b[31m0.8261631575257635\u001b[0m, time: 179.26\n",
      "epoch: 50, loss: 101.68787, loss1: 0.76210, loss2_3: 100.92578\n",
      "\ttrain_acc: 0.8279, test_acc: \u001b[31m0.8264046300407387\u001b[0m, time: 176.92\n",
      "epoch: 51, loss: 101.66797, loss1: 0.76105, loss2_3: 100.90692\n",
      "\ttrain_acc: 0.8269, test_acc: \u001b[31m0.8247922167955818\u001b[0m, time: 178.73\n",
      "epoch: 52, loss: 101.49725, loss1: 0.76130, loss2_3: 100.73595\n",
      "\ttrain_acc: 0.8265, test_acc: \u001b[31m0.825173899157962\u001b[0m, time: 177.10\n",
      "epoch: 53, loss: 101.50025, loss1: 0.76100, loss2_3: 100.73924\n",
      "\ttrain_acc: 0.8267, test_acc: \u001b[31m0.8250960047982926\u001b[0m, time: 177.69\n",
      "epoch: 54, loss: 101.45888, loss1: 0.76220, loss2_3: 100.69668\n",
      "\ttrain_acc: 0.8274, test_acc: \u001b[31m0.8259372638827223\u001b[0m, time: 200.59\n",
      "epoch: 55, loss: 101.44846, loss1: 0.76098, loss2_3: 100.68748\n",
      "\ttrain_acc: 0.8277, test_acc: \u001b[31m0.8258515800870859\u001b[0m, time: 207.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 56, loss: 101.38520, loss1: 0.76120, loss2_3: 100.62400\n",
      "\ttrain_acc: 0.8234, test_acc: \u001b[31m0.8220581247711853\u001b[0m, time: 206.00\n",
      "epoch: 57, loss: 101.46735, loss1: 0.76151, loss2_3: 100.70584\n",
      "\ttrain_acc: 0.8280, test_acc: \u001b[31m0.825578949828243\u001b[0m, time: 208.56\n",
      "epoch: 58, loss: 101.22287, loss1: 0.76034, loss2_3: 100.46253\n",
      "\ttrain_acc: 0.8279, test_acc: \u001b[31m0.8259528427546561\u001b[0m, time: 209.55\n",
      "epoch: 59, loss: 101.26020, loss1: 0.76162, loss2_3: 100.49858\n",
      "\ttrain_acc: 0.8282, test_acc: \u001b[31m0.8265214715802429\u001b[0m, time: 210.92\n",
      "best_acc: 0.8265214715802429\n",
      "epoch: 60, loss: 101.16820, loss1: 0.76065, loss2_3: 100.40755\n",
      "\ttrain_acc: 0.8281, test_acc: \u001b[31m0.8257658962914496\u001b[0m, time: 211.49\n",
      "epoch: 61, loss: 101.19486, loss1: 0.75872, loss2_3: 100.43613\n",
      "\ttrain_acc: 0.8275, test_acc: \u001b[31m0.8259840004985239\u001b[0m, time: 210.73\n",
      "epoch: 62, loss: 101.16990, loss1: 0.75780, loss2_3: 100.41210\n",
      "\ttrain_acc: 0.8280, test_acc: \u001b[31m0.8262566307573669\u001b[0m, time: 211.56\n",
      "epoch: 63, loss: 101.20215, loss1: 0.75872, loss2_3: 100.44343\n",
      "\ttrain_acc: 0.8275, test_acc: \u001b[31m0.8260307371143255\u001b[0m, time: 314.46\n",
      "epoch: 64, loss: 101.11532, loss1: 0.76071, loss2_3: 100.35461\n",
      "\ttrain_acc: 0.8287, test_acc: \u001b[31m0.8266461025557139\u001b[0m, time: 315.66\n",
      "best_acc: 0.8266461025557139\n",
      "epoch: 65, loss: 100.98689, loss1: 0.75952, loss2_3: 100.22736\n",
      "\ttrain_acc: 0.8273, test_acc: \u001b[31m0.8254698977247058\u001b[0m, time: 316.16\n",
      "epoch: 66, loss: 101.08696, loss1: 0.75833, loss2_3: 100.32863\n",
      "\ttrain_acc: 0.8283, test_acc: \u001b[31m0.8260852631660941\u001b[0m, time: 315.05\n",
      "epoch: 67, loss: 100.94006, loss1: 0.75980, loss2_3: 100.18026\n",
      "\ttrain_acc: 0.8274, test_acc: \u001b[31m0.8258671589590197\u001b[0m, time: 316.49\n",
      "epoch: 68, loss: 101.04135, loss1: 0.76152, loss2_3: 100.27983\n",
      "\ttrain_acc: 0.8282, test_acc: \u001b[31m0.8258983167028875\u001b[0m, time: 316.89\n",
      "epoch: 69, loss: 100.98526, loss1: 0.75749, loss2_3: 100.22778\n",
      "\ttrain_acc: 0.8289, test_acc: \u001b[31m0.8266850497355487\u001b[0m, time: 315.63\n",
      "best_acc: 0.8266850497355487\n",
      "epoch: 70, loss: 100.81146, loss1: 0.75827, loss2_3: 100.05319\n",
      "\ttrain_acc: 0.8284, test_acc: \u001b[31m0.8268018912750528\u001b[0m, time: 315.87\n",
      "best_acc: 0.8268018912750528\n",
      "epoch: 71, loss: 100.96845, loss1: 0.76024, loss2_3: 100.20821\n",
      "\ttrain_acc: 0.8286, test_acc: \u001b[31m0.8265759976320115\u001b[0m, time: 315.70\n",
      "epoch: 72, loss: 100.81313, loss1: 0.75789, loss2_3: 100.05525\n",
      "\ttrain_acc: 0.8289, test_acc: \u001b[31m0.8267006286074825\u001b[0m, time: 315.70\n",
      "epoch: 73, loss: 100.94647, loss1: 0.75864, loss2_3: 100.18783\n",
      "\ttrain_acc: 0.8292, test_acc: \u001b[31m0.8272147313813006\u001b[0m, time: 314.87\n",
      "best_acc: 0.8272147313813006\n",
      "epoch: 74, loss: 100.79658, loss1: 0.75840, loss2_3: 100.03818\n",
      "\ttrain_acc: 0.8290, test_acc: \u001b[31m0.8262098941415652\u001b[0m, time: 315.68\n",
      "epoch: 75, loss: 100.73423, loss1: 0.75594, loss2_3: 99.97829\n",
      "\ttrain_acc: 0.8291, test_acc: \u001b[31m0.8280482010297634\u001b[0m, time: 314.87\n",
      "best_acc: 0.8280482010297634\n",
      "epoch: 76, loss: 100.80352, loss1: 0.75734, loss2_3: 100.04618\n",
      "\ttrain_acc: 0.8248, test_acc: \u001b[31m0.8228137000599787\u001b[0m, time: 315.98\n",
      "epoch: 77, loss: 100.85497, loss1: 0.75814, loss2_3: 100.09683\n",
      "\ttrain_acc: 0.8275, test_acc: \u001b[31m0.8256957913677471\u001b[0m, time: 315.66\n",
      "epoch: 78, loss: 100.84501, loss1: 0.75751, loss2_3: 100.08750\n",
      "\ttrain_acc: 0.8272, test_acc: \u001b[31m0.8252440040816644\u001b[0m, time: 314.90\n",
      "epoch: 79, loss: 100.73214, loss1: 0.75747, loss2_3: 99.97467\n",
      "\ttrain_acc: 0.8293, test_acc: \u001b[31m0.826770733531185\u001b[0m, time: 316.53\n",
      "epoch: 80, loss: 100.72311, loss1: 0.75708, loss2_3: 99.96603\n",
      "\ttrain_acc: 0.8272, test_acc: \u001b[31m0.8250648470544248\u001b[0m, time: 318.92\n",
      "epoch: 81, loss: 100.71412, loss1: 0.75647, loss2_3: 99.95765\n",
      "\ttrain_acc: 0.8290, test_acc: \u001b[31m0.8263890511688049\u001b[0m, time: 316.81\n",
      "epoch: 82, loss: 100.71317, loss1: 0.75862, loss2_3: 99.95456\n",
      "\ttrain_acc: 0.8291, test_acc: \u001b[31m0.8265915765039453\u001b[0m, time: 317.59\n",
      "epoch: 83, loss: 100.74171, loss1: 0.75773, loss2_3: 99.98398\n",
      "\ttrain_acc: 0.8292, test_acc: \u001b[31m0.827308204612904\u001b[0m, time: 318.68\n",
      "epoch: 84, loss: 100.70176, loss1: 0.75711, loss2_3: 99.94465\n",
      "\ttrain_acc: 0.8290, test_acc: \u001b[31m0.8268797856347222\u001b[0m, time: 316.69\n",
      "epoch: 85, loss: 100.64872, loss1: 0.75716, loss2_3: 99.89156\n",
      "\ttrain_acc: 0.8295, test_acc: \u001b[31m0.827160205329532\u001b[0m, time: 318.89\n",
      "epoch: 86, loss: 100.58541, loss1: 0.75737, loss2_3: 99.82804\n",
      "\ttrain_acc: 0.8288, test_acc: \u001b[31m0.8262566307573669\u001b[0m, time: 317.60\n",
      "epoch: 87, loss: 100.56782, loss1: 0.75703, loss2_3: 99.81078\n",
      "\ttrain_acc: 0.8303, test_acc: \u001b[31m0.8271212581496974\u001b[0m, time: 316.95\n",
      "epoch: 88, loss: 100.51967, loss1: 0.75771, loss2_3: 99.76196\n",
      "\ttrain_acc: 0.8281, test_acc: \u001b[31m0.8265526293241107\u001b[0m, time: 317.93\n",
      "epoch: 89, loss: 100.52061, loss1: 0.75585, loss2_3: 99.76476\n",
      "\ttrain_acc: 0.8293, test_acc: \u001b[31m0.8272380996892015\u001b[0m, time: 316.37\n",
      "epoch: 90, loss: 100.51945, loss1: 0.75602, loss2_3: 99.76343\n",
      "\ttrain_acc: 0.8283, test_acc: \u001b[31m0.8256178970080776\u001b[0m, time: 318.32\n",
      "epoch: 91, loss: 100.48077, loss1: 0.75591, loss2_3: 99.72486\n",
      "\ttrain_acc: 0.8292, test_acc: \u001b[31m0.8267551546592511\u001b[0m, time: 316.94\n",
      "epoch: 92, loss: 100.46882, loss1: 0.75541, loss2_3: 99.71341\n",
      "\ttrain_acc: 0.8300, test_acc: \u001b[31m0.8270901004058296\u001b[0m, time: 317.04\n",
      "epoch: 93, loss: 100.39932, loss1: 0.75559, loss2_3: 99.64373\n",
      "\ttrain_acc: 0.8294, test_acc: \u001b[31m0.8269265222505239\u001b[0m, time: 318.39\n",
      "epoch: 94, loss: 100.46212, loss1: 0.75527, loss2_3: 99.70685\n",
      "\ttrain_acc: 0.8300, test_acc: \u001b[31m0.8270978898417966\u001b[0m, time: 316.22\n",
      "epoch: 95, loss: 100.46547, loss1: 0.75672, loss2_3: 99.70875\n",
      "\ttrain_acc: 0.8284, test_acc: \u001b[31m0.8261631575257635\u001b[0m, time: 320.25\n",
      "epoch: 96, loss: 100.36492, loss1: 0.75506, loss2_3: 99.60986\n",
      "\ttrain_acc: 0.8292, test_acc: \u001b[31m0.8267473652232842\u001b[0m, time: 318.27\n",
      "epoch: 97, loss: 100.44940, loss1: 0.75686, loss2_3: 99.69254\n",
      "\ttrain_acc: 0.8290, test_acc: \u001b[31m0.8260385265502925\u001b[0m, time: 317.42\n",
      "epoch: 98, loss: 100.37897, loss1: 0.75681, loss2_3: 99.62216\n",
      "\ttrain_acc: 0.8297, test_acc: \u001b[31m0.8271524158935651\u001b[0m, time: 317.95\n",
      "epoch: 99, loss: 100.29351, loss1: 0.75558, loss2_3: 99.53793\n",
      "\ttrain_acc: 0.8291, test_acc: \u001b[31m0.8267162074794164\u001b[0m, time: 316.18\n",
      "epoch: 100, loss: 100.27359, loss1: 0.75503, loss2_3: 99.51856\n",
      "\ttrain_acc: 0.8294, test_acc: \u001b[31m0.8271134687137305\u001b[0m, time: 301.94\n",
      "epoch: 101, loss: 100.27235, loss1: 0.75268, loss2_3: 99.51967\n",
      "\ttrain_acc: 0.8288, test_acc: \u001b[31m0.8264591560925073\u001b[0m, time: 306.02\n",
      "epoch: 102, loss: 100.29095, loss1: 0.75510, loss2_3: 99.53585\n",
      "\ttrain_acc: 0.8307, test_acc: \u001b[31m0.8275418876919123\u001b[0m, time: 304.58\n",
      "epoch: 103, loss: 100.27815, loss1: 0.75571, loss2_3: 99.52244\n",
      "\ttrain_acc: 0.8297, test_acc: \u001b[31m0.8268719961987553\u001b[0m, time: 257.33\n",
      "epoch: 104, loss: 100.18597, loss1: 0.75544, loss2_3: 99.43053\n",
      "\ttrain_acc: 0.8297, test_acc: \u001b[31m0.8268096807110197\u001b[0m, time: 251.67\n",
      "epoch: 105, loss: 100.25934, loss1: 0.75542, loss2_3: 99.50392\n",
      "\ttrain_acc: 0.8294, test_acc: \u001b[31m0.8276587292314164\u001b[0m, time: 250.29\n",
      "epoch: 106, loss: 100.37532, loss1: 0.75521, loss2_3: 99.62011\n",
      "\ttrain_acc: 0.8294, test_acc: \u001b[31m0.8268719961987553\u001b[0m, time: 253.26\n",
      "epoch: 107, loss: 100.33593, loss1: 0.75436, loss2_3: 99.58157\n",
      "\ttrain_acc: 0.8293, test_acc: \u001b[31m0.8269966271742263\u001b[0m, time: 247.14\n",
      "epoch: 108, loss: 100.24596, loss1: 0.75283, loss2_3: 99.49313\n",
      "\ttrain_acc: 0.8299, test_acc: \u001b[31m0.8267863124031188\u001b[0m, time: 252.58\n",
      "epoch: 109, loss: 100.22305, loss1: 0.75468, loss2_3: 99.46837\n",
      "\ttrain_acc: 0.8295, test_acc: \u001b[31m0.8261787363976975\u001b[0m, time: 247.03\n",
      "epoch: 110, loss: 100.12525, loss1: 0.75462, loss2_3: 99.37063\n",
      "\ttrain_acc: 0.8302, test_acc: \u001b[31m0.8273237834848378\u001b[0m, time: 255.97\n",
      "epoch: 111, loss: 100.20801, loss1: 0.75614, loss2_3: 99.45187\n",
      "\ttrain_acc: 0.8303, test_acc: \u001b[31m0.8271134687137305\u001b[0m, time: 275.17\n",
      "epoch: 112, loss: 100.14925, loss1: 0.75346, loss2_3: 99.39578\n",
      "\ttrain_acc: 0.8306, test_acc: \u001b[31m0.8274795722041767\u001b[0m, time: 326.42\n",
      "epoch: 113, loss: 100.18863, loss1: 0.75434, loss2_3: 99.43429\n",
      "\ttrain_acc: 0.8297, test_acc: \u001b[31m0.8272614679971023\u001b[0m, time: 673.58\n",
      "epoch: 114, loss: 100.13123, loss1: 0.75671, loss2_3: 99.37452\n",
      "\ttrain_acc: 0.8302, test_acc: \u001b[31m0.8270901004058296\u001b[0m, time: 795.11\n",
      "epoch: 115, loss: 100.19732, loss1: 0.75260, loss2_3: 99.44472\n",
      "\ttrain_acc: 0.8307, test_acc: \u001b[31m0.8271446264575982\u001b[0m, time: 934.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 116, loss: 100.04363, loss1: 0.75300, loss2_3: 99.29063\n",
      "\ttrain_acc: 0.8301, test_acc: \u001b[31m0.8267162074794164\u001b[0m, time: 1015.16\n",
      "epoch: 117, loss: 100.14688, loss1: 0.75413, loss2_3: 99.39275\n",
      "\ttrain_acc: 0.8305, test_acc: \u001b[31m0.827035574354061\u001b[0m, time: 896.39\n",
      "epoch: 118, loss: 100.13788, loss1: 0.75615, loss2_3: 99.38173\n",
      "\ttrain_acc: 0.8306, test_acc: \u001b[31m0.8281416742613668\u001b[0m, time: 232.56\n",
      "best_acc: 0.8281416742613668\n",
      "epoch: 119, loss: 100.16233, loss1: 0.75399, loss2_3: 99.40834\n",
      "\ttrain_acc: 0.8305, test_acc: \u001b[31m0.8274717827682098\u001b[0m, time: 247.89\n",
      "epoch: 120, loss: 100.09071, loss1: 0.75461, loss2_3: 99.33610\n",
      "\ttrain_acc: 0.8303, test_acc: \u001b[31m0.8266850497355487\u001b[0m, time: 244.19\n",
      "epoch: 121, loss: 100.06966, loss1: 0.75346, loss2_3: 99.31620\n",
      "\ttrain_acc: 0.8306, test_acc: \u001b[31m0.8271446264575982\u001b[0m, time: 244.14\n",
      "epoch: 122, loss: 100.08975, loss1: 0.75405, loss2_3: 99.33570\n",
      "\ttrain_acc: 0.8306, test_acc: \u001b[31m0.8276431503594824\u001b[0m, time: 243.98\n",
      "epoch: 123, loss: 100.05184, loss1: 0.75328, loss2_3: 99.29857\n",
      "\ttrain_acc: 0.8305, test_acc: \u001b[31m0.8277833602068874\u001b[0m, time: 250.58\n",
      "epoch: 124, loss: 99.99540, loss1: 0.75178, loss2_3: 99.24362\n",
      "\ttrain_acc: 0.8301, test_acc: \u001b[31m0.8262644201933338\u001b[0m, time: 249.85\n",
      "epoch: 125, loss: 99.99954, loss1: 0.75363, loss2_3: 99.24591\n",
      "\ttrain_acc: 0.8301, test_acc: \u001b[31m0.8271679947654991\u001b[0m, time: 253.69\n",
      "epoch: 126, loss: 99.88689, loss1: 0.75170, loss2_3: 99.13519\n",
      "\ttrain_acc: 0.8306, test_acc: \u001b[31m0.827027784918094\u001b[0m, time: 248.99\n",
      "epoch: 127, loss: 99.86672, loss1: 0.75242, loss2_3: 99.11430\n",
      "\ttrain_acc: 0.8303, test_acc: \u001b[31m0.8265214715802429\u001b[0m, time: 251.27\n",
      "epoch: 128, loss: 99.96768, loss1: 0.75393, loss2_3: 99.21375\n",
      "\ttrain_acc: 0.8305, test_acc: \u001b[31m0.8270667320979288\u001b[0m, time: 249.42\n",
      "epoch: 129, loss: 100.02592, loss1: 0.75499, loss2_3: 99.27093\n",
      "\ttrain_acc: 0.8307, test_acc: \u001b[31m0.8266461025557139\u001b[0m, time: 253.31\n",
      "epoch: 130, loss: 100.03921, loss1: 0.75480, loss2_3: 99.28441\n",
      "\ttrain_acc: 0.8306, test_acc: \u001b[31m0.8268408384548874\u001b[0m, time: 275.45\n",
      "epoch: 131, loss: 99.95506, loss1: 0.75494, loss2_3: 99.20012\n",
      "\ttrain_acc: 0.8304, test_acc: \u001b[31m0.8263578934249372\u001b[0m, time: 305.33\n",
      "epoch: 132, loss: 100.00930, loss1: 0.75426, loss2_3: 99.25504\n",
      "\ttrain_acc: 0.8307, test_acc: \u001b[31m0.8276509397954495\u001b[0m, time: 700.08\n",
      "epoch: 133, loss: 100.03693, loss1: 0.75376, loss2_3: 99.28318\n",
      "\ttrain_acc: 0.8306, test_acc: \u001b[31m0.8270199954821271\u001b[0m, time: 544.99\n",
      "epoch: 134, loss: 99.84950, loss1: 0.75147, loss2_3: 99.09804\n",
      "\ttrain_acc: 0.8313, test_acc: \u001b[31m0.8283909362123089\u001b[0m, time: 440.19\n",
      "best_acc: 0.8283909362123089\n",
      "epoch: 135, loss: 99.88989, loss1: 0.75334, loss2_3: 99.13655\n",
      "\ttrain_acc: 0.8309, test_acc: \u001b[31m0.8282039897491023\u001b[0m, time: 923.20\n",
      "epoch: 136, loss: 99.86046, loss1: 0.75281, loss2_3: 99.10765\n",
      "\ttrain_acc: 0.8309, test_acc: \u001b[31m0.8277522024630196\u001b[0m, time: 976.14\n",
      "epoch: 137, loss: 99.85223, loss1: 0.75309, loss2_3: 99.09913\n",
      "\ttrain_acc: 0.8305, test_acc: \u001b[31m0.82691094337859\u001b[0m, time: 582.21\n",
      "epoch: 138, loss: 99.74535, loss1: 0.75353, loss2_3: 98.99182\n",
      "\ttrain_acc: 0.8313, test_acc: \u001b[31m0.8281572531333006\u001b[0m, time: 248.75\n",
      "epoch: 139, loss: 99.82270, loss1: 0.75378, loss2_3: 99.06892\n",
      "\ttrain_acc: 0.8314, test_acc: \u001b[31m0.8283130418526394\u001b[0m, time: 204.00\n",
      "epoch: 140, loss: 99.82160, loss1: 0.75406, loss2_3: 99.06754\n",
      "\ttrain_acc: 0.8300, test_acc: \u001b[31m0.8270745215338957\u001b[0m, time: 198.02\n",
      "epoch: 141, loss: 99.77988, loss1: 0.75177, loss2_3: 99.02811\n",
      "\ttrain_acc: 0.8305, test_acc: \u001b[31m0.8279858855420279\u001b[0m, time: 197.50\n",
      "epoch: 142, loss: 99.80379, loss1: 0.75192, loss2_3: 99.05188\n",
      "\ttrain_acc: 0.8302, test_acc: \u001b[31m0.8274250461524081\u001b[0m, time: 197.41\n",
      "epoch: 143, loss: 99.85759, loss1: 0.75207, loss2_3: 99.10552\n",
      "\ttrain_acc: 0.8305, test_acc: \u001b[31m0.827175784201466\u001b[0m, time: 197.58\n",
      "epoch: 144, loss: 99.70658, loss1: 0.75275, loss2_3: 98.95382\n",
      "\ttrain_acc: 0.8295, test_acc: \u001b[31m0.8267473652232842\u001b[0m, time: 197.85\n",
      "epoch: 145, loss: 99.79590, loss1: 0.75298, loss2_3: 99.04292\n",
      "\ttrain_acc: 0.8307, test_acc: \u001b[31m0.8274250461524081\u001b[0m, time: 197.68\n",
      "epoch: 146, loss: 99.93608, loss1: 0.75234, loss2_3: 99.18374\n",
      "\ttrain_acc: 0.8311, test_acc: \u001b[31m0.8281962003131353\u001b[0m, time: 197.51\n",
      "epoch: 147, loss: 99.81947, loss1: 0.75352, loss2_3: 99.06595\n",
      "\ttrain_acc: 0.8297, test_acc: \u001b[31m0.8258282117791851\u001b[0m, time: 196.98\n",
      "epoch: 148, loss: 99.67411, loss1: 0.75114, loss2_3: 98.92298\n",
      "\ttrain_acc: 0.8313, test_acc: \u001b[31m0.8273938884085403\u001b[0m, time: 197.25\n",
      "epoch: 149, loss: 99.73573, loss1: 0.75252, loss2_3: 98.98320\n",
      "\ttrain_acc: 0.8310, test_acc: \u001b[31m0.8280092538499287\u001b[0m, time: 197.29\n",
      "epoch: 150, loss: 99.67777, loss1: 0.75298, loss2_3: 98.92479\n",
      "\ttrain_acc: 0.8302, test_acc: \u001b[31m0.826770733531185\u001b[0m, time: 198.08\n",
      "epoch: 151, loss: 99.72590, loss1: 0.75233, loss2_3: 98.97357\n",
      "\ttrain_acc: 0.8308, test_acc: \u001b[31m0.8268642067627883\u001b[0m, time: 197.73\n",
      "epoch: 152, loss: 99.68491, loss1: 0.75341, loss2_3: 98.93151\n",
      "\ttrain_acc: 0.8302, test_acc: \u001b[31m0.8270199954821271\u001b[0m, time: 196.91\n",
      "epoch: 153, loss: 99.63756, loss1: 0.75239, loss2_3: 98.88517\n",
      "\ttrain_acc: 0.8314, test_acc: \u001b[31m0.8273783095366064\u001b[0m, time: 196.98\n",
      "epoch: 154, loss: 99.64372, loss1: 0.75198, loss2_3: 98.89174\n",
      "\ttrain_acc: 0.8317, test_acc: \u001b[31m0.8276275714875486\u001b[0m, time: 197.48\n",
      "epoch: 155, loss: 99.64776, loss1: 0.75266, loss2_3: 98.89510\n",
      "\ttrain_acc: 0.8312, test_acc: \u001b[31m0.8276275714875486\u001b[0m, time: 197.06\n",
      "epoch: 156, loss: 99.57757, loss1: 0.75187, loss2_3: 98.82570\n",
      "\ttrain_acc: 0.8316, test_acc: \u001b[31m0.8281572531333006\u001b[0m, time: 198.71\n",
      "epoch: 157, loss: 99.65115, loss1: 0.75403, loss2_3: 98.89712\n",
      "\ttrain_acc: 0.8315, test_acc: \u001b[31m0.8278534651305899\u001b[0m, time: 186.76\n",
      "epoch: 158, loss: 99.69342, loss1: 0.75440, loss2_3: 98.93902\n",
      "\ttrain_acc: 0.8315, test_acc: \u001b[31m0.8272303102532346\u001b[0m, time: 155.77\n",
      "epoch: 159, loss: 99.59430, loss1: 0.75355, loss2_3: 98.84075\n",
      "\ttrain_acc: 0.8312, test_acc: \u001b[31m0.8264124194767057\u001b[0m, time: 125.20\n",
      "epoch: 160, loss: 99.59702, loss1: 0.75247, loss2_3: 98.84456\n",
      "\ttrain_acc: 0.8315, test_acc: \u001b[31m0.8272225208172677\u001b[0m, time: 125.16\n",
      "epoch: 161, loss: 99.51699, loss1: 0.75236, loss2_3: 98.76463\n",
      "\ttrain_acc: 0.8302, test_acc: \u001b[31m0.8258905272669206\u001b[0m, time: 125.72\n",
      "epoch: 162, loss: 99.55869, loss1: 0.75085, loss2_3: 98.80785\n",
      "\ttrain_acc: 0.8310, test_acc: \u001b[31m0.8277366235910858\u001b[0m, time: 125.62\n",
      "epoch: 163, loss: 99.44314, loss1: 0.75198, loss2_3: 98.69116\n",
      "\ttrain_acc: 0.8311, test_acc: \u001b[31m0.827175784201466\u001b[0m, time: 125.74\n",
      "epoch: 164, loss: 99.46776, loss1: 0.75077, loss2_3: 98.71699\n",
      "\ttrain_acc: 0.8306, test_acc: \u001b[31m0.8268174701469867\u001b[0m, time: 125.13\n",
      "epoch: 165, loss: 99.64250, loss1: 0.75142, loss2_3: 98.89107\n",
      "\ttrain_acc: 0.8316, test_acc: \u001b[31m0.8275418876919123\u001b[0m, time: 122.58\n",
      "epoch: 166, loss: 99.48314, loss1: 0.75207, loss2_3: 98.73107\n",
      "\ttrain_acc: 0.8294, test_acc: \u001b[31m0.8253997928010033\u001b[0m, time: 122.22\n",
      "epoch: 167, loss: 99.56452, loss1: 0.74994, loss2_3: 98.81458\n",
      "\ttrain_acc: 0.8316, test_acc: \u001b[31m0.8273705201006395\u001b[0m, time: 124.45\n",
      "epoch: 168, loss: 99.55851, loss1: 0.75198, loss2_3: 98.80653\n",
      "\ttrain_acc: 0.8303, test_acc: \u001b[31m0.826505892708309\u001b[0m, time: 124.60\n",
      "epoch: 169, loss: 99.54456, loss1: 0.75195, loss2_3: 98.79261\n",
      "\ttrain_acc: 0.8287, test_acc: \u001b[31m0.8239899048909869\u001b[0m, time: 122.19\n",
      "epoch: 170, loss: 99.50591, loss1: 0.75259, loss2_3: 98.75332\n",
      "\ttrain_acc: 0.8318, test_acc: \u001b[31m0.8275886243077138\u001b[0m, time: 122.17\n",
      "epoch: 171, loss: 99.44097, loss1: 0.75246, loss2_3: 98.68851\n",
      "\ttrain_acc: 0.8241, test_acc: \u001b[31m0.8211545501990201\u001b[0m, time: 126.23\n",
      "epoch: 172, loss: 99.49661, loss1: 0.75417, loss2_3: 98.74244\n",
      "\ttrain_acc: 0.8312, test_acc: \u001b[31m0.8272380996892015\u001b[0m, time: 123.49\n",
      "epoch: 173, loss: 99.51414, loss1: 0.75143, loss2_3: 98.76271\n",
      "\ttrain_acc: 0.8318, test_acc: \u001b[31m0.8277833602068874\u001b[0m, time: 122.11\n",
      "epoch: 174, loss: 99.44262, loss1: 0.75226, loss2_3: 98.69036\n",
      "\ttrain_acc: 0.8323, test_acc: \u001b[31m0.8268719961987553\u001b[0m, time: 123.94\n",
      "epoch: 175, loss: 99.54227, loss1: 0.75010, loss2_3: 98.79217\n",
      "\ttrain_acc: 0.8321, test_acc: \u001b[31m0.8271134687137305\u001b[0m, time: 126.60\n",
      "epoch: 176, loss: 99.52304, loss1: 0.75124, loss2_3: 98.77180\n",
      "\ttrain_acc: 0.8316, test_acc: \u001b[31m0.8278534651305899\u001b[0m, time: 123.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 177, loss: 99.46758, loss1: 0.75282, loss2_3: 98.71477\n",
      "\ttrain_acc: 0.8301, test_acc: \u001b[31m0.8259061061388545\u001b[0m, time: 122.48\n",
      "epoch: 178, loss: 99.35583, loss1: 0.74926, loss2_3: 98.60657\n",
      "\ttrain_acc: 0.8317, test_acc: \u001b[31m0.8277444130270527\u001b[0m, time: 122.56\n",
      "epoch: 179, loss: 99.40483, loss1: 0.75149, loss2_3: 98.65334\n",
      "\ttrain_acc: 0.8320, test_acc: \u001b[31m0.8272380996892015\u001b[0m, time: 126.22\n",
      "epoch: 180, loss: 99.33420, loss1: 0.75227, loss2_3: 98.58193\n",
      "\ttrain_acc: 0.8315, test_acc: \u001b[31m0.82823514749297\u001b[0m, time: 205.95\n",
      "epoch: 181, loss: 99.40909, loss1: 0.75062, loss2_3: 98.65847\n",
      "\ttrain_acc: 0.8312, test_acc: \u001b[31m0.8273627306646726\u001b[0m, time: 479.59\n",
      "epoch: 182, loss: 99.36432, loss1: 0.74991, loss2_3: 98.61442\n",
      "\ttrain_acc: 0.8319, test_acc: \u001b[31m0.827565255999813\u001b[0m, time: 504.88\n",
      "epoch: 183, loss: 99.42398, loss1: 0.74998, loss2_3: 98.67401\n",
      "\ttrain_acc: 0.8322, test_acc: \u001b[31m0.8277599918989866\u001b[0m, time: 646.07\n",
      "epoch: 184, loss: 99.41297, loss1: 0.74942, loss2_3: 98.66355\n",
      "\ttrain_acc: 0.8320, test_acc: \u001b[31m0.8274484144603089\u001b[0m, time: 684.28\n",
      "epoch: 185, loss: 99.48113, loss1: 0.74960, loss2_3: 98.73153\n",
      "\ttrain_acc: 0.8312, test_acc: \u001b[31m0.827027784918094\u001b[0m, time: 545.79\n",
      "epoch: 186, loss: 99.43690, loss1: 0.74942, loss2_3: 98.68747\n",
      "\ttrain_acc: 0.8324, test_acc: \u001b[31m0.8279547277981602\u001b[0m, time: 422.40\n",
      "epoch: 187, loss: 99.36862, loss1: 0.74994, loss2_3: 98.61868\n",
      "\ttrain_acc: 0.8300, test_acc: \u001b[31m0.8262566307573669\u001b[0m, time: 322.54\n",
      "epoch: 188, loss: 99.36388, loss1: 0.75079, loss2_3: 98.61309\n",
      "\ttrain_acc: 0.8302, test_acc: \u001b[31m0.8264435772205735\u001b[0m, time: 150.66\n",
      "epoch: 189, loss: 99.39211, loss1: 0.75155, loss2_3: 98.64056\n",
      "\ttrain_acc: 0.8319, test_acc: \u001b[31m0.8272848363050032\u001b[0m, time: 142.44\n",
      "epoch: 190, loss: 99.41172, loss1: 0.75123, loss2_3: 98.66049\n",
      "\ttrain_acc: 0.8303, test_acc: \u001b[31m0.8263345251170363\u001b[0m, time: 145.18\n",
      "epoch: 191, loss: 99.32761, loss1: 0.75049, loss2_3: 98.57712\n",
      "\ttrain_acc: 0.8319, test_acc: \u001b[31m0.8273315729208048\u001b[0m, time: 149.60\n",
      "epoch: 192, loss: 99.38605, loss1: 0.75001, loss2_3: 98.63604\n",
      "\ttrain_acc: 0.8323, test_acc: \u001b[31m0.8280949376455651\u001b[0m, time: 208.58\n",
      "epoch: 193, loss: 99.31516, loss1: 0.75098, loss2_3: 98.56419\n",
      "\ttrain_acc: 0.8326, test_acc: \u001b[31m0.8277288341551188\u001b[0m, time: 125.15\n",
      "epoch: 194, loss: 99.32997, loss1: 0.74962, loss2_3: 98.58035\n",
      "\ttrain_acc: 0.8318, test_acc: \u001b[31m0.8274951510761106\u001b[0m, time: 125.11\n",
      "epoch: 195, loss: 99.21611, loss1: 0.74905, loss2_3: 98.46706\n",
      "\ttrain_acc: 0.8319, test_acc: \u001b[31m0.8276820975393172\u001b[0m, time: 124.87\n",
      "epoch: 196, loss: 99.22778, loss1: 0.75054, loss2_3: 98.47723\n",
      "\ttrain_acc: 0.8322, test_acc: \u001b[31m0.8269732588663254\u001b[0m, time: 125.23\n",
      "epoch: 197, loss: 99.20506, loss1: 0.74921, loss2_3: 98.45585\n",
      "\ttrain_acc: 0.8326, test_acc: \u001b[31m0.827432835588375\u001b[0m, time: 125.45\n",
      "epoch: 198, loss: 99.26722, loss1: 0.75135, loss2_3: 98.51587\n",
      "\ttrain_acc: 0.8321, test_acc: \u001b[31m0.8272225208172677\u001b[0m, time: 125.92\n",
      "epoch: 199, loss: 99.14564, loss1: 0.75066, loss2_3: 98.39498\n",
      "\ttrain_acc: 0.8330, test_acc: \u001b[31m0.8271524158935651\u001b[0m, time: 123.39\n",
      "epoch: 200, loss: 99.25506, loss1: 0.74927, loss2_3: 98.50579\n",
      "\ttrain_acc: 0.8323, test_acc: \u001b[31m0.8274094672804743\u001b[0m, time: 122.79\n",
      "epoch: 201, loss: 99.33732, loss1: 0.75142, loss2_3: 98.58590\n",
      "\ttrain_acc: 0.8328, test_acc: \u001b[31m0.8281962003131353\u001b[0m, time: 122.73\n",
      "epoch: 202, loss: 99.24835, loss1: 0.74949, loss2_3: 98.49886\n",
      "\ttrain_acc: 0.8324, test_acc: \u001b[31m0.8276119926156147\u001b[0m, time: 125.24\n",
      "epoch: 203, loss: 99.28174, loss1: 0.74920, loss2_3: 98.53254\n",
      "\ttrain_acc: 0.8327, test_acc: \u001b[31m0.827845675694623\u001b[0m, time: 122.61\n",
      "epoch: 204, loss: 99.19604, loss1: 0.75127, loss2_3: 98.44477\n",
      "\ttrain_acc: 0.8326, test_acc: \u001b[31m0.8278378862586561\u001b[0m, time: 122.02\n",
      "epoch: 205, loss: 99.16267, loss1: 0.74983, loss2_3: 98.41284\n",
      "\ttrain_acc: 0.8319, test_acc: \u001b[31m0.8267863124031188\u001b[0m, time: 125.50\n",
      "epoch: 206, loss: 99.18080, loss1: 0.74864, loss2_3: 98.43216\n",
      "\ttrain_acc: 0.8326, test_acc: \u001b[31m0.82823514749297\u001b[0m, time: 125.80\n",
      "epoch: 207, loss: 99.20723, loss1: 0.74878, loss2_3: 98.45845\n",
      "\ttrain_acc: 0.8326, test_acc: \u001b[31m0.8276587292314164\u001b[0m, time: 122.02\n",
      "epoch: 208, loss: 99.26071, loss1: 0.74913, loss2_3: 98.51158\n",
      "\ttrain_acc: 0.8301, test_acc: \u001b[31m0.8249713738228215\u001b[0m, time: 123.07\n",
      "epoch: 209, loss: 99.11612, loss1: 0.74883, loss2_3: 98.36729\n",
      "\ttrain_acc: 0.8317, test_acc: \u001b[31m0.8266928391715156\u001b[0m, time: 127.53\n",
      "epoch: 210, loss: 99.20040, loss1: 0.74746, loss2_3: 98.45295\n",
      "\ttrain_acc: 0.8318, test_acc: \u001b[31m0.8264513666565404\u001b[0m, time: 124.54\n",
      "epoch: 211, loss: 99.20423, loss1: 0.74972, loss2_3: 98.45452\n",
      "\ttrain_acc: 0.8329, test_acc: \u001b[31m0.8279469383621932\u001b[0m, time: 122.56\n",
      "epoch: 212, loss: 99.14158, loss1: 0.74903, loss2_3: 98.39255\n",
      "\ttrain_acc: 0.8328, test_acc: \u001b[31m0.8265915765039453\u001b[0m, time: 122.57\n",
      "epoch: 213, loss: 99.21476, loss1: 0.75065, loss2_3: 98.46410\n",
      "\ttrain_acc: 0.8296, test_acc: \u001b[31m0.8251894780298958\u001b[0m, time: 124.20\n",
      "epoch: 214, loss: 99.13247, loss1: 0.75035, loss2_3: 98.38213\n",
      "\ttrain_acc: 0.8324, test_acc: \u001b[31m0.8271991525093668\u001b[0m, time: 264.80\n",
      "epoch: 215, loss: 99.21718, loss1: 0.74913, loss2_3: 98.46805\n",
      "\ttrain_acc: 0.8332, test_acc: \u001b[31m0.8279858855420279\u001b[0m, time: 319.53\n",
      "epoch: 216, loss: 99.12112, loss1: 0.74903, loss2_3: 98.37209\n",
      "\ttrain_acc: 0.8314, test_acc: \u001b[31m0.8265993659399123\u001b[0m, time: 681.26\n",
      "epoch: 217, loss: 99.12568, loss1: 0.74885, loss2_3: 98.37682\n",
      "\ttrain_acc: 0.8319, test_acc: \u001b[31m0.8267084180434495\u001b[0m, time: 766.06\n",
      "epoch: 218, loss: 99.08374, loss1: 0.75003, loss2_3: 98.33371\n",
      "\ttrain_acc: 0.8327, test_acc: \u001b[31m0.827705465847218\u001b[0m, time: 813.24\n",
      "epoch: 219, loss: 99.02371, loss1: 0.74893, loss2_3: 98.27478\n",
      "\ttrain_acc: 0.8327, test_acc: \u001b[31m0.8280871482095982\u001b[0m, time: 527.62\n",
      "epoch: 220, loss: 99.08258, loss1: 0.74833, loss2_3: 98.33425\n",
      "\ttrain_acc: 0.8329, test_acc: \u001b[31m0.8276587292314164\u001b[0m, time: 166.59\n",
      "epoch: 221, loss: 99.06812, loss1: 0.74816, loss2_3: 98.31997\n",
      "\ttrain_acc: 0.8333, test_acc: \u001b[31m0.8280326221578296\u001b[0m, time: 301.21\n",
      "epoch: 222, loss: 99.00664, loss1: 0.75023, loss2_3: 98.25642\n",
      "\ttrain_acc: 0.8328, test_acc: \u001b[31m0.827970306670094\u001b[0m, time: 122.10\n",
      "epoch: 223, loss: 99.07326, loss1: 0.74810, loss2_3: 98.32515\n",
      "\ttrain_acc: 0.8308, test_acc: \u001b[31m0.8261319997818958\u001b[0m, time: 121.98\n",
      "epoch: 224, loss: 99.02827, loss1: 0.74894, loss2_3: 98.27934\n",
      "\ttrain_acc: 0.8325, test_acc: \u001b[31m0.826638313119747\u001b[0m, time: 121.95\n",
      "epoch: 225, loss: 99.13107, loss1: 0.74884, loss2_3: 98.38224\n",
      "\ttrain_acc: 0.8326, test_acc: \u001b[31m0.8279391489262262\u001b[0m, time: 121.78\n",
      "epoch: 226, loss: 99.03885, loss1: 0.74848, loss2_3: 98.29038\n",
      "\ttrain_acc: 0.8329, test_acc: \u001b[31m0.828242936928937\u001b[0m, time: 121.81\n",
      "epoch: 227, loss: 99.01895, loss1: 0.74879, loss2_3: 98.27016\n",
      "\ttrain_acc: 0.8324, test_acc: \u001b[31m0.8276743081033502\u001b[0m, time: 121.78\n",
      "epoch: 228, loss: 99.05782, loss1: 0.74883, loss2_3: 98.30898\n",
      "\ttrain_acc: 0.8330, test_acc: \u001b[31m0.8279157806183254\u001b[0m, time: 121.78\n",
      "epoch: 229, loss: 99.02952, loss1: 0.74858, loss2_3: 98.28094\n",
      "\ttrain_acc: 0.8333, test_acc: \u001b[31m0.8277599918989866\u001b[0m, time: 121.83\n",
      "epoch: 230, loss: 99.05116, loss1: 0.74792, loss2_3: 98.30323\n",
      "\ttrain_acc: 0.8318, test_acc: \u001b[31m0.8267239969153833\u001b[0m, time: 121.73\n",
      "epoch: 231, loss: 99.07447, loss1: 0.74920, loss2_3: 98.32527\n",
      "\ttrain_acc: 0.8328, test_acc: \u001b[31m0.8281650425692676\u001b[0m, time: 121.75\n",
      "epoch: 232, loss: 98.98274, loss1: 0.74821, loss2_3: 98.23453\n",
      "\ttrain_acc: 0.8329, test_acc: \u001b[31m0.8275029405120775\u001b[0m, time: 121.65\n",
      "epoch: 233, loss: 99.01787, loss1: 0.74920, loss2_3: 98.26867\n",
      "\ttrain_acc: 0.8327, test_acc: \u001b[31m0.8276587292314164\u001b[0m, time: 121.62\n",
      "epoch: 234, loss: 98.99775, loss1: 0.74984, loss2_3: 98.24791\n",
      "\ttrain_acc: 0.8332, test_acc: \u001b[31m0.8280092538499287\u001b[0m, time: 121.63\n",
      "epoch: 235, loss: 99.02748, loss1: 0.74961, loss2_3: 98.27787\n",
      "\ttrain_acc: 0.8335, test_acc: \u001b[31m0.8280404115937965\u001b[0m, time: 124.31\n",
      "epoch: 236, loss: 98.95234, loss1: 0.74815, loss2_3: 98.20419\n",
      "\ttrain_acc: 0.8329, test_acc: \u001b[31m0.8274873616401437\u001b[0m, time: 124.50\n",
      "epoch: 237, loss: 99.08258, loss1: 0.74980, loss2_3: 98.33278\n",
      "\ttrain_acc: 0.8336, test_acc: \u001b[31m0.8275496771278792\u001b[0m, time: 124.97\n",
      "epoch: 238, loss: 99.00918, loss1: 0.74728, loss2_3: 98.26190\n",
      "\ttrain_acc: 0.8319, test_acc: \u001b[31m0.8274484144603089\u001b[0m, time: 125.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 239, loss: 99.00005, loss1: 0.74809, loss2_3: 98.25197\n",
      "\ttrain_acc: 0.8322, test_acc: \u001b[31m0.8274717827682098\u001b[0m, time: 124.91\n",
      "epoch: 240, loss: 99.05230, loss1: 0.75013, loss2_3: 98.30218\n",
      "\ttrain_acc: 0.8332, test_acc: \u001b[31m0.8278768334384907\u001b[0m, time: 125.18\n",
      "epoch: 241, loss: 99.09377, loss1: 0.74964, loss2_3: 98.34413\n",
      "\ttrain_acc: 0.8330, test_acc: \u001b[31m0.8281183059534659\u001b[0m, time: 124.52\n",
      "epoch: 242, loss: 98.99564, loss1: 0.75043, loss2_3: 98.24520\n",
      "\ttrain_acc: 0.8331, test_acc: \u001b[31m0.828367567904408\u001b[0m, time: 124.67\n",
      "epoch: 243, loss: 98.89686, loss1: 0.74841, loss2_3: 98.14845\n",
      "\ttrain_acc: 0.8337, test_acc: \u001b[31m0.8284610411360114\u001b[0m, time: 124.43\n",
      "best_acc: 0.8284610411360114\n",
      "epoch: 244, loss: 98.89383, loss1: 0.74801, loss2_3: 98.14582\n",
      "\ttrain_acc: 0.8331, test_acc: \u001b[31m0.8275263088199784\u001b[0m, time: 124.13\n",
      "epoch: 245, loss: 99.01166, loss1: 0.74833, loss2_3: 98.26333\n",
      "\ttrain_acc: 0.8319, test_acc: \u001b[31m0.8275185193840114\u001b[0m, time: 122.06\n",
      "epoch: 246, loss: 98.96129, loss1: 0.74777, loss2_3: 98.21353\n",
      "\ttrain_acc: 0.8333, test_acc: \u001b[31m0.8283519890324742\u001b[0m, time: 121.78\n",
      "epoch: 247, loss: 98.91755, loss1: 0.74716, loss2_3: 98.17039\n",
      "\ttrain_acc: 0.8332, test_acc: \u001b[31m0.8281416742613668\u001b[0m, time: 123.26\n",
      "epoch: 248, loss: 98.92235, loss1: 0.74774, loss2_3: 98.17461\n",
      "\ttrain_acc: 0.8334, test_acc: \u001b[31m0.8274016778445072\u001b[0m, time: 124.00\n",
      "epoch: 249, loss: 98.91843, loss1: 0.74787, loss2_3: 98.17056\n",
      "\ttrain_acc: 0.8326, test_acc: \u001b[31m0.82691094337859\u001b[0m, time: 121.76\n",
      "epoch: 250, loss: 98.92252, loss1: 0.74808, loss2_3: 98.17444\n",
      "\ttrain_acc: 0.8328, test_acc: \u001b[31m0.8278223073867221\u001b[0m, time: 122.32\n"
     ]
    }
   ],
   "source": [
    "for num_model in range(1):  # just one train\n",
    "    net=newModel().to(device)\n",
    "    lr = 0.0001\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr,weight_decay=5e-4)\n",
    "    criterion = ContrastiveLoss()\n",
    "    criterion_model = nn.CrossEntropyLoss(reduction='sum')\n",
    "    \n",
    "    best_acc=0\n",
    "    EPOCH=250\n",
    "    for epoch in range(EPOCH):\n",
    "        loss_ls=[]\n",
    "        loss1_ls=[]\n",
    "        loss2_3_ls=[]\n",
    "        t0=time.time()\n",
    "        net.train()\n",
    "        for seq1,seq2,label,label1,label2 in train_iter_cont:\n",
    "                output1=net(seq1)\n",
    "                output2=net(seq2)\n",
    "                output3=net.trainModel(seq1)\n",
    "                output4=net.trainModel(seq2)\n",
    "                \n",
    "                loss1=criterion(output1, output2, label)\n",
    "                loss2=criterion_model(output3,label1)\n",
    "                loss3=criterion_model(output4,label2)\n",
    "                loss=loss1+loss2+loss3\n",
    "    #             print(loss)\n",
    "                optimizer.zero_grad() \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_ls.append(loss.item())\n",
    "                loss1_ls.append(loss1.item())\n",
    "                loss2_3_ls.append((loss2+loss3).item())\n",
    "\n",
    "\n",
    "        net.eval() \n",
    "        with torch.no_grad(): \n",
    "            train_acc=evaluate_accuracy(train_iter,net)\n",
    "            test_acc=evaluate_accuracy(val_iter,net)\n",
    "            \n",
    "        results=f\"epoch: {epoch+1}, loss: {np.mean(loss_ls):.5f}, loss1: {np.mean(loss1_ls):.5f}, loss2_3: {np.mean(loss2_3_ls):.5f}\\n\"\n",
    "        results+=f'\\ttrain_acc: {train_acc:.4f}, test_acc: {colored(test_acc,\"red\")}, time: {time.time()-t0:.2f}'\n",
    "        print(results)\n",
    "        if test_acc>best_acc:\n",
    "            best_acc=test_acc\n",
    "#             torch.save({\"best_acc\":best_acc,\"model\":net.state_dict()},f'compareModel/2021ACS_PepFormer/Model/{num_model}.pl')\n",
    "            print(f\"best_acc: {best_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T16:03:41.030221Z",
     "start_time": "2021-10-20T16:03:40.996244Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T16:03:41.034983Z",
     "start_time": "2021-10-20T16:03:41.031687Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs.argmax(dim=1):\n",
    "            y_pred.append(int(_))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T16:03:41.040418Z",
     "start_time": "2021-10-20T16:03:41.036136Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred_prob(data_iter, net):\n",
    "    y_pred = []\n",
    "    for x, y in data_iter:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        outputs=net.trainModel(x)\n",
    "        for _ in outputs:\n",
    "            y_pred.append(list(map(float, _)))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T16:03:52.217931Z",
     "start_time": "2021-10-20T16:03:41.041481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8302451936472555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82     64602\n",
      "           1       0.80      0.89      0.84     64602\n",
      "\n",
      "    accuracy                           0.83    129204\n",
      "   macro avg       0.83      0.83      0.83    129204\n",
      "weighted avg       0.83      0.83      0.83    129204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate_accuracy(test_iter,net)\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "# prediction\n",
    "y_pred = pred(test_iter, net)\n",
    "print(classification_report(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T16:04:01.723094Z",
     "start_time": "2021-10-20T16:03:52.219115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf auc : 0.9126659943439498\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AUC\n",
    "probs = np.array(pred_prob(test_iter, net))[:, 1]\n",
    "rf_auc = roc_auc_score(test_label, probs)\n",
    "print('rf auc : {}'.format(rf_auc))\n",
    "# plot the roc curve for the model81\n",
    "rf_fpr, rf_tpr, _ = roc_curve(test_label, probs)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='RF AUC = {:.4f}'.format(rf_auc), color='orange')\n",
    "plt.title('ROC curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "cf_matrix = confusion_matrix(test_label, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=',.0f')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
