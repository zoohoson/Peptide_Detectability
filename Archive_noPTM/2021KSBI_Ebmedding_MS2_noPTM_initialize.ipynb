{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-17T12:34:35.648621Z",
     "start_time": "2021-10-17T12:34:34.875443Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-17T12:34:35.664495Z",
     "start_time": "2021-10-17T12:34:35.651226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 21)\n"
     ]
    }
   ],
   "source": [
    "df_aaindex = pd.read_csv('../data/aaindex/df_aaindex19.csv')\n",
    "print(df_aaindex.shape)\n",
    "df_aaindex.head(1)\n",
    "tmp = df_aaindex.drop('Unnamed: 0',axis=1).T\n",
    "aa2val = dict()\n",
    "for aa, val in zip(tmp.index, tmp.values):\n",
    "    aa2val[aa]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-17T12:34:41.118383Z",
     "start_time": "2021-10-17T12:34:39.679896Z"
    }
   },
   "outputs": [],
   "source": [
    "df_detect_peptide_train = pd.read_csv('../data/df_detect_peptide_train_noptm_210930_includeDigest.csv')\n",
    "test = pd.read_csv('../data/df_detect_peptide_test_noptm_210930_includeDigest.csv')\n",
    "train, val = train_test_split(df_detect_peptide_train, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-17T12:34:41.133830Z",
     "start_time": "2021-10-17T12:34:41.120072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide</th>\n",
       "      <th>En</th>\n",
       "      <th>Ec</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>protein</th>\n",
       "      <th>PEP</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63979</th>\n",
       "      <td>K.QVTTAENLKDQTVYIVLDKAEYLR.D</td>\n",
       "      <td>NDFVRLFKQVTTAEN</td>\n",
       "      <td>LDKAEYLRDMEANLL</td>\n",
       "      <td>VTTAENLKDQTVYIV</td>\n",
       "      <td>TVYIVLDKAEYLRDM</td>\n",
       "      <td>sp|O43913|ORC5_HUMAN</td>\n",
       "      <td>QVTTAENLKDQTVYIVLDKAEYLR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            peptide               En               Ec  \\\n",
       "63979  K.QVTTAENLKDQTVYIVLDKAEYLR.D  NDFVRLFKQVTTAEN  LDKAEYLRDMEANLL   \n",
       "\n",
       "                    E1               E2               protein  \\\n",
       "63979  VTTAENLKDQTVYIV  TVYIVLDKAEYLRDM  sp|O43913|ORC5_HUMAN   \n",
       "\n",
       "                            PEP  ID  \n",
       "63979  QVTTAENLKDQTVYIVLDKAEYLR   1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-17T12:34:41.142349Z",
     "start_time": "2021-10-17T12:34:41.135295Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_labelEnc(df):\n",
    "    label_enc = {v:k+1 for k, v in enumerate('ARNDCQEGHILKMFPSTWYV')}\n",
    "    label_enc['Z']=0\n",
    "    aa_data = [np.array([seq.count(a) for a in 'ARNDCQEGHILKMFPSTWYV'] + list(np.array([aa2val[aa] for aa in seq]).sum(axis=0)))\n",
    "               for seq in df.PEP.values]\n",
    "    pep_data = [[label_enc[aa] for aa in seq] + [0]*(30-len(seq))\n",
    "               for seq in df.PEP.values]\n",
    "    en_data = [[label_enc[aa] for aa in seq]\n",
    "               for seq in df.En.values]\n",
    "    ec_data = [[label_enc[aa] for aa in seq]\n",
    "               for seq in df.Ec.values]\n",
    "    e1_data = [[label_enc[aa] for aa in seq]\n",
    "               if seq != '-' else [0 for _ in range(15)]\n",
    "               for seq in df.E1.values]\n",
    "    e2_data = [[label_enc[aa] for aa in seq]\n",
    "               if seq != '-' else [0 for _ in range(15)]\n",
    "               for seq in df.E2.values]\n",
    "    return np.array(aa_data), np.array(pep_data), np.array(en_data), np.array(ec_data), np.array(e1_data), np.array(e2_data), np.array(df.ID.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-17T12:35:04.030590Z",
     "start_time": "2021-10-17T12:34:41.143547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337179, 39) (337179, 30) (337179, 15) (337179, 15) (337179, 15) (337179, 15) (337179,)\n",
      "(84295, 39) (84295, 30) (84295, 15) (84295, 15) (84295, 15) (84295, 15) (84295,)\n",
      "(88998, 39) (88998, 30) (88998, 15) (88998, 15) (88998, 15) (88998, 15) (88998,)\n"
     ]
    }
   ],
   "source": [
    "aa_train, pep_train, en_train, ec_train, e1_train, e2_train, y_train = get_data_labelEnc(train)\n",
    "aa_val, pep_val, en_val, ec_val, e1_val, e2_val, y_val = get_data_labelEnc(val)\n",
    "aa_test, pep_test, en_test, ec_test, e1_test, e2_test, y_test = get_data_labelEnc(test)\n",
    "print(aa_train.shape, pep_train.shape, en_train.shape, ec_train.shape, e1_train.shape, e2_train.shape, y_train.shape)\n",
    "print(aa_val.shape, pep_val.shape, en_val.shape, ec_val.shape, e1_val.shape, e2_val.shape, y_val.shape)\n",
    "print(aa_test.shape, pep_test.shape, en_test.shape, ec_test.shape, e1_test.shape, e2_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-17T12:37:10.666382Z",
     "start_time": "2021-10-17T12:35:04.032273Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ms2 = pd.read_csv('noPTM_MS2_prediction211008_result.msms', sep='\\t')\n",
    "cols = ['Intensities', 'Masses', 'Modified Sequence', 'Charge']\n",
    "pep2cmzint = {p:[c, m, i] for i, m, p, c in df_ms2[cols].values}\n",
    "\n",
    "get_idx = lambda x: int(round(float(x), 2)*100)\n",
    "\n",
    "def get_spectrum(pep2cmzint):\n",
    "    pep2tensor = dict()\n",
    "    for pep, (c, m, i) in pep2cmzint.items():\n",
    "        tensor = np.zeros((5, 100000))\n",
    "        i = np.array(list(map(float, i.split(';'))))\n",
    "        m2idx = np.array(list(map(get_idx, m.split(';'))))\n",
    "        idx2inten = {k:v for k, v in zip(m2idx, i) if k <= 100000-1}  # Dalton 제한\n",
    "        \n",
    "        row_idx = c-1\n",
    "        col_idx = np.array(list(idx2inten.keys()))\n",
    "        val = np.array(list(idx2inten.values()))\n",
    "        tensor[row_idx, col_idx] = val\n",
    "        \n",
    "        pep2tensor[pep]=tensor\n",
    "    return pep2tensor\n",
    "\n",
    "pep2tensor = get_spectrum(pep2cmzint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T22:42:08.983905Z",
     "start_time": "2021-10-07T22:42:08.632177Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TIIERSSAR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f410b7841830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mms2_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpep2tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPEP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-f410b7841830>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mms2_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpep2tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPEP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'TIIERSSAR'"
     ]
    }
   ],
   "source": [
    "ms2_train = np.array([pep2tensor[p] for p in train.PEP.unique()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-17T12:37:11.811078Z",
     "start_time": "2021-10-17T12:37:10.667966Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*8)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-17T12:37:11.815885Z",
     "start_time": "2021-10-17T12:37:11.813166Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# high param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-17T12:37:12.825219Z",
     "start_time": "2021-10-17T12:37:11.817081Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0874c912b23b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmp2_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# spectrum_mp2 = tf.reshape(mp2_, [1996])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectrum_2dcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp2_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspectrum_mp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mnet_spectrum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp2_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sp' is not defined"
     ]
    }
   ],
   "source": [
    "pep = tf.keras.layers.Input(shape=((30,)))\n",
    "input1_ = tf.keras.layers.Embedding(21, 32, input_length=30, mask_zero=True)(pep)\n",
    "input1 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(input1_)\n",
    "\n",
    "input2 = tf.keras.layers.Input(shape=((39,)))  # peptide info\n",
    "\n",
    "n = tf.keras.layers.Input(shape=((15,)))\n",
    "input3_ = tf.keras.layers.Embedding(21, 16, input_length=15, mask_zero=True)(n)\n",
    "input3 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(input3_)\n",
    "\n",
    "c = tf.keras.layers.Input(shape=((15,)))\n",
    "input4_ = tf.keras.layers.Embedding(21, 16, input_length=15, mask_zero=True)(c)\n",
    "input4 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(input4_)\n",
    "\n",
    "m1 = tf.keras.layers.Input(shape=((15,)))\n",
    "input5_ = tf.keras.layers.Embedding(21, 16, input_length=15, mask_zero=True)(m1)\n",
    "input5 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(input5_)\n",
    "\n",
    "m2 = tf.keras.layers.Input(shape=((15,)))\n",
    "input6_ = tf.keras.layers.Embedding(21, 16, input_length=15, mask_zero=True)(m2)\n",
    "input6 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(input6_)\n",
    "\n",
    "\n",
    "# charge_prediction\n",
    "# MS2_prediction\n",
    "# get_MS2_tensor to use peptide LSTM init\n",
    "spectrum = tf.keras.layers.Input(shape=((5, 100000, 1)))\n",
    "spectrum_mp1 = tf.keras.layers.MaxPooling2D(pool_size=(1, 50))(spectrum)  # (, 5, 2000, 1)\n",
    "spectrum_2dcnn = tf.keras.layers.Conv2D(kernel_size=(5,4), filters=4, strides=(5,1), padding='same')(spectrum_mp1)  # (, 1, 2000, 4)\n",
    "mp2 = tf.keras.layers.MaxPooling2D(pool_size=(1, 6), strides=(1, 4))(spectrum_2dcnn)  # (, 1, 500, 4)\n",
    "mp2_ = tf.reshape(mp2, [1,-1])\n",
    "# spectrum_mp2 = tf.reshape(mp2_, [1996])\n",
    "print(spectrum_2dcnn.shape, sp.shape, mp2_.shape, spectrum_mp2.shape)\n",
    "net_spectrum = tf.keras.layers.Dense(512, activation='relu')(mp2_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T04:30:12.916648Z",
     "start_time": "2021-10-08T04:30:12.524898Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 2000, 4) (None, 1, 499, 4) (1, None) (1996,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The last dimension of the inputs to `Dense` should be defined. Found `None`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-16748692fb3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# spectrum_mp2 = tf.reshape(mp2_, [1996])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectrum_2dcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp2_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspectrum_mp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mnet_spectrum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp2_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TF2.4/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TF2.4/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TF2.4/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TF2.4/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TF2.4/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2712\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TF2.4/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0mlast_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlast_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m       raise ValueError('The last dimension of the inputs to `Dense` '\n\u001b[0m\u001b[1;32m   1183\u001b[0m                        'should be defined. Found `None`.')\n\u001b[1;32m   1184\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The last dimension of the inputs to `Dense` should be defined. Found `None`."
     ]
    }
   ],
   "source": [
    "cnn1 = tf.keras.layers.Conv1D(filters=16, kernel_size=3, strides=1, padding='same')(input1)\n",
    "lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16))(cnn1)\n",
    "net_lstm_ = tf.keras.layers.Dense(16, activation='relu')(lstm1)\n",
    "net_lstm = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_lstm_)\n",
    "\n",
    "net_dense1_ = tf.keras.layers.Dense(32, activation='relu')(input2)\n",
    "net_dense1 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_dense1_)\n",
    "\n",
    "cnn3 = tf.keras.layers.Conv1D(filters=8, kernel_size=3, strides=1, padding='same')(input3)\n",
    "digest_n = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8))(cnn3)\n",
    "net_n_ = tf.keras.layers.Dense(8, activation='relu')(digest_n)\n",
    "net_n = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_n_)\n",
    "\n",
    "cnn4 = tf.keras.layers.Conv1D(filters=8, kernel_size=3, strides=1, padding='same')(input4)\n",
    "digest_c = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8))(cnn4)\n",
    "net_c_ = tf.keras.layers.Dense(8, activation='relu')(digest_c)\n",
    "net_c = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_c_)\n",
    "\n",
    "cnn5 = tf.keras.layers.Conv1D(filters=8, kernel_size=3, strides=1, padding='same')(input5)\n",
    "digest_m1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8))(cnn5)\n",
    "net_m1_ = tf.keras.layers.Dense(8, activation='relu')(digest_m1)\n",
    "net_m1 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_m1_)\n",
    "\n",
    "cnn6 = tf.keras.layers.Conv1D(filters=8, kernel_size=3, strides=1, padding='same')(input6)\n",
    "digest_m2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8))(cnn6)\n",
    "net_m2_ = tf.keras.layers.Dense(8, activation='relu')(digest_m2)\n",
    "net_m2 = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net_m2_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "merge = tf.keras.layers.concatenate([net_lstm, \n",
    "                                     net_dense1,\n",
    "                                     net_n,\n",
    "                                     net_c,\n",
    "                                     net_m1,\n",
    "                                     net_m2,\n",
    "                                    net_spectrum])\n",
    "\n",
    "net1 = tf.keras.layers.Dense(64, activation='relu')(merge)\n",
    "net1_drop = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net1)\n",
    "net3 = tf.keras.layers.Dense(32, activation='relu')(net1_drop)\n",
    "net3_drop = tf.keras.layers.Dropout(np.random.uniform(0, 0.2))(net3)\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation = 'sigmoid')(net3_drop)\n",
    "\n",
    "model_high = tf.keras.Model(inputs=[pep, input2,\n",
    "                                    n, c,\n",
    "                                    m1, m2,\n",
    "                                    spectrum],\n",
    "                            outputs=[output])\n",
    "\n",
    "model_high.summary()\n",
    "\n",
    "model_high.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                      mode='min', \n",
    "                                      verbose=1,\n",
    "                                      patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-30T17:56:19.442Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2635/2635 [==============================] - 138s 45ms/step - loss: 5.3948 - accuracy: 0.5155 - val_loss: 0.5869 - val_accuracy: 0.7172\n",
      "Epoch 2/300\n",
      " 879/2635 [=========>....................] - ETA: 1:07 - loss: 0.7107 - accuracy: 0.6330"
     ]
    }
   ],
   "source": [
    "history = model_high.fit([pep_train, aa_train, en_train, ec_train, e1_train, e2_train],\n",
    "                    y_train, \n",
    "                    epochs=300,\n",
    "                    batch_size=128,\n",
    "                    validation_data=([pep_val, aa_val, en_val, ec_val, e1_val, e2_val], y_val),\n",
    "                    callbacks=[es]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-30T17:56:20.823Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,2))\n",
    "plt.subplot(1,2,1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.subplot(1,2,2)\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-30T17:56:30.552Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_high.evaluate([pep_test, aa_test, en_test, ec_test, e1_test, e2_test], y_test)\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "# prediction\n",
    "y_pred = [1 if i>=0.5 else 0 for i in model_high.predict([pep_test, aa_test, en_test, ec_test, e1_test, e2_test])]\n",
    "print(classification_report(y_test, y_pred))\n",
    "# AUC\n",
    "probs = model_high.predict([pep_test, aa_test, en_test, ec_test, e1_test, e2_test])\n",
    "rf_auc = roc_auc_score(y_test, probs)\n",
    "print('rf auc : {}'.format(rf_auc))\n",
    "# plot the roc curve for the model_high\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, probs)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='RF AUC = {:.4f}'.format(rf_auc), color='orange')\n",
    "plt.title('ROC curve')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=',.0f')\n",
    "plt.show()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2.4",
   "language": "python",
   "name": "tf2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
